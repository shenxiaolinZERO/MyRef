% Encoding: UTF-8

@TechReport{ShinBayesian,
  author   = {Shin, Minchularroluto},
  title    = {Bayesian GMM},
  abstract = {In this paper, I study a semiparametric Bayesian method for over-identified
	moment
	
	condition models. A mixture of parametric distributions with random
	weights
	
	is used to flexibly model an unknown data generating process. The
	random mixture
	
	weights are defined by the exponential tilting projection method to
	ensure that the joint
	
	distribution of the data distribution and the structural parameters
	are internally consistent
	
	with the moment restrictions. In this framework, I make several contributions
	
	to Bayesian estimation and inference, as well as model specification.
	First, I develop
	
	simulation-based posterior sampling algorithms based on Markov chain
	Monte Carlo
	
	(MCMC) and sequential Monte Carlo (SMC) methods. Second, I provide
	a method
	
	to compute the marginal likelihood and use it for Bayesian model selection
	(moment
	
	selection) and model averaging. Lastly, I extend the scope of Bayesian
	analysis for
	
	moment condition models. These generalizations include dynamic moment
	condition
	
	models with time-dependent data and moment condition models with exogenous
	dynamic
	
	latent variables.x},
  crossref = {R},
  file     = {ShinBayesian.pdf:ShinBayesian.pdf:PDF},
}

@InProceedings{Jamali2009TrustWalker,
  author    = {Jamali, Mohsen and Ester, Martin},
  title     = {TrustWalker: A Random Walk Model for Combining Trust-based and Item-based Recommendation},
  booktitle = {Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year      = {2009},
  series    = {KDD '09},
  pages     = {397--406},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Collaborative filtering is the most popular approach to build recommender
	systems and has been successfully employed in many applications.
	However, it cannot make recommendations for so-called cold start
	users that have rated only a very small number of items. In addition,
	these methods do not know how confident they are in their recommendations.
	Trust-based recommendation methods assume the additional knowledge
	of a trust network among users and can better deal with cold start
	users, since users only need to be simply connected to the trust
	network. On the other hand, the sparsity of the user item ratings
	forces the trust-based approach to consider ratings of indirect neighbors
	that are only weakly trusted, which may decrease its precision. In
	order to find a good trade-off, we propose a random walk model combining
	the trust-based and the collaborative filtering approach for recommendation.
	The random walk model allows us to define and to measure the confidence
	of a recommendation. We performed an evaluation on the Epinions dataset
	and compared our model with existing trust-based and collaborative
	filtering methods.},
  acmid     = {1557067},
  comment   = {model: TrustWalker
	
	
	random walk on trust network, then random walk on items},
  crossref  = {Imafuji2002Effects},
  file      = {Jamali2009TrustWalker.pdf:Jamali2009TrustWalker.pdf:PDF},
  isbn      = {978-1-60558-495-9},
  keywords  = {random walk, recommendation, trust},
  location  = {Paris, France},
  numpages  = {10},
}

@InProceedings{vStajner2013Automatic,
  author    = {\v{S}tajner, Tadej and Thomee, Bart and Popescu, Ana-Maria and Pennacchiotti, Marco and Jaimes, Alejandro},
  title     = {Automatic Selection of Social Media Responses to News},
  booktitle = {Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year      = {2013},
  series    = {KDD '13},
  pages     = {50--58},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Social media responses to news have increasingly gained in importance
	as they can enhance a consumer's news reading experience, promote
	information sharing and aid journalists in assessing their readership's
	response to a story. Given that the number of responses to an online
	news article may be huge, a common challenge is that of selecting
	only the most interesting responses for display. This paper addresses
	this challenge by casting message selection as an optimization problem.
	We define an objective function which jointly models the messages'
	utility scores and their entropy. We propose a near-optimal solution
	to the underlying optimization problem, which leverages the submodularity
	property of the objective function. Our solution first learns the
	utility of individual messages in isolation and then produces a diverse
	selection of interesting messages by maximizing the defined objective
	function. The intuitions behind our work are that an interesting
	selection of messages contains diverse, informative, opinionated
	and popular messages referring to the news article, written mostly
	by users that have authority on the topic. Our intuitions are embodied
	by a rich set of content, social and user features capturing the
	aforementioned aspects. We evaluate our approach through both human
	and automatic experiments, and demonstrate it outperforms the state
	of the art. Additionally, we perform an in-depth analysis of the
	annotated ``interesting'' responses, shedding light on the subjectivity
	around the selection process and the perception of interestingness.},
  acmid     = {2487659},
  groups    = {Twitter},
  isbn      = {978-1-4503-2174-7},
  keywords  = {microblogging, sampling, social media, summarization},
  location  = {Chicago, Illinois, USA},
  numpages  = {9},
}

@Article{Aalst2005Discovering,
  author    = {Wil M. P. van der Aalst and Hajo A. Reijers and Minseok Song},
  title     = {Discovering Social Networks from Event Logs},
  journal   = {Computer Supported Cooperative Work (CSCW)},
  year      = {2005},
  volume    = {14},
  number    = {6},
  pages     = {549-593},
  month     = {October},
  abstract  = {Process mining techniques allow for the discovery of knowledge based
	on so-called Event logs i.e., a log recording the execution of activities
	in some business process. Many information systems provide such logs,
	e.g., most WFM, ERP, CRM, SCM, and B2B systems record transactions
	in a systematic way. Process mining techniques typically focus on
	performance and control-flow issues. However, event logs typically
	also log the performer, e.g., the person initiating or completing
	some activity. This paper focuses on mining social networks using
	this information. For example, it is possible to build a social network
	based on the hand-over of work from one performer to the next. By
	combining concepts from workflow management and social network analysis,
	it is possible to discover and analyze social networks. This paper
	defines metrics, presents a tool, and applies these to a real event
	log within the setting of a large Dutch organization.},
  keywords  = {business process management - data mining - Petri nets - process mining - social network analysis - workflow management},
  owner     = {Cheyenne},
  timestamp = {2009.09.30},
}

@InProceedings{Abel2011Analyzing,
  author    = {Abel, Fabian and Gao, Qi and Houben, Geert-Jan and Tao, Ke},
  title     = {Analyzing user modeling on twitter for personalized news recommendations},
  booktitle = {Proceedings of the 19th international conference on User modeling, adaption, and personalization},
  year      = {2011},
  series    = {UMAP'11},
  pages     = {1--12},
  address   = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  abstract  = {How can micro-blogging activities on Twitter be leveraged for user
	modeling and personalization? In this paper we investigate this question
	and introduce a framework for user modeling on Twitter which enriches
	the semantics of Twitter messages (tweets) and identifies topics
	and entities (e.g. persons, events, products) mentioned in tweets.
	We analyze how strategies for constructing hashtag-based, entity-based
	or topic-based user profiles benefit from semantic enrichment and
	explore the temporal dynamics of those profiles. We further measure
	and compare the performance of the user modeling strategies in context
	of a personalized news recommendation system. Our results reveal
	how semantic enrichment enhances the variety and quality of the generated
	user profiles. Further, we see how the different user modeling strategies
	impact personalization and discover that the consideration of temporal
	profile patterns can improve recommendation quality.},
  acmid     = {2021857},
  groups    = {Recommender Systems, Twitter},
  isbn      = {978-3-642-22361-7},
  keywords  = {personalization, semantics, twitter, user modeling},
  location  = {Girona, Spain},
  numpages  = {12},
  url       = {http://dl.acm.org/citation.cfm?id=2021855.2021857},
}

@InProceedings{Abel2012Semantics,
  author    = {Abel, Fabian and Hauff, Claudia and Houben, Geert-Jan and Stronkman, Richard and Tao, Ke},
  title     = {Semantics + Filtering + Search = Twitcident. Exploring Information in Social Web Streams},
  booktitle = {Proceedings of the 23rd ACM Conference on Hypertext and Social Media},
  year      = {2012},
  series    = {HT '12},
  pages     = {285--294},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2310043},
  comment   = {Automatically filtering relevant information about a real-world incident
	from Social Web streams and making the information accessible and
	findable in the given context of the incident are non-trivial scientific
	challenges. In this paper, we engineer and evaluate solutions that
	analyze the semantics of Social Web data streams to solve these challenges.
	We introduce Twitcident, a framework and Web-based system for filtering,
	searching and analyzing information about real-world incidents or
	crises. Given an incident, our framework automatically starts tracking
	and filtering information that is relevant for the incident from
	Social Web streams and Twitter particularly. It enriches the semantics
	of streamed messages to profile incidents and to continuously improve
	and adapt the information filtering to the current temporal context.
	Faceted search and analytical tools allow people and emergency services
	to retrieve particular information fragments and overview and analyze
	the current situation as reported on the Social Web.
	
	
	We put our Twitcident system into practice by connecting it to emergency
	broadcasting services in the Netherlands to allow for the retrieval
	of relevant information from Twitter streams for any incident that
	is reported by those services. We conduct large-scale experiments
	in which we evaluate (i) strategies for filtering relevant information
	for a given incident and (ii) search strategies for finding particular
	information pieces. Our results prove that the semantic enrichment
	offered by our framework leads to major and significant improvements
	of both the filtering and the search performance. A demonstration
	is available via: http://wis.ewi.tudelft.nl/twitcident/},
  groups    = {Twitter},
  isbn      = {978-1-4503-1335-3},
  keywords  = {filtering, search, semantic enrichment, social web streams, twitcident, twitter},
  location  = {Milwaukee, Wisconsin, USA},
  numpages  = {10},
}

@InProceedings{Adamic2008Knowledge,
  author    = {Adamic, Lada A. and Zhang, Jun and Bakshy, Eytan and Ackerman, Mark S.},
  title     = {Knowledge sharing and yahoo answers: everyone knows something},
  booktitle = {WWW '08: Proceeding of the 17th international conference on World Wide Web},
  year      = {2008},
  pages     = {665--674},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Yahoo Answers (YA) is a large and diverse question-answer
	
	forum, acting not only as a medium for sharing technical
	
	knowledge, but as a place where one can seek advice, gather
	
	opinions, and satisfy one's curiosity about a countless num-
	
	ber of things. In this paper, we seek to understand YA's
	
	knowledge sharing activity. We analyze the forum categories
	
	and cluster them according to content characteristics and
	
	patterns of interaction among the users. While interactions
	
	in some categories resemble expertise sharing forums, others
	
	incorporate discussion, everyday advice, and support. With
	
	such a diversity of categories in which one can participate,
	
	we nd that some users focus narrowly on specic topics,
	
	while others participate across categories. This not only al-
	
	lows us to map related categories, but to characterize the
	
	entropy of the users' interests. We nd that lower entropy
	
	correlates with receiving higher answer ratings, but only for
	
	categories where factual expertise is primarily sought after.
	
	We combine both user attributes and answer characteristics
	
	to predict, within a given category, whether a particular an-
	
	swer will be chosen as the best answer by the asker},
  comment   = {Data: Yahoo Answers
	
	Part I:
	
	Statistical Study
	
	1) discussions can be cluster into three different types accordng
	to its avg thread length, post length and asker-replier overlap.
	e.g. technical QA shorter, asker do seldom reply, and marrige discussions
	longer, more like discuss.
	
	2)network analysis: tech cluster authors have smaller in and out degree
	
	3)user entrophy in topics, user focus is not very positive correlated
	to its expertise
	
	PartII:
	
	Predict chosen answer use feature, logistic regression
	
	Programming Marriage Wrestling
	
	reply length +   +   +  
	
	thread length      
	
	user # best ans. +   +   +  
	
	user # replies      
	
	prediction 0.729 0.693 0.692
	
	accuracy
	
	+ (positive coecient), - (negative coecient)
	
	*(p<0.05),** (p < 0.01), *** (p < 0.001)},
  file      = {Adamic2008Knowledge.pdf:Adamic2008Knowledge.pdf:PDF},
  isbn      = {978-1-60558-085-2},
  location  = {Beijing, China},
}

@Article{adamic2000power,
  author    = {Adamic, L.A. and others},
  title     = {{Power-law distribution of the world wide web}},
  journal   = {Science},
  year      = {2000},
  volume    = {287},
  number    = {5461},
  pages     = {2115},
  publisher = {AAAS},
}

@ARTICLE{Adomavicius2005Incorporating,
  author = {Adomavicius, Gediminas and Sankaranarayanan, Ramesh and Sen, Shahana
	and Tuzhilin, Alexander},
  title = {Incorporating Contextual Information in Recommender Systems Using
	a Multidimensional Approach},
  journal = {ACM Trans. Inf. Syst.},
  year = {2005},
  volume = {23},
  pages = {103--145},
  number = {1},
  month = jan,
  abstract = {The article presents a multidimensional (MD) approach to recommender
	systems that can provide recommendations based on additional contextual
	information besides the typical information on users and items used
	in most of the current recommender systems. This approach supports
	multiple dimensions, profiling information, and hierarchical aggregation
	of recommendations. The article also presents a multidimensional
	rating estimation method capable of selecting two-dimensional segments
	of ratings pertinent to the recommendation context and applying standard
	collaborative filtering or other traditional two-dimensional rating
	estimation techniques to these segments. A comparison of the multidimensional
	and two-dimensional rating estimation approaches is made, and the
	tradeoffs between the two are studied. Moreover, the article introduces
	a combined rating estimation method, which identifies the situations
	where the MD approach outperforms the standard two-dimensional approach
	and uses the MD approach in those situations and the standard two-dimensional
	approach elsewhere. Finally, the article presents a pilot empirical
	study of the combined approach, using a multidimensional movie recommender
	system that was developed for implementing this approach and testing
	its performance.},
  acmid = {1055714},
  address = {New York, NY, USA},
  file = {Adomavicius2005Incorporating.pdf:Adomavicius2005Incorporating.pdf:PDF},
  issn = {1046-8188},
  issue_date = {January 2005},
  keywords = {Recommender systems, collaborative filtering, context-aware recommender
	systems, multidimensional data models, multidimensional recommender
	systems, personalization, rating estimation},
  numpages = {43},
  publisher = {ACM}
}

@INCOLLECTION{Adomavicius2011Context,
  author = {Adomavicius, Gediminas and Tuzhilin, Alexander},
  title = {Context-aware recommender systems},
  booktitle = {Recommender systems handbook},
  publisher = {Springer},
  year = {2011},
  pages = {217--253},
  file = {Adomavicius2011Context.pdf:Adomavicius2011Context.pdf:PDF},
  timestamp = {2014.09.13}
}

@Article{adomavicius2005toward,
  author    = {Adomavicius, G. and Tuzhilin, A.},
  title     = {{Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions}},
  journal   = {IEEE transactions on knowledge and data engineering},
  year      = {2005},
  volume    = {17(6)},
  pages     = {734--749},
  file      = {:adomavicius2005toward.pdf:PDF},
  groups    = {Recommender Systems},
  publisher = {Published by the IEEE Computer Society},
}

@InProceedings{Adomavicius2010stability,
  author    = {Adomavicius, Gediminas and Zhang, Jingjing},
  title     = {On the stability of recommendation algorithms},
  booktitle = {Proceedings of the fourth ACM conference on Recommender systems},
  year      = {2010},
  series    = {RecSys '10},
  pages     = {47--54},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {The paper introduces stability as a new measure of the
	
	recommender systems performance. In general, we define a
	
	recommendation algorithm to be “stable” if its predictions for the
	
	
	same items are consistent over a period of time, assuming that any
	
	
	new ratings that have been submitted to the recommender system
	
	over the same period of time are in complete agreement with
	
	system’s prior predictions. In this paper, we advocate that
	
	stability should be a desired property of recommendation
	
	algorithms, because unstable recommendations can lead to user
	
	confusion and, therefore, reduce trust in recommender systems.
	
	Furthermore, we empirically evaluate stability of several popular
	
	
	recommendation algorithms. Our results suggest that modelbased recommendation
	techniques demonstrate higher stability
	
	than memory-based collaborative filtering heuristics. We also
	
	find that the stability measure for recommendation techniques is
	
	influenced by many factors, including the sparsity of the initial
	
	
	rating data, the number of new incoming ratings (representing the
	
	
	length of the time period over which the stability is being
	
	measured), the distribution of the newly added rating values, and
	
	
	the rating normalization procedures employed by the
	
	recommendation algorithms.},
  acmid     = {1864722},
  file      = {Adomavicius2010stability.pdf:Adomavicius2010stability.pdf:PDF},
  groups    = {Recommender Systems},
  isbn      = {978-1-60558-906-0},
  keywords  = {collaborative filtering, evaluation of recommender systems, performance measures, stability of recommendation algorithms},
  location  = {Barcelona, Spain},
  numpages  = {8},
}

@INCOLLECTION{Aggarwal2012survey,
  author = {Aggarwal, Charu C and Zhai, ChengXiang},
  title = {A survey of text clustering algorithms},
  booktitle = {Mining Text Data},
  publisher = {Springer},
  year = {2012},
  pages = {77--128},
  abstract = {Clustering is a widely studied data mining problem in the text domains.
	The problem finds numerous applications in customer segmentation,
	classification, collaborative filtering, visualization, document
	organization, and indexing. In this chapter, we will provide a detailed
	survey of the problem of text clustering. We will study the key challenges
	of the clustering problem, as it applies to the text domain. We will
	discuss the key methods used for text clustering, and their relative
	advantages. We will also discuss a number of recent advances in the
	area in the context of social network and linked data.},
  file = {Aggarwal2012survey.pdf:Aggarwal2012survey.pdf:PDF}
}

@InProceedings{Agichtein2008Finding,
  author    = {Agichtein, Eugene and Castillo, Carlos and Donato, Debora and Gionis, Aristides and Mishne, Gilad},
  title     = {Finding high-quality content in social media},
  booktitle = {WSDM '08: Proceedings of the international conference on Web search and web data mining},
  year      = {2008},
  pages     = {183--194},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {The quality of user-generated content varies drastically from
	
	excellent to abuse and spam. As the availability of such con-
	
	tent increases, the task of identifying high-quality content
	
	in sites based on user contributions|social media sites|
	
	becomes increasingly important. Social media in general
	
	exhibit a rich variety of information sources: in addition to
	
	the content itself, there is a wide array of non-content infor-
	
	mation available, such as links between items and explicit
	
	quality ratings from members of the community. In this pa-
	
	per we investigate methods for exploiting such community
	
	feedback to automatically identify high quality content. As
	
	a test case, we focus on Yahoo! Answers, a large community
	
	question/answering portal that is particularly rich in the
	
	amount and types of content and social interactions avail-
	
	able in it. We introduce a general classification framework
	
	for combining the evidence from di®erent sources of infor-
	
	mation, that can be tuned automatically for a given social
	
	media type and quality de¯nition. In particular, for the
	
	community question/answering domain, we show that our
	
	system is able to separate high-quality items from the rest
	
	with an accuracy close to that of humans},
  comment   = {Data: Yahoo! Answers
	
	Featue:
	
	UQV Average number of "stars" to questions by the same
	
	asker.
	
	; The punctuation density in the question's subject.
	
	; The question's category (assigned by the asker).
	
	; \Normalized Clickthrough:" The number of clicks on
	
	the question thread, normalized by the average number
	
	of clicks for all questions in its category.
	
	UAV Average number of "Thumbs up" received by answers
	
	written by the asker of the current question.
	
	; Number of words per sentence.
	
	UA Average number of answers with references (URLs)
	
	given by the asker of the current question.
	
	UQ Fraction of questions asked by the asker in which he
	
	opens the question's answers to voting (instead of pick-
	
	ing the best answer by hand).
	
	UQ Average length of the questions by the asker.
	
	UAV The number of \best answers" authored by the user.
	
	U The number of days the user was active in the system.
	
	UAV \Thumbs up" received by the answers wrote by the
	
	asker of the current question, minus \thumbs down",
	
	divided by total number of \thumbs" received.
	
	; \Clicks over Views:" The number of clicks on a ques-
	
	tion thread divided by the number of times the ques-
	
	tion thread was retrieved as a search result (see [2]).
	
	; The KL-divergence between the question's language
	
	model and a model estimated from a collection of ques-
	
	tion answered by the Yahoo editorial team (available
	
	in http://ask.yahoo.com).
	
	; The fraction of words that are not in the list of the
	
	top-10 words in the collection, ranked by frequency.
	
	; The number of \capitalization errors" in the question
	
	(e.g., sentence not starting with a capitalized word).
	
	U The number of days that has passed since the asker
	
	wrote his/her ¯rst question or answer in the system.
	
	UAV The total number of answers of the asker that have
	
	been selected as the \best answer".
	
	UQ The number of questions that the asker has asked in
	
	its most active category, over the total number of ques-
	
	tions that the asker has asked.
	
	; The entropy of the part-of-speech tags of the question..},
  file      = {Agichtein2008Finding.pdf:Agichtein2008Finding.pdf:PDF},
  isbn      = {978-1-59593-927-9},
  location  = {Palo Alto, California, USA},
  owner     = {Cheyenne},
  timestamp = {2009.09.22},
}

@Article{Agichtein2009Social,
  author    = {Eugene Agichtein and Evgeniy Gabrilovich and Hongyuan Zha},
  title     = {The Social Future of Web Search: Modeling, Exploiting, and Searching Collaboratively Generated Content},
  journal   = {IEEE Data Engineering Bulletin},
  year      = {2009},
  volume    = {32(2)},
  pages     = {52-61},
  file      = {Agichtein2009Social.pdf:Agichtein2009Social.pdf:PDF},
  owner     = {linchen},
  timestamp = {2011.10.22},
}

@INPROCEEDINGS{Agrawal1994Fast,
  author = {Agrawal, Rakesh and Srikant, Ramakrishnan},
  title = {Fast Algorithms for Mining Association Rules in Large Databases},
  booktitle = {Proceedings of the 20th International Conference on Very Large Data
	Bases},
  year = {1994},
  series = {VLDB '94},
  pages = {487--499},
  address = {San Francisco, CA, USA},
  publisher = {Morgan Kaufmann Publishers Inc.},
  acmid = {672836},
  file = {Agrawal1994Fast.pdf:Agrawal1994Fast.pdf:PDF},
  isbn = {1-55860-153-8},
  numpages = {13},
  url = {http://dl.acm.org/citation.cfm?id=645920.672836}
}

@ARTICLE{ahmed2009recovering,
  author = {Ahmed, A. and Xing, E.P.},
  title = {{Recovering time-varying networks of dependencies in social and biological
	studies}},
  journal = {Proceedings of the National Academy of Sciences},
  year = {2009},
  volume = {106},
  pages = {11878},
  number = {29},
  file = {ahmed2009recovering.pdf:ahmed2009recovering.pdf:PDF},
  issn = {0027-8424},
  publisher = {National Acad Sciences}
}

@Article{Ahn2008new,
  author   = {Hyung Jun Ahn},
  title    = {A new similarity measure for collaborative filtering to alleviate the new user cold-starting problem},
  journal  = {Information Sciences},
  year     = {2008},
  volume   = {178},
  number   = {1},
  pages    = {37 - 51},
  abstract = {Collaborative filtering is one of the most successful and widely used
	methods of automated product recommendation in online stores. The
	most critical component of the method is the mechanism of finding
	similarities among users using product ratings data so that products
	can be recommended based on the similarities. The calculation of
	similarities has relied on traditional distance and vector similarity
	measures such as Pearson’s correlation and cosine which, however,
	have been seldom questioned in terms of their effectiveness in the
	recommendation problem domain. This paper presents a new heuristic
	similarity measure that focuses on improving recommendation performance
	under cold-start conditions where only a small number of ratings
	are available for similarity calculation for each user. Experiments
	using three different datasets show the superiority of the measure
	in new user cold-start conditions. },
  file     = {Ahn2008new.pdf:Ahn2008new.pdf:PDF},
  groups   = {Recommender Systems},
  issn     = {0020-0255},
  keywords = {Similarity measure},
}

@ARTICLE{Airoldi2008Mixed,
  author = {Airoldi, E.M. and Blei, D.M. and Fienberg, S.E. and Xing, E.P.},
  title = {{Mixed membership stochastic blockmodels}},
  journal = {The Journal of Machine Learning Research},
  year = {2008},
  volume = {9},
  pages = {1981--2014},
  file = {Airoldi2008Mixed.pdf:Airoldi2008Mixed.pdf:PDF},
  issn = {1532-4435},
  publisher = {JMLR. org}
}

@Article{albert2002statistical,
  author    = {Albert, R. and Barab{\'a}si, A.L.},
  title     = {{Statistical mechanics of complex networks}},
  journal   = {Reviews of modern physics},
  year      = {2002},
  volume    = {74},
  number    = {1},
  pages     = {47--97},
  abstract  = {This paper reviews the recent advances in the field of complex networks,
	focusing on the statistical mechanics of topology and dynamics},
  publisher = {APS},
}

@Article{albert1999internet,
  author    = {Albert, R. and Jeong, H. and Barab{\'a}si, A.L.},
  title     = {{Internet: Diameter of the world-wide web}},
  journal   = {Nature},
  year      = {1999},
  volume    = {401},
  number    = {6749},
  pages     = {130--131},
  issn      = {0028-0836},
  publisher = {Nature Publishing Group},
}

@InProceedings{Aleman-Meza2006Semantic,
  author    = {Aleman-Meza, Boanerges and Nagarajan, Meenakshi and Ramakrishnan, Cartic and Ding, Li and Kolari, Pranam and Sheth, Amit P. and Arpinar, I. Budak and Joshi, Anupam and Finin, Tim},
  title     = {Semantic analytics on social networks: experiences in addressing the problem of conflict of interest detection},
  booktitle = {WWW '06: Proceedings of the 15th international conference on World Wide Web},
  year      = {2006},
  pages     = {407--416},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {In this paper, we describe a Semantic Web application that detects
	Conflict of Interest (COI) relationships among potential reviewers
	and authors of scientific papers. This application discovers various
	'semantic associations' between the reviewers and authors in a populated
	ontology to determine a degree of Conflict of Interest. This ontology
	was created by integrating entities and relationships from two social
	networks, namely "knows," from a FOAF (Friend-of-a-Friend) social
	network and "co-author," from the underlying co-authorship network
	of the DBLP bibliography. We describe our experiences developing
	this application in the context of a class of Semantic Web applications,
	which have important research and engineering challenges in common.
	In addition, we present an evaluation of our approach for real-life
	COI detection.},
  isbn      = {1-59593-323-9},
  location  = {Edinburgh, Scotland},
}

@InProceedings{Allan1998On-line,
  author    = {Allan, James and Papka, Ron and Lavrenko, Victor},
  title     = {On-line new event detection and tracking},
  booktitle = {Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval},
  year      = {1998},
  series    = {SIGIR '98},
  pages     = {37--45},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {290954},
  comment   = {strict online setting: make decisions on one story before looking
	at any subsequent stories
	
	
	methods: single pass clustering,},
  file      = {Allan1998On-line.pdf:Allan1998On-line.pdf:PDF},
  isbn      = {1-58113-015-5},
  location  = {Melbourne, Australia},
  numpages  = {9},
}

@ARTICLE{Alon2006Ranking,
  author = {Alon, Noga},
  title = {Ranking tournaments},
  journal = {SIAM Journal on Discrete Mathematics},
  year = {2006},
  volume = {20},
  pages = {137--142},
  number = {1},
  abstract = {A tournament is an oriented complete graph. The feedback arc set problem
	for
	
	tournaments is the optimization problem of determining the minimum
	possible number of edges of
	
	a given input tournament T whose reversal makes T acyclic. Ailon,
	Charikar, and Newman showed
	
	that this problem is NP-hard under randomized reductions. Here we
	show that it is in fact NP-hard.
	
	This settles a conjecture of Bang-Jensen and Thomassen.},
  file = {Alon2006Ranking.pdf:Alon2006Ranking.pdf:PDF},
  publisher = {SIAM}
}

@InProceedings{AlSumait2008Online,
  author    = {AlSumait, L. and Barbara, D. and Domeniconi, C.},
  title     = {On-line LDA: Adaptive Topic Models for Mining Text Streams with Applications to Topic Detection and Tracking},
  booktitle = {Data Mining, 2008. ICDM '08. Eighth IEEE International Conference on},
  year      = {2008},
  pages     = {3-12},
  abstract  = {This paper presents online topic model (OLDA), a topic model that
	automatically captures the thematic patterns and identifies emerging
	topics of text streams and their changes over time. Our approach
	allows the topic modeling framework, specifically the latent Dirichlet
	allocation (LDA) model, to work in an online fashion such that it
	incrementally builds an up-to-date model (mixture of topics per document
	and mixture of words per topic) when a new document (or a set of
	documents) appears. A solution based on the empirical Bayes method
	is proposed. The idea is to incrementally update the current model
	according to the information inferred from the new stream of data
	with no need to access previous data. The dynamics of the proposed
	approach also provide an efficient mean to track the topics over
	time and detect the emerging topics in real time. Our method is evaluated
	both qualitatively and quantitatively using benchmark datasets. In
	our experiments, the OLDA has discovered interesting patterns by
	just analyzing a fraction of data at a time. Our tests also prove
	the ability of OLDA to align the topics across the epochs with which
	the evolution of the topics over time is captured. The OLDA is also
	comparable to, and sometimes better than, the original LDA in predicting
	the likelihood of unseen documents.},
  issn      = {1550-4786},
  keywords  = {Bayes methods;data mining;text analysis;adaptive topic model;empirical Bayes method;latent Dirichlet allocation;online LDA;pattern discovery;text stream mining;topic detection;topic tracking;Application software;Benchmark testing;Computer science;Data mining;Linear discriminant analysis;Organizing;Pattern analysis;Software libraries;USA Councils;Yarn},
}

@InProceedings{Alvanaki2011EnBlogue,
  author    = {Alvanaki, Foteini and Sebastian, Michel and Ramamritham, Krithi and Weikum, Gerhard},
  title     = {EnBlogue: Emergent Topic Detection in Web 2.0 Streams},
  booktitle = {Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data},
  year      = {2011},
  series    = {SIGMOD '11},
  pages     = {1271--1274},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Emergent topics are newly arising themes in news, blogs, or tweets,
	often implied by interesting and unexpected correlations of tags
	or entities. We present the enBlogue system for emergent topic detection.
	The name enBlogue reflects the analogy with emerging trends in fashion
	often referred to as en Vogue. EnBlogue continuously monitors Web
	2.0 streams and keeps track of sudden changes in tag correlations
	which can be adjusted using personalization to reflect particular
	user interests. We demonstrate enBlogue with several real-time monitoring
	scenarios as well as with time lapse on archived data.},
  acmid     = {1989473},
  groups    = {Recommender Systems, Twitter},
  isbn      = {978-1-4503-0661-4},
  keywords  = {emergent topics, web 2.0 streams},
  location  = {Athens, Greece},
  numpages  = {4},
}

@INPROCEEDINGS{Amati2011FUB,
  author = {Gianni Amati and Giuseppe Amodeo and Marco Bianchi and Alessandro
	Celi and Cesidio De Nicola and Michele},
  title = {FUB, IASI-CNR, UNIVAQ at TREC 2011},
  booktitle = {TREC},
  year = {2011},
  file = {Amati2011FUB.pdf:Amati2011FUB.pdf:PDF},
  owner = {linchen},
  timestamp = {2012.01.15}
}

@Article{Amati2004Query,
  author    = {Amati, G. and Carpineto, C. and Romano, G.},
  title     = {Query difficulty, robustness, and selective application of query expansion},
  journal   = {Advances in Information Retrieval},
  year      = {2004},
  pages     = {127--137},
  abstract  = {There is increasing interest in improving the robustness of IR systems,
	
	i.e. their effectiveness on difficult queries. A system is robust
	when it achieves
	
	both a high Mean Average Precision (MAP) value for the entire set
	of topics and
	
	a significant MAP value over its worst X topics (MAP(X)). It is a
	well known
	
	fact that Query Expansion (QE) increases global MAP but hurts the
	performance
	
	on the worst topics. A selective application of QE would thus be a
	natural answer
	
	to obtain a more robust retrieval system.
	
	We define two information theoretic functions which are shown to be
	correlated
	
	respectively with the average precision and with the increase of average
	precision
	
	under the application of QE. The second measure is used to selectively
	apply QE.
	
	This method achieves a performance similar to that with unexpanded
	method on
	
	the worst topics, and better performance than full QE on the whole
	set of topics.},
  file      = {Amati2004Query.pdf:Amati2004Query.pdf:PDF},
  publisher = {Springer},
}

@InProceedings{Amatriain2009wisdom,
  author    = {Amatriain, Xavier and Lathia, Neal and Pujol, Josep M. and Kwak, Haewoon and Oliver, Nuria},
  title     = {The wisdom of the few: a collaborative filtering approach based on expert opinions from the web},
  booktitle = {Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval},
  year      = {2009},
  pages     = {532--539},
  address   = {Boston, MA, USA},
  publisher = {ACM},
  abstract  = {Nearest-neighbor collaborative filtering provides a successful
	
	means of generating recommendations for web users. However,
	
	this approach suffers from several shortcomings, including
	
	data sparsity and noise, the cold-start problem, and
	
	scalability. In this work, we present a novel method for recommending
	
	items to users based on expert opinions. Our
	
	method is a variation of traditional collaborative filtering:
	
	rather than applying a nearest neighbor algorithm to the
	
	user-rating data, predictions are computed using a set of expert
	
	neighbors from an independent dataset, whose opinions
	
	are weighted according to their similarity to the user. This
	
	method promises to address some of the weaknesses in traditional
	
	collaborative filtering, while maintaining comparable
	
	accuracy. We validate our approach by predicting a subset
	
	of the Netflix data set. We use ratings crawled from a web
	
	portal of expert reviews, measuring results both in terms of
	
	prediction accuracy and recommendation list precision. Finally,
	
	we explore the ability of our method to generate useful
	
	recommendations, by reporting the results of a user-study
	
	where users prefer the recommendations generated by our
	
	approach.},
  comment   = {Data: Netflix
	
	methodology:
	
	1)experts are movie critics
	
	2)rating incoporating expert rating},
  file      = {:amatriain2009wisdom.pdf:PDF},
  groups    = {Recommender Systems},
  keywords  = {collaborative filtering, cosine similarity, experts, nearest neighbors, recommender system, top-n recommendations},
}

@InProceedings{Arguello2008Document,
  author    = {Arguello, J. and Elsas, J.L. and Callan, J. and Carbonell, J.G.},
  title     = {Document representation and query expansion models for blog recommendation},
  booktitle = {Proc. of the 2nd Intl. Conf. on Weblogs and Social Media (ICWSM)},
  year      = {2008},
  file      = {Arguello2008Document.pdf:Arguello2008Document.pdf:PDF},
  groups    = {Twitter},
}

@INPROCEEDINGS{Arora2008Latent,
  author = {Arora, R. and Ravindran, B.},
  title = {Latent Dirichlet Allocation and Singular Value Decomposition Based
	Multi-document Summarization},
  booktitle = {Data Mining, 2008. ICDM '08. Eighth IEEE International Conference
	on},
  year = {2008},
  pages = {713-718},
  month = {Dec},
  abstract = {Multi-Document Summarization deals with computing a summary for a
	set of related articles such that they give the user a general view
	about the events. One of the objectives is that the sentences should
	cover the different events in the documents with the information
	covered in as few sentences as possible. Latent Dirichlet Allocation
	can breakdown these documents into different topics or events. However
	to reduce the common information content the sentences of the summary
	need to be orthogonal to each other since orthogonal vectors have
	the lowest possible similarity and correlation between them. Singular
	Value Decompositions used to get the orthogonal representations of
	vectors and representing sentences as vectors, we can get the sentences
	that are orthogonal to each other in the LDA mixture model weighted
	term domain. Thus using LDA we find the different topics in the documents
	and using SVD we find the sentences that best represent these topics.
	Finally we present the evaluation of the algorithms on the DUC2002
	Corpus multi-document summarization tasks using the ROUGE evaluator
	to evaluate the summaries. Compared to DUC 2002 winners, our algorithms
	gave significantly better ROUGE-1 recall measures.},
  issn = {1550-4786},
  keywords = {abstracting;document handling;singular value decomposition;vectors;DUC2002
	Corpus multidocument summarization tasks;LDA mixture model weighted
	term domain;ROUGE evaluator;latent Dirichlet allocation;orthogonal
	representations;orthogonal vectors;singular value decomposition;Bayesian
	methods;Computer science;Context modeling;Data engineering;Data mining;Frequency;Joining
	processes;Linear discriminant analysis;Probability distribution;Singular
	value decomposition;Multi-Document Summarization;Natural Language
	Processing}
}

@INPROCEEDINGS{Arora2014Provable,
  author = {Sanjeev Arora and Aditya Bhaskara and Rong Ge and Tengyu Ma},
  title = {Provable Bounds for Learning Some Deep Representations},
  booktitle = {Proceedings of ICML},
  year = {2014},
  pages = {519-527},
  abstract = {We give algorithms with provable guarantees that learn a class of
	deep nets in the generative model view popularized by Hinton and
	others. Our generative model is an n node multilayer neural net that
	has degree at most $n^{\gamma}$ for some $\gamma < 1$ and each edge
	has a random edge weight in [-1,1]. Our algorithm learns almost all
	networks in this class with polynomial running time. The sample complexity
	is quadratic or cubic depending upon the details of the model. The
	algorithm uses layerwise learning. It is based upon a novel idea
	of observing correlations among features and using these to infer
	the underlying edge structure via a global graph recovery procedure.
	The analysis of the algorithm reveals interesting structure of neural
	nets with random edge weights.},
  file = {Arora2014Provable.pdf:Arora2014Provable.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.06.24}
}

@InProceedings{AuYeung2011Strength,
  author    = {Au Yeung, Ching-man and Iwata, Tomoharu},
  title     = {Strength of Social Influence in Trust Networks in Product Review Sites},
  booktitle = {Proceedings of the Fourth ACM International Conference on Web Search and Data Mining},
  year      = {2011},
  series    = {WSDM '11},
  pages     = {495--504},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Some popular product review sites such as Epinions allow users to
	establish a trust network among themselves, indicating who they trust
	in providing product reviews and ratings. While trust relations have
	been found to be useful in generating personalised recommendations,
	the relations between trust and product ratings has so far been overlooked.
	In this paper, we examine large datasets collected from Epinions
	and Ciao, two popular product review sites. We discover that in general
	users who trust each other tend to have smaller differences in their
	ratings as time passes, giving support to the theories of homophily
	and social influence. However, we also discover that this does not
	hold true across all trusted users. A trust relation does not guarantee
	that two users have similar preferences, implying that personalised
	recommendations based on trust relations do not necessarily produce
	more accurate predictions. We propose a method to estimate the strengths
	of trust relations so as to estimate the true influence among the
	trusted users. Our method extends the popular matrix factorisation
	technique for collaborative filtering, which allow us to generate
	more accurate rating predictions at the same time. We also show that
	the estimated strengths of trust relations correlate with the similarity
	among the users. Our work contributes to the understanding of the
	interplay between trust relations and product ratings, and suggests
	that trust networks may serve as a more general socialising venue
	than only an indication of similarity in user preferences.},
  acmid     = {1935899},
  comment   = {empirical study shows the difference between two users ratings tend
	to be smaller as their trust relationship last
	
	
	method:
	
	
	pq+combination of trustees' ratings
	
	incorporate a linear combination of trustee's ratings, where the coefficients
	need to be learnt},
  file      = {AuYeung2011Strength.pdf:AuYeung2011Strength.pdf:PDF},
  isbn      = {978-1-4503-0493-1},
  keywords  = {collaborative filtering, matrix factorization, recommender systems, social influence, trust network},
  location  = {Hong Kong, China},
  numpages  = {10},
  timestamp = {2015.11.26},
}

@InCollection{AzariSoufiani2013Generalized,
  author    = {Azari Soufiani, Hossein and Chen, William and Parkes, David C and Xia, Lirong},
  title     = {Generalized Method-of-Moments for Rank Aggregation},
  booktitle = {Advances in Neural Information Processing Systems 26},
  publisher = {Curran Associates, Inc.},
  year      = {2013},
  editor    = {C. J. C. Burges and L. Bottou and M. Welling and Z. Ghahramani and K. Q. Weinberger},
  pages     = {2706--2714},
  abstract  = {In this paper we propose a class of efficient Generalized Method-of-Moments(GMM)
	algorithms for computing parameters of the Plackett-Luce model, where
	the data consists of full rankings over alternatives. Our technique
	is based on breaking the full rankings into pairwise comparisons,
	and then computing parameters that satisfy a set of generalized moment
	conditions. We identify conditions for the output of GMM to be unique,
	and identify a general class of consistent and inconsistent breakings.
	We then show by theory and experiments that our algorithms run significantly
	faster than the classical Minorize-Maximization (MM) algorithm, while
	achieving competitive statistical efficiency.},
  comment   = {(1) several variants of the BTL model
	
	with ties
	
	with home teams
	
	
	(2) introduce a minoring function and simplify the iterative optimiing
	process},
  file      = {AzariSoufiani2013Generalized.pdf:AzariSoufiani2013Generalized.pdf:PDF},
  timestamp = {2016.04.18},
  url       = {http://papers.nips.cc/paper/4997-generalized-method-of-moments-for-rank-aggregation.pdf},
}

@InProceedings{Azizi2014Learning,
  author    = {Elham Azizi and Edoardo Airoldi and James Galagan},
  title     = {Learning Modular Structures from Network Data and Node Variables},
  booktitle = {Proceedings of ICML},
  year      = {2014},
  pages     = {1102--1110},
  abstract  = {A standard technique for understanding underlying dependency structures
	among a set of variables posits a shared conditional probability
	distribution for the variables measured on individuals within a group.
	This approach is often referred to as module networks, where individuals
	are represented by nodes in a network, groups are termed modules,
	and the focus is on estimating the network structure among modules.
	However, estimation solely from node-specific variables can lead
	to spurious dependencies, and unverifiable structural assumptions
	are often used for regularization. Here, we propose an extended model
	that leverages direct observations about the network in addition
	to node-specific variables. By integrating complementary data types,
	we avoid the need for structural assumptions. We illustrate theoretical
	and practical significance of the model and develop a reversible-jump
	MCMC learning procedure for learning modules and model parameters.
	We demonstrate the method accuracy in predicting modular structures
	from synthetic data and capability to learn regulatory modules in
	the Mycobacterium tuberculosis gene regulatory network.},
  comment   = {a hundred of conditions},
  file      = {Azizi2014Learning.pdf:Azizi2014Learning.pdf:PDF},
  owner     = {littlep},
  timestamp = {2014.06.22},
}

@InProceedings{B'ir'o2009Linked,
  author    = {B\'{\i}r\'{o}, Istv\'{a}n and Sikl\'{o}si, D\'{a}vid and Szab\'{o}, J\'{a}cint and Bencz\'{u}r, Andr\'{a}s A.},
  title     = {Linked latent Dirichlet allocation in web spam filtering},
  booktitle = {AIRWeb '09: Proceedings of the 5th International Workshop on Adversarial Information Retrieval on the Web},
  year      = {2009},
  pages     = {37--40},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Latent Dirichlet allocation (LDA) (Blei, Ng, Jordan 2003) is a fully
	generative statistical language model on the content and topics of
	a corpus of documents. In this paper we apply an extension of LDA
	for web spam classification. Our linked LDA technique takes also
	linkage into account: topics are propagated along links in such a
	way that the linked document directly influences the words in the
	linking document. The inferred LDA model can be applied for classification
	as dimensionality reduction similarly to latent semantic indexing.
	We test linked LDA on the WEBSPAM-UK2007 corpus. By using BayesNet
	classifier, in terms of the AUC of classification, we achieve 3%
	improvement over plain LDA with BayesNet, and 8% over the public
	link features with C4.5. The addition of this method to a log-odds
	based combination of strong link and content baseline classifiers
	results in a 3% improvement in AUC. Our method even slightly improves
	over the best Web Spam Challenge 2008 result.},
  isbn      = {978-1-60558-438-6},
  location  = {Madrid, Spain},
}

@INPROCEEDINGS{Buttcher2006Term,
  author = {B\"{u}ttcher, Stefan and Clarke, Charles L. A. and Lushman, Brad},
  title = {Term Proximity Scoring for Ad-hoc Retrieval on Very Large Text Collections},
  booktitle = {Proceedings of the 29th Annual International ACM SIGIR Conference
	on Research and Development in Information Retrieval},
  year = {2006},
  series = {SIGIR '06},
  pages = {621--622},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We propose an integration of term proximity scoring into Okapi BM25.
	The relative retrieval effectiveness of our retrieval method, compared
	to pure BM25, varies from collection to collection.We present an
	experimental evaluation of our method and show that the gains achieved
	over BM25 as the size of the underlying text collection increases.
	We also show that for stemmed queries the impact of term proximity
	scoring is larger than for unstemmed queries.},
  acmid = {1148285},
  isbn = {1-59593-369-7},
  keywords = {information retrieval, query processing, term proximity},
  location = {Seattle, Washington, USA},
  numpages = {2}
}

@InProceedings{backstrom2006group,
  author       = {Backstrom, L. and Huttenlocher, D. and Kleinberg, J. and Lan, X.},
  title        = {{Group formation in large social networks: membership, growth, and evolution}},
  booktitle    = {Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining},
  year         = {2006},
  pages        = {44--54},
  organization = {ACM},
  abstract     = {The processes by which communities come together, attract new members,
	and develop over time is a central research issue in the social sciences
	- political movements, professional organizations, and religious
	denominations all provide fundamental examples of such communities.
	In the digital domain, on-line groups are becoming increasingly prominent
	due to the growth of community and social networking sites such as
	MySpace and LiveJournal. However, the challenge of collecting and
	analyzing large-scale time-resolved data on social groups and communities
	has left most basic questions about the evolution of such groups
	largely unresolved: what are the structural features that influence
	whether individuals will join communities, which communities will
	grow rapidly, and how do the overlaps among pairs of communities
	change over time.Here we address these questions using two large
	sources of data: friendship links and community membership on LiveJournal,
	and co-authorship and conference publications in DBLP. Both of these
	datasets provide explicit user-defined communities, where conferences
	serve as proxies for communities in DBLP. We study how the evolution
	of these communities relates to properties such as the structure
	of the underlying social networks. We find that the propensity of
	individuals to join communities, and of communities to grow rapidly,
	depends in subtle ways on the underlying network structure. For example,
	the tendency of an individual to join a community is influenced not
	just by the number of friends he or she has within the community,
	but also crucially by how those friends are connected to one another.
	We use decision-tree techniques to identify the most significant
	structural determinants of these properties. We also develop a novel
	methodology for measuring movement of individuals between communities,
	and show how such movements are closely aligned with changes in the
	topics of interest within the communities.},
  file         = {backstrom2006group.pdf:backstrom2006group.pdf:PDF},
  isbn         = {1595933395},
}

@InProceedings{Baeza-Yates2009User,
  author    = {Baeza-Yates, Ricardo},
  title     = {User generated content: how good is it?},
  booktitle = {WICOW '09: Proceedings of the 3rd workshop on Information credibility on the web},
  year      = {2009},
  pages     = {1--2},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {User Generated Content (UGC) is one of the main current trends in
	the Web. This trend has allowed all people that can access the Internet
	to publish content in different media, such as text (e.g. blogs),
	photos or video. This data can be crucial for many applications,
	in particular for semantic search.
	
	
	It is early to say which impact UGC will have and to what extent.
	However, the impact will be clearly related to the quality of this
	content.
	
	
	Hence, how good is the content that people generate in the so called
	Web 2.0? Clearly is not as good as editorial content in the Web site
	of a publisher. However, histories of success such as the case of
	the Wikipedia, show that it can be quite good. In addition, the quality
	gap is balanced by volume, as user generated content is much larger
	than, say, editorial content. In fact, Ramakrishnan and Tomkins estimate
	that UGC generates daily from 8 to 10GB while the professional Web
	only generates 2GB in the same time.
	
	
	How we can estimate the quality of UGC? One possibility is to directly
	evaluate the quality, but that is not easy as depends on the type
	of content and the availability of human judgments. One example of
	such approach is the study of Yahoo! Answers done by Agichtein et
	al. In this work they start from a judged question/answer collection
	where good questions usually have good answers. Then they predict
	good questions and good answers, obtaining an AUC (area under the
	curve of the precision-recall graph) of 0.76 and 0.88, respectively.
	
	
	A second possibility is obtaining indirect evidence of the quality.
	For example, use UGC for a given task and then evaluate the quality
	of the task results. One such example is the extraction of semantic
	relations done by Baeza-Yates and Tiberi. To evaluate the quality
	of the results they used the Open Directory Project (ODP), showing
	that the results had a precision of over 60%. For the cases that
	were not found in the ODP, a manually verified sample showed that
	the real precision was close to 100%. What happened was that the
	ODP was not specific enough to contain very specific relations, and
	every day the problem gets worse as we have more data. This example
	shows the quality of ODP as well as the semantic encoded in queries.
	Notice that we can define queries as implicit UGC, because each query
	can be considered an implicit tag to Web pages that are clicked for
	that query, and hence we have an implicit folksonomy.
	
	
	A final alternative is crossing different UGC sources and infer from
	there the quality of those sources. An example of this case, is the
	work by Van Zwol et al. where they use collective knowledge (wisdom
	of crowds) to extend image tags, and prove that almost 70% of the
	tags can be semantically classified by using Wordnet and Wikipedia.
	This exposes the quality of both Flickr tags and Wikipedia.
	
	
	Our main motivation, is that by being able to generate semantic resources
	automatically from the Web (and in particular the Web 2.0), even
	with noise, coupling that with open content resources, we can create
	a virtuous feedback circuit. In fact, explicit and implicit folksonomies
	can be used to do supervised machine learning without the need of
	manual intervention (or at least drastically reduce it) to improve
	semantic tagging. After that, we can feedback the results on itself,
	and repeat the process. Using the right conditions, every iteration
	should improve the output, obtaining a virtuous cycle. As a side
	effect, we can also improve Web search, our main goal.},
  comment   = {seems to be a keynote speak},
  file      = {Baeza-Yates2009User.pdf:Baeza-Yates2009User.pdf:PDF},
  isbn      = {978-1-60558-488-1},
  location  = {Madrid, Spain},
}

@Conference{baeza2007extracting,
  author       = {Baeza-Yates, R. and Tiberi, A.},
  title        = {{Extracting semantic relations from query logs}},
  booktitle    = {Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining},
  year         = {2007},
  pages        = {76--85},
  organization = {ACM},
  abstract     = {In this paper we study a large query log of more than twenty
	
	million queries with the goal of extracting the semantic re-
	
	lations that are implicitly captured in the actions of users
	
	submitting queries and clicking answers. Previous query log
	
	analyses were mostly done with just the queries and not the
	
	actions that followed after them. We rst propose a novel
	
	way to represent queries in a vector space based on a graph
	
	derived from the query-click bipartite graph. We then an-
	
	alyze the graph produced by our query log, showing that
	
	it is less sparse than previous results suggested, and that
	
	almost all the measures of these graphs follow power laws,
	
	shedding some light on the searching user behavior as well
	
	as on the distribution of topics that people want in the Web.
	
	The representation we introduce allows to infer interesting
	
	semantic relationships between queries. Second, we provide
	
	an experimental analysis on the quality of these relations,
	
	showing that most of them are relevant. Finally we sketch
	
	an application that detects multitopical URLs.},
  file         = {baeza2007extracting.pdf:baeza2007extracting.pdf:PDF},
}

@CONFERENCE{Bailey2007Overview,
  author = {Bailey, P. and Craswell, N. and De Vries, AP and Soboroff, I.},
  title = {Overview of the TREC 2007 Enterprise Track (DRAFT)},
  booktitle = {Proc. of TREC},
  year = {2007},
  owner = {Cheyenne},
  timestamp = {2009.09.21}
}

@INPROCEEDINGS{Bakhshi2014Demographics,
  author = {Bakhshi, Saeideh and Kanuparthy, Partha and Gilbert, Eric},
  title = {Demographics, Weather and Online Reviews: A Study of Restaurant Recommendations},
  booktitle = {Proceedings of the 23rd International Conference on World Wide Web},
  year = {2014},
  series = {WWW '14},
  pages = {443--454},
  address = {Republic and Canton of Geneva, Switzerland},
  publisher = {International World Wide Web Conferences Steering Committee},
  abstract = {Online recommendation sites are valuable information sources that
	people contribute to, and often use to choose restaurants. However,
	little is known about the dynamics behind participation in these
	online communities and how the recommendations in these communities
	are formed. In this work, we take a first look at online restaurant
	recommendation communities to study what endogenous (i.e., related
	to entities being reviewed) and exogenous factors influence people's
	participation in the communities, and to what extent. We analyze
	an online community corpus of 840K restaurants and their 1.1M associated
	reviews from 2002 to 2011, spread across every U.S. state. We construct
	models for number of reviews and ratings by community members, based
	on several dimensions of endogenous and exogenous factors. We find
	that while endogenous factors such as restaurant attributes (e.g.,
	meal, price, service) affect recommendations, surprisingly, exogenous
	factors such as demographics (e.g., neighborhood diversity, education)
	and weather (e.g., temperature, rain, snow, season) also exert a
	significant effect on reviews. We find that many of the effects in
	online communities can be explained using offline theories from experimental
	psychology. Our study is the first to look at exogenous factors and
	how it related to online online restaurant reviews. It has implications
	for designing online recommendation sites, and in general, social
	media and online communities},
  acmid = {2568021},
  file = {Bakhshi2014Demographics.pdf:Bakhshi2014Demographics.pdf:PDF},
  isbn = {978-1-4503-2744-2},
  keywords = {cumulative link model, demographics, negative binomial regression,
	online evaluation, online participation, online ratings, ordered
	logistic regression, ratings, recommendation sites, reviews, weather},
  location = {Seoul, Korea},
  numpages = {12},
  timestamp = {2014.09.13}
}

@InProceedings{Balog2007People,
  author    = {Balog, Krisztian},
  title     = {People search in the enterprise},
  booktitle = {SIGIR '07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval},
  year      = {2007},
  pages     = {916--916},
  address   = {New York, NY, USA},
  publisher = {ACM},
  isbn      = {978-1-59593-597-7},
  location  = {Amsterdam, The Netherlands},
}

@InProceedings{Balog2006Formal,
  author    = {Balog, Krisztian and Azzopardi, Leif and de Rijke, Maarten},
  title     = {Formal models for expert finding in enterprise corpora},
  booktitle = {SIGIR '06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval},
  year      = {2006},
  pages     = {43--50},
  address   = {New York, NY, USA},
  publisher = {ACM},
  isbn      = {1-59593-369-7},
  location  = {Seattle, Washington, USA},
}

@InProceedings{Balog2007Broad,
  author    = {Balog, Krisztian and Bogers, Toine and Azzopardi, Leif and de Rijke, Maarten and van den Bosch, Antal},
  title     = {Broad expertise retrieval in sparse data environments},
  booktitle = {SIGIR '07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval},
  year      = {2007},
  pages     = {551--558},
  address   = {New York, NY, USA},
  publisher = {ACM},
  isbn      = {978-1-59593-597-7},
  location  = {Amsterdam, The Netherlands},
}

@InProceedings{Balog2008Non-local,
  author    = {Balog, Krisztian and de Rijke, Maarten},
  title     = {Non-local evidence for expert finding},
  booktitle = {CIKM '08: Proceeding of the 17th ACM conference on Information and knowledge management},
  year      = {2008},
  pages     = {489--498},
  address   = {New York, NY, USA},
  publisher = {ACM},
  file      = {Balog2008Non-local.pdf:Balog2008Non-local.pdf:PDF},
  isbn      = {978-1-59593-991-3},
  location  = {Napa Valley, California, USA},
}

@InProceedings{Balog2007Finding,
  author    = {Balog, Krisztian and de Rijke, Maarten},
  title     = {Finding similar experts},
  booktitle = {SIGIR '07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval},
  year      = {2007},
  pages     = {821--822},
  address   = {New York, NY, USA},
  publisher = {ACM},
  isbn      = {978-1-59593-597-7},
  location  = {Amsterdam, The Netherlands},
}

@InProceedings{Balog2006Finding,
  author    = {Balog, Krisztian and de Rijke, Maarten},
  title     = {Finding experts and their details in e-mail corpora},
  booktitle = {WWW '06: Proceedings of the 15th international conference on World Wide Web},
  year      = {2006},
  pages     = {1035--1036},
  address   = {New York, NY, USA},
  publisher = {ACM},
  isbn      = {1-59593-323-9},
  location  = {Edinburgh, Scotland},
}

@InProceedings{Balog2008Bloggers,
  author    = {Balog, Krisztian and de Rijke, Maarten and Weerkamp, Wouter},
  title     = {Bloggers as experts: feed distillation using expert retrieval models},
  booktitle = {SIGIR '08: Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval},
  year      = {2008},
  pages     = {753--754},
  address   = {New York, NY, USA},
  publisher = {ACM},
  isbn      = {978-1-60558-164-4},
  location  = {Singapore, Singapore},
}

@INCOLLECTION{Baltrunas2011Context,
  author = {Baltrunas, Linas and Ludwig, Bernd and Peer, Stefan and Ricci, Francesco},
  title = {Context-aware places of interest recommendations for mobile users},
  booktitle = {Design, User Experience, and Usability. Theory, Methods, Tools and
	Practice},
  publisher = {Springer},
  year = {2011},
  pages = {531--540}
}

@InProceedings{Baltrunas2011Matrix,
  author    = {Baltrunas, Linas and Ludwig, Bernd and Ricci, Francesco},
  title     = {Matrix Factorization Techniques for Context Aware Recommendation},
  booktitle = {Proceedings of the Fifth ACM Conference on Recommender Systems},
  year      = {2011},
  series    = {RecSys '11},
  pages     = {301--304},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Context aware recommender systems (CARS) adapt the recommendations
	to the specific situation in which the items will be consumed. In
	this paper we present a novel context-aware recommendation algorithm
	that extends Matrix Factorization. We model the interaction of the
	contextual factors with item ratings introducing additional model
	parameters. The performed experiments show that the proposed solution
	provides comparable results to the best, state of the art, and more
	complex approaches. The proposed solution has the advantage of smaller
	computational cost and provides the possibility to represent at different
	granularities the interaction between context and items. We have
	exploited the proposed model in two recommendation applications:
	places of interest and music.},
  acmid     = {2043988},
  comment   = {r=uv + b_u + b_v + \sum B+{i,j,c_l} 


b },
  file      = {Baltrunas2011Matrix.pdf:Baltrunas2011Matrix.pdf:PDF},
  isbn      = {978-1-4503-0683-6},
  keywords  = {collaborative filtering, context-based reasoning, matrix factorization, recommender systems},
  location  = {Chicago, Illinois, USA},
  numpages  = {4},
}

@InProceedings{Baltrunas2009Context,
  author    = {Baltrunas, Linas and Ricci, Francesco},
  title     = {Context-based Splitting of Item Ratings in Collaborative Filtering},
  booktitle = {Proceedings of the Third ACM Conference on Recommender Systems},
  year      = {2009},
  series    = {RecSys '09},
  pages     = {245--248},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Collaborative Filtering (CF) recommendations are computed by leveraging
	a historical data set of users' ratings for items. It assumes that
	the users' previously recorded ratings can help in predicting future
	ratings. This has been validated extensively, but in some domains
	item ratings can be influenced by contextual conditions, such as
	the time or the goal of the item consumption. This type of information
	is not exploited by standard CF models. This paper introduces and
	analyzes a novel pre-filtering technique for context-aware CF called
	item splitting. In this approach, the ratings of certain items are
	split, according to the value of an item-dependent contextual condition.
	Each split item generates two fictitious items that are used in the
	prediction algorithm instead of the original one. We evaluated this
	approach on real world and semi-synthetic data sets using matrix-factorization
	and nearest neighbor CF algorithms. We show that item splitting can
	be beneficial and its performance depends on the item selection method
	and on the influence of the contextual variables on the item ratings.},
  acmid     = {1639759},
  comment   = {identify items with significant different ratings 
a split is determined by selecting a contextual variable and a partition of its values in two sets
for each item, split the rating to two subsets, create two new artificial items with ratings belong to these two subsets },
  file      = {Baltrunas2009Context.pdf:Baltrunas2009Context.pdf:PDF},
  isbn      = {978-1-60558-435-5},
  keywords  = {collaborative filtering, context-based reasoning, item split, recommender systems},
  location  = {New York, New York, USA},
  numpages  = {4},
}

@INPROCEEDINGS{Banerjee2002scaling,
  author = {Banerjee, A. and Ghosh, J.},
  title = {On scaling up balanced clustering algorithms},
  booktitle = {Proc. 2nd SIAM Int. Conf. Data Mining},
  year = {2002},
  pages = {333--349},
  file = {Banerjee2002scaling.pdf:Banerjee2002scaling.pdf:PDF}
}

@InProceedings{Bansal2007BlogScope,
  author    = {Bansal, Nilesh and Koudas, Nick},
  title     = {BlogScope: spatio-temporal analysis of the blogosphere},
  booktitle = {Proceedings of the 16th international conference on World Wide Web},
  year      = {2007},
  series    = {WWW '07},
  pages     = {1269--1270},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1242802},
  file      = {Bansal2007BlogScope.pdf:Bansal2007BlogScope.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-1-59593-654-7},
  keywords  = {blogs, information discovery, text analysis, trends, visualization},
  location  = {Banff, Alberta, Canada},
  numpages  = {2},
}

@InProceedings{Bansal2007Blogscope,
  author       = {Bansal, N. and Koudas, N.},
  title        = {Blogscope: a system for online analysis of high volume text streams},
  booktitle    = {Proceedings of the 33rd international conference on Very large data bases},
  year         = {2007},
  pages        = {1410--1413},
  organization = {VLDB Endowment},
  abstract     = {We present BlogScope (www.blogscope.net), a system for
	
	online analysis of temporally ordered streaming text, cur-
	
	rently applied to the analysis of the Blogosphere1. The sys-
	
	tem currently tracks over ten million blogs and handles hun-
	
	dreds of thousands of updates daily. BlogScope is an infor-
	
	mation discovery and text analysis system that offers a set
	
	of unique features. Such features include, spatio-temporal
	
	analysis of blogs, flexible navigation of the Blogosphere through
	
	information bursts, keyword correlations and burst synop-
	
	sis, as well as enhanced ranking functions for improved query
	
	answer relevance. We describe the system, its design and the
	
	features of the current version of BlogScope.},
  comment      = {BlogScope identifies what is ‘interest-
	
	ing’, when it was ‘interesting’, why it is ‘interesting’, and
	
	where it is ‘interesting’.
	
	
	On its front page, BlogScope dis-
	
	plays a list of hot keywords. Such keywords are computed
	
	daily from the actual content of blog posts. Based on this
	
	list, a user can formulate a query to seek relevant blog posts.
	
	The traditional text query interface is also supported to
	
	identify posts relevant to a query, in case one is seeking spe-
	
	cific information. Once the keywords of interest are identi-
	
	fied, a query is formed and relevant blog posts are retrieved.
	
	The next question BlogScope aids to answer is when it was
	
	interesting. To answer this question, BlogScope plots the
	
	popularity of the query keywords in blog posts, as a function
	
	of time, and identifies and marks interesting temporal re-
	
	gions as bursts in the keyword popularity. The third step of
	
	the analysis is to investigate why it is interesting. Correlated
	
	keywords (intuitively defined as keywords closely related to
	
	the keyword query at the specified temporal interval) are au-
	
	tomatically displayed by BlogScope. Such keywords aim to
	
	provide explanations or provide insights as to why the key-
	
	word experiences a surge in its popularity. Based on these
	
	keywords, one can refine the search and drill down in the
	
	temporal dimension towards a more focused subset of blog
	
	posts. The final step is to identify where it is interesting.
	
	BlogScope associates with each blog its geographical coordi-
	
	nates. This information is used to annotate the world map
	
	with regions where bloggers are writing about the searched
	
	query.},
  file         = {Bansal2007Blogscope.pdf:Bansal2007Blogscope.pdf:PDF},
}

@ARTICLE{Barabasi2005origin,
  author = {Barabasi, A.L.},
  title = {The origin of bursts and heavy tails in human dynamics},
  journal = {Nature},
  year = {2005},
  volume = {435},
  pages = {207–211},
  file = {Barabasi2005origin.pdf:Barabasi2005origin.pdf:PDF}
}

@InProceedings{Becker2010Learning,
  author    = {Becker, Hila and Naaman, Mor and Gravano, Luis},
  title     = {Learning Similarity Metrics for Event Identification in Social Media},
  booktitle = {Proceedings of the Third ACM International Conference on Web Search and Data Mining},
  year      = {2010},
  series    = {WSDM '10},
  pages     = {291--300},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Social media sites (e.g., Flickr, YouTube, and Facebook) are a popular
	distribution outlet for users looking to share their experiences
	and interests on the Web. These sites host substantial amounts of
	user-contributed materials (e.g., photographs, videos, and textual
	content) for a wide variety of real-world events of different type
	and scale. By automatically identifying these events and their associated
	user-contributed social media documents, which is the focus of this
	paper, we can enable event browsing and search in state-of-the-art
	search engines. To address this problem, we exploit the rich "context"
	associated with social media content, including user-provided annotations
	(e.g., title, tags) and automatically generated information (e.g.,
	content creation time). Using this rich context, which includes both
	textual and non-textual features, we can define appropriate document
	similarity metrics to enable online clustering of media to events.
	As a key contribution of this paper, we explore a variety of techniques
	for learning multi-feature similarity metrics for social media documents
	in a principled manner. We evaluate our techniques on large-scale,
	real-world datasets of event images from Flickr. Our evaluation results
	suggest that our approach identifies events, and their associated
	social media documents, more effectively than the state-of-the-art
	strategies on which we build.},
  acmid     = {1718524},
  groups    = {Twitter},
  isbn      = {978-1-60558-889-6},
  keywords  = {event identification, similarity metric learning, social media},
  location  = {New York, New York, USA},
  numpages  = {10},
}

@INPROCEEDINGS{Beel2013Research,
  author = {Beel, Joeran and Langer, Stefan and Genzmehr, Marcel and Gipp, Bela
	and Breitinger, Corinna and N\"{u}rnberger, Andreas},
  title = {Research Paper Recommender System Evaluation: A Quantitative Literature
	Survey},
  booktitle = {Proceedings of the International Workshop on Reproducibility and
	Replication in Recommender Systems Evaluation},
  year = {2013},
  series = {RepSys '13},
  pages = {15--22},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Over 80 approaches for academic literature recommendation exist today.
	The approaches were introduced and evaluated in more than 170 research
	articles, as well as patents, presentations and blogs. We reviewed
	these approaches and found most evaluations to contain major shortcomings.
	Of the approaches proposed, 21% were not evaluated. Among the evaluated
	approaches, 19% were not evaluated against a baseline. Of the user
	studies performed, 60% had 15 or fewer participants or did not report
	on the number of participants. Information on runtime and coverage
	was rarely provided. Due to these and several other shortcomings
	described in this paper, we conclude that it is currently not possible
	to determine which recommendation approaches for academic literature
	are the most promising. However, there is little value in the existence
	of more than 80 approaches if the best performing approaches are
	unknown.},
  acmid = {2532512},
  file = {Beel2013Research.pdf:Beel2013Research.pdf:PDF},
  isbn = {978-1-4503-2465-6},
  keywords = {comparative study, evaluation, recommender systems, research paper
	recommender systems, survey},
  location = {Hong Kong, China},
  numpages = {8}
}

@INPROCEEDINGS{Bekkerman2001Feature,
  author = {Bekkerman, Ron and El-Yaniv, Ran and Tishby, Naftali and Winter,
	Yoad},
  title = {On Feature Distributional Clustering for Text Categorization},
  booktitle = {Proceedings of the 24th Annual International ACM SIGIR Conference
	on Research and Development in Information Retrieval},
  year = {2001},
  series = {SIGIR '01},
  pages = {146--153},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {383976},
  doi = {10.1145/383952.383976},
  isbn = {1-58113-331-6},
  location = {New Orleans, Louisiana, USA},
  numpages = {8},
  url = {http://doi.acm.org/10.1145/383952.383976}
}

@InProceedings{Bell2007Scalable,
  author       = {Bell, R.M. and Koren, Y.},
  title        = {Scalable collaborative filtering with jointly derived neighborhood interpolation weights},
  booktitle    = {Data Mining, 2007. ICDM 2007. Seventh IEEE International Conference on},
  year         = {2007},
  pages        = {43--52},
  organization = {Ieee},
  abstract     = {Recommender systems based on collaborative filtering
	
	predict user preferences for products or services by learning
	
	past user-item relationships. A predominant approach
	
	to collaborative filtering is neighborhood based (“k-nearest
	
	neighbors”), where a user-item preference rating is interpolated
	
	from ratings of similar items and/or users. We enhance
	
	the neighborhood-based approach leading to substantial
	
	improvement of prediction accuracy, without a
	
	meaningful increase in running time. First, we remove
	
	certain so-called “global effects” from the data to make
	
	the ratings more comparable, thereby improving interpolation
	
	accuracy. Second, we show how to simultaneously derive
	
	interpolation weights for all nearest neighbors, unlike
	
	previous approaches where each weight is computed separately.
	
	By globally solving a suitable optimization problem,
	
	this simultaneous interpolation accounts for the many interactions
	
	between neighbors leading to improved accuracy.
	
	Our method is very fast in practice, generating a prediction
	
	in about 0.2 milliseconds. Importantly, it does not require
	
	training many parameters or a lengthy preprocessing, making
	
	it very practical for large scale applications. Finally, we
	
	show how to apply these methods to the perceivably much
	
	slower user-oriented approach. To this end, we suggest a
	
	novel scheme for low dimensional embedding of the users.
	
	We evaluate these methods on the Netflix dataset, where they
	
	deliver significantly better results than the commercial Netflix
	
	Cinematch recommender system.},
  file         = {Bell2007Scalable.pdf:Bell2007Scalable.pdf:PDF},
  groups       = {Recommender Systems},
}

@Conference{Benajiba2008Arabic,
  author    = {Benajiba, Y. and Rosso, P.},
  title     = {Arabic Named Entity Recognition using Conditional Random Fields},
  booktitle = {Proc. of Workshop on HLT \& NLP within the Arabic World, LREC},
  year      = {2008},
  volume    = {8},
  owner     = {Cheyenne},
  timestamp = {2009.09.21},
}

@InProceedings{Bennett2012Modeling,
  author    = {Bennett, Paul N. and White, Ryen W. and Chu, Wei and Dumais, Susan T. and Bailey, Peter and Borisyuk, Fedor and Cui, Xiaoyuan},
  title     = {Modeling the Impact of Short- and Long-term Behavior on Search Personalization},
  booktitle = {Proceedings of the 35th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year      = {2012},
  series    = {SIGIR '12},
  pages     = {185--194},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {User behavior provides many cues to improve the relevance of search
	results through personalization. One aspect of user behavior that
	provides especially strong signals for delivering better relevance
	is an individual's history of queries and clicked documents. Previous
	studies have explored how short-term behavior or long-term behavior
	can be predictive of relevance. Ours is the first study to assess
	how short-term (session) behavior and long-term (historic) behavior
	interact, and how each may be used in isolation or in combination
	to optimally contribute to gains in relevance through search personalization.
	Our key findings include: historic behavior provides substantial
	benefits at the start of a search session; short-term session behavior
	contributes the majority of gains in an extended search session;
	and the combination of session and historic behavior out-performs
	using either alone. We also characterize how the relative contribution
	of each model changes throughout the duration of a session. Our findings
	have implications for the design of search systems that leverage
	user behavior to personalize the search experience.},
  acmid     = {2348312},
  comment   = {Methodology
	
	
	Document is weighted by an aggregated function that intergrates related
	queries proposed by the same user and the actions the user took w.r.t
	to documents returned to related queries
	
	
	where 
	
	
	related queries are selected from current session, historic and aggregated
	views, and weighted by a temporal decay function},
  doi       = {10.1145/2348283.2348312},
  file      = {Bennett2012Modeling.pdf:Bennett2012Modeling.pdf:PDF},
  isbn      = {978-1-4503-1472-5},
  keywords  = {personalization, web search},
  location  = {Portland, Oregon, USA},
  numpages  = {10},
  timestamp = {2015.03.04},
  url       = {http://doi.acm.org/10.1145/2348283.2348312},
}

@InProceedings{Bermingham2010Classifying,
  author    = {Bermingham, Adam and Smeaton, Alan F.},
  title     = {Classifying sentiment in microblogs: is brevity an advantage?},
  booktitle = {Proceedings of the 19th ACM international conference on Information and knowledge management},
  year      = {2010},
  series    = {CIKM '10},
  pages     = {1833--1836},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Microblogs as a new textual domain offer a unique proposition for
	sentiment analysis. Their short document length suggests any sentiment
	they contain is compact and explicit. However, this short length
	coupled with their noisy nature can pose difficulties for standard
	machine learning document representations. In this work we examine
	the hypothesis that it is easier to classify the sentiment in these
	short form documents than in longer form documents. Surprisingly,
	we find classifying sentiment in microblogs easier than in blogs
	and make a number of observations pertaining to the challenge of
	supervised learning for sentiment analysis in microblogs.},
  acmid     = {1871741},
  doi       = {http://doi.acm.org/10.1145/1871437.1871741},
  file      = {Bermingham2010Classifying.pdf:Bermingham2010Classifying.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-1-4503-0099-5},
  keywords  = {machine learning, sentiment analysis, user generated content},
  location  = {Toronto, ON, Canada},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/1871437.1871741},
}

@InProceedings{Bharat1998Improved,
  author    = {Bharat, Krishna and Henzinger, Monika R.},
  title     = {Improved algorithms for topic distillation in a hyperlinked environment},
  booktitle = {SIGIR '98: Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval},
  year      = {1998},
  pages     = {104--111},
  address   = {New York, NY, USA},
  publisher = {ACM},
  doi       = {http://doi.acm.org/10.1145/290941.290972},
  isbn      = {1-58113-015-5},
  location  = {Melbourne, Australia},
}

@Conference{bian2008finding,
  author       = {Bian, J. and Liu, Y. and Agichtein, E. and Zha, H.},
  title        = {{Finding the right facts in the crowd: factoid question answering over social media}},
  booktitle    = {Proceeding of the 17th international conference on World Wide Web},
  year         = {2008},
  pages        = {467--476},
  organization = {ACM},
  abstract     = {Community Question Answering has emerged as a popu-
	
	lar and e®ective paradigm for a wide range of information
	
	needs. For example, to ¯nd out an obscure piece of trivia, it
	
	is now possible and even very e®ective to post a question on
	
	a popular community QA site such as Yahoo! Answers, and
	
	to rely on other users to provide answers, often within min-
	
	utes. The importance of such community QA sites is magni-
	
	¯ed as they create archives of millions of questions and hun-
	
	dreds of millions of answers, many of which are invaluable for
	
	the information needs of other searchers. However, to make
	
	this immense body of knowledge accessible, e®ective answer
	
	retrieval is required. In particular, as any user can con-
	
	tribute an answer to a question, the majority of the content
	
	re°ects personal, often unsubstantiated opinions. A rank-
	
	ing that combines both relevance and quality is required to
	
	make such archives usable for factual information retrieval.
	
	This task is challenging, as the structure and the contents
	
	of community QA archives di®er signi¯cantly from the web
	
	setting. To address this problem we present a general rank-
	
	ing framework for factual information retrieval from social
	
	media. Results of a large scale evaluation demonstrate that
	
	our method is highly e®ective at retrieving well-formed, fac-
	
	tual answers to questions, as evaluated on a standard factoid
	
	QA benchmark. We also show that our learning framework
	
	can be tuned with the minimum of manual labeling. Finally,
	
	we provide result analysis to gain deeper understanding of
	
	which features are signi¯cant for social media search and re-
	
	trieval. Our system can be used as a crucial building block
	
	for combining results from a variety of social media content
	
	with general web search results, and to better integrate so-
	
	cial media content for e®ective information access.},
  comment      = {Aim: answer retrieval
	
	Features:
	
	content feature(question, answer overlap, semantic/length ratio)
	
	statistical feature(length,lifetime,popularity,rank)
	
	community feature(author popularity, author score)
	
	Algorithm:
	
	Learning to rank with prefered pairs (user evaluated, plus vote fraction
	minus vote)
	
	linear combination of regression trees of features
	
	optimize to achieve maximal matching order of hypothesis function
	and preference pair},
  file         = {bian2008finding.pdf:bian2008finding.pdf:PDF},
}

@InProceedings{Bian2009Learning,
  author    = {Bian, Jiang and Liu, Yandong and Zhou, Ding and Agichtein, Eugene and Zha, Hongyuan},
  title     = {Learning to recognize reliable users and content in social media with coupled mutual reinforcement},
  booktitle = {WWW '09: Proceedings of the 18th international conference on World wide web},
  year      = {2009},
  pages     = {51--60},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Community Question Answering has emerged as a popular forum for users
	to pose questions for other users to answer. over the last few years,
	CQA portals sucha s naver and Yahoo! Answers have exploded in popularity,
	and now provide a viable alternative to general poupose web search.
	at the same time, the answers to past questions submitted in CQA
	sites comprise a valuable knowledge repository which could be a gold
	mine for information retrieval and automatic quetion answering. Unfortunately,
	the quality of the submitted questions and answers varies widely-
	increasingly so that a large fraction of the content is not usable
	for answering queries. Previous approaches for retrieving relevant
	and high quality content have been proposed, but they require large
	amounts of manually labeled data - which limits the applicability
	of the supervised approaches to new sites and domains, In this paper
	we address this problem by developing a semi-supervised coupled mutual
	reinforcement framework for simultaneously caculating content quality
	and user reputation, that requires relatively few labeled examples
	to initialize the training process. Results of a large scale evaluation
	demonstrate that our methods are more effective than previous approaches
	for finding high-quality answers, questions, and users. More importantly,
	our quality etimation significantly improves the accuracy of search
	over CQA archives over the state-of-art methods.},
  comment   = {Data: Yahoo Answers
	
	as ranking
	
	main idea: simultaneously model the quality of ansers, questions and
	the reputation of answerer and asker
	
	
	answerer reputation is proportional to the combined score of answerer's
	answers
	
	answer score is proportional to linear combination of answerer reputation
	and question score
	
	
	etc.},
  doi       = {http://doi.acm.org/10.1145/1526709.1526717},
  file      = {Bian2009Learning.pdf:Bian2009Learning.pdf:PDF},
  isbn      = {978-1-60558-487-4},
  location  = {Madrid, Spain},
}

@ARTICLE{Biancalana2013Approach,
  author = {Biancalana, Claudio and Gasparetti, Fabio and Micarelli, Alessandro
	and Sansonetti, Giuseppe},
  title = {An Approach to Social Recommendation for Context-aware Mobile Services},
  journal = {ACM Trans. Intell. Syst. Technol.},
  year = {2013},
  volume = {4},
  pages = {10:1--10:31},
  number = {1},
  month = feb,
  abstract = {Nowadays, several location-based services (LBSs) allow their users
	to take advantage of information from the Web about points of interest
	(POIs) such as cultural events or restaurants. To the best of our
	knowledge, however, none of these provides information taking into
	account user preferences, or other elements, in addition to location,
	that contribute to define the context of use. The provided suggestions
	do not consider, for example, time, day of week, weather, user activity
	or means of transport. This article describes a social recommender
	system able to identify user preferences and information needs, thus
	suggesting personalized recommendations related to POIs in the surroundings
	of the user's current location. The proposed approach achieves the
	following goals: (i) to supply, unlike the current LBSs, a methodology
	for identifying user preferences and needs to be used in the information
	filtering process; (ii) to exploit the ever-growing amount of information
	from social networking, user reviews, and local search Web sites;
	(iii) to establish procedures for defining the context of use to
	be employed in the recommendation of POIs with low effort. The flexibility
	of the architecture is such that our approach can be easily extended
	to any category of POI. Experimental tests carried out on real users
	enabled us to quantify the benefits of the proposed approach in terms
	of performance improvement.},
  acmid = {2414435},
  address = {New York, NY, USA},
  articleno = {10},
  doi = {10.1145/2414425.2414435},
  file = {Biancalana2013Approach.pdf:Biancalana2013Approach.pdf:PDF},
  issn = {2157-6904},
  issue_date = {January 2013},
  keywords = {Social recommender system, ubiquitous computing, user modeling},
  numpages = {31},
  publisher = {ACM},
  url = {http://doi.acm.org/10.1145/2414425.2414435}
}

@Article{Blei2007correlated,
  author   = {Blei, D.M. and Lafferty, J.D.},
  title    = {{A correlated topic model of science}},
  journal  = {Annals of Applied Statistics},
  year     = {2007},
  volume   = {1(1)},
  number   = {1},
  pages    = {17--35},
  abstract = {Topic models, such as latent Dirichlet allocation (LDA), can be useful
	
	 tools for the statistical analysis of document collections and other
	discrete
	
	 data. The LDA model assumes that the words of each document arise
	from a
	
	 mixture of topics, each of which is a distribution over the vocabulary.
	A limitation
	
	 of LDA is the inability to model topic correlation even though, for
	
	 example, a document about genetics is more likely to also be about
	disease
	
	 than X-ray astronomy. This limitation stems from the use of the Dirichlet
	distribution
	
	 to model the variability among the topic proportions. In this paper
	
	 we develop the correlated topic model (CTM), where the topic proportions
	
	 exhibit correlation via the logistic normal distribution. We derive
	a fast variational inference algorithm
	
	 for approximate posterior inference in this model, which is complicated
	by
	
	 the fact that the logistic normal is not conjugate to the multinomial.
	We apply
	
	 the CTM to the articles from Science published from 1990 to 1999,
	a data
	
	 set that comprises 57M words. The CTM gives a better fit of the data
	than
	
	 LDA, and we demonstrate its use as an exploratory tool of large document
	
	 collections.},
  file     = {Blei2007correlated.pdf:Blei2007correlated.pdf:PDF},
  groups   = {LDA},
}

@Article{Blei2003Latent,
  author    = {Blei, D.M. and Ng, A.Y. and Jordan, M.I.},
  title     = {Latent dirichlet allocation},
  journal   = {Journal of Machine Learning Research},
  year      = {2003},
  volume    = {3},
  number    = {6},
  pages     = {993--1022},
  groups    = {LDA},
  publisher = {MIT Press Cambridge, MA, USA},
}

@ARTICLE{Blei2010Nested,
  author = {Blei, David M. and Griffiths, Thomas L. and Jordan, Michael I.},
  title = {The Nested Chinese Restaurant Process and Bayesian Nonparametric
	Inference of Topic Hierarchies},
  journal = {J. ACM},
  year = {2010},
  volume = {57},
  pages = {7:1--7:30},
  number = {2},
  month = feb,
  abstract = {We present the nested Chinese restaurant process (nCRP), a stochastic
	process that assigns
	
	probability distributions to ensembles of infinitely deep, infinitely
	branching trees. We show how this
	
	stochastic process can be used as a prior distribution in a Bayesian
	nonparametric model of document
	
	collections. Specifically, we present an application to information
	retrieval in which documents are
	
	modeled as paths down a random tree, and the preferential attachment
	dynamics of the nCRP leads
	
	to clustering of documents according to sharing of topics at multiple
	levels of abstraction. Given a
	
	corpus of documents, a posterior inference algorithm finds an approximation
	to a posterior distribution
	
	over trees, topics and allocations of words to levels of the tree.
	We demonstrate this algorithm on
	
	collections of scientific abstracts from several journals. This model
	exemplifies a recent trend in
	
	statistical machine learning},
  acmid = {1667056},
  address = {New York, NY, USA},
  articleno = {7},
  file = {Blei2010Nested.pdf:Blei2010Nested.pdf:PDF},
  issn = {0004-5411},
  issue_date = {January 2010},
  keywords = {Bayesian nonparametric statistics, unsupervised learning},
  numpages = {30},
  publisher = {ACM}
}

@ARTICLE{Blei2006Variational,
  author = {Blei, David M and Jordan, Michael I and others},
  title = {Variational inference for Dirichlet process mixtures},
  journal = {Bayesian analysis},
  year = {2006},
  volume = {1},
  pages = {121--143},
  number = {1},
  abstract = {Dirichlet process (DP) mixture models are the cornerstone of nonparametric
	Bayesian statistics, and the development of Monte-Carlo Markov chain
	(MCMC) sampling methods for DP mixtures has enabled the application
	of nonparametric Bayesian methods to a variety of practical data
	analysis problems. However, MCMC sampling can be prohibitively slow,
	and it is important to explore alternatives. One class of alternatives
	is provided by variational methods, a class of deterministic algorithms
	that convert inference problems into optimization problems (Opper
	and Saad 2001; Wainwright and Jordan 2003). Thus far, variational
	methods have mainly been explored in the parametric setting, in particular
	within the formalism of the exponential family (Attias 2000; Ghahramani
	and Beal 2001; Blei et al. 2003). In this paper, we present a variational
	inference algorithm for DP mixtures. We present experiments that
	compare the algorithm to Gibbs sampling algorithms for DP mixtures
	of Gaussians and present an application to a large-scale image analysis
	problem.},
  file = {Blei2006Variational.pdf:Blei2006Variational.pdf:PDF},
  publisher = {International Society for Bayesian Analysis},
  timestamp = {2015.08.31}
}

@InProceedings{Blei2006Dynamic,
  author    = {Blei, David M. and Lafferty, John D.},
  title     = {Dynamic topic models},
  booktitle = {ICML '06: Proceedings of the 23rd international conference on Machine learning},
  year      = {2006},
  pages     = {113--120},
  address   = {New York, NY, USA},
  publisher = {ACM},
  doi       = {http://doi.acm.org/10.1145/1143844.1143859},
  groups    = {LDA},
  isbn      = {1-59593-383-2},
  location  = {Pittsburgh, Pennsylvania},
}

@Article{Bobadilla2012collaborative,
  author   = {Jesús Bobadilla and Fernando Ortega and Antonio Hernando and Jesús Bernal},
  title    = {A collaborative filtering approach to mitigate the new user cold start problem},
  journal  = {Knowledge-Based Systems},
  year     = {2012},
  volume   = {26},
  number   = {0},
  pages    = {225 - 238},
  abstract = {The new user cold start issue represents a serious problem in recommender
	systems as it can lead to the loss of new users who decide to stop
	using the system due to the lack of accuracy in the recommendations
	received in that first stage in which they have not yet cast a significant
	number of votes with which to feed the recommender system’s collaborative
	filtering core. For this reason it is particularly important to design
	new similarity metrics which provide greater precision in the results
	offered to users who have cast few votes. This paper presents a new
	similarity measure perfected using optimization based on neural learning,
	which exceeds the best results obtained with current metrics. The
	metric has been tested on the Netflix and Movielens databases, obtaining
	important improvements in the measures of accuracy, precision and
	recall when applied to new user cold start situations. The paper
	includes the mathematical formalization describing how to obtain
	the main quality measures of a recommender system using leave-one-out
	cross validation. },
  doi      = {http://dx.doi.org/10.1016/j.knosys.2011.07.021},
  groups   = {Recommender Systems},
  issn     = {0950-7051},
  keywords = {Cold start},
  url      = {http://www.sciencedirect.com/science/article/pii/S0950705111001882},
}

@Article{Bobadilla2013Recommender,
  author   = {J. Bobadilla and F. Ortega and A. Hernando and A. Gutiérrez},
  title    = {Recommender systems survey},
  journal  = {Knowledge-Based Systems},
  year     = {2013},
  volume   = {46},
  number   = {0},
  pages    = {109 - 132},
  abstract = {Abstract Recommender systems have developed in parallel with the web.
	They were initially based on demographic, content-based and collaborative
	filtering. Currently, these systems are incorporating social information.
	In the future, they will use implicit, local and personal information
	from the Internet of things. This article provides an overview of
	recommender systems as well as collaborative filtering methods and
	algorithms; it also explains their evolution, provides an original
	classification for these systems, identifies areas of future implementation
	and develops certain areas selected for past, present or future importance.
	},
  doi      = {http://dx.doi.org/10.1016/j.knosys.2013.03.012},
  file     = {Bobadilla2013Recommender.pdf:Bobadilla2013Recommender.pdf:PDF},
  groups   = {Recommender Systems},
  issn     = {0950-7051},
  keywords = {Recommender systems},
  url      = {http://www.sciencedirect.com/science/article/pii/S0950705113001044},
}

@ARTICLE{bohannon2009counterterrorism,
  author = {Bohannon, J.},
  title = {{Counterterrorism's New Tool:'Metanetwork'Analysis}},
  journal = {Science},
  year = {2009},
  volume = {325},
  pages = {409},
  number = {5939},
  file = {bohannon2009counterterrorism.pdf:bohannon2009counterterrorism.pdf:PDF},
  publisher = {AAAS}
}

@CONFERENCE{Bolelli2007clustering,
  author = {Bolelli, L. and Ertekin, S. and Zhou, D. and Giles, C.L.},
  title = {A clustering method for web data with multi-type interrelated components},
  booktitle = {Proceedings of the 16th international conference on World Wide Web},
  year = {2007},
  pages = {1121--1122},
  organization = {ACM New York, NY, USA},
  owner = {Cheyenne},
  timestamp = {2009.09.21}
}

@INPROCEEDINGS{Bolelli2009Finding,
  author = {Bolelli, Levent and Ertekin, Seyda and Zhou, Ding and Giles, C. Lee},
  title = {Finding topic trends in digital libraries},
  booktitle = {JCDL '09: Proceedings of the 9th ACM/IEEE-CS joint conference on
	Digital libraries},
  year = {2009},
  pages = {69--72},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1555400.1555411},
  isbn = {978-1-60558-322-8},
  location = {Austin, TX, USA}
}

@Article{Bollen2011Twitter,
  author    = {Bollen, J. and H Mao and Xiao-Jun Zeng},
  title     = {Twitter mood predicts the stock market},
  journal   = {Journal of Computational Science},
  year      = {2011},
  volume    = {2},
  number    = {1},
  pages     = {1-8},
  month     = {03/2011},
  abstract  = {Behavioral economics tells us that emotions can profoundly affect
	individual behavior and decision-making. Does this also apply to
	societies at large, i.e., can societies experience mood states that
	affect their collective decision making? By extension is the public
	mood correlated or even predictive of economic indicators? Here we
	investigate whether measurements of collective mood states derived
	from large-scale Twitter feeds are correlated to the value of the
	Dow Jones Industrial Average (DJIA) over time. We analyze the text
	content of daily Twitter feeds by two mood tracking tools, namely
	OpinionFinder that measures positive vs. negative mood and Google-Profile
	of Mood States (GPOMS) that measures mood in terms of 6 dimensions
	(Calm, Alert, Sure, Vital, Kind, and Happy). We cross-validate the
	resulting mood time series by comparing their ability to detect the
	public{\textquoteright}s response to the presidential election and
	Thanksgiving day in 2008. A Granger causality analysis and a Self-Organizing
	Fuzzy Neural Network are then used to investigate the hypothesis
	that public mood states, as measured by the OpinionFinder and GPOMS
	mood time series, are predictive of changes in DJIA closing values.
	Our results indicate that the accuracy of DJIA predictions can be
	significantly improved by the inclusion of specific public mood dimensions
	but not others. We find an accuracy of 87.6\% in predicting the daily
	up and down changes in the closing values of the DJIA and a reduction
	of the Mean Average Percentage Error by more than 6\%.},
  doi       = {10.1016/j.jocs.2010.12.007},
  file      = {Bollen2011Twitter.pdf:Bollen2011Twitter.pdf:PDF},
  groups    = {Twitter},
  keywords  = {Computation and Language, Physics and Society, Social and Information Networks},
  owner     = {linchen},
  timestamp = {2011.11.01},
}

@InProceedings{Bonzanini2013Extractive,
  author    = {Bonzanini, Marco and Martinez-Alvarez, Miguel and Roelleke, Thomas},
  title     = {Extractive Summarisation via Sentence Removal: Condensing Relevant Sentences into a Short Summary},
  booktitle = {Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year      = {2013},
  series    = {SIGIR '13},
  pages     = {893--896},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Many on-line services allow users to describe their opinions about
	a product or a service through a review. In order to help other users
	to find out the major opinion about a given topic, without the effort
	to read several reviews, multi-document summarisation is required.
	This research proposes an approach for extractive summarisation,
	supporting different scoring techniques, such as cosine similarity
	or divergence, as a method for finding representative sentences.
	The main contribution of this paper is the definition of an algorithm
	for sentence removal, developed to maximise the score between the
	summary and the original document. Instead of ranking the sentences
	and selecting the most important ones, the algorithm iteratively
	removes unimportant sentences until a desired compression rate is
	reached. Experimental results show that variations of the sentence
	removal algorithm provide good performance.},
  acmid     = {2484149},
  doi       = {10.1145/2484028.2484149},
  groups    = {Twitter},
  isbn      = {978-1-4503-2034-4},
  keywords  = {divergence, opinion summarisation, sentence removal},
  location  = {Dublin, Ireland},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/2484028.2484149},
}

@InProceedings{Bordino2013Penguins,
  author    = {Bordino, Ilaria and Mejova, Yelena and Lalmas, Mounia},
  title     = {Penguins in Sweaters, or Serendipitous Entity Search on User-generated Content},
  booktitle = {Proceedings of the 22Nd ACM International Conference on Conference on Information \&\#38; Knowledge Management},
  year      = {2013},
  series    = {CIKM '13},
  pages     = {109--118},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {In many cases, when browsing the Web users are searching for specific
	information or answers to concrete questions. Sometimes, though,
	users find unexpected, yet interesting and useful results, and are
	encouraged to explore further. What makes a result serendipitous?
	We propose to answer this question by exploring the potential of
	entities extracted from two sources of user-generated content --
	Wikipedia, a user-curated online encyclopedia, and Yahoo! Answers,
	a more unconstrained question/answering forum -- in promoting serendipitous
	search. In this work, the content of each data source is represented
	as an entity network, which is further enriched with metadata about
	sentiment, writing quality, and topical category. We devise an algorithm
	based on lazy random walk with restart to retrieve entity recommendations
	from the networks. We show that our method provides novel results
	from both datasets, compared to standard web search engines. However,
	unlike previous research, we find that choosing highly emotional
	entities does not increase user interest for many categories of entities,
	suggesting a more complex relationship between topic matter and the
	desirable metadata attributes in serendipitous search.},
  acmid     = {2505680},
  comment   = {lazy random walk = probablity to stay at the same node, probablity
	to transit to another (related) node
	
	start with the query entity
	
	combine the median rank from two entity networks (Yahoo! Answers and
	WikiPedia)
	
	filter results that (1) share at least one topical category with the
	query entity (2) more sentimental results (3) results with higher
	readability},
  file      = {Bordino2013Penguins.pdf:Bordino2013Penguins.pdf:PDF},
  isbn      = {978-1-4503-2263-8},
  keywords  = {entity networks, entity search, interestingness, metadata, serendipity},
  location  = {San Francisco, California, USA},
  numpages  = {10},
}

@InProceedings{Bourke2011Power,
  author    = {Bourke, Steven and McCarthy, Kevin and Smyth, Barry},
  title     = {Power to the People: Exploring Neighbourhood Formations in Social Recommender System},
  booktitle = {Proceedings of the Fifth ACM Conference on Recommender Systems},
  year      = {2011},
  series    = {RecSys '11},
  pages     = {337--340},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {The explosive growth of online social networks in recent times has
	presented a powerful source of information to be utilised in personalised
	recommendations. Unsurprisingly there has already been a large body
	of work completed in the recommender system field to incorporate
	this social information into the recommendation process. In this
	paper we examine the practice of leveraging a user's social graph
	in order to generate recommendations. Using various neighbourhood
	selection strategies, we examine the user satisfaction and the level
	of perceived trust in the recommendations received.},
  acmid     = {2043997},
  comment   = {live user study
	
	different strategies to choose neighbors},
  doi       = {10.1145/2043932.2043997},
  file      = {Bourke2011Power.pdf:Bourke2011Power.pdf:PDF},
  isbn      = {978-1-4503-0683-6},
  keywords  = {collaborative filtering, facebook, recommender system, social network},
  location  = {Chicago, Illinois, USA},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/2043932.2043997},
}

@Article{BouzaProbabilistic,
  author = {Bouza, A. and Reif, G. and Bernstein, A.},
  title  = {Probabilistic Partial User Model Similarity for Collaborative Filtering},
  file   = {BouzaProbabilistic.pdf:BouzaProbabilistic.pdf:PDF},
  groups = {Recommender Systems},
}

@CONFERENCE{brandes2009network,
  author = {Brandes, U. and Kenis, P. and Lerner, J. and van Raaij, D.},
  title = {{Network analysis of collaboration structure in Wikipedia}},
  booktitle = {Proceedings of the 18th international conference on World wide web},
  year = {2009},
  pages = {731--740},
  organization = {ACM},
  abstract = {In this paper we give models and algorithms to describe and
	
	analyze the collaboration among authors of Wikipedia from
	
	a network analytical perspective. The edit network encodes
	
	who interacts how with whom when editing an article; it significantly
	
	extends previous network models that code author
	
	communities in Wikipedia. Several characteristics summarizing
	
	some aspects of the organization process and allowing
	
	the analyst to identify certain types of authors can be obtained
	
	from the edit network. Moreover, we propose several
	
	indicators characterizing the global network structure and
	
	methods to visualize edit networks. It is shown that the
	
	structural network indicators are correlated with quality labels
	
	of the associated Wikipedia articles.},
  file = {brandes2009network.pdf:brandes2009network.pdf:PDF}
}

@ARTICLE{Brin1998anatomy,
  author = {Brin, S. and Page, L.},
  title = {The anatomy of a large-scale hypertextual Web search engine},
  journal = {Computer networks and ISDN systems},
  year = {1998},
  volume = {30},
  pages = {107--117},
  number = {1-7},
  publisher = {Elsevier}
}

@ARTICLE{Bulterman2002computing,
  author = {R.W. Bulterman and F.W. van der Sommen and G. Zwaan and T. Verhoeff
	and A.J.M. van Gasteren and W.H.J. Feijen},
  title = {On computing a longest path in a tree },
  journal = {Information Processing Letters },
  year = {2002},
  volume = {81},
  pages = {93 - 96},
  number = {2},
  doi = {http://dx.doi.org/10.1016/S0020-0190(01)00198-3},
  issn = {0020-0190},
  keywords = {Program derivation},
  url = {http://www.sciencedirect.com/science/article/pii/S0020019001001983}
}

@INPROCEEDINGS{Cai2007MusicSense,
  author = {Cai, Rui and Zhang, Chao and Wang, Chong and Zhang, Lei and Ma, Wei-Ying},
  title = {MusicSense: Contextual Music Recommendation Using Emotional Allocation
	Modeling},
  booktitle = {Proceedings of the 15th International Conference on Multimedia},
  year = {2007},
  series = {MULTIMEDIA '07},
  pages = {553--556},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {1291369},
  doi = {10.1145/1291233.1291369},
  isbn = {978-1-59593-702-5},
  keywords = {MusicSense, contextual music recommendation, emotional allocation
	modeling, moods},
  location = {Augsburg, Germany},
  numpages = {4},
  url = {http://doi.acm.org/10.1145/1291233.1291369}
}

@INPROCEEDINGS{CalaisGuerra2011From,
  author = {Calais Guerra, Pedro Henrique and Veloso, Adriano and Meira,Jr.,
	Wagner and Almeida, Virg\'{\i}lio},
  title = {From Bias to Opinion: A Transfer-learning Approach to Real-time Sentiment
	Analysis},
  booktitle = {Proceedings of the 17th ACM SIGKDD International Conference on Knowledge
	Discovery and Data Mining},
  year = {2011},
  series = {KDD '11},
  pages = {150--158},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Real-time interaction, which enables live discussions, has become
	
	a key feature of most Web applications. In such an environment,
	
	the ability to automatically analyze user opinions and sentiments
	as
	
	discussions develop is a powerful resource known as real time sentiment
	
	analysis. However, this task comes with several challenges,
	
	including the need to deal with highly dynamic textual content that
	
	is characterized by changes in vocabulary and its subjective meaning
	
	and the lack of labeled data needed to support supervised classifiers.
	
	In this paper, we propose a transfer learning strategy to
	
	perform real time sentiment analysis. We identify a task – opinion
	
	holder bias prediction – which is strongly related to the sentiment
	
	analysis task; however, in constrast to sentiment analysis, it builds
	
	accurate models since the underlying relational data follows a stationary
	
	distribution.
	
	Instead of learning textual models to predict content polarity
	
	(i.e., the traditional sentiment analysis approach), we first measure
	
	the bias of social media users toward a topic, by solving a relational
	
	learning task over a network of users connected by endorsements
	
	(e.g., retweets in Twitter). We then analyze sentiments by transferring
	
	user biases to textual features. This approach works because
	
	while new terms may arise and old terms may change their meaning,
	
	user bias tends to be more consistent over time as a basic property
	
	of human behavior. Thus, we adopted user bias as the basis for
	
	building accurate classification models. We applied our model to
	
	posts collected from Twitter on two topics: the 2010 Brazilian Presidential
	
	Elections and the 2010 season of Brazilian Soccer League.
	
	Our results show that knowing the bias of only 10% of users generates
	
	an F1 accuracy level ranging from 80% to 90% in predicting
	
	user sentiment in tweets.},
  acmid = {2020438},
  doi = {10.1145/2020408.2020438},
  file = {CalaisGuerra2011From.pdf:CalaisGuerra2011From.pdf:PDF},
  isbn = {978-1-4503-0813-7},
  keywords = {opinion mining, relational learning, sentiment analysis, social media,
	transfer learning},
  location = {San Diego, California, USA},
  numpages = {9},
  url = {http://doi.acm.org/10.1145/2020408.2020438}
}

@INPROCEEDINGS{Campbell2003Expertise,
  author = {Campbell, Christopher S. and Maglio, Paul P. and Cozzi, Alex and
	Dom, Byron},
  title = {Expertise identification using email communications},
  booktitle = {CIKM '03: Proceedings of the twelfth international conference on
	Information and knowledge management},
  year = {2003},
  pages = {528--531},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/956863.956965},
  isbn = {1-58113-723-0},
  location = {New Orleans, LA, USA}
}

@ARTICLE{Campos2014Survey,
  author = {Campos, Ricardo and Dias, Ga\"{e}l and Jorge, Al\'{\i}pio M. and
	Jatowt, Adam},
  title = {Survey of Temporal Information Retrieval and Related Applications},
  journal = {ACM Comput. Surv.},
  year = {2014},
  volume = {47},
  pages = {15:1--15:41},
  number = {2},
  month = aug,
  abstract = {Temporal information retrieval has been a topic of great interest
	in recent years. Its purpose is to improve the effectiveness of information
	retrieval methods by exploiting temporal information in documents
	and queries. In this article, we present a survey of the existing
	literature on temporal information retrieval. In addition to giving
	an overview of the field, we categorize the relevant research, describe
	the main contributions, and compare different approaches. We organize
	existing research to provide a coherent view, discuss several open
	issues, and point out some possible future research directions in
	this area. Despite significant advances, the area lacks a systematic
	arrangement of prior efforts and an overview of state-of-the-art
	approaches. Moreover, an effective end-to-end temporal retrieval
	system that exploits temporal information to improve the quality
	of the presented results remains undeveloped.},
  acmid = {2619088},
  address = {New York, NY, USA},
  articleno = {15},
  doi = {10.1145/2619088},
  file = {Campos2014Survey.pdf:Campos2014Survey.pdf:PDF},
  issn = {0360-0300},
  issue_date = {August 2014},
  keywords = {Temporal information retrieval, query classification, temporal queries,
	temporal search engines, time-based clustering},
  numpages = {41},
  publisher = {ACM},
  timestamp = {2014.10.04},
  url = {http://doi.acm.org/10.1145/2619088}
}

@InProceedings{Cao2008Selecting,
  author    = {Cao, Guihong and Nie, Jian-Yun and Gao, Jianfeng and Robertson, Stephen},
  title     = {Selecting good expansion terms for pseudo-relevance feedback},
  booktitle = {Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval},
  year      = {2008},
  series    = {SIGIR '08},
  pages     = {243--250},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Pseudo-relevance feedback assumes that most frequent terms in the
	
	pseudo-feedback documents are useful for the retrieval. In this study,
	
	we re-examine this assumption and show that it does not hold in
	
	reality – many expansion terms identified in traditional approaches
	
	are indeed unrelated to the query and harmful to the retrieval. We
	
	also show that good expansion terms cannot be distinguished from
	
	bad ones merely on their distributions in the feedback documents
	
	and in the whole collection. We then propose to integrate a term
	
	classification process to predict the usefulness of expansion terms.
	
	Multiple additional features can be integrated in this process. Our
	
	experiments on three TREC collections show that retrieval
	
	effectiveness can be much improved when term classification is
	
	used. In addition, we also demonstrate that good terms should be
	
	identified directly according to their possible impact on the retrieval
	
	effectiveness, i.e. using supervised learning, instead of unsupervised
	
	learning.},
  acmid     = {1390377},
  doi       = {http://doi.acm.org/10.1145/1390334.1390377},
  file      = {Cao2008Selecting.pdf:Cao2008Selecting.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-1-60558-164-4},
  keywords  = {Pseudo-relevance feedback, SVM, expansion term classification, language models},
  location  = {Singapore, Singapore},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/1390334.1390377},
}

@INPROCEEDINGS{cao2010generalized,
  author = {Cao, X. and Cong, G. and Cui, B. and Jensen, C.S.},
  title = {{A generalized framework of exploring category information for question
	retrieval in community question answer archives}},
  booktitle = {Proceedings of the 19th international conference on World wide web},
  year = {2010},
  pages = {201--210},
  organization = {ACM},
  abstract = {Community Question Answering (CQA) has emerged as a popular type of
	service where users ask and answer questions and access historical
	question-answer pairs. CQA archives contain very large volumes of
	questions organized into a hierarchy of categories. As an essential
	function of CQA services, question retrieval in a CQA archive aims
	to retrieve historical question-answer pairs that are relevant to
	a query question. In this paper, we present a new approach to exploiting
	category information of questions for improving the performance of
	question retrieval, and we apply the approach to existing question
	retrieval models, including a state-of-the-art question retrieval
	model. Experiments conducted on real CQA data demonstrate that the
	proposed techniques are capable of outperforming a variety of baseline
	methods significantly.},
  file = {cao2010generalized.pdf:cao2010generalized.pdf:PDF}
}

@ARTICLE{Carota2002Semiparametric,
  author = {Carota, Cinzia and Parmigiani, Giovanni},
  title = {Semiparametric regression for count data},
  journal = {Biometrika},
  year = {2002},
  volume = {89},
  pages = {265--281},
  number = {2},
  publisher = {Biometrika Trust}
}

@Article{Carpineto2001information-theoretic,
  author    = {Carpineto, Claudio and de Mori, Renato and Romano, Giovanni and Bigi, Brigitte},
  title     = {An information-theoretic approach to automatic query expansion},
  journal   = {ACM Trans. Inf. Syst.},
  year      = {2001},
  volume    = {19},
  pages     = {1--27},
  month     = {January},
  acmid     = {366860},
  address   = {New York, NY, USA},
  doi       = {http://doi.acm.org/10.1145/366836.366860},
  file      = {Carpineto2001information-theoretic.pdf:Carpineto2001information-theoretic.pdf:PDF},
  groups    = {Twitter},
  issn      = {1046-8188},
  issue     = {1},
  keywords  = {automatic query expansion, information retrieval, information theory, pseudorelevance feedback},
  numpages  = {27},
  publisher = {ACM},
  url       = {http://doi.acm.org/10.1145/366836.366860},
}

@ARTICLE{Carpineto2002Improving,
  author = {Carpineto, Claudio and Romano, Giovanni and Giannini, Vittorio},
  title = {Improving retrieval feedback with multiple term-ranking function
	combination},
  journal = {ACM Trans. Inf. Syst.},
  year = {2002},
  volume = {20},
  pages = {259--290},
  month = {July},
  acmid = {568728},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/568727.568728},
  file = {Carpineto2002Improving.pdf:Carpineto2002Improving.pdf:PDF},
  issn = {1046-8188},
  issue = {3},
  keywords = {automatic query expansion, information retrieval, method combination,
	retrieval feedback, short queries},
  numpages = {32},
  publisher = {ACM},
  url = {http://doi.acm.org/10.1145/568727.568728}
}

@Article{Carreras2001Boosting,
  author    = {Xavier Carreras and Llu\'{\i}s M{\`a}rquez},
  title     = {Boosting Trees for Anti-Spam Email Filtering},
  journal   = {CoRR},
  year      = {2001},
  volume    = {cs.CL/0109015},
  bibsource = {DBLP, http://dblp.uni-trier.de},
  ee        = {http://arxiv.org/abs/cs.CL/0109015},
}

@InProceedings{Castillo2011Information,
  author    = {Castillo, Carlos and Mendoza, Marcelo and Poblete, Barbara},
  title     = {Information credibility on twitter},
  booktitle = {Proceedings of the 20th international conference on World wide web},
  year      = {2011},
  series    = {WWW '11},
  pages     = {675--684},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {We analyze the information credibility of news propagated through
	Twitter, a popular microblogging service. Previous research has shown
	that most of the messages posted on Twitter are truthful, but the
	service is also used to spread misinformation and false rumors, often
	unintentionally.
	
	
	On this paper we focus on automatic methods for assessing the credibility
	of a given set of tweets. Specifically, we analyze microblog postings
	related to "trending" topics, and classify them as credible or not
	credible, based on features extracted from them. We use features
	from users' posting and re-posting ("re-tweeting") behavior, from
	the text of the posts, and from citations to external sources.
	
	
	We evaluate our methods using a significant number of human assessments
	about the credibility of items on a recent sample of Twitter postings.
	Our results shows that there are measurable differences in the way
	messages propagate, that can be used to classify them automatically
	as credible or not credible, with precision and recall in the range
	of 70% to 80%.},
  acmid     = {1963500},
  doi       = {http://doi.acm.org/10.1145/1963405.1963500},
  file      = {Castillo2011Information.pdf:Castillo2011Information.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-1-4503-0632-4},
  keywords  = {social media analytics, social media credibility, twitter},
  location  = {Hyderabad, India},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1963405.1963500},
}

@InProceedings{Cataldi2010Emerging,
  author    = {Cataldi, Mario and Di Caro, Luigi and Schifanella, Claudio},
  title     = {Emerging topic detection on Twitter based on temporal and social terms evaluation},
  booktitle = {Proceedings of the Tenth International Workshop on Multimedia Data Mining},
  year      = {2010},
  series    = {MDMKDD '10},
  pages     = {4:1--4:10},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Twitter is a user-generated content system that allows its users to
	share short text messages, called tweets, for a variety of purposes,
	including daily conversations, URLs sharing and information news.
	Considering its world-wide distributed network of users of any age
	and social condition, it represents a low level news flashes portal
	that, in its impressive short response time, has the principal advantage.
	
	
	In this paper we recognize this primary role of Twitter and we propose
	a novel topic detection technique that permits to retrieve in real-time
	the most emergent topics expressed by the community. First, we extract
	the contents (set of terms) of the tweets and model the term life
	cycle according to a novel aging theory intended to mine the emerging
	ones. A term can be defined as emerging if it frequently occurs in
	the specified time interval and it was relatively rare in the past.
	Moreover, considering that the importance of a content also depends
	on its source, we analyze the social relationships in the network
	with the well-known Page Rank algorithm in order to determine the
	authority of the users. Finally, we leverage a navigable topic graph
	which connects the emerging terms with other semantically related
	keywords, allowing the detection of the emerging topics, under user-specified
	time constraints. We provide different case studies which show the
	validity of the proposed approach.},
  acmid     = {1814249},
  articleno = {4},
  doi       = {http://doi.acm.org/10.1145/1814245.1814249},
  groups    = {Twitter},
  isbn      = {978-1-4503-0220-3},
  keywords  = {aging theory, text analysis, topic detection},
  location  = {Washington, D.C.},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1814245.1814249},
}

@INPROCEEDINGS{Celik2014Efficient,
  author = {Safiye Celik and Benjamin Logsdon and Su-In Lee},
  title = {Efficient Dimensionality Reduction for High-Dimensional Network Estimation},
  booktitle = {Proceedings of ICML},
  year = {2014},
  pages = {1334-1342},
  abstract = {We propose module graphical lasso (MGL), an aggressive dimensionality
	reduction and network estimation technique for a high-dimensional
	Gaussian graphical model (GGM). MGL achieves scalability, interpretability
	and robustness by exploiting the modularity property of many real-world
	networks. Variables are organized into tightly coupled modules and
	a graph structure is estimated to determine the conditional independencies
	among modules. MGL iteratively learns the module assignment of variables,
	the latent variables, each corresponding to a module, and the parameters
	of the GGM of the latent variables. In synthetic data experiments,
	MGL outperforms the standard graphical lasso and three other methods
	that incorporate latent variables into GGMs. When applied to gene
	expression data from ovarian cancer, MGL outperforms standard clustering
	algorithms in identifying functionally coherent gene sets and predicting
	survival time of patients. The learned modules and their dependencies
	provide novel insights into cancer biology as well as identifying
	possible novel drug targets.},
  file = {Celik2014Efficient.pdf:Celik2014Efficient.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.06.22}
}

@InProceedings{Chakrabarti2014Joint,
  author    = {Deepayan Chakrabarti and Stanislav Funiak and Jonathan Chang and Sofus A. Macskassy},
  title     = {Joint Inference of Multiple Label Types in Large Networks},
  booktitle = {Proceedings of ICML},
  year      = {2014},
  abstract  = {We tackle the problem of inferring node labels
	
	in a partially labeled graph where each node in
	
	the graph has multiple label types and each label
	
	type has a large number of possible labels. Our
	
	primary example, and the focus of this paper, is
	
	the joint inference of label types such as hometown,
	
	current city, and employers, for users connected
	
	by a social network. Standard label propagation
	
	fails to consider the properties of the label
	
	types and the interactions between them. Our
	
	proposed method, called EDGEEXPLAIN, explicitly
	
	models these, while still enabling scalable
	
	inference under a distributed message-passing
	
	architecture. On a billion-node subset of the
	
	Facebook social network, EDGEEXPLAIN significantly
	
	outperforms label propagation for several
	
	label types, with lifts of up to 120% for recall@1
	
	and 60% for recall@3.},
  comment   = {propagate (a subset)
	
	jointly explain friendship
	
	maximize the explainability, e.g. a label is the reason an edge exist
	
	a sigmoid function truncate to only one type can explain the friendship},
  file      = {Chakrabarti2014Joint.pdf:Chakrabarti2014Joint.pdf:PDF},
  owner     = {littlep},
  timestamp = {2014.06.22},
}

@INPROCEEDINGS{Chaney2015Probabilistic,
  author = {Chaney, Allison J.B. and Blei, David M. and Eliassi-Rad, Tina},
  title = {A Probabilistic Model for Using Social Networks in Personalized Item
	Recommendation},
  booktitle = {Proceedings of the 9th ACM Conference on Recommender Systems},
  year = {2015},
  series = {RecSys '15},
  pages = {43--50},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {2800193},
  file = {Chaney2015Probabilistic.pdf:Chaney2015Probabilistic.pdf:PDF},
  isbn = {978-1-4503-3692-5},
  keywords = {probabilistic models, recommender systems, social networks},
  location = {Vienna, Austria},
  numpages = {8},
  timestamp = {2015.11.12}
}

@InProceedings{Chang2013Towards,
  author    = {Chang, Yi and Wang, Xuanhui and Mei, Qiaozhu and Liu, Yan},
  title     = {Towards Twitter context summarization with user influence models},
  booktitle = {Proceedings of the sixth ACM international conference on Web search and data mining},
  year      = {2013},
  series    = {WSDM '13},
  pages     = {527--536},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Twitter has become one of the most popular platforms for users to
	share information in real time. However, as an individual tweet is
	short and lacks sufficient contextual information, users cannot effectively
	understand or consume information on Twitter, which can either make
	users less engaged or even detached from using Twitter. In order
	to provide informative context to a Twitter user, we propose the
	task of Twitter context summarization, which generates a succinct
	summary from a large but noisy Twitter context tree. Traditional
	summarization techniques only consider text information, which is
	insufficient for Twitter context summarization task, since text information
	on Twitter is very sparse. Given that there are rich user interactions
	in Twitter, we thus study how to improve summarization methods by
	leveraging such signals. In particular, we study how user influence
	models, which project user interaction information onto a Twitter
	context tree, can help Twitter context summarization within a supervised
	learning framework. To evaluate our methods, we construct a data
	set by asking human editors to manually select the most informative
	tweets as a summary. Our experimental results based on this editorial
	data set show that Twitter context summarization is a promising research
	topic and pairwise user influence signals can significantly improve
	the task performance.},
  acmid     = {2433464},
  comment   = {extractive},
  doi       = {10.1145/2433396.2433464},
  groups    = {Twitter},
  isbn      = {978-1-4503-1869-3},
  keywords  = {summarization, twitter context tree, user influence model},
  location  = {Rome, Italy},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2433396.2433464},
}

@INPROCEEDINGS{Charlin2015Dynamic,
  author = {Charlin, Laurent and Ranganath, Rajesh and McInerney, James and Blei,
	David M.},
  title = {Dynamic Poisson Factorization},
  booktitle = {Proceedings of the 9th ACM Conference on Recommender Systems},
  year = {2015},
  series = {RecSys '15},
  pages = {155--162},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Models for recommender systems use latent factors to explain the preferences
	and behaviors of users with respect to a set of items (e.g., movies,
	books, academic papers). Typically, the latent factors are assumed
	to be static and, given these factors, the observed pref- erences
	and behaviors of users are assumed to be generated without order.
	These assumptions limit the explorative and predictive capabilities
	of such models, since users' interests and item popularity may evolve
	over time. To address this, we propose dPF, a dynamic matrix factorization
	model based on the recent Poisson factorization model for recommendations.
	dPF models the time evolving latent factors with a Kalman filter
	and the actions with Poisson distributions. We derive a scalable
	variational inference algorithm to infer the latent factors. Finally,
	we demonstrate dPF on 10 years of user click data from arXiv.org,
	one of the largest repository of scientific papers and a formidable
	source of information about the behavior of scientists. Empirically
	we show performance improvement over both static and, more recently
	proposed, dynamic recommendation models. We also provide a thorough
	exploration of the inferred posteriors over the latent variables.},
  acmid = {2800174},
  file = {Charlin2015Dynamic.pdf:Charlin2015Dynamic.pdf:PDF},
  isbn = {978-1-4503-3692-5},
  keywords = {collaborative filtering, dynamic models, matrix factorization, probabilistic
	models, state space models, variational inference},
  location = {Vienna, Austria},
  numpages = {8},
  timestamp = {2015.12.02}
}

@ARTICLE{Chawla2002SMOTE,
  author = {Chawla, Nitesh V and Bowyer, Kevin W and Hall, Lawrence O and Kegelmeyer,
	W Philip},
  title = {SMOTE: Synthetic Minority Over-sampling Technique},
  journal = {Journal of Artificial Intelligence Research},
  year = {2002},
  volume = {16},
  pages = {321--357}
}

@InProceedings{Chemudugunta2007Modeling,
  author       = {Chemudugunta, C. and Smyth, P. and Steyvers, M.},
  title        = {Modeling general and specific aspects of documents with a probabilistic topic model},
  booktitle    = {Advances in Neural Information Processing Systems 19: Proceedings of the 2006 Conference},
  year         = {2007},
  pages        = {241-248},
  address      = {Vancouver, B.C., Canada},
  organization = {Neural Information Processing Systems (NIPS) Foundation},
  publisher    = {MIT Press},
  file         = {Chemudugunta2007Modeling.pdf:Chemudugunta2007Modeling.pdf:PDF},
  groups       = {LDA},
  owner        = {Cheyenne},
  timestamp    = {2009.09.22},
}

@InProceedings{Chen2011TI,
  author    = {Chun Chen and Feng Li and Beng Chin Ooi and Sai Wu},
  title     = {TI: an efficient indexing mechanism for real-time search on tweets.},
  booktitle = {SIGMOD Conference'11},
  year      = {2011},
  pages     = {649-660},
  abstract  = {Real-time search dictates that new contents be made available for
	search immediately following their creation. From the database perspective,
	this requirement may be quite easily met by creating an up-to-date
	index for the contents and measuring search quality by the time gap
	between insertion time and availability of the index. This approach,
	however, poses new challenges for micro-blogging systems where thousands
	of concurrent users may upload their micro-blogs or tweets simultaneously.
	Due to the high update and query loads, conventional approaches would
	either fail to index the huge amount of newly created contents in
	real time or fall short of providing a scalable indexing service.
	
	
	In this paper, we propose a tweet index called the TI (Tweet Index),
	an adaptive indexing scheme for microblogging systems such as Twitter.
	The intuition of the TI is to index the tweets that may appear as
	a search result with high probability and delay indexing some other
	tweets. This strategy significantly reduces the indexing cost without
	compromising the quality of the search results. In the TI, we also
	devise a new ranking scheme by combining the relationship between
	the users and tweets. We group tweets into topics and update the
	ranking of a topic dynamically. The experiments on a real Twitter
	dataset confirm the efficiency of the TI.},
  file      = {Chen2011TI.pdf:Chen2011TI.pdf:PDF},
  groups    = {Twitter},
  owner     = {linchen},
  timestamp = {2011.11.01},
}

@ARTICLE{Chen2013Hybrid,
  author = {Lin Chen and Lin Chun and Lin Ziyu and Zou Quan},
  title = {Hybrid pseudo-relevance feedback for microblog retrieval},
  journal = {Journal of Information Science},
  year = {2013},
  volume = {39},
  number = {6},
  owner = {littlep},
  timestamp = {2013.11.05}
}

@Article{chen2013hybrid,
  author    = {Chen, Lin and Chun, Lin and Ziyu, Lin and Quan, Zou},
  title     = {Hybrid pseudo-relevance feedback for microblog retrieval},
  journal   = {Journal of Information Science},
  year      = {2013},
  volume    = {39},
  number    = {6},
  pages     = {773--788},
  groups    = {Recommender Systems, Twitter},
  publisher = {Sage Publications},
}

@INPROCEEDINGS{Chen1996empirical,
  author = {Chen, S.F. and Goodman, J.},
  title = {An empirical study of smoothing techniques for language modeling},
  booktitle = {Proceedings of the 34th annual meeting on Association for Computational
	Linguistics},
  year = {1996},
  pages = {310--318},
  organization = {Association for Computational Linguistics},
  file = {Chen1996empirical.pdf:Chen1996empirical.pdf:PDF}
}

@ARTICLE{Chen2011Semi,
  author = {Shouchun Chen and Fei Wang and Yangqiu Song and Changshui Zhang},
  title = {Semi-supervised ranking aggregation },
  journal = {Information Processing \& Management },
  year = {2011},
  volume = {47},
  pages = {415 - 425},
  number = {3},
  abstract = {Ranking aggregation is a task of combining multiple ranking lists
	given by several experts or simple rankers to get a hopefully better
	ranking. It is applicable in several fields such as meta search and
	collaborative filtering. Most of the existing work is under an unsupervised
	framework. In these methods, the performances are usually limited
	especially in unreliable case since labeled information is not involved
	in. In this paper, we propose a semi-supervised ranking aggregation
	method, in which preference constraints of several item pairs are
	given. In our method, the aggregation function is learned based on
	the ordering agreement of different rankers. The ranking scores assigned
	by this ranking function on the labeled data should be consistent
	with the given pairwise order constraints while the ranking scores
	on the unlabeled data obey the intrinsic manifold structure of the
	rank items. The experimental results on toy data and the \{OHSUMED\}
	data are presented to illustrate the validity of our method. },
  doi = {http://dx.doi.org/10.1016/j.ipm.2010.09.003},
  file = {Chen2011Semi.pdf:Chen2011Semi.pdf:PDF},
  issn = {0306-4573},
  keywords = {Ranking aggregation},
  timestamp = {2015.09.23},
  url = {http://www.sciencedirect.com/science/article/pii/S0306457310000750}
}

@INPROCEEDINGS{Chen2014Boosting,
  author = {Shang-Tse Chen and Hsuan-Tien Lin and Chi-Jen Lu},
  title = {Boosting with Online Binary Learners for the Multiclass Bandit Problem},
  booktitle = {Proceedings of ICML},
  year = {2014},
  pages = {368-346},
  abstract = {We consider the problem of online multiclass prediction in the bandit
	setting. Compared with the full-information setting, in which the
	learner can receive the true label as feedback after making each
	prediction, the bandit setting assumes that the learner can only
	know the correctness of the predicted label. Because the bandit setting
	is more restricted, it is difficult to design good bandit learners
	and currently there are not many bandit learners. In this paper,
	we propose an approach that systematically converts existing online
	binary classifiers to promising bandit learners with strong theoretical
	guarantee. The approach matches the idea of boosting, which has been
	shown to be powerful for batch learning as well as online learning.
	In particular, we establish the weak-learning condition on the online
	binary classifiers, and show that the condition allows automatically
	constructing a bandit learner with arbitrary strength by combining
	several of those classifiers. Experimental results on several real-world
	data sets demonstrate the effectiveness of the proposed approach.},
  file = {Chen2014Boosting.pdf:Chen2014Boosting.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.06.23}
}

@Conference{chen2009collaborative,
  author       = {Chen, W.Y. and Chu, J.C. and Luan, J. and Bai, H. and Wang, Y. and Chang, E.Y.},
  title        = {{Collaborative filtering for orkut communities: discovery of user latent behavior}},
  booktitle    = {Proceedings of the 18th international conference on World wide web},
  year         = {2009},
  pages        = {681--690},
  organization = {ACM},
}

@InProceedings{Chen2013Modeling,
  author    = {Chen, Wei and Hsu, Wynne and Lee, Mong Li},
  title     = {Modeling User's Receptiveness over Time for Recommendation},
  booktitle = {Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year      = {2013},
  series    = {SIGIR '13},
  pages     = {373--382},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Existing recommender systems model user interests and the
	
	social influences independently. In reality, user interests may
	
	change over time, and as the interests change, new friends
	
	may be added while old friends grow apart and the new
	
	friendships formed may cause further interests change. This
	
	complex interaction requires the joint modeling of user interest
	
	and social relationships over time. In this paper, we
	
	propose a probabilistic generative model, called Receptive-
	
	ness over Time Model (RTM), to capture this interaction.
	
	We design a Gibbs sampling algorithm to learn the receptiveness
	
	and interest distributions among users over time. The
	
	results of experiments on a real world dataset demonstrate
	
	that RTM-based recommendation outperforms the state-ofthe-
	
	art recommendation methods. Case studies also show
	
	that RTM is able to discover the user interest shift and receptiveness
	
	change over time.},
  acmid     = {2484047},
  comment   = {model: RTM 
	
	LDA type generative model
	
	in a timeslot:
	
	choose a friend according to his receptiveness distribution at the
	time, and choose a topic according to the friend's preference, 
	
	
	for all timestamps:
	
	the user preference, and receptiveness shifts, dependent on the last
	timeslot
	
	the dependency between two consecutive snapshots is the previous preference
	is proportional to the parameter for the next time in a dirichlet
	distribution
	
	the general user topic -item- topic distribution rating parameter
	doesn't change
	
	experiments: epinions},
  file      = {Chen2013Modeling.pdf:Chen2013Modeling.pdf:PDF},
  isbn      = {978-1-4503-2034-4},
  keywords  = {collaborative filtering, personalization, recommendation, social trust},
  location  = {Dublin, Ireland},
  numpages  = {10},
  timestamp = {2015.12.02},
}

@Conference{Chen2009Efficient,
  author       = {Chen, W. and Wang, Y. and Yang, S.},
  title        = {{Efficient influence maximization in social networks}},
  booktitle    = {Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining},
  year         = {2009},
  pages        = {199--208},
  organization = {ACM},
  abstract     = {Influence maximization is the problem of finding a small subset
	
	of nodes (seed nodes) in a social network that could maximize the
	
	spread of influence. In this paper, we study the efficient influence
	
	maximization from two complementary directions. One is to improve
	
	the original greedy algorithm of [5] and its improvement [7]
	
	to further reduce its running time, and the second is to propose new
	
	degree discount heuristics that improves influence spread. We evaluate
	
	our algorithms by experiments on two large academic collaboration
	
	graphs obtained from the online archival database arXiv.org.
	
	Our experimental results show that (a) our improved greedy algorithm
	
	achieves better running time comparing with the improvement
	
	of [7] with matching influence spread, (b) our degree discount
	
	heuristics achieve much better influence spread than classic degree
	
	and centrality-based heuristics, and when tuned for a specific influence
	
	cascade model, it achieves almost matching influence thread
	
	with the greedy algorithm, and more importantly (c) the degree discount
	
	heuristics run only in milliseconds while even the improved
	
	greedy algorithms run in hours in our experiment graphs with a few
	
	tens of thousands of nodes.
	
	Based on our results, we believe that fine-tuned heuristics may
	
	provide truly scalable solutions to the influence maximization problem
	
	with satisfying influence spread and blazingly fast running
	
	time. Therefore, contrary to what implied by the conclusion of [5]
	
	that traditional heuristics are outperformed by the greedy approximation
	
	algorithm, our results shed new lights on the research of
	
	heuristic algorithms.},
  comment      = {In each round i, the algorithm adds one
	
	vertex into the selected set S such that this vertex together with
	current
	
	set S maximizes the influence spread},
  file         = {Chen2009Efficient.pdf:Chen2009Efficient.pdf:PDF},
  keywords     = {social networks, influence maximization, heuristic algorithms},
}

@InProceedings{Chen2013Pairwise,
  author    = {Chen, Xi and Bennett, Paul N. and Collins-Thompson, Kevyn and Horvitz, Eric},
  title     = {Pairwise Ranking Aggregation in a Crowdsourced Setting},
  booktitle = {Proceedings of the Sixth ACM International Conference on Web Search and Data Mining},
  year      = {2013},
  series    = {WSDM '13},
  pages     = {193--202},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Inferring rankings over elements of a set of objects, such as documents
	or images, is a key learning problem for such important applications
	as Web search and recommender systems. Crowdsourcing services provide
	an inexpensive and efficient means to acquire preferences over objects
	via labeling by sets of annotators. We propose a new model to predict
	a gold-standard ranking that hinges on combining pairwise comparisons
	via crowdsourcing. In contrast to traditional ranking aggregation
	methods, the approach learns about and folds into consideration the
	quality of contributions of each annotator. In addition, we minimize
	the cost of assessment by introducing a generalization of the traditional
	active learning scenario to jointly select the annotator and pair
	to assess while taking into account the annotator quality, the uncertainty
	over ordering of the pair, and the current model uncertainty. We
	formalize this as an active learning strategy that incorporates an
	exploration-exploitation tradeoff and implement it using an efficient
	online Bayesian updating scheme. Using simulated and real-world data,
	we demonstrate that the active learning strategy achieves significant
	reductions in labeling cost while maintaining accuracy.},
  acmid     = {2433420},
  comment   = {inconsistent annotations
	
	anotatation quality
	
	budget concious},
  doi       = {10.1145/2433396.2433420},
  file      = {Chen2013Pairwise.pdf:Chen2013Pairwise.pdf:PDF},
  isbn      = {978-1-4503-1869-3},
  keywords  = {crowdsourcing, pairwise preference, ranking},
  location  = {Rome, Italy},
  numpages  = {10},
  timestamp = {2015.09.22},
  url       = {http://doi.acm.org/10.1145/2433396.2433420},
}

@InProceedings{Chen2011Diversifying,
  author    = {Chen, Xiangru and Wang, Haofen and Sun, Xinruo and Pan, Junfeng and Yu, Yong},
  title     = {Diversifying Product Search Results},
  booktitle = {Proceedings of the 34th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year      = {2011},
  series    = {SIGIR '11},
  pages     = {1093--1094},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {In recent years, online shopping is becoming more and more popular.
	Users type keyword queries on product search systems to find relevant
	products, accessories, and even related products. However, existing
	product search systems always return very similar products on the
	first several pages instead of taking diversity into consideration.
	In this paper, we propose a novel approach to address the diversity
	issue in the context of product search. We transform search result
	diversification into a combination of diversifying product categories
	and diversifying product attribute values within each category. The
	two sub-problems are optimization problems which can be reduced into
	well-known NP-hard problems respectively. We further leverage greedy-based
	approximation algorithms for efficient product search results re-ranking.},
  acmid     = {2010065},
  comment   = {category},
  file      = {Chen2011Diversifying.pdf:Chen2011Diversifying.pdf:PDF},
  isbn      = {978-1-4503-0757-4},
  keywords  = {product search, result diversification},
  location  = {Beijing, China},
  numpages  = {2},
  timestamp = {2016.04.25},
}

@InProceedings{Chen2013Emerging,
  author    = {Chen, Yan and Amiri, Hadi and Li, Zhoujun and Chua, Tat-Seng},
  title     = {{Emerging topic detection for organizations from microblogs}},
  booktitle = {Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval - SIGIR '13},
  year      = {2013},
  pages     = {43},
  address   = {New York, New York, USA},
  month     = jul,
  publisher = {ACM Press},
  abstract  = {Microblog services have emerged as an essential way to strengthen
	the communications among individuals and organizations. These services
	promote timely and active discussions and comments towards products,
	markets as well as public events, and have attracted a lot of attentions
	from organizations. In particular, emerging topics are of immediate
	concerns to organizations since they signal current concerns of,
	and feedback by their users. Two challenges must be tackled for effective
	emerging topic detection. One is the problem of real-time relevant
	data collection and the other is the ability to model the emerging
	characteristics of detected
	
	topics and identify them before they become hot topics.
	
	To tackle these challenges, we first design a novel scheme to
	
	crawl the relevant messages related to the designated organization
	
	by monitoring multi-aspects of microblog content,
	
	including users, the evolving keywords and their temporal
	
	sequence. We then develop an incremental clustering framework
	
	to detect new topics, and employ a range of content
	
	and temporal features to help in promptly detecting hot emerging
	
	topics. Extensive evaluations on a representative
	
	real-world dataset based on Twitter data demonstrate that
	
	our scheme is able to characterize emerging topics well and
	
	detect them before they become hot topics.},
  doi       = {10.1145/2484028.2484057},
  file      = {Chen2013Emerging.pdf:Chen2013Emerging.pdf:PDF},
  groups    = {Twitter},
  isbn      = {9781450320344},
  keywords  = {brand monitoring,emerging topic detection,microblog service,organization monitoring,topic detection},
  url       = {http://dl.acm.org/citation.cfm?id=2484028.2484057},
}

@InProceedings{Chen2014Weighted,
  author    = {Yudong Chen and Shiau Hong Lim and Huan Xu},
  title     = {Weighted Graph Clustering with Non-Uniform Uncertainties W},
  booktitle = {Proceedings of ICML},
  year      = {2014},
  pages     = {1172-1180},
  abstract  = {We study the graph clustering problem where each observation (edge
	or no-edge between a pair of nodes) may have a different level of
	confidence/uncertainty. We propose a clustering algorithm that is
	based on optimizing an appropriate weighted objective, where larger
	weights are given to observations with lower uncertainty. Our approach
	leads to a convex optimization problem that is efficiently solvable.
	We analyze our approach under a natural generative model, and establish
	theoretical guarantees for recovering the underlying clusters. Our
	main result is a general theorem that applies to any given weight
	and distribution for the uncertainty. By optimizing over the weights,
	we derive a provably {optimal} weighting scheme, which matches the
	information theoretic lower bound up to logarithmic factors and leads
	to strong performance bounds in several specific settings. By optimizing
	over the uncertainty distribution, we show that non-uniform uncertainties
	can actually help. In particular, if the graph is built by spending
	a limited amount of resource to take measurement on each node pair,
	then it is beneficial to allocate the resource in a non-uniform fashion
	to obtain accurate measurements on a few pairs of nodes, rather than
	obtaining inaccurate measurements on many pairs. We provide simulation
	results that validate our theoretical findings.},
  comment   = {assume there are no links across cluster, there are links between
	each pair of nodes in the same cluster},
  file      = {Chen2014Weighted.pdf:Chen2014Weighted.pdf:PDF},
  owner     = {littlep},
  timestamp = {2014.06.22},
}

@ARTICLE{Chen2011Projection,
  author = {Chen, Yunmei and Ye, Xiaojing},
  title = {Projection onto a simplex},
  journal = {arXiv preprint arXiv:1101.6081},
  year = {2011},
  file = {Chen2011Projection.pdf:Chen2011Projection.pdf:PDF}
}

@ARTICLE{Chen2013Learning,
  author = {Z. Chen and T. Li and Y. Sun},
  title = {A Learning Approach to SQL Query Results Ranking Using Skyline and
	Users' Current Navigational Behavior},
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  year = {2013},
  volume = {25},
  pages = {2683-2693},
  number = {12},
  month = {Dec},
  abstract = {Users often find that their queries against a database return too
	many answers, many of them irrelevant. A common solution is to rank
	the query results. The effectiveness of a ranking function depends
	on how well it captures users' preferences. However, database systems
	often do not have the complete information about users' preferences
	and users' preferences are often heterogeneous (i.e., some preferences
	are static and common to all users while some are dynamic and diverse).
	Existing solutions do not address these two issues. In this paper,
	we propose a novel approach to address these shortcomings: 1) it
	addresses the heterogeneous issue by using skyline to capture users'
	static and common preferences and using users' current navigational
	behavior to capture users' dynamic and diverse preferences; 2) it
	addresses the incompleteness issue by using a machine learning technique
	to learn a ranking function based on training examples constructed
	from the above two types of information. Experimental results demonstrate
	the benefits of our approach.},
  doi = {10.1109/TKDE.2012.128},
  file = {Chen2013Learning.pdf:Chen2013Learning.pdf:PDF},
  issn = {1041-4347},
  keywords = {SQL;database management systems;human computer interaction;learning
	(artificial intelligence);query processing;SQL query results ranking;database
	systems;machine learning technique;ranking function;skyline;training;user
	diverse preferences;users common preferences;users current navigational
	behavior;users dynamic preferences;users static preferences;Databases;Information
	retrieval;Query processing;Search problems;Structured query language;Support
	vector machines;Data and knowledge visualization;interactive data
	exploration and discovery}
}

@INPROCEEDINGS{Chen2014Topic,
  author = {Zhiyuan Chen and Bing Liu},
  title = {Topic Modeling using Topics from Many Domains, Lifelong Learning
	and Big Data},
  booktitle = {Proceedings of ICML},
  year = {2014},
  pages = {694-702},
  abstract = {Topic modeling has been commonly used to discover topics from document
	collections. However, unsupervised models can generate many incoherent
	topics. To address this problem, several knowledge-based topic models
	have been proposed to incorporate prior domain knowledge from the
	user. This work advances this research much further and shows that
	without any user input, we can mine the prior knowledge automatically
	and dynamically from topics already found from a large number of
	domains. This paper first proposes a novel method to mine such prior
	knowledge dynamically in the modeling process, and then a new topic
	model to use the knowledge to guide the model inference. What is
	also interesting is that this approach offers a novel lifelong learning
	algorithm for topic discovery, which exploits the big (past) data
	and knowledge gained from such data for subsequent modeling. Our
	experimental results using product reviews from 50 domains demonstrate
	the effectiveness of the proposed approach.},
  file = {Chen2014Topic.pdf:Chen2014Topic.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.06.24}
}

@INPROCEEDINGS{Chen2015AVER,
  author = {Chen, Zhen and Xia, Feng and Jiang, Huizhen and Liu, Haifeng and
	Zhang, Jun},
  title = {AVER: Random Walk Based Academic Venue Recommendation},
  booktitle = {Proceedings of the 24th International Conference on World Wide Web},
  year = {2015},
  series = {WWW '15 Companion},
  pages = {579--584},
  address = {Republic and Canton of Geneva, Switzerland},
  publisher = {International World Wide Web Conferences Steering Committee},
  acmid = {2741738},
  file = {Chen2015AVER.pdf:Chen2015AVER.pdf:PDF},
  isbn = {978-1-4503-3473-0},
  keywords = {academic venue recommendation, big scholarly data, co-publication
	network, random walk},
  location = {Florence, Italy},
  numpages = {6},
  timestamp = {2015.12.02}
}

@INPROCEEDINGS{Cheng2014Parallel,
  author = {Cheng, Dehua and Liu, Yan},
  title = {Parallel Gibbs Sampling for Hierarchical Dirichlet Processes via
	Gamma Processes Equivalence},
  booktitle = {Proceedings of the 20th ACM SIGKDD International Conference on Knowledge
	Discovery and Data Mining},
  year = {2014},
  series = {KDD '14},
  pages = {562--571},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {The hierarchical Dirichlet process (HDP) is an intuitive and elegant
	technique to model data with latent groups. However, it has not been
	widely used for practical applications due to the high computational
	costs associated with inference. In this paper, we propose an effective
	parallel Gibbs sampling algorithm for HDP by exploring its connections
	with the gamma-gamma-Poisson process. Specifically, we develop a
	novel framework that combines bootstrap and Reversible Jump MCMC
	algorithm to enable parallel variable updates. We also provide theoretical
	convergence analysis based on Gibbs sampling with asynchronous variable
	updates. Experiment results on both synthetic datasets and two large-scale
	text collections show that our algorithm can achieve considerable
	speedup as well as better inference accuracy for HDP compared with
	existing parallel sampling algorithms.},
  acmid = {2623708},
  doi = {10.1145/2623330.2623708},
  file = {Cheng2014Parallel.pdf:Cheng2014Parallel.pdf:PDF},
  isbn = {978-1-4503-2956-9},
  keywords = {hierarchical dirichlet process, parallel inference, topic model},
  location = {New York, New York, USA},
  numpages = {10},
  timestamp = {2015.08.26},
  url = {http://doi.acm.org/10.1145/2623330.2623708}
}

@INPROCEEDINGS{Cheng2012Hierarchical,
  author = {Cheng, Wei and Zhang, Xiang and Pan, Feng and Wang, Wei},
  title = {Hierarchical Co-clustering Based on Entropy Splitting},
  booktitle = {Proceedings of the 21st ACM International Conference on Information
	and Knowledge Management},
  year = {2012},
  series = {CIKM '12},
  pages = {1472--1476},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Two dimensional contingency tables or co-occurrence matrices arise
	frequently in various important applications such as text analysis
	and web-log mining. As a fundamental research topic, co-clustering
	aims to generate a meaningful partition of the contingency table
	to reveal hidden relationships between rows and columns. Traditional
	co-clustering algorithms usually produce a predefined number of flat
	partition of both rows and columns, which do not reveal relationship
	among clusters. To address this limitation, hierarchical co-clustering
	algorithms have attracted a lot of research interests recently. Although
	successful in various applications, the existing hierarchial co-clustering
	algorithms are usually based on certain heuristics and do not have
	solid theoretical background.
	
	
	In this paper, we present a new co-clustering algorithm with solid
	information theoretic background. It simultaneously constructs a
	hierarchical structure of both row and column clusters which retains
	sufficient mutual information between rows and columns of the contingency
	table. An efficient and effective greedy algorithm is developed which
	grows a co-cluster hierarchy by successively performing row-wise
	or column-wise splits that lead to the maximal mutual information
	gain. Extensive experiments on real datasets demonstrate that our
	algorithm can reveal essential relationships of row (and column)
	clusters and has better clustering precision than existing algorithms.},
  acmid = {2398455},
  file = {Cheng2012Hierarchical.pdf:Cheng2012Hierarchical.pdf:PDF},
  isbn = {978-1-4503-1156-4},
  keywords = {co-clustering, contingency table, entropy, text analysis},
  location = {Maui, Hawaii, USA},
  numpages = {5},
  timestamp = {2015.11.12}
}

@ARTICLE{cho2009ourselves,
  author = {Cho, A.},
  title = {{Ourselves and Our Interactions: The Ultimate Physics Problem?}},
  journal = {Science},
  year = {2009},
  volume = {325},
  pages = {406},
  number = {5939},
  file = {cho2009ourselves.pdf:cho2009ourselves.pdf:PDF},
  publisher = {AAAS}
}

@INPROCEEDINGS{Choi2003Topic,
  author = {Choi, Ikkyu and Kim, Minkoo},
  title = {Topic distillation using hierarchy concept tree},
  booktitle = {SIGIR '03: Proceedings of the 26th annual international ACM SIGIR
	conference on Research and development in informaion retrieval},
  year = {2003},
  pages = {371--372},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {In this paper, we propose a new approach for topic distillation on
	World Wide Web. Topic distillation is to find quality documents related
	to the user query topic. Our approach is based on Bharat's topic
	distillation algorithm [1]. We present the analysis of hyperlink
	graph structure using hierarchy concept tree to solve the mixed hubs
	problem that is also remained in the Bharat's algorithm. For assigning
	better weights to hyperlinks which point to relevant documents among
	hyperlinks in a document, we try to find the relationship in documents
	connected by hyperlinks using content analysis and we assign weights
	to hyperlinks based on the relationship. We evaluated this algorithm
	using 50 topics on WT10g corpus and obtained improved results.},
  doi = {http://doi.acm.org/10.1145/860435.860506},
  isbn = {1-58113-646-3},
  location = {Toronto, Canada}
}

@INPROCEEDINGS{Choi2012CONSENTO,
  author = {Choi, Jaehoon and Kim, Donghyeon and Kim, Seongsoon and Lee, Junkyu
	and Lim, Sangrak and Lee, Sunwon and Kang, Jaewoo},
  title = {CONSENTO: A New Framework for Opinion Based Entity Search and Summarization},
  booktitle = {Proceedings of the 21st ACM International Conference on Information
	and Knowledge Management},
  year = {2012},
  series = {CIKM '12},
  pages = {1935--1939},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Search engines have become an important decision making tool today.
	Decision making queries are often subjective, such as "a good birthday
	present for my girlfriend", "best action movies in 2010", to name
	a few. Unfortunately, such queries may not be answered properly by
	conventional search systems. In order to address this problem, we
	introduce Consento, a consensus search engine designed to answer
	subjective queries. Consento performs segment indexing, as opposed
	to document indexing, to capture semantics from user opinions more
	precisely. In particular, we define a new indexing unit, Maximal
	Coherent Semantic Unit (MCSU).
	
	
	An MCSU represents a segment of a document, which captures a single
	coherent semantic. We also introduce a new ranking method, called
	ConsensusRank that counts online comments referring to an entity
	as a weighted vote. In order to validate the efficacy of the proposed
	framework, we compare Consento with standard retrieval models and
	their recent extensions for opinion based entity ranking. Experiments
	using movie and hotel data show the effectiveness of our framework.},
  acmid = {2398547},
  file = {Choi2012CONSENTO.pdf:Choi2012CONSENTO.pdf:PDF},
  isbn = {978-1-4503-1156-4},
  keywords = {consensus rank, consensus search, entity search, maximal coherent
	semantic unit, sentiment analysis},
  location = {Maui, Hawaii, USA},
  numpages = {5},
  timestamp = {2014.5.25}
}

@INPROCEEDINGS{Chu2009Personalized,
  author = {Chu, Wei and Park, Seung-Taek},
  title = {Personalized recommendation on dynamic content using predictive bilinear
	models},
  booktitle = {Proceedings of the 18th international conference on World wide web},
  year = {2009},
  series = {WWW '09},
  pages = {691--700},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {In Web-based services of dynamic content (such as news articles),
	recommender systems face the difficulty of timely identifying new
	items of high-quality and providing recommendations for new users.
	We propose a feature-based machine learning approach to personalized
	recommendation that is capable of handling the cold-start issue effectively.
	We maintain profiles of content of interest, in which temporal characteristics
	of the content, e.g. popularity and freshness, are updated in real-time
	manner. We also maintain profiles of users including demographic
	information and a summary of user activities within Yahoo! properties.
	Based on all features in user and content profiles, we develop predictive
	bilinear regression models to provide accurate personalized recommendations
	of new items for both existing and new users. This approach results
	in an offline model with light computational overhead compared with
	other recommender systems that require online re-training. The proposed
	framework is general and flexible for other personalized tasks. The
	superior performance of our approach is verified on a large-scale
	data set collected from the Today-Module on Yahoo! Front Page, with
	comparison against six competitive approaches.},
  acmid = {1526802},
  doi = {10.1145/1526709.1526802},
  isbn = {978-1-60558-487-4},
  keywords = {bilinear models, dynamic features, personalization, ranking, recommender
	systems, regression, user and content profile},
  location = {Madrid, Spain},
  numpages = {10},
  url = {http://doi.acm.org/10.1145/1526709.1526802}
}

@BOOK{chung1997spectral,
  title = {Spectral graph theory},
  publisher = {Amer Mathematical Society},
  year = {1997},
  author = {Chung, F.R.K.}
}

@ARTICLE{clauset2004finding,
  author = {Clauset, A. and Newman, MEJ and Moore, C.},
  title = {Finding community structure in very large networks},
  journal = {Physical Review E},
  year = {2004},
  volume = {70},
  pages = {66111},
  number = {6},
  publisher = {APS}
}

@ARTICLE{cohn2001missing,
  author = {Cohn, D. and Hofmann, T.},
  title = {{The missing link-a probabilistic model of document content and hypertext
	connectivity}},
  journal = {Advances in neural information processing systems},
  year = {2001},
  pages = {430--436},
  publisher = {MIT; 1998}
}

@INPROCEEDINGS{Cong2008Finding,
  author = {Cong, Gao and Wang, Long and Lin, Chin-Yew and Song, Young-In and
	Sun, Yueheng},
  title = {Finding question-answer pairs from online forums},
  booktitle = {SIGIR '08: Proceedings of the 31st annual international ACM SIGIR
	conference on Research and development in information retrieval},
  year = {2008},
  pages = {467--474},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1390334.1390415},
  isbn = {978-1-60558-164-4},
  location = {Singapore, Singapore}
}

@INPROCEEDINGS{Cortes2014Ensemble,
  author = {Corinna Cortes and Vitaly Kuznetsov and Mehryar Mohri},
  title = {Ensemble Methods for Structured Prediction},
  booktitle = {Proceedings of ICML},
  year = {2014},
  abstract = {We present a series of learning algorithms and theoretical guarantees
	for designing accurate ensembles of structured prediction tasks.
	This includes several randomized and deterministic algorithms devised
	by converting on-line learning algorithms to batch ones, and a boosting-style
	algorithm applicable in the context of structured prediction with
	a large number of labels. We give a detailed study of all these algorithms,
	including the description of new on-line-to-batch conversions and
	learning guarantees. We also report the results of extensive experiments
	with these algorithms in several structured prediction tasks.},
  file = {Cortes2014Ensemble.pdf:Cortes2014Ensemble.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.06.23}
}

@INPROCEEDINGS{Cortes2014Deep,
  author = {Corinna Cortes and Mehryar Mohri and Umar Syed},
  title = {Deep Boosting},
  booktitle = {Proceedings of ICML},
  year = {2014},
  abstract = {We present a new ensemble learning algorithm, DeepBoost, which can
	use as base classifiers a hypothesis set containing deep decision
	trees, or members of other rich or complex families, and succeed
	in achieving high accuracy without overfitting the data. The key
	to the success of the algorithm is a 'capacity-conscious' criterion
	for the selection of the hypotheses. We give new data-dependent learning
	bounds for convex ensembles expressed in terms of the Rademacher
	complexities of the sub-families composing the base classifier set,
	and the mixture weight assigned to each sub-family. Our algorithm
	directly benefits from these guarantees since it seeks to minimize
	the corresponding learning bound. We give a full description of our
	algorithm, including the details of its derivation, and report the
	results of several experiments showing that its performance compares
	favorably to that of AdaBoost and Logistic Regression and their L_1-regularized
	variants.},
  file = {Cortes2014Deep.pdf:Cortes2014Deep.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.06.23}
}

@Article{Counts2011Taking,
  author    = {Counts, S and Fisher, K},
  title     = {Taking It All In ? Visual Attention in Microblog Consumption},
  journal   = {Artificial Intelligence},
  year      = {2011},
  pages     = {97--104},
  groups    = {Twitter},
  owner     = {linchen},
  publisher = {AAAI},
  timestamp = {2011.11.01},
  url       = {http://www.aaai.org/ocs/index.php/ICWSM/ICWSM11/paper/viewPDFInterstitial/2769/3298},
}

@InProceedings{Cozman2003Semi,
  author    = {Cozman, Fabio Gagliardi and Cohen, Ira and Cirelo, Marcelo Cesar and others},
  title     = {Semi-supervised learning of mixture models},
  booktitle = {ICML},
  year      = {2003},
  pages     = {99--106},
  abstract  = {This paper analyzes the performance of semisupervised
	
	learning of mixture models. We show
	
	that unlabeled data can lead to an increase in
	
	classification error even in situations where additional
	
	labeled data would decrease classification
	
	error. We present a mathematical analysis of
	
	this “degradation” phenomenon and show that it
	
	is due to the fact that bias may be adversely affected
	
	by unlabeled data. We discuss the impact
	
	of these theoretical results to practical situations.},
  comment   = {classifiers are built from a combination of Nl labeled and Nu unlabeled
	samples. A sample is generated from p(C,X), the probability that
	any sample is labeled is fixed and independent of the samples},
  file      = {Cozman2003Semi.pdf:Cozman2003Semi.pdf:PDF},
}

@CONFERENCE{Craswell2005Overview,
  author = {Craswell, N. and de Vries, A. and Soboroff, I.},
  title = {Overview of the trec-2005 enterprise track},
  booktitle = {TREC 2005 Conference Notebook},
  year = {2005},
  pages = {199--205},
  owner = {Cheyenne},
  timestamp = {2009.09.21}
}

@InProceedings{Cremonesi2010Performance,
  author    = {Cremonesi, Paolo and Koren, Yehuda and Turrin, Roberto},
  title     = {Performance of Recommender Algorithms on Top-n Recommendation Tasks},
  booktitle = {Proceedings of the Fourth ACM Conference on Recommender Systems},
  year      = {2010},
  series    = {RecSys '10},
  pages     = {39--46},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {In many commercial systems, the 'best bet' recommendations are shown,
	but the predicted rating values are not. This is usually referred
	to as a top-N recommendation task, where the goal of the recommender
	system is to find a few specific items which are supposed to be most
	appealing to the user. Common methodologies based on error metrics
	(such as RMSE) are not a natural fit for evaluating the top-N recommendation
	task. Rather, top-N performance can be directly measured by alternative
	methodologies based on accuracy metrics (such as precision/recall).
	
	
	An extensive evaluation of several state-of-the art recommender algorithms
	suggests that algorithms optimized for minimizing RMSE do not necessarily
	perform as expected in terms of top-N recommendation task. Results
	show that improvements in RMSE often do not translate into accuracy
	improvements. In particular, a naive non-personalized algorithm can
	outperform some common recommendation approaches and almost match
	the accuracy of sophisticated algorithms. Another finding is that
	the very few top popular items can skew the top-N performance. The
	analysis points out that when evaluating a recommender algorithm
	on the top-N recommendation task, the test set should be chosen carefully
	in order to not bias accuracy metrics towards non-personalized solutions.
	Finally, we offer practitioners new variants of two collaborative
	filtering algorithms that, regardless of their RMSE, significantly
	outperform other recommender algorithms in pursuing the top-N recommendation
	task, with offering additional practical advantages. This comes at
	surprise given the simplicity of these two methods.},
  acmid     = {1864721},
  comment   = {We observe that about 33% of ratings collected
	
	by Netflix involve only the 1.7% of most popular items (i.e.,
	
	302 items).
	
	
	RMSE oriented algorithms do not outperform non-personalized algorithms},
  doi       = {10.1145/1864708.1864721},
  file      = {Cremonesi2010Performance.pdf:Cremonesi2010Performance.pdf:PDF},
  isbn      = {978-1-60558-906-0},
  keywords  = {evaluation, precision, recall, top-n recommendations},
  location  = {Barcelona, Spain},
  numpages  = {8},
  timestamp = {2015.09.21},
  url       = {http://doi.acm.org/10.1145/1864708.1864721},
}

@InProceedings{Cui2012Discover,
  author    = {Cui, Anqi and Zhang, Min and Liu, Yiqun and Ma, Shaoping and Zhang, Kuo},
  title     = {Discover Breaking Events with Popular Hashtags in Twitter},
  booktitle = {Proceedings of the 21st ACM International Conference on Information and Knowledge Management},
  year      = {2012},
  series    = {CIKM '12},
  pages     = {1794--1798},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {In this paper, we utilize tags in Twitter (the hashtags) as an indicator
	of events. We first study the properties of hashtags for event detection.
	Based on several observations, we proposed three attributes of hashtags,
	including (1) instability for temporal analysis, (2) Twitter meme
	possibility to distinguish social events from virtual topics or memes,
	and (3) authorship entropy for mining the most contributed authors.
	Based on these attributes, breaking events are discovered with hashtags,
	which cover a wide range of social events among different languages
	in the real world.},
  acmid     = {2398519},
  doi       = {10.1145/2396761.2398519},
  groups    = {Recommender Systems, Twitter},
  isbn      = {978-1-4503-1156-4},
  keywords  = {burst detection, hashtag, social media, twitter},
  location  = {Maui, Hawaii, USA},
  numpages  = {5},
  url       = {http://doi.acm.org/10.1145/2396761.2398519},
}

@CONFERENCE{D'Amore2004Expertise,
  author = {D'Amore, R.},
  title = {Expertise community detection},
  booktitle = {Proceedings of the 27th annual international ACM SIGIR conference
	on Research and development in information retrieval},
  year = {2004},
  pages = {498--499},
  organization = {ACM New York, NY, USA},
  owner = {Cheyenne},
  timestamp = {2009.09.21}
}

@InProceedings{Dalvi2013Para,
  author    = {Dalvi, Nilesh N and Kumar, Ravi and Pang, Bo},
  title     = {Para 'Normal' Activity: On the Distribution of Average Ratings.},
  booktitle = {Proceedings of the Seventh International AAAI Conference on Weblogs and Social Media (ICWSM)},
  year      = {2013},
  pages     = {110-119},
  comment   = {Selection bias: users select entities that they expect to like and
	hence rate them positively
	
	choice supportive bias which is the tendency to retroactively ascribe
	positive attributes to an option one has selected},
  file      = {Dalvi2013Para.pdf:Dalvi2013Para.pdf:PDF},
}

@InProceedings{Damak2013Effectiveness,
  author    = {Damak, Firas and Pinel-Sauvagnat, Karen and Boughanem, Mohand and Cabanac, Guillaume},
  title     = {Effectiveness of State-of-the-art Features for Microblog Search},
  booktitle = {Proceedings of the 28th Annual ACM Symposium on Applied Computing},
  year      = {2013},
  series    = {SAC '13},
  pages     = {914--919},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {We investigate in this paper information retrieval in microblogs exploiting
	different state-of-the-art features. Microbloggers, besides posting
	microblogs, search for fresh and relevant information related to
	their interests, by submitting a query to a microblog search engine.
	The majority of approaches that collect information from microblogs
	exploit features such as the recency of the microblog, the authority
	of his/her author... to improve the quality of their results. In
	this paper, we evaluated some of the state-of-the-art features to
	determine those that discriminate relevant from irrelevant microblogs
	given an information need. Then, we used the selected features to
	learn models to determine their effectiveness in a microblog search
	task. We conducted a series of experiments using the dataset and
	topics of the TREC Microblog 2011 and 2012 tracks. Results show that
	content, hypertextuality, and recency are the best predictors of
	relevance. We also found that Naive Bayes was the most effective
	learning approach for this type of classification.},
  acmid     = {2480537},
  doi       = {10.1145/2480362.2480537},
  groups    = {Twitter},
  isbn      = {978-1-4503-1656-9},
  keywords  = {feature evaluation, information retrieval, microblog search},
  location  = {Coimbra, Portugal},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/2480362.2480537},
}

@Conference{danescu2009opinions,
  author       = {Danescu-Niculescu-Mizil, C. and Kossinets, G. and Kleinberg, J. and Lee, L.},
  title        = {{How opinions are received by online communities: a case study on amazon. com helpfulness votes}},
  booktitle    = {Proceedings of the 18th international conference on World wide web},
  year         = {2009},
  pages        = {141--150},
  organization = {ACM},
  file         = {danescu2009opinions.pdf:danescu2009opinions.pdf:PDF},
}

@INPROCEEDINGS{Daneshmand2014Estimating,
  author = {Hadi Daneshmand and Manuel Gomez-Rodriguez and Le Song and Bernhard
	Schoelkopf},
  title = {Estimating Diffusion Network Structures: Recovery Conditions, Sample
	Complexity \& Soft-thresholding Algorithm},
  booktitle = {Proceedings of ICML},
  year = {2014},
  pages = {788-796},
  abstract = {Information spreads across social and technological networks, but
	often the network structures are hidden from us and we only observe
	the traces left by the diffusion processes, called cascades. Can
	we recover the hidden network structures from these observed cascades?
	What kind of cascades and how many cascades do we need? Are there
	some network structures which are more difficult than others to recover?
	Can we design efficient inference algorithms with provable guarantees?
	Despite the increasing availability of cascade data and methods for
	inferring networks from these data, a thorough theoretical understanding
	of the above questions remains largely unexplored in the literature.
	In this paper, we investigate the network structure inference problem
	for a general family of continuous-time diffusion models using an
	l1-regularized likelihood maximization framework. We show that, as
	long as the cascade sampling process satisfies a natural incoherence
	condition, our framework can recover the correct network structure
	with high probability if we observe O(d^3 log N) cascades, where
	d is the maximum number of parents of a node and N is the total number
	of nodes. Moreover, we develop a simple and efficient soft-thresholding
	inference algorithm, which we use to illustrate the consequences
	of our theoretical results, and show that our framework outperforms
	other alternatives in practice.},
  file = {Daneshmand2014Estimating.pdf:Daneshmand2014Estimating.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.06.24}
}

@INPROCEEDINGS{Das2013Generating,
  author = {Das, Mahashweta and Rahman, Habibur and Das, Gautam and Hristidis,
	Vagelis},
  title = {Generating informative snippet to maximize item visibility},
  booktitle = {Proceedings of the 22nd ACM international conference on Conference
	on information \&\#38; knowledge management},
  year = {2013},
  series = {CIKM '13},
  pages = {1721--1726},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {The widespread use and growing popularity of online collaborative
	content sites has created rich resources for users to consult in
	order to make purchasing decisions on various items such as e-commerce
	products, restaurants, etc. Ideally, a user wants to quickly decide
	whether an item is desirable, from the list of items returned as
	a result of her search query. This has created new challenges for
	producers/manufacturers (e.g., Dell) or retailers (e.g., Amazon,
	eBay) of such items to compose succinct summarizations of web item
	descriptions, henceforth referred to as snippets, that are likely
	to maximize the items' visibility among users. We exploit the availability
	of user feedback in collaborative content sites in the form of tags
	to identify the most important item attributes that must be highlighted
	in an item snippet. We investigate the problem of finding the top-k
	best snippets for an item that are likely to maximize the probability
	that the user preference (available in the form of search query)
	is satisfied. Since a search query returns multiple relevant items,
	we also study the problem of finding the best diverse set of snippets
	for the items in order to maximize the probability of a user liking
	at least one of the top items. We develop an exact top-k algorithm
	for each of the problem and perform detailed experiments on synthetic
	and real data crawled from the web to to demonstrate the utility
	of our problems and effectiveness of our solutions.},
  acmid = {2505606},
  doi = {10.1145/2505515.2505606},
  file = {Das2013Generating.pdf:Das2013Generating.pdf:PDF},
  isbn = {978-1-4503-2263-8},
  keywords = {collaborative tagging, item attributes, naive bayes, snippet},
  location = {San Francisco, California, USA},
  numpages = {6},
  timestamp = {2014.08.27},
  url = {http://doi.acm.org/10.1145/2505515.2505606}
}

@INPROCEEDINGS{Das2014Automated,
  author = {Sanmay Das and Allen Lavoie},
  title = {Automated inference of point of view from user interactions in collective
	intelligence venues},
  booktitle = {Proceedings of ICML},
  year = {2014},
  pages = {90-98},
  abstract = {Empirical evaluation of trust and manipulation in large-scale collective
	intelligence processes is challenging. The datasets involved are
	too large for thorough manual study, and current automated options
	are limited. We introduce a statistical framework which classifies
	point of view based on user interactions. The framework works on
	Web-scale datasets and is applicable to a wide variety of collective
	intelligence processes. It enables principled study of such issues
	as manipulation, trustworthiness of information, and potential bias.
	We demonstrate the model's effectiveness in determining point of
	view on both synthetic data and a dataset of Wikipedia user interactions.
	We build a combined model of topics and points-of-view on the entire
	history of English Wikipedia, and show how it can be used to find
	potentially biased articles and visualize user interactions at a
	high level.},
  file = {Das2014Automated.pdf:Das2014Automated.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.06.24}
}

@InProceedings{De2012Local,
  author    = {De, Abir and Desarkar, Maunendra Sankar and Ganguly, Niloy and Mitra, Pabitra},
  title     = {Local Learning of Item Dissimilarity Using Content and Link Structure},
  booktitle = {Proceedings of the Sixth ACM Conference on Recommender Systems},
  year      = {2012},
  series    = {RecSys '12},
  pages     = {221--224},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {In the Recommendation Problem, it is often important to find a set
	of items similar to a particular item or a group of items. This problem
	of finding similar items for the recommendation task may also be
	viewed as a link prediction problem in a network, where the items
	can be treated as the nodes. The strength of the edge connecting
	two items represents the similarity between the items. In this context,
	a central challenge is to suitably define an appropriate dissimilarity
	function between the items. For content based recommender systems,
	the dissimilarity function should take into account the individual
	attributes of the items. The same attribute may have different importances
	in different parts of the underlying network. We focus on the problem
	of learning a suitable dissimilarity function between items and address
	it by formulating it as a constrained optimization problem which
	captures the local weightages of the attributes in different regions
	of the graph. The constraints are imposed in such a way that the
	non-connected nodes show higher value of dissimilarity than the connected
	nodes. The local tuning of the weights learns the optimal value of
	weights in various parts of the network: from the portions having
	rich graph information to the portions having only content information.
	Detailed experimentation shows the superiority of the proposed algorithm
	over the Adamic Adar metric as well as logistic regression methodology.},
  acmid     = {2365999},
  comment   = {to compute the maximal probability of an edge appear between two disconnected
	nodes is to 
	
	minimize the accumulated dissimilarity between all neighbouring nodes
	and targets
	
	with respect to 
	
	w, the weight that combines all features
	
	constrained by
	
	connected nodes are closer than the target
	
	disconnected nodes are farer than the target},
  doi       = {10.1145/2365952.2365999},
  file      = {De2012Local.pdf:De2012Local.pdf:PDF},
  groups    = {Recommender Systems},
  isbn      = {978-1-4503-1270-7},
  keywords  = {collaborative filtering, content based recommendation, information retrieval},
  location  = {Dublin, Ireland},
  numpages  = {4},
  timestamp = {2014.06.08},
  url       = {http://doi.acm.org/10.1145/2365952.2365999},
}

@ARTICLE{Dean2008MapReduce,
  author = {Dean, Jeffrey and Ghemawat, Sanjay},
  title = {MapReduce: simplified data processing on large clusters},
  journal = {Communications of the ACM},
  year = {2008},
  volume = {51},
  pages = {107--113},
  number = {1},
  file = {Dean2008MapReduce.pdf:Dean2008MapReduce.pdf:PDF},
  publisher = {ACM}
}

@InProceedings{DeChoudhury2011Identifying,
  author    = {De Choudhury, Munmun and Counts, Scott and Czerwinski, Mary},
  title     = {Identifying relevant social media content: leveraging information diversity and user cognition},
  booktitle = {Proceedings of the 22nd ACM conference on Hypertext and hypermedia},
  year      = {2011},
  series    = {HT '11},
  pages     = {161--170},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {As users turn to large scale social media systems like Twitter for
	topic-based content exploration, they quickly face the issue that
	there may be hundreds of thousands of items matching any given topic
	they might query. Given the scale of the potential result sets, how
	does one identify the 'best' or 'right' set of items? We explore
	a solution that aligns characteristics of the information space,
	including specific content attributes and the information diversity
	of the results set, with measurements of human information processing,
	including engagement and recognition memory. Using Twitter as a test
	bed, we propose a greedy iterative clustering technique for selecting
	a set of items on a given topic that matches a specified level of
	diversity.
	
	
	In a user study, we show that our proposed method yields sets of items
	that were, on balance, more engaging, better remembered, and rated
	as more interesting and informative compared to baseline techniques.
	Additionally, diversity indeed seemed to be important to participants
	in the study in the consumption of content. However as a rather surprising
	result, we also observe that content was perceived to be more relevant
	when it was highly homogeneous or highly heterogeneous. In this light,
	implications for the selection and evaluation of topic-centric item
	sets in social media contexts are discussed.},
  acmid     = {1995990},
  doi       = {http://doi.acm.org/10.1145/1995966.1995990},
  file      = {DeChoudhury2011Identifying.pdf:DeChoudhury2011Identifying.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-1-4503-0256-2},
  keywords  = {cognition, information seeking, information selection, real-time search, social media, twitter, user interfaces},
  location  = {Eindhoven, The Netherlands},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1995966.1995990},
}

@INPROCEEDINGS{Deng2012Complexity,
  author = {Deng, Ting and Fan, Wenfei and Geerts, Floris},
  title = {On the Complexity of Package Recommendation Problems},
  booktitle = {Proceedings of the 31st Symposium on Principles of Database Systems},
  year = {2012},
  series = {PODS '12},
  pages = {261--272},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {2213592},
  doi = {10.1145/2213556.2213592},
  isbn = {978-1-4503-1248-6},
  keywords = {complexity, query relaxation, recommendation problems},
  location = {Scottsdale, Arizona, USA},
  numpages = {12},
  timestamp = {2014.10.28},
  url = {http://doi.acm.org/10.1145/2213556.2213592}
}

@INPROCEEDINGS{DenilNarrowing,
  author = {Misha Denil and David Matheson and Nando De Freitas},
  title = {Narrowing the Gap: Random Forests In Theory and In Practice},
  abstract = {Despite widespread interest and practical use, the theoretical properties
	of random forests are still not well understood. In this paper we
	contribute to this understanding in two ways. We present a new theoreti-
	cally tractable variant of random regression forests and prove that
	our algorithm is con- sistent. We also provide an empirical eval-
	uation, comparing our algorithm and other theoretically tractable
	random forest models to the random forest algorithm used in prac-
	tice. Our experiments provide insight into the relative importance
	of different simplifi- cations that theoreticians have made to ob-
	tain tractable models for analysis.},
  file = {DenilNarrowing.pdf:DenilNarrowing.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.06.23}
}

@INPROCEEDINGS{Devooght2015Dynamic,
  author = {Devooght, Robin and Kourtellis, Nicolas and Mantrach, Amin},
  title = {Dynamic Matrix Factorization with Priors on Unknown Values},
  booktitle = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge
	Discovery and Data Mining},
  year = {2015},
  series = {KDD '15},
  pages = {189--198},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Advanced and effective collaborative filtering methods based on explicit
	feedback assume that unknown ratings do not follow the same model
	as the observed ones not missing at random). In this work, we build
	on this assumption, and introduce a novel dynamic matrix factorization
	framework that allows to set an explicit prior on unknown values.
	When new ratings, users, or items enter the system, we can update
	the factorization in time independent of the size of data (number
	of users, items and ratings). Hence, we can quickly recommend items
	even to very recent users. We test our methods on three large datasets,
	including two very sparse ones, in static and dynamic conditions.
	In each case, we outrank state-of-the-art matrix factorization methods
	that do not use a prior on unknown ratings.},
  acmid = {2783346},
  isbn = {978-1-4503-3664-2},
  keywords = {collaborative filtering, matrix factorization, recommender systems},
  location = {Sydney, NSW, Australia},
  numpages = {10},
  timestamp = {2016.06.25}
}

@CONFERENCE{di2008representing,
  author = {Di, N. and Yao, C. and Duan, M. and Zhu, J. and Li, X.},
  title = {{Representing a web page as sets of named entities of multiple types:
	a model and some preliminary applications}},
  booktitle = {Proceeding of the 17th international conference on World Wide Web},
  year = {2008},
  pages = {1099--1100},
  organization = {ACM}
}

@ARTICLE{diesner2005communication,
  author = {Diesner, J. and Frantz, T.L. and Carley, K.M.},
  title = {{Communication Networks from the Enron Email Corpus "It's Always
	About the People. Enron is no Different"}},
  journal = {Computational \& Mathematical Organization Theory},
  year = {2005},
  volume = {11},
  pages = {201--228},
  number = {3},
  issn = {1381-298X},
  publisher = {Springer}
}

@INPROCEEDINGS{Dietz2007Unsupervised,
  author = {Dietz, Laura and Bickel, Steffen and Scheffer, Tobias},
  title = {Unsupervised prediction of citation influences},
  booktitle = {ICML '07: Proceedings of the 24th international conference on Machine
	learning},
  year = {2007},
  pages = {233--240},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Publication repositories contain an abundance of information about
	the evolution of scientific research areas. We address the problem
	of creating a visualization of a research area that describes the
	flow of topics between papers, quantifies the impact that papers
	have on each other, and helps to identify key contributions. To this
	end, we devise a probabilistic topic model that explains the generation
	of documents; the model incorporates the aspects of topical innovation
	and topical inheritance via citations. We evaluate the model's ability
	to predict the strength of influence of citations against manually
	rated citations.},
  doi = {http://doi.acm.org/10.1145/1273496.1273526},
  file = {Dietz2007Unsupervised.pdf:Dietz2007Unsupervised.pdf:PDF},
  isbn = {978-1-59593-793-3},
  location = {Corvalis, Oregon}
}

@INPROCEEDINGS{Ding2006R1-PCA:,
  author = {Ding, Chris and Zhou, Ding and He, Xiaofeng and Zha, Hongyuan},
  title = {R1-PCA: rotational invariant L1-norm principal component analysis
	for robust subspace factorization},
  booktitle = {ICML '06: Proceedings of the 23rd international conference on Machine
	learning},
  year = {2006},
  pages = {281--288},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1143844.1143880},
  isbn = {1-59593-383-2},
  location = {Pittsburgh, Pennsylvania}
}

@INPROCEEDINGS{Ding2001Minmax,
  author = {Ding, Chris H. Q. and He, Xiaofeng and Zha, Hongyuan and Gu, Ming
	and Simon, Horst D.},
  title = {A Min-max Cut Algorithm for Graph Partitioning and Data Clustering},
  booktitle = {ICDM '01: Proceedings of the 2001 IEEE International Conference on
	Data Mining},
  year = {2001},
  pages = {107--114},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  isbn = {0-7695-1119-8}
}

@ARTICLE{ding2008using,
  author = {Ding, S. and Cong, G. and Lin, C.Y. and Zhu, X.},
  title = {Using conditional random fields to extract contexts and answers of
	questions from online forums},
  journal = {Proceedings of ACL-08: HLT},
  year = {2008},
  pages = {710--718},
  file = {ding2008using.pdf:ding2008using.pdf:PDF},
  publisher = {Citeseer}
}

@ARTICLE{Ding2014Survey,
  author = {Zhaoyun Ding and Yan Jia and Bin Zhou},
  title = {Survey of Data Mining for Microblogs},
  journal = {Journal of Computer Research and Development},
  year = {2014},
  volume = {51},
  number = {4},
  owner = {littlep},
  timestamp = {2014.05.25}
}

@InProceedings{Ding2013Learning,
  author    = {Ding, Zhuoye and Qiu, Xipeng and Zhang, Qi and Huang, Xuanjing},
  title     = {Learning Topical Translation Model for Microblog Hashtag Suggestion},
  booktitle = {Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence},
  year      = {2013},
  series    = {IJCAI'13},
  pages     = {2078--2084},
  publisher = {AAAI Press},
  abstract  = {Hashtags can be viewed as an indication to the context of the tweet
	or as the core idea expressed in the tweet. They provide valuable
	information for many applications, such as information retrieval,
	opinion mining, text classification, and so on. However, only a small
	number of microblogs are manually tagged. To address this problem,
	in this work, we propose a topical translation model for microblog
	hashtag suggestion. We assume that the content and hashtags of the
	tweet are talking about the same themes but written in different
	languages. Under the assumption, hashtag suggestion is modeled as
	a translation process from content to hashtags. Moreover, in order
	to cover the topic of tweets, the proposed model regards the translation
	probability to be topic-specific. It uses topic-specific word trigger
	to bridge the vocabulary gap between the words in tweets and hashtags,
	and discovers the topics of tweets by a topic model designed for
	microblogs. Experimental results on the dataset crawled from real
	world microblogging service demonstrate that the proposed method
	outperforms state-of-the-art methods.},
  acmid     = {2540427},
  groups    = {Recommender Systems, Twitter},
  isbn      = {978-1-57735-633-2},
  location  = {Beijing, China},
  numpages  = {7},
  url       = {http://dl.acm.org/citation.cfm?id=2540128.2540427},
}

@CONFERENCE{Dom2003Graph-based,
  author = {Dom, B. and Eiron, I. and Cozzi, A. and Zhang, Y.},
  title = {Graph-based ranking algorithms for e-mail expertise analysis},
  booktitle = {Proceedings of the 8th ACM SIGMOD workshop on Research issues in
	data mining and knowledge discovery},
  year = {2003},
  pages = {42--48},
  organization = {ACM New York, NY, USA},
  owner = {Cheyenne},
  timestamp = {2009.09.21}
}

@ARTICLE{Dourisboure2009Extraction,
  author = {Dourisboure, Yon and Geraci, Filippo and Pellegrini, Marco},
  title = {Extraction and classification of dense implicit communities in the
	Web graph},
  journal = {ACM Trans. Web},
  year = {2009},
  volume = {3},
  pages = {1--36},
  number = {2},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/1513876.1513879},
  issn = {1559-1131},
  publisher = {ACM}
}

@INPROCEEDINGS{Dourisboure2007Extraction,
  author = {Dourisboure, Yon and Geraci, Filippo and Pellegrini, Marco},
  title = {Extraction and classification of dense communities in the web},
  booktitle = {WWW '07: Proceedings of the 16th international conference on World
	Wide Web},
  year = {2007},
  pages = {461--470},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1242572.1242635},
  isbn = {978-1-59593-654-7},
  location = {Banff, Alberta, Canada}
}

@ARTICLE{Drosou2012DisC,
  author = {Drosou, Marina and Pitoura, Evaggelia},
  title = {DisC Diversity: Result Diversification Based on Dissimilarity and
	Coverage},
  journal = {Proc. VLDB Endow.},
  year = {2012},
  volume = {6},
  pages = {13--24},
  number = {1},
  month = nov,
  abstract = {Recently, result diversification has attracted a lot of attention
	as a means to improve the quality of results retrieved by user queries.
	In this paper, we propose a new, intuitive definition of diversity
	called DisC diversity. A DisC diverse subset of a query result contains
	objects such that each object in the result is represented by a similar
	object in the diverse subset and the objects in the diverse subset
	are dissimilar to each other. We show that locating a minimum DisC
	diverse subset is an NP-hard problem and provide heuristics for its
	approximation. We also propose adapting DisC diverse subsets to a
	different degree of diversification. We call this operation zooming.
	We present efficient implementations of our algorithms based on the
	M-tree, a spatial index structure, and experimentally evaluate their
	performance.},
  acmid = {2428538},
  file = {:Drosou2012DisCPPT.pptx:PowerPoint;Drosou2012DisC.pdf:Drosou2012DisC.pdf:PDF},
  issn = {2150-8097},
  issue_date = {November 2012},
  numpages = {12},
  publisher = {VLDB Endowment},
  url = {http://dl.acm.org/citation.cfm?id=2428536.2428538}
}

@InProceedings{Du2009Large,
  author    = {Du, Nan and Faloutsos, Christos and Wang, Bai and Akoglu, Leman},
  title     = {Large human communication networks: patterns and a utility-driven generator},
  booktitle = {Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining},
  year      = {2009},
  series    = {KDD '09},
  pages     = {269--278},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1557054},
  doi       = {http://doi.acm.org/10.1145/1557019.1557054},
  file      = {Du2009Large.pdf:Du2009Large.pdf:PDF},
  isbn      = {978-1-60558-495-9},
  keywords  = {cliques, graph generators, social networks},
  location  = {Paris, France},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1557019.1557054},
}

@INPROCEEDINGS{Du2015Dirichlet,
  author = {Du, Nan and Farajtabar, Mehrdad and Ahmed, Amr and Smola, Alexander
	J. and Song, Le},
  title = {Dirichlet-Hawkes Processes with Applications to Clustering Continuous-Time
	Document Streams},
  booktitle = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge
	Discovery and Data Mining},
  year = {2015},
  series = {KDD '15},
  pages = {219--228},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Clusters in document streams, such as online news articles, can be
	induced by their textual contents, as well as by the temporal dynamics
	of their arriving patterns. Can we leverage both sources of information
	to obtain a better clustering of the documents, and distill information
	that is not possible to extract using contents only? In this paper,
	we propose a novel random process, referred to as the Dirichlet-Hawkes
	process, to take into account both information in a unified framework.
	A distinctive feature of the proposed model is that the preferential
	attachment of items to clusters according to cluster sizes, present
	in Dirichlet processes, is now driven according to the intensities
	of cluster-wise self-exciting temporal point processes, the Hawkes
	processes. This new model establishes a previously unexplored connection
	between Bayesian Nonparametrics and temporal Point Processes, which
	makes the number of clusters grow to accommodate the increasing complexity
	of online streaming contents, while at the same time adapts to the
	ever changing dynamics of the respective continuous arrival time.
	We conducted large-scale experiments on both synthetic and real world
	news articles, and show that Dirichlet-Hawkes processes can recover
	both meaningful topics and temporal dynamics, which leads to better
	predictive performance in terms of content perplexity and arrival
	time of future documents.},
  acmid = {2783411},
  doi = {10.1145/2783258.2783411},
  file = {Du2015Dirichlet.pdf:Du2015Dirichlet.pdf:PDF},
  isbn = {978-1-4503-3664-2},
  keywords = {dirichlet process, document modeling, hawkes process},
  location = {Sydney, NSW, Australia},
  numpages = {10},
  timestamp = {2015.08.25},
  url = {http://doi.acm.org/10.1145/2783258.2783411}
}

@Article{Duan2013Supporting,
  author     = {Duan, Huizhong and Zhai, ChengXiang and Cheng, Jinxing and Gattani, Abhishek},
  title      = {Supporting Keyword Search in Product Database: A Probabilistic Approach},
  journal    = {Proc. VLDB Endow.},
  year       = {2013},
  volume     = {6},
  number     = {14},
  pages      = {1786--1797},
  month      = sep,
  issn       = {2150-8097},
  abstract   = {The ability to let users search for products conveniently in
	
	product database is critical to the success of e-commerce.
	
	Although structured query languages (e.g. SQL) can be
	
	used to eectively access the product database, it is very
	
	dicult for end users to learn and use. In this paper, we
	
	study how to optimize search over structured product entities
	
	(represented by specications) with keyword queries
	
	such as \cheap gaming laptop". One major diculty in
	
	this problem is the vocabulary gap between the specications
	
	of products in the database and the keywords people
	
	use in search queries. To solve the problem, we propose
	
	a novel probabilistic entity retrieval model based on query
	
	generation, where the entities would be ranked for a given
	
	keyword query based on the likelihood that a user who likes
	
	an entity would pose the query. Dierent ways to estimate
	
	the model parameters would lead to dierent variants of
	
	ranking functions. We start with simple estimates based on
	
	the specications of entities, and then leverage user reviews
	
	and product search logs to improve the estimation. Multiple
	
	estimation algorithms are developed based on Maximum
	
	Likelihood and Maximum a Posteriori estimators. We evaluate
	
	the proposed product entity retrieval models on two
	
	newly created product search test collections. The results
	
	show that the proposed model signicantly outperforms the
	
	existing retrieval models, beneting from the modeling of
	
	attribute-level relevance. Despite the focus on product retrieval,
	
	the proposed modeling method is general and opens
	
	up many new opportunities in analyzing structured entity
	
	data with unstructured text data. We show the proposed
	
	probabilistic model can be easily adapted for many interesting
	
	applications including facet generation and review annotation.},
  acmid      = {2556562},
  comment    = {review-> category -> feature word},
  file       = {Duan2013Supporting.pdf:Duan2013Supporting.pdf:PDF},
  issue_date = {September 2013},
  numpages   = {12},
  publisher  = {VLDB Endowment},
  timestamp  = {2014.05.25},
}

@ARTICLE{Dumais1990Indexing,
  author = {Dumais, s. Deerwester and S.T. Furnas and G.W. Landauer and T. K
	and R. Harshman},
  title = {Indexing by latent semantic analysis},
  journal = {Journal of the American society for information science},
  year = {1990},
  volume = {41},
  pages = {391--407},
  number = {6},
  owner = {Cheyenne},
  timestamp = {2009.09.21}
}

@Article{Efron2011Information,
  author     = {Efron, Miles},
  title      = {Information search and retrieval in microblogs},
  journal    = {J. Am. Soc. Inf. Sci. Technol.},
  year       = {2011},
  volume     = {62},
  pages      = {996--1008},
  month      = {June},
  abstract   = {Modern information retrieval (IR) has come to terms with numerous
	new media in efforts to help
	
	people find information in increasingly diverse settings. Among these
	new media are so-called
	
	microblogs. A microblog is a stream of text that is written by an
	author over time. It consists of
	
	many very brief updates that are presented to the microblog’s readers
	in reverse-chronological
	
	order. Today the service called Twitter is the most popular microblogging
	platform. While
	
	microblogging is increasingly popular, methods for organizing and
	providing access to microblog
	
	data are still new. This article offers an introduction to the problems
	that face researchers and
	
	developers of IR systems in microblog settings. After an overview
	of microblogs and the
	
	behavior surrounding them, the article describes established problems
	in microblog retrieval such
	
	as entity search, sentiment analysis, and modeling abstractions such
	as authority and quality. The
	
	article also treats user-created metadata that often appear in microblogs.
	Because the problem of
	
	microblog search is so new, the article concludes with a discussion
	of particularly pressing
	
	research issues yet to be studied in the field.},
  acmid      = {1988577},
  address    = {New York, NY, USA},
  doi        = {http://dx.doi.org/10.1002/asi.21512},
  file       = {Efron2011Information.pdf:Efron2011Information.pdf:PDF},
  groups     = {Twitter},
  issn       = {1532-2882},
  issue      = {6},
  issue_date = {June 2011},
  keywords   = {Twitter, information needs, information retrieval, usage studies, weblogs},
  numpages   = {13},
  owner      = {linchen},
  publisher  = {John Wiley \& Sons, Inc.},
  timestamp  = {2011.11.01},
  url        = {http://dx.doi.org/10.1002/asi.21512},
}

@InProceedings{Efron2011University,
  author    = {Miles Efron},
  title     = {The University of Illinois' Graduate School of Library and Information Science at TREC 2011},
  booktitle = {TREC},
  year      = {2011},
  file      = {Efron2011University.pdf:Efron2011University.pdf:PDF},
  groups    = {Twitter},
  owner     = {linchen},
  timestamp = {2012.01.15},
}

@InProceedings{Efron2010Hashtag,
  author    = {Efron, Miles},
  title     = {Hashtag retrieval in a microblogging environment},
  booktitle = {Proceeding of the 33rd international ACM SIGIR conference on Research and development in information retrieval},
  year      = {2010},
  series    = {SIGIR '10},
  pages     = {787--788},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Microblog services let users broadcast brief textual messages to people
	who "follow" their activity. Often these posts contain terms called
	hashtags, markers of a post's meaning, audience, etc. This poster
	treats the following problem: given a user's stated topical interest,
	retrieve useful hashtags from microblog posts. Our premise is that
	a user interested in topic x might like to find hashtags that are
	often applied to posts about x. This poster proposes a language modeling
	approach to hashtag retrieval. The main contribution is a novel method
	of relevance feedback based on hashtags. The approach is tested on
	a corpus of data harvested from twitter.com.},
  acmid     = {1835616},
  doi       = {http://doi.acm.org/10.1145/1835449.1835616},
  file      = {Efron2010Hashtag.pdf:Efron2010Hashtag.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-1-4503-0153-4},
  keywords  = {hashtag, microblog, relevance feedback, twitter},
  location  = {Geneva, Switzerland},
  numpages  = {2},
  owner     = {linchen},
  timestamp = {2011.11.01},
  url       = {http://doi.acm.org/10.1145/1835449.1835616},
}

@InProceedings{Efron2011Estimation,
  author    = {Efron, Miles and Golovchinsky, Gene},
  title     = {Estimation methods for ranking recent information},
  booktitle = {Proceedings of the 34th international ACM SIGIR conference on Research and development in Information},
  year      = {2011},
  series    = {SIGIR '11},
  pages     = {495--504},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Temporal aspects of documents can impact relevance for certain kinds
	of queries. In this paper, we build on earlier work of modeling temporal
	information. We propose an extension to the Query Likelihood Model
	that incorporates query-specific information to estimate rate parameters,
	and we introduce a temporal factor into language model smoothing
	and query expansion using pseudo-relevance feedback. We evaluate
	these extensions using a Twitter corpus and two newspaper article
	collections. Results suggest that, compared to prior approaches,
	our models are more effective at capturing the temporal variability
	of relevance associated with some topics.},
  acmid     = {2009984},
  doi       = {http://doi.acm.org/10.1145/2009916.2009984},
  file      = {Efron2011Estimation.pdf:Efron2011Estimation.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-1-4503-0757-4},
  keywords  = {information retrieval, microblogs, ranking algorithms, time},
  location  = {Beijing, China},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2009916.2009984},
}

@ARTICLE{Egghe2007Dynamic,
  author = {Egghe, L.},
  title = {Dynamic h-index: the Hirsch index in function of time},
  journal = {Journal of the American Society for Information Science and Technology},
  year = {2007},
  volume = {58},
  pages = {452--454},
  number = {3},
  publisher = {JOHN WILEY \& SONS INC}
}

@ARTICLE{Egghe2006Theory,
  author = {Egghe, L.},
  title = {Theory and practise of the g-index},
  journal = {Scientometrics},
  year = {2006},
  volume = {69},
  pages = {131--152},
  number = {1},
  publisher = {Akad{\'e}miai Kiad{\'o}, co-published with Springer Science+ Business
	Media BV, Formerly Kluwer Academic Publishers BV}
}

@InProceedings{Elsas2008Retrieval,
  author    = {Elsas, Jonathan L. and Arguello, Jaime and Callan, Jamie and Carbonell, Jaime G.},
  title     = {Retrieval and feedback models for blog feed search},
  booktitle = {Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval},
  year      = {2008},
  series    = {SIGIR '08},
  pages     = {347--354},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1390394},
  doi       = {http://doi.acm.org/10.1145/1390334.1390394},
  file      = {Elsas2008Retrieval.pdf:Elsas2008Retrieval.pdf:PDF},
  isbn      = {978-1-60558-164-4},
  keywords  = {blog retrieval, federated search, query expansion},
  location  = {Singapore, Singapore},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/1390334.1390394},
}

@INPROCEEDINGS{Elsas2009It,
  author = {Elsas, Jonathan L. and Carbonell, Jaime G.},
  title = {It pays to be picky: an evaluation of thread retrieval in online
	forums},
  booktitle = {SIGIR '09: Proceedings of the 32nd international ACM SIGIR conference
	on Research and development in information retrieval},
  year = {2009},
  pages = {714--715},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1571941.1572092},
  isbn = {978-1-60558-483-6},
  location = {Boston, MA, USA}
}

@InProceedings{Erkan2004Lexpagerank,
  author    = {Erkan, G. and Radev, D.R.},
  title     = {Lexpagerank: Prestige in multi-document text summarization},
  booktitle = {Proceedings of EMNLP},
  year      = {2004},
  volume    = {4},
  groups    = {Twitter},
}

@ARTICLE{Erkan2004LexRank,
  author = {Erkan, G\"{u}nes and Radev, Dragomir R.},
  title = {LexRank: Graph-based Lexical Centrality As Salience in Text Summarization},
  journal = {J. Artif. Int. Res.},
  year = {2004},
  volume = {22},
  pages = {457--479},
  number = {1},
  month = dec,
  acmid = {1622501},
  address = {USA},
  issn = {1076-9757},
  issue_date = {July 2004},
  numpages = {23},
  publisher = {AI Access Foundation}
}

@ARTICLE{Erosheva2004Mixed,
  author = {Erosheva, Elena and Fienberg, Stephen and Lafferty, John},
  title = {Mixed-membership models of scientific publications},
  journal = {Proceedings of the National Academy of Sciences},
  year = {2004},
  volume = {101},
  pages = {5220--5227},
  number = {suppl 1},
  abstract = {PNAS is one of world's most cited multidisciplinary scientific journals.
	The PNAS official classification structure of subjects is reflected
	in topic labels submitted by the authors of articles, largely related
	to traditionally established disciplines. These include broad field
	classifications into physical sciences, biological sciences, social
	sciences, and further subtopic classifications within the fields.
	Focusing on biological sciences, we explore an internal soft-classification
	structure of articles based only on semantic decompositions of abstracts
	and bibliographies and compare it with the formal discipline classifications.
	Our model assumes that there is a fixed number of internal categories,
	each characterized by multinomial distributions over words (in abstracts)
	and references (in bibliographies). Soft classification for each
	article is based on proportions of the article's content coming from
	each category. We discuss the appropriateness of the model for the
	PNAS database as well as other features of the data relevant to soft
	classification.},
  file = {Erosheva2004Mixed.pdf:Erosheva2004Mixed.pdf:PDF},
  publisher = {National Acad Sciences},
  timestamp = {2015.12.04}
}

@ARTICLE{Esslimani2011Densifying,
  author = {Esslimani, Ilham and Brun, Armelle and Boyer, Anne},
  title = {Densifying a behavioral recommender system by social networks link
	prediction methods},
  journal = {Social Network Analysis and Mining},
  year = {2011},
  volume = {1},
  pages = {159--172},
  number = {3},
  publisher = {Springer}
}

@INPROCEEDINGS{Ester1996density,
  author = {Ester, Martin and Kriegel, Hans-Peter and Sander, J{\"o}rg and Xu,
	Xiaowei},
  title = {A density-based algorithm for discovering clusters in large spatial
	databases with noise.},
  booktitle = {Kdd},
  year = {1996},
  volume = {96},
  number = {34},
  pages = {226--231}
}

@Article{Fang2007Probabilistic,
  author    = {Fang, H. and Zhai, C.},
  title     = {Probabilistic models for expert finding},
  journal   = {Lecture Notes in Computer Science},
  year      = {2007},
  volume    = {4425},
  pages     = {418},
  abstract  = {A common task in many applications is to find persons who are knowledgeable
	about a given topic (i.e., expert finding). In this paper, we propose
	and develop a general probabilistic framework for studying expert
	finding problem and derive two families of generative models (candidate
	generation models and topic generation models) from the framework.
	These models subsume most existing language models proposed for expert
	finding. We further propose several techniques to improve the estimation
	of the proposed models, including incorporating topic expansion,
	using a mixture model to model candidate mentions in the supporting
	documents, and defining an email count-based prior in the topic generation
	model. Our experiments show that the proposed estimation strategies
	are all effective to improve retrieval accuracy.},
  file      = {Fang2007Probabilistic.pdf:Fang2007Probabilistic.pdf:PDF},
  owner     = {Cheyenne},
  publisher = {Springer},
  timestamp = {2009.09.21},
}

@INPROCEEDINGS{Fang2012Latent,
  author = {Fang, Yi and Si, Luo},
  title = {A Latent Pairwise Preference Learning Approach for Recommendation
	from Implicit Feedback},
  booktitle = {Proceedings of the 21st ACM International Conference on Information
	and Knowledge Management},
  year = {2012},
  series = {CIKM '12},
  pages = {2567--2570},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Most of the current recommender systems heavily rely on explicit user
	feedback such as ratings on items to model users' interests. However,
	in many applications, it is very hard to collect the explicit feedback,
	while implicit feedback such as user clicks may be more available.
	Furthermore, it is often more suitable for many recommender systems
	to address a ranking problem than a rating predicting problem. This
	paper proposes a latent pairwise preference learning (LPPL) approach
	for recommendation with implicit feedback. LPPL directly models user
	preferences with respect to a set of items rather than the rating
	scores on individual items, which are modeled with a set of features
	by analyzing clickthrough data available in many real-world recommender
	systems. The LPPL approach models both the latent variables of group
	structure of users and the pairwise preferences simultaneously. We
	conduct experiments on the testbed from a real-world recommender
	system and demonstrate that the proposed approach can effectively
	improve the recommendation performance against several baseline algorithms.},
  acmid = {2398693},
  isbn = {978-1-4503-1156-4},
  keywords = {implicit feedback, pairwise preferences, recommender systems},
  location = {Maui, Hawaii, USA},
  numpages = {4},
  timestamp = {2015.11.12}
}

@INPROCEEDINGS{Fang2012Mining,
  author = {Fang, Yi and Si, Luo and Somasundaram, Naveen and Yu, Zhengtao},
  title = {Mining Contrastive Opinions on Political Texts Using Cross-perspective
	Topic Model},
  booktitle = {Proceedings of the Fifth ACM International Conference on Web Search
	and Data Mining},
  year = {2012},
  series = {WSDM '12},
  pages = {63--72},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {2124306},
  doi = {10.1145/2124295.2124306},
  isbn = {978-1-4503-0747-5},
  keywords = {contrastive opinions, opinion mining, opinion retrieval, topic modeling},
  location = {Seattle, Washington, USA},
  numpages = {10},
  url = {http://doi.acm.org/10.1145/2124295.2124306}
}

@INPROCEEDINGS{Feng2006intelligent,
  author = {Feng, Donghui and Shaw, Erin and Kim, Jihie and Hovy, Eduard},
  title = {An intelligent discussion-bot for answering student queries in threaded
	discussions},
  booktitle = {IUI '06: Proceedings of the 11th international conference on Intelligent
	user interfaces},
  year = {2006},
  pages = {171--177},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1111449.1111488},
  isbn = {1-59593-287-9},
  location = {Sydney, Australia}
}

@InProceedings{Figueiredo:2009:EQT:1645953.1646070,
  author    = {Figueiredo, Flavio and Bel\'{e}m, Fabiano and Pinto, Henrique and Almeida, Jussara and Gon\c{c}alves, Marcos and Fernandes, David and Moura, Edleno and Cristo, Marco},
  title     = {Evidence of quality of textual features on the web 2.0},
  booktitle = {Proceeding of the 18th ACM conference on Information and knowledge management},
  year      = {2009},
  series    = {CIKM '09},
  pages     = {909--918},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {The growth of popularity of Web 2.0 applications greatly increased
	the amount of social media content available on the
	
	Internet. However, the unsupervised, user-oriented nature
	
	of this source of information, and thus, its potential lack
	
	of quality, have posed a challenge to information retrieval
	
	(IR) services. Previous work focuses mostly only on tags,
	
	although a consensus about its eﬀectiveness as supporting
	
	information for IR services has not yet been reached. Moreover, other
	textual features of the Web 2.0 are generally
	
	overseen by previous research.
	
	In this context, this work aims at assessing the relative
	
	quality of distinct textual features available on the Web
	
	2.0. Towards this goal, we analyzed four features (title,
	
	tags, description and comments) in four popular applications (CiteULike,
	Last.FM, Yahoo! Video, and Youtube).
	
	Firstly, we characterized data from these applications in order to
	extract evidence of quality of each feature with respect
	
	to usage, amount of content, descriptive and discriminative
	
	power as well as of content diversity across features. Afterwards,
	a series of classiﬁcation experiments were conducted
	
	as a case study for quality evaluation. Characterization and
	
	classiﬁcation results indicate that: 1) when considered separately,
	tags is the most promising feature, achieving the best
	
	classiﬁcation results, although its absence in a non-negligible
	
	fraction of objects may aﬀect its potential use; and 2) each
	
	feature may bring diﬀerent pieces of information, and combining their
	contents can improve classiﬁcation},
  acmid     = {1646070},
  comment   = {study the quality of some texual features (tags, title, content, )
	in information spread
	
	highlight: good analysis
	
	discriminative power and Descriptive power of each feature},
  doi       = {http://doi.acm.org/10.1145/1645953.1646070},
  isbn      = {978-1-60558-512-3},
  keywords  = {social media, textual features, web 2.0,feature analysis,online social network,statistical analysis},
  location  = {Hong Kong, China},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1645953.1646070},
}

@ARTICLE{Fisher1970Correspondence,
  author = {Franklin M. Fisher},
  title = {A Correspondence Principle for Simultaneous Equation Models},
  journal = {Econometrica},
  year = {1970},
  volume = {38},
  pages = {73-92},
  number = {1},
  abstract = {This paper examines the implications of the position that simultaneous
	equation models are limiting approximations to nonsimultaneous ones
	as time lags go to zero, observations being on averages or sums of
	variables over time. Necessary conditions that a given simultaneous
	model can be the limit of such processes in a reasonable way are
	derived. This leads to tests on the specification of the model and
	of submodels thereof, which tests examine the interrelations between
	equations.},
  file = {Fisher1970Correspondence.pdf:Fisher1970Correspondence.pdf:PDF},
  issn = {00129682, 14680262},
  publisher = {[Wiley, Econometric Society]},
  url = {http://www.jstor.org/stable/1909242}
}

@InProceedings{Forsati2015PushTrust,
  author    = {Forsati, Rana and Barjasteh, Iman and Masrour, Farzan and Esfahanian, Abdol-Hossein and Radha, Hayder},
  title     = {PushTrust: An Efficient Recommendation Algorithm by Leveraging Trust and Distrust Relations},
  booktitle = {Proceedings of the 9th ACM Conference on Recommender Systems},
  year      = {2015},
  series    = {RecSys '15},
  pages     = {51--58},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {The significance of social-enhanced recommender systems is increasing,
	along with its practicality, as online reviews, ratings, friendship
	links, and follower relationships are increasingly becoming available.
	In recent years, there has been an upsurge of interest in exploiting
	social information, such as trust and distrust relations in recommendation
	algorithms. The goal is to improve the quality of suggestions and
	mitigate the data sparsity and the cold-start users problems in existing
	systems. In this paper, we introduce a general collaborative social
	ranking model to rank the latent features of users extracted from
	rating data based on the social context of users. In contrast to
	existing social regularization methods, the proposed framework is
	able to simultaneously leverage trust, distrust, and neutral relations,
	and has a linear dependency on the social network size. By integrating
	the ranking based social regularization idea into the matrix factorization
	algorithm, we propose a novel recommendation algorithm, dubbed PushTrust.
	Our experiments on the Epinions dataset demonstrate that collaboratively
	ranking the latent features of users by exploiting trust and distrust
	relations leads to a substantial increase in performance, and to
	effectively deal with cold-start users problem.},
  acmid     = {2800198},
  comment   = {Method: PushTrust
	
	
	hinge loss regularizer
	
	so if a trust friend similarity is larger than the maximal of distrusted
	user, the hinge loss is 0
	
	doesn't explicitly optimize the difference between users and their
	neighbors, but try to rank trusted friends at the top of the list
	of all neighbors
	
	
	Experiment: epinions},
  file      = {Forsati2015PushTrust.pdf:Forsati2015PushTrust.pdf:PDF},
  isbn      = {978-1-4503-3692-5},
  keywords  = {collaborative filtering, collaborative social ranking, matrix factorization, social regularization},
  location  = {Vienna, Austria},
  numpages  = {8},
  timestamp = {2015.11.26},
}

@Article{Forsati2014Matrix,
  author     = {Forsati, Rana and Mahdavi, Mehrdad and Shamsfard, Mehrnoush and Sarwat, Mohamed},
  title      = {Matrix Factorization with Explicit Trust and Distrust Side Information for Improved Social Recommendation},
  journal    = {ACM Trans. Inf. Syst.},
  year       = {2014},
  volume     = {32},
  number     = {4},
  pages      = {17:1--17:38},
  month      = oct,
  issn       = {1046-8188},
  abstract   = {With the advent of online social networks, recommender systems have
	became crucial for the success of many online applications/services
	due to their significance role in tailoring these applications to
	user-specific needs or preferences. Despite their increasing popularity,
	in general, recommender systems suffer from data sparsity and cold-start
	problems. To alleviate these issues, in recent years, there has been
	an upsurge of interest in exploiting social information such as trust
	relations among users along with the rating data to improve the performance
	of recommender systems. The main motivation for exploiting trust
	information in the recommendation process stems from the observation
	that the ideas we are exposed to and the choices we make are significantly
	influenced by our social context. However, in large user communities,
	in addition to trust relations, distrust relations also exist between
	users. For instance, in Epinions, the concepts of personal “web of
	trust” and personal “block list” allow users to categorize their
	friends based on the quality of reviews into trusted and distrusted
	friends, respectively. Hence, it will be interesting to incorporate
	this new source of information in recommendation as well. In contrast
	to the incorporation of trust information in recommendation which
	is thriving, the potential of explicitly incorporating distrust relations
	is almost unexplored. In this article, we propose a matrix factorization-based
	model for recommendation in social rating networks that properly
	incorporates both trust and distrust relationships aiming to improve
	the quality of recommendations and mitigate the data sparsity and
	cold-start users issues. Through experiments on the Epinions dataset,
	we show that our new algorithm outperforms its standard trust-enhanced
	or distrust-enhanced counterparts with respect to accuracy, thereby
	demonstrating the positive effect that incorporation of explicit
	distrust information can have on recommender systems.},
  acmid      = {2641564},
  address    = {New York, NY, USA},
  articleno  = {17},
  comment    = {method 
	
	
	hinge loss function
	
	
	The gap between two circles guarantees that there always exists a
	safe margin between u1’s agreements with his
	
	trusted and distrusted friends.
	
	
	
	for every triple of trust and distrust friends, similarity trust is
	larger than distrust 
	
	
	similar and dissimilar items.},
  file       = {Forsati2014Matrix.pdf:Forsati2014Matrix.pdf:PDF},
  issue_date = {October 2014},
  keywords   = {Matrix factorization, recommender systems, social relationships},
  numpages   = {38},
  publisher  = {ACM},
}

@BOOK{Freeman2004development,
  title = {The development of social network analysis: a study in the sociology
	of science},
  publisher = {Empirical Press Vancouver, BC},
  year = {2004},
  author = {Freeman, L.C. }
}

@ARTICLE{Frey2007Clustering,
  author = {Brendan J. Frey and Delbert Dueck},
  title = {Clustering by Passing Messages Between Data Points},
  journal = {Science},
  year = {2007},
  volume = {315},
  pages = {972--976},
  file = {Frey2007Clustering.pdf:Frey2007Clustering.pdf:PDF}
}

@INPROCEEDINGS{Fu2014User,
  author = {Fu, Y and Liu, B and Ge, Y and Yao, Z and Xiong, H},
  title = {User Preference Learning with Multiple Information Fusion for Restaurant
	Recommendation},
  booktitle = {Proceedings of the 2014 SIAM International Conference on Data Mining},
  year = {2014},
  pages = {470-478},
  file = {Fu2014User.pdf:Fu2014User.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.05.26}
}

@INPROCEEDINGS{Fujiwara2014Efficient,
  author = {Yasuhiro Fujiwara and Go Irie},
  title = {Efficient Label Propagation},
  booktitle = {Proceedings of ICML},
  year = {2014},
  pages = {783-791},
  abstract = {Label propagation is a popular graph-based semi-supervised learning
	framework. So as to obtain the optimal labeling scores, the label
	propagation algorithm requires an inverse matrix which incurs the
	high computational cost of O(n^3+cn^2), where n and c are the numbers
	of data points and labels, respectively. This paper proposes an efficient
	label propagation algorithm that guarantees exactly the same labeling
	results as those yielded by optimal labeling scores. The key to our
	approach is to iteratively compute lower and upper bounds of labeling
	scores to prune unnecessary score computations. This idea significantly
	reduces the computational cost to O(cnt) where t is the average number
	of iterations for each label and t << n in practice. Experiments
	demonstrate the significant superiority of our algorithm over existing
	label propagation methods.},
  file = {Fujiwara2014Efficient.pdf:Fujiwara2014Efficient.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.06.24}
}

@InProceedings{G'omez2008Statistical,
  author    = {G\'{o}mez, Vicen\c{c} and Kaltenbrunner, Andreas and L\'{o}pez, Vicente},
  title     = {Statistical analysis of the social network and discussion threads in slashdot},
  booktitle = {WWW '08: Proceeding of the 17th international conference on World Wide Web},
  year      = {2008},
  pages     = {645--654},
  address   = {New York, NY, USA},
  publisher = {ACM},
  doi       = {http://doi.acm.org/10.1145/1367497.1367585},
  isbn      = {978-1-60558-085-2},
  location  = {Beijing, China},
}

@Article{Ganesan2012Opinion,
  author    = {Ganesan, Kavita and Zhai, ChengXiang},
  title     = {Opinion-based entity ranking},
  journal   = {Information retrieval},
  year      = {2012},
  volume    = {15},
  number    = {2},
  pages     = {116--150},
  abstract  = {The deployment of Web 2.0 technologies has led to rapid
	
	growth of various opinions and reviews on the web, such
	
	as reviews on products and opinions about people. Such
	
	content can be very useful to help people nd interesting
	
	entities like products, businesses and people based on their
	
	individual preferences or tradeos. Most existing work on
	
	leveraging opinionated content has focused on integrating
	
	and summarizing opinions on entities to help users better
	
	digest all the opinions. In this paper, we propose a dierent
	
	way of leveraging opinionated content, which is to directly
	
	rank entities based on a user's preferences. Our basic idea
	
	is to represent each entity with the text of all the reviews of
	
	the entity. Given a user's keyword query that expresses the
	
	desired features of an entity, we can then rank all the candidate
	
	entities based on how well their reviews match the
	
	user's preferences. We study several methods for solving
	
	this problem, including both standard text retrieval models
	
	and extensions of them to capture multiple aspects of preferences
	
	and perform opinion expansion. Experiment results on
	
	ranking entities based on opinions in two dierent domains
	
	(i.e., hotels and cars) show that the proposed extensions are
	
	eective and lead to improvement of ranking accuracy over
	
	the standard text retrieval models for this task.},
  comment   = {standad retrieve model (BM25)
	
	+
	
	aspect modeling, aggregate score over aspects
	
	+
	
	opinion expansion},
  file      = {Ganesan2012Opinion.pdf:Ganesan2012Opinion.pdf:PDF},
  publisher = {Springer},
}

@INPROCEEDINGS{Ganesan2010Opinosis,
  author = {Ganesan, Kavita and Zhai, ChengXiang and Han, Jiawei},
  title = {Opinosis: A Graph-based Approach to Abstractive Summarization of
	Highly Redundant Opinions},
  booktitle = {Proceedings of the 23rd International Conference on Computational
	Linguistics},
  year = {2010},
  series = {COLING '10},
  pages = {340--348},
  address = {Stroudsburg, PA, USA},
  publisher = {Association for Computational Linguistics},
  acmid = {1873820},
  file = {Ganesan2010Opinosis.pdf:Ganesan2010Opinosis.pdf:PDF},
  location = {Beijing, China},
  numpages = {9},
  url = {http://dl.acm.org/citation.cfm?id=1873781.1873820}
}

@Article{Ganti2010Keyword,
  author     = {Ganti, Venkatesh and He, Yeye and Xin, Dong},
  title      = {Keyword++: A Framework to Improve Keyword Search over Entity Databases},
  journal    = {Proc. VLDB Endow.},
  year       = {2010},
  volume     = {3},
  number     = {1-2},
  pages      = {711--722},
  month      = sep,
  issn       = {2150-8097},
  abstract   = {Keyword search over entity databases (e.g., product, movie databases)
	is an important problem. Current techniques for keyword search on
	databases may often return incomplete and imprecise results. On the
	one hand, they either require that relevant entities contain all
	(or most) of the query keywords, or that relevant entities and the
	query keywords occur together in several documents from a known collection.
	Neither of these requirements may be satisfied for a number of user
	queries. Hence results for such queries are likely to be incomplete
	in that highly relevant entities may not be returned. On the other
	hand, although some returned entities contain all (or most) of the
	query keywords, the intention of the keywords in the query could
	be different from that in the entities. Therefore, the results could
	also be imprecise.
	
	
	To remedy this problem, in this paper, we propose a general framework
	that can improve an existing search interface by translating a keyword
	query to a structured query. Specifically, we leverage the keyword
	to attribute value associations discovered in the results returned
	by the original search interface. We show empirically that the translated
	structured queries alleviate the above problems.},
  acmid      = {1920932},
  comment    = {Addressed problems:
	
	incomplete: some query keywords do not appear and thus not returned
	
	inprecise: all query keywords are contained but result irrelevant
	
	builds upon a given baseline keyword search interface over an entity
	database
	
	
	We develop techniques that measure the correlation between
	
	a keyword and a predicate (or an ordering clause) by
	
	analyzing two result sets, from the baseline search engine,
	
	of a differential query pair with respect to the keyword.
	
	
	 We improve the quality of keyword to predicate mapping
	
	by aggregating measured correlations over multiple differential
	
	query pairs discovered from the query log},
  issue_date = {September 2010},
  numpages   = {12},
  publisher  = {VLDB Endowment},
  timestamp  = {2016.4.25},
}

@INPROCEEDINGS{Ganu2009Beyond,
  author = {Ganu, Gayatree and Elhadad, Noemie and Marian, Am{\'e}lie},
  title = {Beyond the Stars: Improving Rating Predictions using Review Text
	Content},
  booktitle = {Proceedings of Twelfth International Workshop on the Web and Databases},
  year = {2009},
  abstract = {Online reviews are an important asset for users deciding to buy a
	
	product, see a movie, or go to a restaurant, as well as for businesses
	
	tracking user feedback. However, most reviews are written
	
	in a free-text format, and are therefore difficult for computer systems
	
	to understand, analyze, and aggregate. One consequence of
	
	this lack of structure is that searching text reviews is often frustrating
	
	for users. User experience would be greatly improved if
	
	the structure and sentiment conveyed in the content of the reviews
	
	were taken into account. Our work focuses on identifying this information
	
	from free-form text reviews, and using the knowledge
	
	to improve user experience in accessing reviews. Specifically, we
	
	focused on improving recommendation accuracy in a restaurant review
	
	scenario. In this paper, we report on our classification effort,
	
	and on the insight on user-reviewing behavior that we gained in the
	
	process. We propose new ad-hoc and regression-based recommendation
	
	measures, that both take into account the textual component
	
	of user reviews. Our results show that using textual information results
	
	in better general or personalized review score predictions than
	
	those derived from the numerical star ratings given by the users.},
  file = {Ganu2009Beyond.pdf:Ganu2009Beyond.pdf:PDF},
  owner = {csgueste},
  timestamp = {2016.05.29}
}

@InProceedings{Gao2012Joint,
  author    = {Gao, Wei and Li, Peng and Darwish, Kareem},
  title     = {Joint Topic Modeling for Event Summarization Across News and Social Media Streams},
  booktitle = {Proceedings of the 21st ACM International Conference on Information and Knowledge Management},
  year      = {2012},
  series    = {CIKM '12},
  pages     = {1173--1182},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Social media streams such as Twitter are regarded as faster first-hand
	sources of information generated by massive users. The content diffused
	through this channel, although noisy, provides important complement
	and sometimes even a substitute to the traditional news media reporting.
	In this paper, we propose a novel unsupervised approach based on
	topic modeling to summarize trending subjects by jointly discovering
	the representative and complementary information from news and tweets.
	Our method captures the content that enriches the subject matter
	by reinforcing the identification of complementary sentence-tweet
	pairs. To valuate the complementarity of a pair, we leverage topic
	modeling formalism by combining a two-dimensional topic-aspect model
	and a cross-collection approach in the multi-document summarization
	literature. The final summaries are generated by co-ranking the news
	sentences and tweets in both sides simultaneously. Experiments give
	promising results as compared to state-of-the-art baselines.},
  acmid     = {2398417},
  doi       = {10.1145/2396761.2398417},
  groups    = {Twitter},
  isbn      = {978-1-4503-1156-4},
  keywords  = {complementary summary, cross-collection topic-aspect model, gibbs sampling, lda},
  location  = {Maui, Hawaii, USA},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2396761.2398417},
}

@INPROCEEDINGS{Ge2011Cost,
  author = {Ge, Yong and Liu, Qi and Xiong, Hui and Tuzhilin, Alexander and Chen,
	Jian},
  title = {Cost-aware Travel Tour Recommendation},
  booktitle = {Proceedings of the 17th ACM SIGKDD International Conference on Knowledge
	Discovery and Data Mining},
  year = {2011},
  series = {KDD '11},
  pages = {983--991},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {2020568},
  doi = {10.1145/2020408.2020568},
  isbn = {978-1-4503-0813-7},
  keywords = {cost-aware recommendation, matrix factorization},
  location = {San Diego, California, USA},
  numpages = {9},
  timestamp = {2014.10.28},
  url = {http://doi.acm.org/10.1145/2020408.2020568}
}

@InProceedings{Gemulla2011Large-scale,
  author    = {Gemulla, Rainer and Nijkamp, Erik and Haas, Peter J. and Sismanis, Yannis},
  title     = {Large-scale matrix factorization with distributed stochastic gradient descent},
  booktitle = {Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining},
  year      = {2011},
  series    = {KDD '11},
  pages     = {69--77},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2020426},
  doi       = {10.1145/2020408.2020426},
  groups    = {matrix factorization},
  isbn      = {978-1-4503-0813-7},
  keywords  = {distributed matrix factorization, mapreduce, recommendation system, stochastic gradient descent},
  location  = {San Diego, California, USA},
  numpages  = {9},
  url       = {http://doi.acm.org/10.1145/2020408.2020426},
}

@INPROCEEDINGS{Geng2008Adapting,
  author = {Geng, Liqiang and Wang, Hao and Wang, Xin and Korba, Larry},
  title = {Adapting LDA Model to Discover Author-Topic Relations for Email Analysis},
  booktitle = {DaWaK '08: Proceedings of the 10th international conference on Data
	Warehousing and Knowledge Discovery},
  year = {2008},
  pages = {337--346},
  address = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  abstract = {Analyzing the author and topic relations in email corpus is an important
	issue in both social network analysis and text mining. The Author-Topic
	model is a statistical model that identifies the author-topic relations.
	However, in its inference process, it ignores the information at
	the document level, i.e., the co-occurrence of words within documents
	are not taken into account in deriving topics. This may not be suitable
	for email analysis. We propose to adapt the Latent Dirichlet Allocation
	model for analyzing email corpus. This method takes into account
	both the author-document relations and the document-topic relations.
	We use the Author-Topic model as the baseline method and propose
	measures to compare our method against the Author-Topic model. We
	did empirical analysis based on experimental results on both simulated
	data sets and the real Enron email data set to show that our method
	obtains better performance than the Author-Topic model.},
  doi = {http://dx.doi.org/10.1007/978-3-540-85836-2_32},
  isbn = {978-3-540-85835-5},
  location = {Turin, Italy}
}

@InProceedings{Gerani2010Proximity,
  author    = {Gerani, Shima and Carman, Mark James and Crestani, Fabio},
  title     = {Proximity-based Opinion Retrieval},
  booktitle = {Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year      = {2010},
  series    = {SIGIR '10},
  pages     = {403--410},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Blog post opinion retrieval aims at finding blog posts that are relevant
	and opinionated about a user's query. In this paper we propose a
	simple probabilistic model for assigning relevant opinion scores
	to documents. The key problem is how to capture opinion expressions
	in the document, that are related to the query topic. Current solutions
	enrich general opinion lexicons by finding query-specific opinion
	lexicons using pseudo-relevance feedback on external corpora or the
	collection itself. In this paper we use a general opinion lexicon
	and propose using proximity information in order to capture opinion
	term relatedness to the query. We propose a proximity-based opinion
	propagation method to calculate the opinion density at each point
	in a document. The opinion density at the position of a query term
	in the document can then be considered as the probability of opinion
	about the query term at that position. The effect of different kernels
	for capturing the proximity is also discussed. Experimental results
	on the BLOG06 dataset show that the proposed method provides significant
	improvement over standard TREC baselines and achieves a 2.5% increase
	in MAP over the best performing run in the TREC 2008 blog track.},
  acmid     = {1835517},
  comment   = {identify opinion expressions that are directed toward the query topic.
	
	
	rank
	
	documents by their likelihood given the query and opinion,},
  file      = {Gerani2010Proximity.pdf:Gerani2010Proximity.pdf:PDF},
  isbn      = {978-1-4503-0153-4},
  keywords  = {blog, opinion, proximity, retrieval, sentiment},
  location  = {Geneva, Switzerland},
  numpages  = {8},
  timestamp = {2014.10.04},
}

@CONFERENCE{Gibson2005Discovering,
  author = {Gibson, D. and Kumar, R. and Tomkins, A.},
  title = {Discovering large dense subgraphs in massive graphs},
  booktitle = {Proceedings of the 31st international conference on Very large data
	bases},
  year = {2005},
  pages = {721--732},
  organization = {VLDB Endowment},
  owner = {Cheyenne},
  timestamp = {2009.09.21}
}

@InProceedings{Gimpel2011Part-of-speech,
  author    = {Gimpel, Kevin and Schneider, Nathan and O'Connor, Brendan and Das, Dipanjan and Mills, Daniel and Eisenstein, Jacob and Heilman, Michael and Yogatama, Dani and Flanigan, Jeffrey and Smith, Noah A.},
  title     = {Part-of-speech tagging for Twitter: annotation, features, and experiments},
  booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers - Volume 2},
  year      = {2011},
  series    = {HLT '11},
  pages     = {42--47},
  address   = {Stroudsburg, PA, USA},
  publisher = {Association for Computational Linguistics},
  abstract  = {We address the problem of part-of-speech tagging for English data
	from the popular micro-blogging service Twitter. We develop a tagset,
	annotate data, develop features, and report tagging results nearing
	90% accuracy. The data and tools have been made available to the
	research community with the goal of enabling richer text analysis
	of Twitter and related social media data sets.},
  acmid     = {2002747},
  groups    = {Twitter},
  isbn      = {978-1-932432-88-6},
  location  = {Portland, Oregon},
  numpages  = {6},
  url       = {http://dl.acm.org/citation.cfm?id=2002736.2002747},
}

@INPROCEEDINGS{Girolami2003equivalence,
  author = {Girolami, Mark and Kab\'{a}n, Ata},
  title = {On an equivalence between PLSI and LDA},
  booktitle = {SIGIR '03: Proceedings of the 26th annual international ACM SIGIR
	conference on Research and development in informaion retrieval},
  year = {2003},
  pages = {433--434},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/860435.860537},
  isbn = {1-58113-646-3},
  location = {Toronto, Canada}
}

@Article{Girvan2002Community,
  author    = {Girvan, M. and Newman, MEJ},
  title     = {Community structure in social and biological networks},
  journal   = {Proceedings of the National Academy of Sciences},
  year      = {2002},
  volume    = {99},
  number    = {12},
  pages     = {7821},
  owner     = {Cheyenne},
  publisher = {National Acad Sciences},
  timestamp = {2009.09.21},
}

@INPROCEEDINGS{Gleich2011Rank,
  author = {Gleich, David F. and Lim, Lek-heng},
  title = {Rank Aggregation via Nuclear Norm Minimization},
  booktitle = {Proceedings of the 17th ACM SIGKDD International Conference on Knowledge
	Discovery and Data Mining},
  year = {2011},
  series = {KDD '11},
  pages = {60--68},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {The process of rank aggregation is intimately intertwined with the
	structure of skew symmetric matrices. We apply recent advances in
	the theory and algorithms of matrix completion to skew-symmetric
	matrices. This combination of ideas produces a new method for ranking
	a set of items. The essence of our idea is that a rank aggregation
	describes a partially filled skew-symmetric matrix. We extend an
	algorithm for matrix completion to handle skew-symmetric data and
	use that to extract ranks for each item.
	
	
	Our algorithm applies to both pairwise comparison and rating data.
	Because it is based on matrix completion, it is robust to both noise
	and incomplete data. We show a formal recovery result for the noiseless
	case and present a detailed study of the algorithm on synthetic data
	and Netflix ratings.},
  acmid = {2020425},
  doi = {10.1145/2020408.2020425},
  file = {Gleich2011Rank.pdf:Gleich2011Rank.pdf:PDF},
  isbn = {978-1-4503-0813-7},
  keywords = {nuclear norm, rank aggregation, skew symmetric},
  location = {San Diego, California, USA},
  numpages = {9},
  timestamp = {2015.09.22},
  url = {http://doi.acm.org/10.1145/2020408.2020425}
}

@Article{Goldwater2011Producing,
  author   = {Goldwater, Sharon and Griffiths, Thomas L and Johnson, Mark},
  title    = {Producing power-law distributions and damping word frequencies with two-stage language models},
  journal  = {Journal of Machine Learning Research},
  year     = {2011},
  volume   = {12},
  number   = {Jul},
  pages    = {2335--2382},
  abstract = {Standard statistical models of language fail to capture one of the
	most striking properties of natural
	
	languages: the power-law distribution in the frequencies of word tokens.
	We present a framework
	
	for developing statistical models that can generically produce power
	laws, breaking generative models
	
	into two stages. The first stage, the generator, can be any standard
	probabilistic model, while the
	
	second stage, the adaptor, transforms the word frequencies of this
	model to provide a closer match
	
	to natural language. We show that two commonly used Bayesian models,
	the Dirichlet-multinomial
	
	model and the Dirichlet process, can be viewed as special cases of
	our framework. We discuss two
	
	stochastic processes—the Chinese restaurant process and its two-parameter
	generalization based
	
	on the Pitman-Yor process—that can be used as adaptors in our framework
	to produce power-law
	
	distributions over word frequencies. We show that these adaptors justify
	common estimation procedures
	
	based on logarithmic or inverse-power transformations of empirical
	frequencies. In addition,
	
	taking the Pitman-Yor Chinese restaurant process as an adaptor justifies
	the appearance of type
	
	frequencies in formal analyses of natural language and improves the
	performance of a model for
	
	unsupervised learning of morphology.},
  comment  = {first generate a sequence of lexical items
	
	then generate a sequence of integers (the index of lexical item, this
	process is DP},
  file     = {Goldwater2011Producing.pdf:Goldwater2011Producing.pdf:PDF},
}

@Article{Golub1970Singular,
  author    = {Golub, G. and Reinsch, C.},
  title     = {Singular value decomposition and least squares solutions},
  journal   = {Numerische Mathematik},
  year      = {1970},
  volume    = {14},
  pages     = {403-420},
  note      = {10.1007/BF02163027},
  groups    = {matrix factorization},
  issn      = {0029-599X},
  issue     = {5},
  keyword   = {Mathematics and Statistics},
  publisher = {Springer Berlin / Heidelberg},
  url       = {http://dx.doi.org/10.1007/BF02163027},
}

@InProceedings{Gong2001Generic,
  author       = {Gong, Y. and Liu, X.},
  title        = {Generic text summarization using relevance measure and latent semantic analysis},
  booktitle    = {Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval},
  year         = {2001},
  pages        = {19--25},
  organization = {Citeseer},
  groups       = {Twitter},
}

@INPROCEEDINGS{Gopal2013Recursive,
  author = {Gopal, Siddharth and Yang, Yiming},
  title = {Recursive Regularization for Large-scale Classification with Hierarchical
	and Graphical Dependencies},
  booktitle = {Proceedings of the 19th ACM SIGKDD International Conference on Knowledge
	Discovery and Data Mining},
  year = {2013},
  series = {KDD '13},
  pages = {257--265},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {2487644},
  doi = {10.1145/2487575.2487644},
  file = {Gopal2013Recursive.pdf:Gopal2013Recursive.pdf:PDF},
  isbn = {978-1-4503-2174-7},
  keywords = {hierarchical classification, large-scale evaluation, parallel optimization,
	recursive regularization},
  location = {Chicago, Illinois, USA},
  numpages = {9},
  url = {http://doi.acm.org/10.1145/2487575.2487644}
}

@InProceedings{Gopalan2015Scalable,
  author    = {Prem Gopalan and Jake Hofman and David Blei},
  title     = {Scalable Recommendation with Hierarchical Poisson Factorization},
  booktitle = {31st Conference on Uncertainty in Artificial Intelligence},
  year      = {2015},
  abstract  = {We develop hierarchical Poisson matrix factorization (HPF), a novel
	method for providing users with high quality recommendations based
	on implicit feedback, such as views, clicks, or purchases. In contrast
	to existing recommendation models, HPF has a number of desirable
	properties. First, we show that HPF more accurately captures the
	long-tailed user activity found in most consumption data by explicitly
	considering the fact that users have finite attention budgets. This
	leads to better estimates of users' latent preferences, and therefore
	superior recommendations, compared to competing methods. Second,
	HPF learns these latent factors by only explicitly considering positive
	examples, eliminating the often costly step of generating artificial
	negative examples when fitting to implicit data. Third, HPF is more
	than just one method---it is the simplest in a class of probabilistic
	models with these properties, and can easily be extended to include
	more complex structure and assumptions. We develop a variational
	algorithm for approximate posterior inference for HPF that scales
	up to large data sets, and we demonstrate its performance on a wide
	variety of real-world recommendation problems---users rating movies,
	listening to songs, reading scientific papers, and reading news articles.
	Our study reveals that hierarchical Poisson factorization definitively
	outperforms previous methods, including nonnegative matrix factorization,
	topic models, and probabilistic matrix factorization techniques.},
  comment   = {sample activity~ Gamma distribution
	
	for each component,sample preference from Gamma distribution
	
	for each item, sample popularity from Gamma
	
	for each component sample attribute
	
	for each user and item, sample rating from posson (component of user
	times component of item)},
  file      = {Gopalan2015Scalable.pdf:Gopalan2015Scalable.pdf:PDF},
  timestamp = {2015.11.12},
}

@INPROCEEDINGS{Gorgoglione2011Effect,
  author = {Gorgoglione, Michele and Panniello, Umberto and Tuzhilin, Alexander},
  title = {The Effect of Context-aware Recommendations on Customer Purchasing
	Behavior and Trust},
  booktitle = {Proceedings of the Fifth ACM Conference on Recommender Systems},
  year = {2011},
  series = {RecSys '11},
  pages = {85--92},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Despite the growing popularity of Context-Aware Recommender Systems
	(CARSs), only limited work has been done on how contextual recommendations
	affect the behavior of customers in real-life settings. In this paper,
	we study the effects of contextual recommendations on the purchasing
	behavior of customers and their trust in the provided recommendations.
	In particular, we did live controlled experiments with real customers
	of a major commercial Italian retailer in which we compared the customers'
	purchasing behavior and measured their trust in the provided recommendations
	across the contextual, content-based and random recommendations.
	As a part of this study, we have investigated the role of accuracy
	and diversity of recommendations on customers' behavior and their
	trust in the provided recommendations for the three types of RSes.
	We have demonstrated that the context-aware RS outperformed the other
	two RSes in terms of accuracy, trust and other economics-based performance
	metrics across most of our experimental settings.},
  acmid = {2043951},
  doi = {10.1145/2043932.2043951},
  file = {Gorgoglione2011Effect.pdf:Gorgoglione2011Effect.pdf:PDF},
  isbn = {978-1-4503-0683-6},
  keywords = {accuracy, context, diversity, purchasing behavior, trust},
  location = {Chicago, Illinois, USA},
  numpages = {8},
  timestamp = {2014.09.13},
  url = {http://doi.acm.org/10.1145/2043932.2043951}
}

@ARTICLE{griffiths2004finding,
  author = {Griffiths, T.L. and Steyvers, M.},
  title = {Finding scientific topics},
  journal = {Proceedings of the National Academy of Sciences},
  year = {2004},
  volume = {101},
  pages = {5228--5235},
  number = {90001},
  publisher = {National Acad Sciences}
}

@Article{guimera2005team,
  author    = {Guimera, R. and Uzzi, B. and Spiro, J. and Amaral, L.A.N.},
  title     = {{Team assembly mechanisms determine collaboration network structure and team performance}},
  journal   = {Science},
  year      = {2005},
  volume    = {308},
  number    = {5722},
  pages     = {697},
  abstract  = {Agents in creative enterprises are embedded in networks that inspire,
	support,
	
	and evaluate their work. Here, we investigate how the mechanisms by
	which
	
	creative teams self-assemble determine the structure of these collaboration
	
	networks. We propose a model for the self-assembly of creative teams
	that has
	
	its basis in three parameters: team size, the fraction of newcomers
	in new
	
	productions, and the tendency of incumbents to repeat previous collaborations.
	
	The model suggests that the emergence of a large connected community
	of
	
	practitioners can be described as a phase transition. We find that
	team assembly mechanisms determine both the structure of the collaboration
	network and
	
	team performance for teams derived from both artistic and scientific
	fields},
  comment   = {the tendency for group size in many different networks often to settle
	around},
  file      = {guimera2005team.pdf:guimera2005team.pdf:PDF},
  publisher = {AAAS},
}

@INPROCEEDINGS{Guiver2009Bayesian,
  author = {John Guiver and Edward Snelson},
  title = {Bayesian inference for Plackett-Luce ranking models},
  booktitle = {n Proceedings of the 26 th International Conference on Machine Learning
	(ICML '09)},
  year = {2009},
  abstract = {This paper gives an efficient Bayesian method
	
	for inferring the parameters of a PlackettLuce
	
	ranking model. Such models are parameterised
	
	distributions over rankings of a finite
	
	set of objects, and have typically been studied
	
	and applied within the psychometric, sociometric
	
	and econometric literature. The inference
	
	scheme is an application of Power EP
	
	(expectation propagation). The scheme is robust
	
	and can be readily applied to large scale
	
	data sets. The inference algorithm extends to
	
	variations of the basic Plackett-Luce model,
	
	including partial rankings. We show a number
	
	of advantages of the EP approach over
	
	the traditional maximum likelihood method.
	
	We apply the method to aggregate rankings
	
	of NASCAR racing drivers over the 2002 season,
	
	and also to rankings of movie genres.},
  file = {Guiver2009Bayesian.pdf:Guiver2009Bayesian.pdf:PDF},
  owner = {csgueste},
  timestamp = {2016.04.19}
}

@InProceedings{Guo2009Analyzing,
  author    = {Guo, Lei and Tan, Enhua and Chen, Songqing and Zhang, Xiaodong and Zhao, Yihong (Eric)},
  title     = {Analyzing patterns of user content generation in online social networks},
  booktitle = {Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining},
  year      = {2009},
  series    = {KDD '09},
  pages     = {369--378},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1557064},
  doi       = {http://doi.acm.org/10.1145/1557019.1557064},
  file      = {Guo2009Analyzing.pdf:Guo2009Analyzing.pdf:PDF},
  isbn      = {978-1-60558-495-9},
  keywords  = {social networks, stretched exponential distribution, user generated content (ugc)},
  location  = {Paris, France},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1557019.1557064},
}

@InProceedings{Gupta2014Online,
  author    = {Gupta, Anupam and Kumar, Amit},
  title     = {Online Steiner Tree with Deletions},
  booktitle = {Proceedings of the Twenty-Fifth Annual ACM-SIAM Symposium on Discrete Algorithms},
  year      = {2014},
  series    = {SODA '14},
  pages     = {455--467},
  publisher = {SIAM},
  abstract  = {In the online Steiner tree problem, the input is a set of vertices
	that appear one-by-one, and we have to maintain a Steiner tree on
	the current set of vertices. The cost of the tree is the total length
	of edges in the tree, and we want this cost to be close to the cost
	of the optimal Steiner tree at all points in time. If we are allowed
	to only add edges, a tight bound of Θ(log n) on the competitiveness
	has been known for two decades. Recently it was shown that if we
	can add one new edge and make one edge swap upon every vertex arrival,
	we can still maintain a constant-competitive tree online.
	
	
	But what if the set of vertices sees both additions and deletions?
	Again, we would like to obtain a low-cost Steiner tree with as few
	edge changes as possible. The original paper of Imase and Waxman
	(SIAM J. Disc. Math, 4(3): 369--384, 1991) had also considered this
	model, and it gave an algorithm that made at most O(n3/2) edge changes
	for the first n requests, and maintained a constant-competitive tree
	online. In this paper we improve on these results:
	
	
	• We give an online algorithm that maintains a Steiner tree under
	only deletions: we start off with a set of vertices, and at each
	time one of the vertices is removed from this set---our Steiner tree
	no longer has to span this vertex. We give an algorithm that changes
	only a constant number of edges upon each request, and maintains
	a constant-competitive tree at all times. Our algorithm uses the
	primal-dual framework and a global charging argument to carefully
	make these constant number of changes.
	
	
	• We also give an algorithm that maintains a Steiner tree in the fully-dynamic
	model (where each request either adds or deletes a vertex). Our algorithm
	for this setting makes a constant number of changes per request in
	an amortized sense.},
  acmid     = {2634108},
  comment   = {hierarchical clustering},
  file      = {Gupta2014Online.pdf:Gupta2014Online.pdf:PDF},
  isbn      = {978-1-611973-38-9},
  location  = {Portland, Oregon},
  numpages  = {13},
  timestamp = {2015.03.05},
  url       = {http://dl.acm.org/citation.cfm?id=2634074.2634108},
}

@INPROCEEDINGS{Gupta2009Understanding,
  author = {Gupta, A. and Srinivasan, P. and Jianbo Shi and Davis, L.S.},
  title = {Understanding videos, constructing plots learning a visually grounded
	storyline model from annotated videos},
  booktitle = {Computer Vision and Pattern Recognition, 2009. CVPR 2009. IEEE Conference
	on},
  year = {2009},
  pages = {2012 -2019},
  month = {june},
  abstract = {Analyzing videos of human activities involves not only recognizing
	actions (typically based on their appearances), but also determining
	the story/plot of the video. The storyline of a video describes causal
	relationships between actions. Beyond recognition of individual actions,
	discovering causal relationships helps to better understand the semantic
	meaning of the activities. We present an approach to learn a visually
	grounded storyline model of videos directly from weakly labeled data.
	The storyline model is represented as an AND-OR graph, a structure
	that can compactly encode storyline variation across videos. The
	edges in the AND-OR graph correspond to causal relationships which
	are represented in terms of spatio-temporal constraints. We formulate
	an Integer Programming framework for action recognition and storyline
	extraction using the storyline model and visual groundings learned
	from training data.},
  doi = {10.1109/CVPR.2009.5206492},
  file = {Gupta2009Understanding.pdf:Gupta2009Understanding.pdf:PDF},
  issn = {1063-6919},
  keywords = {AND-OR graph;encoding;human action recognition;human activity analysis;integer
	programming framework;plots learning construction;semantic meaning;spatio-temporal
	constraint;video annotation;video understanding;visually grounded
	storyline model extraction;graph theory;image representation;integer
	programming;learning (artificial intelligence);spatiotemporal phenomena;video
	coding;}
}

@InProceedings{Guy2010Social,
  author    = {Guy, Ido and Zwerdling, Naama and Ronen, Inbal and Carmel, David and Uziel, Erel},
  title     = {Social Media Recommendation Based on People and Tags},
  booktitle = {Proceedings of the 33rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year      = {2010},
  series    = {SIGIR '10},
  pages     = {194--201},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {We study personalized item recommendation within an enterprise social
	media application suite that includes blogs, bookmarks, communities,
	wikis, and shared files. Recommendations are based on two of the
	core elements of social media - people and tags. Relationship information
	among people, tags, and items, is collected and aggregated across
	different sources within the enterprise. Based on these aggregated
	relationships, the system recommends items related to people and
	tags that are related to the user. Each recommended item is accompanied
	by an explanation that includes the people and tags that led to its
	recommendation, as well as their relationships with the user and
	the item. We evaluated our recommender system through an extensive
	user study. Results show a significantly better interest ratio for
	the tag-based recommender than for the people-based recommender,
	and an even better performance for a combined recommender. Tags applied
	on the user by other people are found to be highly effective in representing
	that user's topics of interest.},
  acmid     = {1835484},
  doi       = {10.1145/1835449.1835484},
  groups    = {Twitter},
  isbn      = {978-1-4503-0153-4},
  keywords  = {collaborative tagging, personalization, recommender systems, social media, social networks, social software},
  location  = {Geneva, Switzerland},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/1835449.1835484},
}

@INPROCEEDINGS{Haeffele2014Structured,
  author = {Benjamin Haeffele and Eric Young and Rene Vidal},
  title = {Structured Low-Rank Matrix Factorization: Optimality, Algorithm,
	and Applications to Image Processing},
  booktitle = {Proceedings of ICML},
  year = {2014},
  pages = {1357-1365},
  abstract = {Recently, convex solutions to low-rank matrix factorization problems
	have received increasing attention in machine learning. However,
	in many applications the data can display other structures beyond
	simply being low-rank. For example, images and videos present complex
	spatio-temporal structures, which are largely ignored by current
	low-rank methods. In this paper we explore a matrix factorization
	technique suitable for large datasets that captures additional structure
	in the factors by using a projective tensor norm, which includes
	classical image regularizers such as total variation and the nuclear
	norm as particular cases. Although the resulting optimization problem
	is not convex, we show that under certain conditions on the factors,
	any local minimizer for the factors yields a global minimizer for
	their product. Examples in biomedical video segmentation and hyperspectral
	compressed recovery show the advantages of our approach on high-dimensional
	datasets.},
  file = {Haeffele2014Structured.pdf:Haeffele2014Structured.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.06.23}
}

@INPROCEEDINGS{Haghighi2009Exploring,
  author = {Haghighi, Aria and Vanderwende, Lucy},
  title = {Exploring Content Models for Multi-document Summarization},
  booktitle = {Proceedings of Human Language Technologies: The 2009 Annual Conference
	of the North American Chapter of the Association for Computational
	Linguistics},
  year = {2009},
  series = {NAACL '09},
  pages = {362--370},
  address = {Stroudsburg, PA, USA},
  publisher = {Association for Computational Linguistics},
  abstract = {We present an exploration of generative probabilistic models for multi-document
	summarization. Beginning with a simple word frequency based model
	(Nenkova and Vanderwende, 2005), we construct a sequence of models
	each injecting more structure into the representation of document
	set content and exhibiting ROUGE gains along the way. Our final model,
	HierSum, utilizes a hierarchical LDA-style model (Blei et al., 2004)
	to represent content specificity as a hierarchy of topic vocabulary
	distributions. At the task of producing generic DUC-style summaries,
	HierSum yields state-of-the-art ROUGE performance and in pairwise
	user evaluation strongly outperforms Toutanova et al. (2007)'s state-of-the-art
	discriminative system. We also explore HierSum's capacity to produce
	multiple 'topical summaries' in order to facilitate content discovery
	and navigation.},
  acmid = {1620807},
  file = {Haghighi2009Exploring.pdf:Books\\Haghighi2009Exploring.pdf:PDF},
  isbn = {978-1-932432-41-1},
  location = {Boulder, Colorado},
  numpages = {9},
  timestamp = {2015.07.20}
}

@Article{hamasaki2006community,
  author    = {Hamasaki, M. and Matsuo, Y. and Ishida, K. and Nakamura, Y. and Nishimura, T. and Takeda, H.},
  title     = {Community Focused Social Network Extraction},
  journal   = {Lecture Notes in Computer Science},
  year      = {2006},
  volume    = {4185},
  pages     = {155},
  publisher = {Springer},
}

@INPROCEEDINGS{Han2000Mining,
  author = {Han, Jiawei and Pei, Jian and Yin, Yiwen},
  title = {Mining frequent patterns without candidate generation},
  booktitle = {Proceedings of the 2000 ACM SIGMOD international conference on Management
	of data},
  year = {2000},
  series = {SIGMOD '00},
  pages = {1--12},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {335372},
  doi = {http://doi.acm.org/10.1145/342009.335372},
  file = {Han2000Mining.pdf:Han2000Mining.pdf:PDF},
  isbn = {1-58113-217-4},
  location = {Dallas, Texas, United States},
  numpages = {12},
  url = {http://doi.acm.org/10.1145/342009.335372}
}

@Article{Hanneke2010Discrete,
  author    = {Steve Hanneke and Wenjie Fu and Eric P. Xing},
  title     = {Discrete temporal models of social networks},
  journal   = {Electronic Journal of Statistics},
  year      = {2010},
  volume    = {4},
  pages     = {585–605},
  file      = {Hanneke2010Discrete.pdf:Hanneke2010Discrete.pdf:PDF},
  owner     = {linchen},
  timestamp = {2011.08.13},
}

@InProceedings{Hannon2010Recommending,
  author    = {Hannon, John and Bennett, Mike and Smyth, Barry},
  title     = {Recommending twitter users to follow using content and collaborative filtering approaches},
  booktitle = {Proceedings of the fourth ACM conference on Recommender systems},
  year      = {2010},
  series    = {RecSys '10},
  pages     = {199--206},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Recently the world of the web has become more social and more real-time.
	Facebook and Twitter are perhaps the exemplars of a new generation
	of social, real-time web services and we believe these types of service
	provide a fertile ground for recommender systems research. In this
	paper we focus on one of the key features of the social web, namely
	the creation of relationships between users. Like recent research,
	we view this as an important recommendation problem -- for a given
	user, UT which other users might be recommended as followers/followees
	-- but unlike other researchers we attempt to harness the real-time
	web as the basis for profiling and recommendation. To this end we
	evaluate a range of different profiling and recommendation strategies,
	based on a large dataset of Twitter users and their tweets, to demonstrate
	the potential for effective and efficient followee recommendation.},
  acmid     = {1864746},
  doi       = {http://doi.acm.org/10.1145/1864708.1864746},
  file      = {Hannon2010Recommending.pdf:Hannon2010Recommending.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-1-60558-906-0},
  keywords  = {collaborative filtering, content based recommendation, twitter, web 2.0},
  location  = {Barcelona, Spain},
  numpages  = {8},
  owner     = {linchen},
  timestamp = {2011.11.01},
  url       = {http://doi.acm.org/10.1145/1864708.1864746},
}

@InProceedings{Hariri2013Query,
  author    = {Hariri, Negar and Mobasher, Bamshad and Burke, Robin},
  title     = {Query-driven Context Aware Recommendation},
  booktitle = {Proceedings of the 7th ACM Conference on Recommender Systems},
  year      = {2013},
  series    = {RecSys '13},
  pages     = {9--16},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Context aware recommender systems go beyond the traditional personalized
	recommendation models by incorporating a form of situational awareness.
	They provide recommendations that not only correspond to a user's
	preference profile, but that are also tailored to a given situation
	or context. We consider the setting in which contextual information
	is represented as a subset of an item feature space describing short-term
	interests or needs of a user in a given situation. This contextual
	information can be provided by the user in the form of an explicit
	query, or derived implicitly.
	
	
	We propose a unified probabilistic model that integrates user profiles,
	item representations, and contextual information. The resulting recommendation
	framework computes the conditional probability of each item given
	the user profile and the additional context. These probabilities
	are used as recommendation scores for ranking items. Our model is
	an extension of the Latent Dirichlet Allocation (LDA) model that
	provides the capability for joint modeling of users, items, and the
	meta-data associated with contexts. Each user profile is modeled
	as a mixture of the latent topics. The discovered latent topics enable
	our system to handle missing data in item features. We demonstrate
	the application of our framework for article and music recommendation.
	In the latter case, the set of popular tags from social tagging Web
	sites are used for context descriptions. Our evaluation results show
	that considering context can help improve the quality of recommendations.},
  acmid     = {2507187},
  comment   = {LDA},
  file      = {Hariri2013Query.pdf:Hariri2013Query.pdf:PDF},
  isbn      = {978-1-4503-2409-0},
  keywords  = {collaborative filtering, context-aware recommendation, graphical models, latent dirichlet allocation},
  location  = {Hong Kong, China},
  numpages  = {8},
}

@InProceedings{Hariri2012Context,
  author    = {Hariri, Negar and Mobasher, Bamshad and Burke, Robin},
  title     = {Context-aware Music Recommendation Based on Latenttopic Sequential Patterns},
  booktitle = {Proceedings of the Sixth ACM Conference on Recommender Systems},
  year      = {2012},
  series    = {RecSys '12},
  pages     = {131--138},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Contextual factors can greatly influence the users' preferences in
	listening to music. Although it is hard to capture these factors
	directly, it is possible to see their effects on the sequence of
	songs liked by the user in his/her current interaction with the system.
	In this paper, we present a context-aware music recommender system
	which infers contextual information based on the most recent sequence
	of songs liked by the user. Our approach mines the top frequent tags
	for songs from social tagging Web sites and uses topic modeling to
	determine a set of latent topics for each song, representing different
	contexts. Using a database of human-compiled playlists, each playlist
	is mapped into a sequence of topics and frequent sequential patterns
	are discovered among these topics. These patterns represent frequent
	sequences of transitions between the latent topics representing contexts.
	Given a sequence of songs in a user's current interaction, the discovered
	patterns are used to predict the next topic in the playlist. The
	predicted topics are then used to post-filter the initial ranking
	produced by a traditional recommendation algorithm. Our experimental
	evaluation suggests that our system can help produce better recommendations
	in comparison to a conventional recommender system based on collaborative
	or content-based filtering. Furthermore, the topic modeling approach
	proposed here is also useful in providing better insight into the
	underlying reasons for song selection and in applications such as
	playlist construction and context prediction.},
  acmid     = {2365979},
  comment   = {assign topics to songs with tags by LDA
	
	topic sequential mining
	
	first, the recommendation engine uses the current active session as
	an input. If the
	
	engine cannot generate any recommendations, the size of
	
	active session window is iteratively decreased by removing
	
	the oldest song until a recommendation is generated or the
	
	window size becomes 0.},
  doi       = {10.1145/2365952.2365979},
  file      = {Hariri2012Context.pdf:Hariri2012Context.pdf:PDF},
  groups    = {Recommender Systems},
  isbn      = {978-1-4503-1270-7},
  keywords  = {collaborative filtering, context-aware recommendation, recommender systems},
  location  = {Dublin, Ireland},
  numpages  = {8},
  timestamp = {2014.06.09},
  url       = {http://doi.acm.org/10.1145/2365952.2365979},
}

@Conference{harper2009facts,
  author       = {Harper, F.M. and Moy, D. and Konstan, J.A.},
  title        = {{Facts or friends?: distinguishing informational and conversational questions in social Q\&A sites}},
  booktitle    = {Proceedings of the 27th international conference on Human factors in computing systems},
  year         = {2009},
  pages        = {759--768},
  organization = {ACM},
  abstract     = {Tens of thousands of questions are asked and answered
	
	every day on social question and answer (Q&A) Web sites
	
	such as Yahoo Answers. While these sites generate an
	
	enormous volume of searchable data, the problem of
	
	determining which questions and answers are archival
	
	quality has grown. One major component of this problem is
	
	the prevalence of conversational questions, identified both
	
	by Q&A sites and academic literature as questions that are
	
	intended simply to start discussion. For example, a
	
	conversational question such as “do you believe in
	
	evolution?” might successfully engage users in discussion,
	
	but probably will not yield a useful web page for users
	
	searching for information about evolution. Using data from
	
	three popular Q&A sites, we confirm that humans can
	
	reliably distinguish between these conversational questions
	
	and other informational questions, and present evidence
	
	that conversational questions typically have much lower
	
	potential archival value than informational questions.
	
	Further, we explore the use of machine learning techniques
	
	to automatically classify questions as conversational or
	
	informational, learning in the process about categorical,
	
	linguistic, and social differences between different question
	
	types. Our algorithms approach human performance,
	
	attaining 89.7% classification accuracy in our experiments.},
  comment      = {classify informational & conversational questions
	
	Data: Yahoo Answers, Answerbag,
	
	and Ask Metafilter
	
	1,volunteer evaluation
	
	The coding tool first asks users to determine if a question is
	
	asked with primarily informational or conversational intent.
	
	It then asks users to rate the question on two dimensions
	
	using Likert scales (5=strongly agree, 1=strongly disagree):
	
	• WRITING QUALITY: I think this question is well-written.
	
	• ARCHIVAL VALUE: I think high-quality answers to this
	
	question will provide information of lasting/archival
	
	value to others.
	
	
	2,Feature
	
	topical Category:
	
	Textual: word,bigram, do not remove stopword
	
	Social Network:
	
	 NUM_NEIGHBORS: The number of neighbors to the
	
	question asker. (How many other users has the question
	
	asker interacted with?)
	
	• PCT_ANSWERS: The question asker's number of
	
	outbound edges as a percentage of all edges connected
	
	to that user. (What fraction of the question asker's
	
	contributions have been answers?)
	
	• CLUST_COEFFICIENT: The clustering coefficient [20] of
	
	the question asker's ego network (How inter-connected
	
	are the question asker's neighbors?) the proportion of links between
	the vertices within its neighbourhood divided by the number of links
	that could possibly exist between them.
	
	
	3,Ensemble Classification
	
	find that the category-based and social network-based
	
	classifiers appear to pick up on much of the same signal
	
	(Q=0.72), perhaps showing that the same “types” of users
	
	tend to post in the same categories. On the other hand, we
	
	see better diversity scores when comparing the output of
	
	text-based and category-based classifiers (Q=0.31) as well
	
	as the social network-based and text-based classifiers
	
	(Q=0.58)},
  file         = {harper2009facts.pdf:harper2009facts.pdf:PDF},
}

@InProceedings{Harper2009Facts,
  author    = {Harper, F. Maxwell and Moy, Daniel and Konstan, Joseph A.},
  title     = {Facts or friends?: distinguishing informational and conversational questions in social Q\&A sites},
  booktitle = {CHI '09: Proceedings of the 27th international conference on Human factors in computing systems},
  year      = {2009},
  pages     = {759--768},
  address   = {New York, NY, USA},
  publisher = {ACM},
  doi       = {http://doi.acm.org/10.1145/1518701.1518819},
  isbn      = {978-1-60558-246-7},
  location  = {Boston, MA, USA},
}

@ARTICLE{Hartigan1979Algorithm,
  author = {Hartigan, John A and Wong, Manchek A},
  title = {Algorithm AS 136: A k-means clustering algorithm},
  journal = {Applied statistics},
  year = {1979},
  pages = {100--108},
  publisher = {JSTOR}
}

@Article{Haveliwala2003Topic-sensitive,
  author    = {Haveliwala, T.H.},
  title     = {Topic-sensitive pagerank: A context-sensitive ranking algorithm for web search},
  journal   = {IEEE Transactions on Knowledge and Data Engineering},
  year      = {2003},
  pages     = {784--796},
  publisher = {IEEE Computer Society},
}

@ARTICLE{haythornthwaite2007network,
  author = {Haythornthwaite, C. and Marin, A. and Smith-Lovin, L. and Zinko,
	N. and others},
  title = {{The network is personal: Introduction to a special issue of Social
	Networks}},
  journal = {Social Networks},
  year = {2007},
  volume = {29},
  pages = {349--356},
  file = {haythornthwaite2007network.pdf:haythornthwaite2007network.pdf:PDF}
}

@Article{He2011Modeling,
  author    = {Ben He and Jimmy Xiangji Huang and Xiaofeng Zhou},
  title     = {Modeling term proximity for probabilistic information retrieval models},
  journal   = {Information Sciences},
  year      = {2011},
  volume    = {8},
  number    = {14},
  pages     = {3017–3031},
  abstract  = {Proximity among query terms has been found to be useful for improving
	retrieval performance. However, its application to classical probabilistic
	information retrieval models, such as Okapi’s BM25, remains a challenging
	research problem. In this paper, we propose to improve the classical
	BM25 model by utilizing the term proximity evidence. Four novel methods,
	namely a window-based N-gram Counting method, Survival Analysis over
	different statistics, including the Poisson process, an exponential
	distribution and an empirical function, are proposed to model the
	proximity between query terms. Through extensive experiments on standard
	TREC collections, our proposed proximity-based BM25 model, called
	BM25P, is compared to strong state-of-the-art evaluation baselines,
	including the original unigram BM25 model, the Markov Random Field
	model, and the positional language model. According to the experimental
	results, the window-based N-gram Counting method, and Survival Analysis
	over an exponential distribution are the most effective among all
	four proposed methods, which lead to marked improvement over the
	baselines. This shows that the use of term proximity considerably
	enhances the retrieval effectiveness of the classical probabilistic
	models. It is therefore recommended to deploy a term proximity component
	in retrieval systems that employ probabilistic models.},
  comment   = {extensive experiments
Review:
extend the BM25 model by taking ngram frequency into account
	
	The final ranking score is a linear combination of ngram models for
	different n
	
	each ngram model is a BM25, with the term weights in BM25 defined
	as some functions borrowed from survival analysis},
  file      = {He2011Modeling.pdf:He2011Modeling.pdf:PDF},
  owner     = {littlep},
  timestamp = {2014.10.04},
}

@CONFERENCE{He2008University,
  author = {He, B. and Macdonald, C. and Ounis, I. and Peng, J. and Santos, R.L.T.},
  title = {University of Glasgow at TREC 2008: Experiments in Blog, Enterprise,
	and Relevance Feedback Tracks with Terrier},
  booktitle = {Proceedings of the 17th Text REtrieval Conference (TREC 2008)},
  year = {2008},
  volume = {9},
  number = {4.8},
  pages = {10--2},
  owner = {Cheyenne},
  timestamp = {2009.09.21}
}

@Article{He2007Combining,
  author   = {Ben He and Iadh Ounis},
  title    = {Combining fields for query expansion and adaptive query expansion},
  journal  = {Information Processing \& Management},
  year     = {2007},
  volume   = {43},
  number   = {5},
  pages    = {1294 - 1307},
  issn     = {0306-4573},
  note     = {<ce:title>Patent Processing</ce:title>},
  abstract = {In this paper, we aim to improve query expansion for ad-hoc retrieval,
	by proposing a more fine-grained term reweighting
	
	process. This fine-grained process uses statistics from the representation
	of documents in various fields, such as their
	
	titles, the anchor text of their incoming links, and their body content.
	The contribution of this paper is twofold: First, we
	
	propose a novel query expansion mechanism on fields by combining field
	evidence available in a corpora. Second, we propose
	
	an adaptive query expansion mechanism that selects an appropriate
	collection resource, either the local collection, or
	
	a high-quality external resource, for query expansion on a per-query
	basis. The two proposed query expansion approaches
	
	are thoroughly evaluated using two standard Text Retrieval Conference
	(TREC) Web collections, namely the WT10G collection
	
	and the large-scale .GOV2 collection. From the experimental results,
	we observe a statistically significant improvement
	
	compared with the baselines. Moreover, we conclude that the adaptive
	query expansion mechanism is very effective
	
	when the external collection used is much larger than the local collection.},
  doi      = {10.1016/j.ipm.2006.11.002},
  file     = {He2007Combining.pdf:He2007Combining.pdf:PDF},
  keywords = {Query expansion on fields},
  url      = {http://www.sciencedirect.com/science/article/pii/S0306457306001956},
}

@INPROCEEDINGS{He2007BLINKS,
  author = {He, H. and Wang, H. and Yang, J. and Yu, P.S.},
  title = {BLINKS: ranked keyword searches on graphs},
  booktitle = {Proceedings of the 2007 ACM SIGMOD international conference on Management
	of data},
  year = {2007},
  pages = {305--316},
  organization = {ACM},
  abstract = {Query processing over graph-structured data is enjoying a growing
	
	number of applications. A top-k keyword search query on a graph
	
	nds the top k answers according to some ranking criteria, where
	
	each answer is a substructure of the graph containing all query keywords.
	
	Current techniques for supporting such queries on general
	
	graphs suffer from several drawbacks, e.g., poor worst-case performance,
	
	not taking full advantage of indexes, and high memory
	
	requirements. To address these problems, we propose BLINKS, a
	
	bi-level indexing and query processing scheme for top-k keyword
	
	search on graphs. BLINKS follows a search strategy with provable
	
	performance bounds, while additionally exploiting a bi-level
	
	index for pruning and accelerating the search. To reduce the index
	
	space, BLINKS partitions a data graph into blocks: The bilevel
	
	index stores summary information at the block level to initiate
	
	and guide search among blocks, and more detailed information
	
	for each block to accelerate search within blocks. Our experiments
	
	show that BLINKS offers orders-of-magnitude performance
	
	improvement over existing approaches.},
  file = {He2007BLINKS.pdf:He2007BLINKS.pdf:PDF}
}

@InProceedings{He2010Context-aware,
  author    = {He, Qi and Pei, Jian and Kifer, Daniel and Mitra, Prasenjit and Giles, Lee},
  title     = {Context-aware citation recommendation},
  booktitle = {Proceedings of the 19th international conference on World wide web},
  year      = {2010},
  series    = {WWW '10},
  pages     = {421--430},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {When you write papers, how many times do you want to
	
	make some citations at a place but you are not sure which
	
	papers to cite? Do you wish to have a recommendation
	
	system which can recommend a small number of good candidates for every
	place that you want to make some citations? In this paper, we present
	our initiative of building a
	
	context-aware citation recommendation system. High quality citation
	recommendation is challenging: not only should
	
	the citations recommended be relevant to the paper under
	
	composition, but also should match the local contexts of the
	
	places citations are made. Moreover, it is far from trivial to
	
	model how the topic of the whole paper and the contexts of
	
	the citation places should aﬀect the selection and ranking of
	
	citations. To tackle the problem, we develop a context-aware
	
	approach. The core idea is to design a novel non-parametric
	
	probabilistic model which can measure the context-based
	
	relevance between a citation context and a document. Our
	
	approach can recommend citations for a context eﬀectively.
	
	Moreover, it can recommend a set of citations for a paper
	
	with high quality. We implement a prototype system in
	
	CiteSeerX. An extensive empirical evaluation in the CiteSeerX digital
	library against many baselines demonstrates
	
	the eﬀectiveness and the scalability of our approach.},
  acmid     = {1772734},
  doi       = {http://doi.acm.org/10.1145/1772690.1772734},
  file      = {He2010Context-aware.pdf:He2010Context-aware.pdf:PDF},
  groups    = {Recommender Systems},
  isbn      = {978-1-60558-799-8},
  keywords  = {bibliometrics, context, gleason's theorem, recommender systems},
  location  = {Raleigh, North Carolina, USA},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1772690.1772734},
}

@INPROCEEDINGS{He2012Document,
  author = {He, Zhanying and Chen, Chun and Bu, Jiajun and Wang, Can and Zhang,
	Lijun and Cai, Deng and He, Xiaofei},
  title = {Document Summarization Based on Data Reconstruction.},
  booktitle = {Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence},
  year = {2012},
  pages = {620-626},
  abstract = {Document summarization is of great value to many
	
	real world applications, such as snippets generation for
	
	search results and news headlines generation. Traditionally,
	
	document summarization is implemented by extracting
	
	sentences that cover the main topics of a document
	
	with a minimum redundancy. In this paper, we
	
	take a different perspective from data reconstruction and
	
	propose a novel framework named Document Summarization
	
	based on Data Reconstruction (DSDR). Specifically,
	
	our approach generates a summary which consist
	
	of those sentences that can best reconstruct the original
	
	document. To model the relationship among sentences,
	
	we introduce two objective functions: (1) linear reconstruction,
	
	which approximates the document by linear
	
	combinations of the selected sentences; (2) nonnegative
	
	linear reconstruction, which allows only additive,
	
	not subtractive, linear combinations. In this framework,
	
	the reconstruction error becomes a natural criterion for
	
	measuring the quality of the summary. For each objective
	
	function, we develop an efficient algorithm to solve
	
	the corresponding optimization problem. Extensive experiments
	
	on summarization benchmark data sets DUC
	
	2006 and DUC 2007 demonstrate the effectiveness of
	
	our proposed approach.},
  file = {He2012Document.pdf:He2012Document.pdf:PDF}
}

@INPROCEEDINGS{Heckerman1997Models,
  author = {Heckerman, David and Meek, Christopher},
  title = {Models and Selection Criteria for Regression and Classification},
  booktitle = {Proceedings of the Thirteenth Conference on Uncertainty in Artificial
	Intelligence},
  year = {1997},
  series = {UAI'97},
  pages = {223--228},
  address = {San Francisco, CA, USA},
  publisher = {Morgan Kaufmann Publishers Inc.},
  acmid = {2074253},
  file = {Heckerman1997Models.pdf:Heckerman1997Models.pdf:PDF},
  isbn = {1-55860-485-5},
  keywords = {Bayesian networks, classification, model averaging, model selection,
	prequential criteria, regression},
  location = {Providence, Rhode Island},
  numpages = {6},
  url = {http://dl.acm.org/citation.cfm?id=2074226.2074253}
}

@TECHREPORT{Heinrich2009Parameter,
  author = {Gregor Heinrich},
  title = {Parameter estimation for text analysis},
  institution = {Fraunhofer IGD,Darmstadt, Germany},
  year = {2009},
  abstract = {Presents parameter estimation methods common with discrete probability
	
	distributions, which is of particular interest in text modeling. Starting
	with
	
	maximum likelihood, a posteriori and Bayesian estimation, central
	concepts like
	
	conjugate distributions and Bayesian networks are reviewed. As an
	application,
	
	the model of latent Dirichlet allocation (LDA) is explained in detail
	with a full
	
	derivation of an approximate inference algorithm based on Gibbs sampling,
	including
	
	a discussion of Dirichlet hyperparameter estimation. Finally, analysis
	
	methods of LDA models are discussed.},
  file = {Heinrich2009Parameter.pdf:Heinrich2009Parameter.pdf:PDF},
  owner = {littlep},
  timestamp = {2015.05.02}
}

@InProceedings{Henderson2012RolX,
  author    = {Henderson, Keith and Gallagher, Brian and Eliassi-Rad, Tina and Tong, Hanghang and Basu, Sugato and Akoglu, Leman and Koutra, Danai and Faloutsos, Christos and Li, Lei},
  title     = {RolX: Structural Role Extraction and Mining in Large Graphs},
  booktitle = {Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year      = {2012},
  series    = {KDD '12},
  pages     = {1231--1239},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Given a network, intuitively two nodes belong to the same role if
	they have similar structural behavior. Roles should be automatically
	determined from the data, and could be, for example, "clique-members,"
	"periphery-nodes," etc. Roles enable numerous novel and useful network-mining
	tasks, such as sense-making, searching for similar nodes, and node
	classification. This paper addresses the question: Given a graph,
	how can we automatically discover roles for nodes? We propose RolX
	(Role eXtraction), a scalable (linear in the number of edges), unsupervised
	learning approach for automatically extracting structural roles from
	general network data. We demonstrate the effectiveness of RolX on
	several network-mining tasks: from exploratory data analysis to network
	transfer learning. Moreover, we compare network role discovery with
	network community discovery. We highlight fundamental differences
	between the two (e.g., roles generalize across disconnected networks,
	communities do not); and show that the two approaches are complimentary
	in nature.},
  acmid     = {2339723},
  comment   = {features , mf for classification},
  doi       = {10.1145/2339530.2339723},
  file      = {Henderson2012RolX.pdf:Henderson2012RolX.pdf:PDF},
  isbn      = {978-1-4503-1462-6},
  keywords  = {graph mining, network classification, sense-making, similarity search, structural role discovery},
  location  = {Beijing, China},
  numpages  = {9},
  timestamp = {2015.09.15},
  url       = {http://doi.acm.org/10.1145/2339530.2339723},
}

@InProceedings{Henderson2011Its,
  author    = {Henderson, Keith and Gallagher, Brian and Li, Lei and Akoglu, Leman and Eliassi-Rad, Tina and Tong, Hanghang and Faloutsos, Christos},
  title     = {It's Who You Know: Graph Mining Using Recursive Structural Features},
  booktitle = {Proceedings of the 17th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year      = {2011},
  series    = {KDD '11},
  pages     = {663--671},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Given a graph, how can we extract good features for the nodes? For
	example, given two large graphs from the same domain, how can we
	use information in one to do classification in the other (i.e., perform
	across-network classification or transfer learning on graphs)? Also,
	if one of the graphs is anonymized, how can we use information in
	one to de-anonymize the other? The key step in all such graph mining
	tasks is to find effective node features. We propose ReFeX (Recursive
	Feature eXtraction), a novel algorithm, that recursively combines
	local (node-based) features with neighborhood (egonet-based) features;
	and outputs regional features -- capturing "behavioral" information.
	We demonstrate how these powerful regional features can be used in
	within-network and across-network classification and de-anonymization
	tasks -- without relying on homophily, or the availability of class
	labels. The contributions of our work are as follows: (a) ReFeX is
	scalable and (b) it is effective, capturing regional ("behavioral")
	information in large graphs. We report experiments on real graphs
	from various domains with over 1M edges, where ReFeX outperforms
	its competitors on typical graph mining tasks like network classification
	and de-anonymization.},
  acmid     = {2020512},
  comment   = {ReFeX
	
	recursively combines local (node-based) features with
	
	neighborhood (egonet-based) features and outputs regional features
	
	
	Given a graph G, compute
	
	a node-feature matrix F with the following properties:
	
	• Structural: The construction of F should not require additional
	
	attribute information on nodes or links.
	
	• Effective: Good node-features should (1) help us predict node
	
	attributes, when such attributes are available (as in the case of
	
	IP traffic that we discuss next), and (2) be transferable across
	
	graphs (e.g., when the graph changes over time).
	
	
	seed features: local and egonet, recursively mean and aggregate},
  doi       = {10.1145/2020408.2020512},
  file      = {Henderson2011Its.pdf:Henderson2011Its.pdf:PDF},
  isbn      = {978-1-4503-0813-7},
  keywords  = {feature extraction, graph mining, identity resolution, network classification},
  location  = {San Diego, California, USA},
  numpages  = {9},
  timestamp = {2015.09.15},
  url       = {http://doi.acm.org/10.1145/2020408.2020512},
}

@InProceedings{Hernandez-Lobato2014Probabilistic,
  author    = {Jose Miguel Hernandez-Lobato and Neil Houlsby and Zoubin Ghahramani},
  title     = {Probabilistic Matrix Factorization with Non-random Missing Data},
  booktitle = {Proceedings of ICML},
  year      = {2014},
  abstract  = {We propose a probabilistic matrix factorization model for collaborative
	filtering that learns from data that is missing not at random(MNAR).
	Matrix factorization models exhibit state-of-the-art predictive performance
	in collaborative filtering. However, these models usually assume
	that the data is missing at random (MAR), and this is rarely the
	case. For example, the data is not MAR if users rate items they like
	more than ones they dislike. When the MAR assumption is incorrect,
	inferences are biased and predictive performance can suffer. Therefore,
	we model both the generative process for the data and the missing
	data mechanism. By learning these two models jointly we obtain improved
	performance over state-of-the-art methods when predicting the ratings
	and when modeling the data observation process. We present the first
	viable MF model for MNAR data. Our results are promising and we expect
	that further research on NMAR models will yield large gains in collaborative
	filtering.},
  comment   = {complete data model = UV  + row/column noise
	
	Heaviside step function to segment numerical ratings
	
	mask matrix = EF + iid noise + column/row/value dependent noise},
  file      = {Hernandez-Lobato2014Probabilistic.pdf:Hernandez-Lobato2014Probabilistic.pdf:PDF},
  owner     = {littlep},
  timestamp = {2014.06.23},
}

@INPROCEEDINGS{Hernandez-Lobato2014Stochastic,
  author = {Jose Miguel Hernandez-Lobato and Neil Houlsby and Zoubin Ghahramani},
  title = {Stochastic Inference for Scalable Probabilistic Modeling of Binary
	Matrices},
  booktitle = {Proceedings of ICML},
  year = {2014},
  abstract = {Fully observed large binary matrices appear in a wide variety of contexts.
	To model them, probabilistic matrix factorization (PMF) methods are
	an attractive solution. However, current batch algorithms for PMF
	can be inefficient because they need to analyze the entire data matrix
	before producing any parameter updates. We derive an efficient stochastic
	inference algorithm for PMF models of fully observed binary matrices.
	Our method exhibits faster convergence rates than more expensive
	batch approaches and has better predictive performance than scalable
	alternatives. The proposed method includes new data subsampling strategies
	which produce large gains over standard uniform subsampling. We also
	address the task of automatically selecting the size of the minibatches
	of data used by our method. For this, we derive an algorithm that
	adjusts this hyper-parameter online.},
  file = {Hernandez-Lobato2014Stochastic.pdf:Hernandez-Lobato2014Stochastic.pdf:PDF},
  owner = {littlep},
  timestamp = {2015.09.10}
}

@INBOOK{Hidasi2012Machine,
  chapter = {Fast ALS-Based Tensor Factorization for Context-Aware Recommendation
	from Implicit Feedback},
  pages = {67--82},
  title = {Machine Learning and Knowledge Discovery in Databases: European Conference,
	ECML PKDD 2012, Bristol, UK, September 24-28, 2012. Proceedings,
	Part II},
  publisher = {Springer Berlin Heidelberg},
  year = {2012},
  editor = {Flach, Peter A. and Bie, Tijl and Cristianini, Nello},
  author = {Hidasi, Bal{\'a}zs and Tikk, Domonkos},
  address = {Berlin, Heidelberg},
  abstract = {Albeit the implicit feedback based recommendation problem—when only
	the user history is available but there are no ratings—is the most
	typical setting in real-world applications, it is much less researched
	than the explicit feedback case. State-of-the-art algorithms that
	are efficient on the explicit case cannot be straightforwardly transformed
	to the implicit case if scalability should be maintained. There are
	few implicit feedback benchmark datasets, therefore new ideas are
	usually experimented on explicit benchmarks. In this paper, we propose
	a generic context-aware implicit feedback recommender algorithm,
	coined iTALS. iTALS applies a fast, ALS-based tensor factorization
	learning method that scales linearly with the number of non-zero
	elements in the tensor. The method also allows us to incorporate
	various contextual information into the model while maintaining its
	computational efficiency. We present two context-aware implementation
	variants of iTALS. The first incorporates seasonality and enables
	to distinguish user behavior in different time intervals. The other
	views the user history as sequential information and has the ability
	to recognize usage pattern typical to certain group of items, e.g.
	to automatically tell apart product types that are typically purchased
	repetitively or once. Experiments performed on five implicit datasets
	(LastFM 1K, Grocery, VoD, and “implicitized” Netflix and MovieLens
	10M) show that by integrating context-aware information with our
	factorization framework into the state-of-the-art implicit recommender
	algorithm the recommendation quality improves significantly.},
  file = {Hidasi2012Machine.pdf:Hidasi2012Machine.pdf:PDF},
  isbn = {978-3-642-33486-3},
  keywords = {recommender systems tensor factorization context awareness implicit
	feedback}
}

@ARTICLE{Hirsch2005index,
  author = {Hirsch, JE},
  title = {An index to quantify an individual's scientific research output},
  journal = {Proceedings of the National Academy of Sciences},
  year = {2005},
  volume = {102},
  pages = {16569--16572},
  number = {46},
  publisher = {National Acad Sciences}
}

@INPROCEEDINGS{Hofmann1999Probabilistic,
  author = {Hofmann, Thomas},
  title = {Probabilistic latent semantic indexing},
  booktitle = {SIGIR '99: Proceedings of the 22nd annual international ACM SIGIR
	conference on Research and development in information retrieval},
  year = {1999},
  pages = {50--57},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/312624.312649},
  file = {Hofmann1999Probabilistic.pdf:Hofmann1999Probabilistic.pdf:PDF},
  isbn = {1-58113-096-1},
  location = {Berkeley, California, United States}
}

@TechReport{HOLCOMB2013News,
  author      = {JESSE HOLCOMB and JEFFREY GOTTFRIED and AMY MITCHELL},
  title       = {News Use Across Social Media Platforms},
  institution = {PewResearch},
  year        = {2013},
  groups      = {Twitter},
  owner       = {littlep},
  timestamp   = {2014.03.02},
}

@INPROCEEDINGS{Hong2009classification-based,
  author = {Hong, Liangjie and Davison, Brian D.},
  title = {A classification-based approach to question answering in discussion
	boards},
  booktitle = {SIGIR '09: Proceedings of the 32nd international ACM SIGIR conference
	on Research and development in information retrieval},
  year = {2009},
  pages = {171--178},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1571941.1571973},
  isbn = {978-1-60558-483-6},
  location = {Boston, MA, USA}
}

@ARTICLE{Hong2012Product,
  author = {Wenxing Hong and Lei Li and Tao Li},
  title = {Product recommendation with temporal dynamics },
  journal = {Expert Systems with Applications },
  year = {2012},
  volume = {39},
  pages = {12398 - 12406},
  number = {16},
  doi = {http://dx.doi.org/10.1016/j.eswa.2012.04.082},
  issn = {0957-4174},
  keywords = {Taxonomy},
  url = {http://www.sciencedirect.com/science/article/pii/S0957417412006793}
}

@INPROCEEDINGS{HonglakLEE2007Efficient,
  author = {Honglak LEE, Alexix Battle, Rajat Raina, Andrew Y. Ng },
  title = {Efficient sparse coding algorithms},
  booktitle = {Proc. 19$^{th}$ NIPS},
  year = {2007},
  pages = {801--808},
  address = {Cambridge, MA, USA},
  owner = {Cheyenne},
  timestamp = {2009.09.21}
}

@INPROCEEDINGS{Houlsby2014Cold,
  author = {Neil Houlsby and Jose Miguel Hernandez-Lobato and Zoubin Ghahramani},
  title = {Cold-start Active Learning with Robust Ordinal Matrix Factorization},
  booktitle = {Proceedings of ICML},
  year = {2014},
  abstract = {We present a new matrix factorization model for rating data and a
	corresponding active learning strategy to address the cold-start
	problem. Cold-start is one of the most challenging tasks for recommender
	systems: what to recommend with new users or items for which one
	has little or no data. An approach is to use active learning to collect
	the most useful initial ratings. However, the performance of active
	learning depends strongly upon having accurate estimates of i) the
	uncertainty in model parameters and ii) the intrinsic noisiness of
	the data. To achieve these estimates we propose a heteroskedastic
	Bayesian model for ordinal matrix factorization. We also present
	a computationally efficient framework for Bayesian active learning
	with this type of complex probabilistic model. This algorithm successfully
	distinguishes between informative and noisy data points. Our model
	yields state-of-the-art predictive performance and, coupled with
	our active learning strategy, enables us to gain useful information
	in the cold-start setting from the very first active sample.},
  file = {Houlsby2014Cold.pdf:Houlsby2014Cold.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.06.23}
}

@Article{Hoyer2004Non-negative,
  author     = {Hoyer, Patrik O.},
  title      = {Non-negative Matrix Factorization with Sparseness Constraints},
  journal    = {J. Mach. Learn. Res.},
  year       = {2004},
  volume     = {5},
  pages      = {1457--1469},
  month      = dec,
  abstract   = {Non-negative matrix factorization (NMF) is a recently developed technique
	for finding parts-based, linear representations of non-negative data.
	Although it has successfully been applied in several applications,
	it does not always result in parts-based representations. In this
	paper, we show how explicitly incorporating the notion of 'sparseness'
	improves the found decompositions. Additionally, we provide complete
	MATLAB code both for standard NMF and for our extension. Our hope
	is that this will further the application of these methods to solving
	novel data-analysis problems},
  acmid      = {1044709},
  groups     = {matrix factorization},
  issn       = {1532-4435},
  issue_date = {12/1/2004},
  numpages   = {13},
  publisher  = {JMLR.org},
  url        = {http://dl.acm.org/citation.cfm?id=1005332.1044709},
}

@INPROCEEDINGS{Hsieh2014Nuclear,
  author = {Cho-Jui Hsieh and Peder Olsen},
  title = {Nuclear Norm Minimization via Active Subspace Selection},
  booktitle = {Proceedings of ICML},
  year = {2014},
  pages = {512-520},
  abstract = {We describe a novel approach to optimizing matrix problems involving
	nuclear norm regularization and apply it to the matrix completion
	problem. We combine methods from non-smooth and smooth optimization.
	At each step we use the proximal gradient to select an active subspace.
	We then find a smooth, convex relaxation of the smaller subspace
	problems and solve these using second order methods. We apply our
	methods to matrix completion problems including Netflix dataset,
	and show that they are more than 6 times faster than state-of-the-art
	nuclear norm solvers. Also, this is the first paper to scale nuclear
	norm solvers to the Yahoo-Music dataset, and the first time in the
	literature that the efficiency of nuclear norm solvers can be compared
	and even compete with non-convex solvers like Alternating Least Squares
	(ALS).},
  file = {Hsieh2014Nuclear.pdf:Hsieh2014Nuclear.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.06.24}
}

@INPROCEEDINGS{Hu2006Opinion,
  author = {Hu, Minqing and Liu, Bing},
  title = {Opinion Feature Extraction Using Class Sequential Rules.},
  booktitle = {AAAI Spring Symposium: Computational Approaches to Analyzing Weblogs},
  year = {2006},
  pages = {61--66},
  file = {Hu2006Opinion.pdf:Hu2006Opinion.pdf:PDF}
}

@INPROCEEDINGS{Hu2004Mining,
  author = {Hu, Minqing and Liu, Bing},
  title = {Mining opinion features in customer reviews},
  booktitle = {AAAI},
  year = {2004},
  volume = {4},
  number = {4},
  pages = {755--760}
}

@InProceedings{Hu2008Collaborative,
  author       = {Hu, Y. and Koren, Y. and Volinsky, C.},
  title        = {{Collaborative filtering for implicit feedback datasets}},
  booktitle    = {Data Mining, 2008. ICDM'08. Eighth IEEE International Conference on},
  year         = {2008},
  pages        = {263--272},
  organization = {IEEE},
  abstract     = {A common task of recommender systems is to improve
	
	customer experience through personalized recommendations based on
	prior implicit feedback. These systems passively track different
	sorts of user behavior, such as purchase history, watching habits
	and browsing activity, in order to model user preferences. Unlike
	the much more extensively researched explicit feedback, we do not
	have any
	
	direct input from the users regarding their preferences. In
	
	particular, we lack substantial evidence on which products
	
	consumer dislike. In this work we identify unique properties of implicit
	feedback datasets. We propose treating the
	
	data as indication of positive and negative preference associated
	with vastly varying conﬁdence levels. This leads to a
	
	factor model which is especially tailored for implicit feedback recommenders.
	We also suggest a scalable optimization procedure, which scales linearly
	with the data size. The
	
	algorithmis used successfully within a recommender system
	
	for television shows. It compares favorably with well tuned
	
	implementations of other known methods. In addition, we
	
	offer a novel way to give explanations to recommendations
	
	given by this factor model.},
  comment      = {implicit feedback = consumption
	
	binary indicates consumption or not
	
	+confidence
	
	MF objective function: confidenc*mf},
  file         = {Hu2009Collaborative.pdf:Hu2009Collaborative.pdf:PDF},
  groups       = {Recommender Systems},
  issn         = {1550-4786},
  owner        = {linchen},
  timestamp    = {2010.11.01},
}

@InProceedings{Hua2013STED,
  author    = {Hua, Ting and Chen, Feng and Zhao, Liang and Lu, Chang-Tien and Ramakrishnan, Naren},
  title     = {STED: Semi-supervised Targeted-interest Event Detectionin in Twitter},
  booktitle = {Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year      = {2013},
  series    = {KDD '13},
  pages     = {1466--1469},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Social microblogs such as Twitter and Weibo are experiencing an explosive
	growth with billions of global users sharing their daily observations
	and thoughts. Beyond public interests (e.g., sports, music), microblogs
	can provide highly detailed information for those interested in public
	health, homeland security, and financial analysis. However, the language
	used in Twitter is heavily informal, ungrammatical, and dynamic.
	Existing data mining algorithms require extensive manually labeling
	to build and maintain a supervised system. This paper presents STED,
	a semi-supervised system that helps users to automatically detect
	and interactively visualize events of a targeted type from twitter,
	such as crimes, civil unrests, and disease outbreaks. Our model first
	applies transfer learning and label propagation to automatically
	generate labeled data, then learns a customized text classifier based
	on mini-clustering, and finally applies fast spatial scan statistics
	to estimate the locations of events. We demonstrate STED's usage
	and benefits using twitter data collected from Latin America countries,
	and show how our system helps to detect and track example events
	such as civil unrests and crimes.},
  acmid     = {2487712},
  doi       = {10.1145/2487575.2487712},
  groups    = {Recommender Systems, Twitter},
  isbn      = {978-1-4503-2174-7},
  keywords  = {event detection, text mining},
  location  = {Chicago, Illinois, USA},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/2487575.2487712},
}

@Article{Huang2009Collaborative,
  author    = {Huang, C. and Yin, J. and Wang, J. and Zheng, L.},
  title     = {Collaborative Filtering Recommendation Algorithm Using Dynamic Similar Neighbor Probability},
  journal   = {Advanced Data Mining and Applications},
  year      = {2009},
  pages     = {165--174},
  file      = {Huang2009Collaborative.pdf:Huang2009Collaborative.pdf:PDF},
  groups    = {Recommender Systems},
  publisher = {Springer},
}

@InProceedings{Huang2010Conversational,
  author    = {Huang, Jeff and Thornton, Katherine M. and Efthimiadis, Efthimis N.},
  title     = {Conversational tagging in twitter},
  booktitle = {Proceedings of the 21st ACM conference on Hypertext and hypermedia},
  year      = {2010},
  series    = {HT '10},
  pages     = {173--178},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Users on Twitter, a microblogging service, started the phenomenon
	of adding tags to their messages sometime around February 2008. These
	tags are distinct from those in other Web 2.0 systems because users
	are less likely to index messages for later retrieval. We compare
	tagging patterns in Twitter with those in Delicious to show that
	tagging behavior in Twitter is different because of its conversational,
	rather than organizational nature. We use a mixed method of statistical
	analysis and an interpretive approach to study the phenomenon. We
	find that tagging in Twitter is more about filtering and directing
	content so that it appears in certain streams. The most illustrative
	example of how tagging in Twitter differs is the phenomenon of the
	Twitter micro-meme: emergent topics for which a tag is created, used
	widely for a few days, then disappears. We describe the micro-meme
	phenomenon and discuss the importance of this new tagging practice
	for the larger real-time search context.},
  acmid     = {1810647},
  doi       = {http://doi.acm.org/10.1145/1810617.1810647},
  file      = {Huang2010Conversational.pdf:Huang2010Conversational.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-1-4503-0041-4},
  keywords  = {memes, tagging, trends, twitter},
  location  = {Toronto, Ontario, Canada},
  numpages  = {6},
  owner     = {linchen},
  timestamp = {2011.11.01},
  url       = {http://doi.acm.org/10.1145/1810617.1810647},
}

@InProceedings{Huang2006Extracting,
  author    = {Jizhou Huang and Ming Zhou and Dan Yang},
  title     = {Extracting Chatbot Knowledge from Online discussion Forums},
  booktitle = {Proc. 11$^{th}$ IJCAI},
  year      = {2006},
  owner     = {Cheyenne},
  timestamp = {2009.09.21},
}

@InProceedings{Huang2009Unified,
  author    = {Huang, Xuanjing and Croft, W. Bruce},
  title     = {A Unified Relevance Model for Opinion Retrieval},
  booktitle = {Proceedings of the 18th ACM Conference on Information and Knowledge Management},
  year      = {2009},
  series    = {CIKM '09},
  pages     = {947--956},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1646075},
  comment   = {task: find opinionated documents about an entity},
  doi       = {10.1145/1645953.1646075},
  file      = {Huang2009Unified.pdf:Huang2009Unified.pdf:PDF},
  isbn      = {978-1-60558-512-3},
  keywords  = {language model, opinion relevance model, opinion retrieval, query expansion, relevance feedback, sentiment analysis},
  location  = {Hong Kong, China},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1645953.1646075},
}

@InProceedings{Huang2012Constrained,
  author    = {Huang, Yu-Jia and Xiang, Evan Wei and Pan, Rong},
  title     = {Constrained Collective Matrix Factorization},
  booktitle = {Proceedings of the Sixth ACM Conference on Recommender Systems},
  year      = {2012},
  series    = {RecSys '12},
  pages     = {237--240},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Transfer learning for collaborative filtering (TLCF) aims to solve
	the sparsity problem by transferring rating knowledge across multiple
	domains. Taking domain difference into ac- count, one of the issues
	in cross-domain collaborative filtering is to selectively transfer
	knowledge from source/auxiliary domains. In particular, this paper
	addresses the problem of inconstant users (users with changeable
	preferences across different domains) when transferring knowledge
	about users from another auxiliary domain. We first formulate the
	problem of inconstant users caused by domain difference and then
	propose a new model that performs constrained collective matrix factorization
	(CCMF). Our experiments on simulated and real data show that CCMF
	has superior performance than other methods.},
  acmid     = {2366003},
  comment   = {transfer from source to target with user-dependent bias(change)
	
	PMF framework},
  doi       = {10.1145/2365952.2366003},
  file      = {Huang2012Constrained.pdf:Huang2012Constrained.pdf:PDF},
  groups    = {Recommender Systems},
  isbn      = {978-1-4503-1270-7},
  keywords  = {collaborative filtering, collective matrix factorization, inconstant users, transfer learning},
  location  = {Dublin, Ireland},
  numpages  = {4},
  timestamp = {2014.06.09},
  url       = {http://doi.acm.org/10.1145/2365952.2366003},
}

@ARTICLE{Huang2010Efficiently,
  author = {Huang, Zhen-Hua and Xiang, Yang and Lin, Chen},
  title = {Efficiently reducing transferring cost of skyline queries over distributed
	networks},
  journal = {Tien Tzu Hsueh Pao/Acta Electronica Sinica},
  year = {2010},
  volume = {38},
  pages = {848 - 852},
  number = {4},
  note = {Computation costs;Distributed environments;Distributed networks;Multidimensional
	objects;Position value;Semantic relationships;Skyline query;Three
	phasis;},
  abstract = {Skyline query processing in distributed environments has recently
	received a lot of attention in information retrieval community. However,
	most existing literatures do not consider how to efficiently reduce
	the transferring cost of skyline quereis on distributed networks.
	In this paper, we propose RTCSQDN(Reducing the Transferring Cost
	of Skyline Queries over Distributed Networks), the efficient sound
	and complete algorithm for balancing the cost of transferring data
	and skyline computation cost on the distributed networks. Specially,
	the PDSQDN algorithm makes use of the semantic relationship between
	parent-space skylines and child-space skylines, and transfers the
	data through three phases. Moreover, we present a novel policy, i.
	e. PTGPV (Policy for Transferring Grouping Position Values), to transfer
	multi-dimensional objects. The PTGPV policy only transfers the position
	values of objects for most dimensional-spaces, and hence it can efficiently
	minimize the volume of data transferred. We also present detailed
	theoretical analyses and extensive experiments that demonstrate our
	algorithms are both efficient and effective.},
  address = {P.O. Box 165, Beijing, 100036, China},
  copyright = {Compilation and indexing terms, Copyright 2010 Elsevier Inc.},
  issn = {03722112},
  key = {Cost reduction},
  keywords = {Algorithms;Computational efficiency;Indexing (of information);Information
	retrieval;},
  language = {Chinese},
  owner = {linchen},
  timestamp = {2010.12.08}
}

@ARTICLE{Huang2010Efficientlya,
  author = {Huang, Zhen-Hua and Xiang, Yang and Lin, Chen},
  title = {Efficiently reducing transferring cost of skyline queries over distributed
	networks},
  journal = {Tien Tzu Hsueh Pao/Acta Electronica Sinica},
  year = {2010},
  volume = {38},
  pages = {848 - 852},
  number = {4},
  note = {Computation costs;Distributed environments;Distributed networks;Multidimensional
	objects;Position value;Semantic relationships;Skyline query;Three
	phasis;},
  abstract = {Skyline query processing in distributed environments has recently
	received a lot of attention in information retrieval community. However,
	most existing literatures do not consider how to efficiently reduce
	the transferring cost of skyline quereis on distributed networks.
	In this paper, we propose RTCSQDN(Reducing the Transferring Cost
	of Skyline Queries over Distributed Networks), the efficient sound
	and complete algorithm for balancing the cost of transferring data
	and skyline computation cost on the distributed networks. Specially,
	the PDSQDN algorithm makes use of the semantic relationship between
	parent-space skylines and child-space skylines, and transfers the
	data through three phases. Moreover, we present a novel policy, i.
	e. PTGPV (Policy for Transferring Grouping Position Values), to transfer
	multi-dimensional objects. The PTGPV policy only transfers the position
	values of objects for most dimensional-spaces, and hence it can efficiently
	minimize the volume of data transferred. We also present detailed
	theoretical analyses and extensive experiments that demonstrate our
	algorithms are both efficient and effective.},
  address = {P.O. Box 165, Beijing, 100036, China},
  copyright = {Compilation and indexing terms, Copyright 2010 Elsevier Inc.},
  issn = {03722112},
  key = {Cost reduction},
  keywords = {Algorithms;Computational efficiency;Indexing (of information);Information
	retrieval;},
  language = {Chinese},
  owner = {linchen},
  timestamp = {2010.12.08}
}

@ARTICLE{Huang2009EAPSC,
  author = {Huang, Zhen-Hua and Xiang, Yang and Lin, Chen},
  title = {EAPSC: Efficient clustering of skyline objects},
  journal = {Moshi Shibie yu Rengong Zhineng/Pattern Recognition and Artificial
	Intelligence},
  year = {2009},
  volume = {22},
  pages = {731 - 734},
  number = {5},
  note = {Index trees;Query optimization;Skyline query;},
  abstract = {A concept, SkyCluster, is proposed. It clusters the skyline objects
	according to their associative distance. The skyline query and cluster
	processing are all CPU-sensitive. Hence, to improve the efficiency
	of obtaining SkyClusters, an efficient approach, EAPSC, is presented
	to cluster skyline objects. EAPSC algorithm is based on the novel
	index tree SLT and employs several interesting properties of SLT
	to produce SkyClusters fast. Furthermore, the theoretical analysis
	and experimental results demonstrate the proposed method is efficient
	and effective.},
  address = {P.O. Box 1130, Hefei, 230031, China},
  copyright = {Compilation and indexing terms, Copyright 2010 Elsevier Inc.},
  issn = {10036059},
  key = {Indexing (of information)},
  language = {Chinese},
  owner = {linchen},
  timestamp = {2010.12.08}
}

@ARTICLE{Huang2009Parsing,
  author = {Huang, Zhen-Hua and Xiang, Yang and Lin, Chen and Sun, Sheng-Li},
  title = {Parsing skyline queries},
  journal = {Tien Tzu Hsueh Pao/Acta Electronica Sinica},
  year = {2009},
  volume = {37},
  pages = {1639 - 1645},
  number = {8},
  note = {Database;Equivalence transformation rules;Query optimization;Relational
	operator;Skyline query;},
  abstract = {The existing works only consider how to efficiently process skyline
	computation for a single table. That is, they assume the issued skyline
	queries do not involve any traditional relational operator. Clearly,
	in most real applications, the query efficiency is extremely low
	because of this unreasonable assumption. Motivated by these facts,
	in this paper, we regard skyline computation as a special relational
	operator and study the equivalence transformation rules of implementation
	order between it and traditional relational operators. Then based
	on these equivalence transformation rules, we can efficiently improve
	the query performance. Moreover, we present sufficient theoretical
	proofs to demonstrate the correctness of the proposed equivalence
	transformation rules. The extensive experiments also show that the
	after-transforming solutions markedly outperforms the before-transforming
	counterparts.},
  address = {P.O. Box 165, Beijing, 100036, China},
  copyright = {Compilation and indexing terms, Copyright 2010 Elsevier Inc.},
  issn = {03722112},
  key = {Indexing (of information)},
  language = {Chinese},
  owner = {linchen},
  timestamp = {2010.12.08}
}

@ARTICLE{Hunter2004MM,
  author = {David R. Hunter},
  title = {MM Algorithms for Generalized Bradley-Terry Models},
  journal = {The Annals of Statistics},
  year = {2004},
  volume = {32},
  pages = {384-406},
  number = {1},
  abstract = {The Bradley-Terry model for paired comparisons is a simple and muchstudied
	means to describe the probabilities of the possible outcomes when
	individuals are judged against one another in pairs. Among the many
	studies of the model in the past 75 years, numerous authors have
	generalized it in several directions, sometimes providing iterative
	algorithms for obtaining maximum likelihood estimates for the generalizations.
	Building on a theory of algorithms known by the initials MM, for
	minorization-maximization, this paper presents a powerful technique
	for producing iterative maximum likelihood estimation algorithms
	for a wide class of generalizations of the Bradley-Terry model. While
	algorithms for problems of this type have tended to be custom-built
	in the literature, the techniques in this paper enable their mass
	production. Simple conditions are stated that guarantee that each
	algorithm described will produce a sequence that converges to the
	unique maximum likelihood estimator. Several of the algorithms and
	convergence results herein are new.},
  file = {Hunter2004MM.pdf:Hunter2004MM.pdf:PDF},
  issn = {00905364},
  publisher = {Institute of Mathematical Statistics},
  url = {http://www.jstor.org/stable/3448514}
}

@INPROCEEDINGS{Imafuji2002Effects,
  author = {Imafuji, Noriko and Kitsuregawa, Masaru},
  title = {Effects of maximum flow algorithm on identifying web community},
  booktitle = {WIDM '02: Proceedings of the 4th international workshop on Web information
	and data management},
  year = {2002},
  pages = {43--48},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/584931.584941},
  isbn = {1-58113-593-9},
  location = {McLean, Virginia, USA}
}

@InProceedings{Ino2005Partitioning,
  author    = {Ino, Hidehiko and Kudo, Mineichi and Nakamura, Atsuyoshi},
  title     = {Partitioning of Web graphs by community topology},
  booktitle = {WWW '05: Proceedings of the 14th international conference on World Wide Web},
  year      = {2005},
  pages     = {661--669},
  address   = {New York, NY, USA},
  publisher = {ACM},
  doi       = {http://doi.acm.org/10.1145/1060745.1060841},
  isbn      = {1-59593-046-9},
  location  = {Chiba, Japan},
}

@INPROCEEDINGS{Inouye2014Admixture,
  author = {David Inouye and Pradeep Ravikumar and Inderjit Dhillon},
  title = {Admixture of Poisson MRFs: A Topic Model with Word Dependencies},
  booktitle = {Proceedings of ICML},
  year = {2014},
  pages = {594-602},
  abstract = {This paper introduces a new topic model based on an admixture of Poisson
	Markov Random Fields (APM), which can model dependencies between
	words as opposed to previous independent topic models such as PLSA
	(Hofmann, 1999), LDA (Blei et al., 2003) or SAM (Reisinger et al.,
	2010). We propose a class of admixture models that generalizes previous
	topic models and show an equivalence between the conditional distribution
	of LDA and independent Poissons—suggesting that APM subsumes the
	modeling power of LDA. We present a tractable method for estimating
	the parameters of an APM based on the pseudo log-likelihood and demonstrate
	the benefits of APM over previous models by preliminary qualitative
	and quantitative experiments.},
  file = {Inouye2014Admixture.pdf:Inouye2014Admixture.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.06.24}
}

@InProceedings{Jamali2010matrix,
  author    = {Jamali, Mohsen and Ester, Martin},
  title     = {A matrix factorization technique with trust propagation for recommendation in social networks},
  booktitle = {RecSys '10: Proceedings of the fourth ACM conference on Recommender systems},
  year      = {2010},
  pages     = {135--142},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Recommender systems are becoming tools of choice to select the
	
	online information relevant to a given user. Collaborative ﬁltering
	
	is the most popular approach to building recommender systems and
	
	has been successfully employed in many applications. With the advent
	of online social networks, the social network based approach
	
	to recommendation has emerged. This approach assumes a social
	
	network among users and makes recommendations for a user based
	
	on the ratings of the users that have direct or indirect social relations
	
	with the given user. As one of their major beneﬁts, social network
	
	based approaches have been shown to reduce the problems with
	
	cold start users. In this paper, we explore a model-based approach
	
	for recommendation in social networks, employing matrix factorization
	techniques. Advancing previous work, we incorporate the
	
	mechanism of trust propagation into the model. Trust propagation
	
	has been shown to be a crucial phenomenon in the social sciences,
	
	in social network analysis and in trust-based recommendation. We
	
	have conducted experiments on two real life data sets, the public
	
	domain Epinions.com dataset and a much larger dataset that we
	
	have recently crawled from Flixster.com. Our experiments demonstrate
	that modeling trust propagation leads to a substantial increase
	
	in recommendation accuracy, in particular for cold start users.},
  comment   = {Best Long Paper in RecSys '10
	
	genre: trust based recommendation
	
	idea: trust propogation, user interest is a combination of trustees
	
	model: socialMF
	
	Data: Epinions from Washington U
	
	 Flixster.com
	
	experiment: performance on cold-start users
	
	Main Contribution: the given user is generated from a set of trusted
	user and noise
	
	 Highlight: very good probabilistic grapyhical model style survey
	of a class of matrix factorization approaches},
  doi       = {http://doi.acm.org/10.1145/1864708.1864736},
  file      = {Jamali2010matrix.pdf:Jamali2010matrix.pdf:PDF},
  groups    = {Recommender Systems},
  isbn      = {978-1-60558-906-0},
  location  = {Barcelona, Spain},
}

@InProceedings{Jamali2009Using,
  author       = {Jamali, M. and Ester, M.},
  title        = {Using a trust network to improve top-N recommendation},
  booktitle    = {Proceedings of the third ACM conference on Recommender systems},
  year         = {2009},
  pages        = {181--188},
  organization = {ACM},
  groups       = {Recommender Systems},
}

@ARTICLE{Japkowicz2002class,
  author = {Japkowicz, Nathalie and Stephen, Shaju},
  title = {The class imbalance problem: A systematic study},
  journal = {Intelligent Data Analysis},
  year = {2002},
  volume = {6(5)},
  pages = {429--449},
  month = {October},
  abstract = {In machine learning problems, differences in prior class probabilities
	-- or class imbalances -- have been reported to hinder the performance
	of some standard classifiers, such as decision trees. This paper
	presents a systematic study aimed at answering three different questions.
	First, we attempt to understand the nature of the class imbalance
	problem by establishing a relationship between concept complexity,
	size of the training set and class imbalance level. Second, we discuss
	several basic re-sampling or cost-modifying methods previously proposed
	to deal with the class imbalance problem and compare their effectiveness.
	The results obtained by such methods on artificial domains are linked
	to results in real-world domains. Finally, we investigate the assumption
	that the class imbalance problem does not only affect decision tree
	systems but also affects other classification systems such as Neural
	Networks and Support Vector Machines.},
  acmid = {1293954},
  address = {Amsterdam, The Netherlands, The Netherlands},
  issn = {1088-467X},
  issue = {5},
  keywords = {C5.0, Multi-Layer Perceptrons, Support Vector Machines, class imbalances,
	concept learning, misclassification costs, re-sampling},
  numpages = {21},
  publisher = {IOS Press},
  url = {http://portal.acm.org/citation.cfm?id=1293951.1293954}
}

@Article{Jawaheer2014Modeling,
  author     = {Jawaheer, Gawesh and Weller, Peter and Kostkova, Patty},
  title      = {Modeling User Preferences in Recommender Systems: A Classification Framework for Explicit and Implicit User Feedback},
  journal    = {ACM Trans. Interact. Intell. Syst.},
  year       = {2014},
  volume     = {4},
  number     = {2},
  pages      = {8:1--8:26},
  month      = jun,
  issn       = {2160-6455},
  abstract   = {Recommender systems are firmly established as a standard technology
	for assisting users with their choices; however, little attention
	has been paid to the application of the user model in recommender
	systems, particularly the variability and noise that are an intrinsic
	part of human behavior and activity. To enable recommender systems
	to suggest items that are useful to a particular user, it can be
	essential to understand the user and his or her interactions with
	the system. These interactions typically manifest themselves as explicit
	and implicit user feedback that provides the key indicators for modeling
	users’ preferences for items and essential information for personalizing
	recommendations. In this article, we propose a classification framework
	for the use of explicit and implicit user feedback in recommender
	systems based on a set of distinct properties that include Cognitive
	Effort, User Model, Scale of Measurement, and Domain Relevance. We
	develop a set of comparison criteria for explicit and implicit user
	feedback to emphasize the key properties. Using our framework, we
	provide a classification of recommender systems that have addressed
	questions about user feedback, and we review state-of-the-art techniques
	to improve such user feedback and thereby improve the performance
	of the recommender system. Finally, we formulate challenges for future
	research on improvement of user feedback.},
  acmid      = {2512208},
  address    = {New York, NY, USA},
  articleno  = {8},
  comment    = {A SURVEY paper, present a classification framework for comparing explicit
	and implicit user feedback based on a set of distinct properties.
	
	These include cognitive effort, user model, scale of measurement,
	domain relevance, sensitivity to noise, polarity, range of users,
	user transparency, and bias},
  doi        = {10.1145/2512208},
  file       = {Jawaheer2014Modeling.pdf:Jawaheer2014Modeling.pdf:PDF},
  issue_date = {July 2014},
  keywords   = {Feedback, explicit feedback, implicit feedback, improvement of feedback, recommender systems},
  numpages   = {26},
  publisher  = {ACM},
  timestamp  = {2015.10.26},
  url        = {http://doi.acm.org/10.1145/2512208},
}

@Conference{jeon2006framework,
  author       = {Jeon, J. and Croft, W.B. and Lee, J.H. and Park, S.},
  title        = {{A framework to predict the quality of answers with non-textual features}},
  booktitle    = {Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval},
  year         = {2006},
  pages        = {228--235},
  organization = {ACM},
  abstract     = {New types of document collections are being developed by
	
	various web services. The service providers keep track of
	
	non-textual features such as click counts. In this paper,
	
	we present a framework to use non-textual features to pre-
	
	dict the quality of documents. We also show our quality
	
	measure can be successfully incorporated into the language
	
	modeling-based retrieval model. We test our approach on
	
	a collection of question and answer pairs gathered from a
	
	community based question answering service where people
	
	ask and answer questions. Experimental results using our
	
	quality measure show a signi¯cant improvement over our
	
	baseline.},
  comment      = {Features Type Corr
	
	Answerer's Acceptance Ratio Percentile 0.1837
	
	Answer Length Integer 0.1733
	
	Questioner's Self Evaluation 1,...5 0.1675
	
	Answerer's Activity Level Integer 0.1430
	
	Answerer's Category Specialty Integer 0.1037
	
	Print Counts Integer 0.0528
	
	Copy Counts Integer 0.0469
	
	Users' Recommendation Integer 0.0351
	
	Editor's Recommendation Binary 0.0285
	
	Sponsor's Answer Binary 0.0232
	
	Click Counts Integer -0.0085
	
	Number of Answers Integer -0.0297
	
	User's Dis-Recommendation Integer -0.0596
	
	
	
	logistic regression p(y|x)=1/Z e^{\lambda feature}
	
	model parameter lambda is chosen by maximum entrophy},
  file         = {jeon2006framework.pdf:jeon2006framework.pdf:PDF},
  isbn         = {1595933697},
  keywords     = {retrieval,QA,content quality},
}

@InProceedings{Jiang2014FEMA,
  author    = {Jiang, Meng and Cui, Peng and Wang, Fei and Xu, Xinran and Zhu, Wenwu and Yang, Shiqiang},
  title     = {FEMA: Flexible Evolutionary Multi-faceted Analysis for Dynamic Behavioral Pattern Discovery},
  booktitle = {Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year      = {2014},
  series    = {KDD '14},
  pages     = {1186--1195},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Behavioral pattern discovery is increasingly being studied to understand
	human behavior and the discovered patterns can be used in many real
	world applications such as web search, recommender system and advertisement
	targeting. Traditional methods usually consider the behaviors as
	simple user and item connections, or represent them with a static
	model. In real world, however, human behaviors are actually complex
	and dynamic: they include correlations between user and multiple
	types of objects and also continuously evolve along time. These characteristics
	cause severe data sparsity and computational complexity problem,
	which pose great challenge to human behavioral analysis and prediction.
	In this paper, we propose a Flexible Evolutionary Multi-faceted Analysis
	(FEMA) framework for both behavior prediction and pattern mining.
	FEMA utilizes a flexible and dynamic factorization scheme for analyzing
	human behavioral data sequences, which can incorporate various knowledge
	embedded in different object domains to alleviate the sparsity problem.
	We give approximation algorithms for efficiency, where the bound
	of approximation loss is theoretically proved. We extensively evaluate
	the proposed method in two real datasets. For the prediction of human
	behaviors, the proposed FEMA significantly outperforms other state-of-the-art
	baseline methods by 17.4%. Moreover, FEMA is able to discover quite
	a number of interesting multi-faceted temporal patterns on human
	behaviors with good interpretability. More importantly, it can reduce
	the run time from hours to minutes, which is significant for industry
	to serve real-time applications.},
  acmid     = {2623644},
  comment   = {tensor factorization, the dim of tensor is : author, affiliation,keyword
	
	time is discreate
	
	the core factorization is the probability of the bahevior before time
	t if the j author group in the f affiliation group publishes k keyword
	group
	
	the constraints are the Laplacian matrices to repressent the similarity
	between entities/keywords/authors
	
	and they want to find the evolution of the core factor},
  file      = {Jiang2014FEMA.pdf:Jiang2014FEMA.pdf:PDF},
  isbn      = {978-1-4503-2956-9},
  keywords  = {behavior modeling, behavioral pattern, evolutionary analysis, flexible regularizers, tensor factorization},
  location  = {New York, New York, USA},
  numpages  = {10},
  timestamp = {2015.12.03},
}

@INPROCEEDINGS{Jin2014Reverse,
  author = {Zhao Zhang Cheqing Jin and Qiangqiang Kang},
  title = {Reverse k-Ranks Query},
  booktitle = {Proceedings of the VLDB Endowment},
  year = {2014},
  volume = {7},
  number = {10},
  pages = {785-796},
  abstract = {Finding matching customers for a given product based on
	
	individual user’s preference is critical for many applications,
	
	especially in e-commerce. Recently, the reverse top-k query
	
	is proposed to return a number of customers who regard a
	
	given product as one of the k most favorite products based
	
	on a linear model. Although a few “hot” products can be
	
	returned to some customers via reverse top-k query, a large
	
	proportion of products (over 90%, as our example illustrates,
	
	see Figure 2) cannot find any matching customers.
	
	Inspired by this observation, we propose a new kind of
	
	query (R-kRanks) which finds for a given product, the topk
	
	customers whose rank for the product is highest among all
	
	customers, to ensure 100% coverage for any given product,
	
	no matter it is hot or niche. Not limited to e-commerce,
	
	the concept of customer-product can be extended to a wider
	
	range of applications, such as dating and job-hunting. Unfortunately,
	
	existing approaches for reverse top-k query cannot
	
	be used to handle R-kRanks conveniently due to infeasibility
	
	of getting enough elements for the query result.
	
	Hence, we propose three novel approaches to efficiently process
	
	R-kRanks query, including one tree-based method and
	
	two batch-pruning-based methods. Analysis of theoretical
	
	and experimental results on real and synthetic data sets illustrates
	
	the efficacy of the proposed methods.},
  file = {Jin2014Reverse.pdf:Jin2014Reverse.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.12.14}
}

@INPROCEEDINGS{Johansson2014Global,
  author = {Fredrik Johansson and Vinay Jethava and Devdatt Dubhashi and Chiranjib
	Bhattacharyya},
  title = {Global graph kernels using geometric embeddings},
  booktitle = {Proceedings of ICML},
  year = {2014},
  pages = {682-690},
  abstract = {Applications of machine learning methods increasingly deal with graph
	structured data through kernels. Most existing graph kernels compare
	graphs in terms of features defined on small subgraphs such as walks,
	paths or graphlets, adopting an inherently local perspective. However,
	several interesting properties such as girth or chromatic number
	are global properties of the graph, and are not captured in local
	substructures. This paper presents two graph kernels defined on unlabeled
	graphs which capture global properties of graphs using the celebrated
	Lovász number and its associated orthonormal representation. We make
	progress towards theoretical results aiding kernel choice, proving
	a result about the separation margin of our kernel for classes of
	graphs. We give empirical results on classification of synthesized
	graphs with important global properties as well as established benchmark
	graph datasets, showing that the accuracy of our kernels is better
	than or competitive to existing graph kernels.},
  file = {Johansson2014Global.pdf:Johansson2014Global.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.06.24}
}

@Book{Jolliffe2002Principal,
  title     = {Principal component analysis},
  publisher = {Wiley Online Library},
  year      = {2002},
  author    = {Jolliffe, I.T. and MyiLibrary},
  volume    = {2},
  groups    = {matrix factorization},
}

@Article{Jones2007Temporal,
  author    = {Jones, Rosie and Diaz, Fernando},
  title     = {Temporal profiles of queries},
  journal   = {ACM Trans. Inf. Syst.},
  year      = {2007},
  volume    = {25},
  month     = {July},
  issn      = {1046-8188},
  acmid     = {1247720},
  address   = {New York, NY, USA},
  articleno = {14},
  doi       = {http://doi.acm.org/10.1145/1247715.1247720},
  file      = {Jones2007Temporal.pdf:Jones2007Temporal.pdf:PDF},
  issue     = {3},
  keywords  = {Time, ambiguity, event detection, language models, precision prediction, query classification, temporal profiles},
  publisher = {ACM},
  url       = {http://doi.acm.org/10.1145/1247715.1247720},
}

@INPROCEEDINGS{Kapralov2014Approximating,
  author = {Kapralov, Michael and Khanna, Sanjeev and Sudan, Madhu},
  title = {Approximating Matching Size from Random Streams},
  booktitle = {Proceedings of the Twenty-Fifth Annual ACM-SIAM Symposium on Discrete
	Algorithms},
  year = {2014},
  series = {SODA '14},
  pages = {734--751},
  publisher = {SIAM},
  abstract = {We present a streaming algorithm that makes one
	
	pass over the edges of an unweighted graph presented
	
	in random order, and produces a polylogarithmic
	
	approximation to the size of the maximum
	
	matching in the graph, while using only polylogarithmic
	
	space. Prior to this work the only approximations
	
	known were a folklore ˜O(
	
	√
	
	n) approximation
	
	with polylogarithmic space in an n vertex
	
	graph and a constant approximation with Ω(n)
	
	space. Our work thus gives the first algorithm
	
	where both the space and approximation factors are
	
	smaller than any polynomial in n.
	
	Our algorithm is obtained by effecting a streaming
	
	implementation of a simple “local” algorithm
	
	that we design for this problem. The local algorithm
	
	produces a O(k · n1/k) approximation to the
	
	size of a maximum matching by exploring the radius
	
	k neighborhoods of vertices, for any parameter
	
	k. We show, somewhat surprisingly, that our local
	
	algorithm can be implemented in the streaming
	
	setting even for k = Ω(logn/ log log n). Our analysis
	
	exposes some of the problems that arise in such
	
	conversions of local algorithms into streaming ones,
	
	and gives techniques to overcome such problems},
  acmid = {2634129},
  file = {Kapralov2014Approximating.pdf:Kapralov2014Approximating.pdf:PDF},
  isbn = {978-1-611973-38-9},
  location = {Portland, Oregon},
  numpages = {18},
  url = {http://dl.acm.org/citation.cfm?id=2634074.2634129}
}

@INPROCEEDINGS{Karatzoglou2010Multiverse,
  author = {Karatzoglou, Alexandros and Amatriain, Xavier and Baltrunas, Linas
	and Oliver, Nuria},
  title = {Multiverse Recommendation: N-dimensional Tensor Factorization for
	Context-aware Collaborative Filtering},
  booktitle = {Proceedings of the Fourth ACM Conference on Recommender Systems},
  year = {2010},
  series = {RecSys '10},
  pages = {79--86},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Context has been recognized as an important factor to consider in
	personalized Recommender Systems. However, most model-based Collaborative
	Filtering approaches such as Matrix Factorization do not provide
	a straightforward way of integrating context information into the
	model. In this work, we introduce a Collaborative Filtering method
	based on Tensor Factorization, a generalization of Matrix Factorization
	that allows for a flexible and generic integration of contextual
	information by modeling the data as a User-Item-Context N-dimensional
	tensor instead of the traditional 2D User-Item matrix. In the proposed
	model, called Multiverse Recommendation, different types of context
	are considered as additional dimensions in the representation of
	the data as a tensor. The factorization of this tensor leads to a
	compact model of the data which can be used to provide context-aware
	recommendations.
	
	
	We provide an algorithm to address the N-dimensional factorization,
	and show that the Multiverse Recommendation improves upon non-contextual
	Matrix Factorization up to 30% in terms of the Mean Absolute Error
	(MAE). We also compare to two state-of-the-art context-aware methods
	and show that Tensor Factorization consistently outperforms them
	both in semi-synthetic and real-world data - improvements range from
	2.5% to more than 12% depending on the data. Noticeably, our approach
	outperforms other methods by a wider margin whenever more contextual
	information is available.},
  acmid = {1864727},
  doi = {10.1145/1864708.1864727},
  file = {Karatzoglou2010Multiverse.pdf:Karatzoglou2010Multiverse.pdf:PDF},
  isbn = {978-1-60558-906-0},
  keywords = {collaborative filtering, context, tensor factorization},
  location = {Barcelona, Spain},
  numpages = {8},
  timestamp = {2014.09.13},
  url = {http://doi.acm.org/10.1145/1864708.1864727}
}

@Article{Kautz1997ReferralWeb:,
  author    = {Kautz, H. and Selman, B. and Shah, M.},
  title     = {ReferralWeb: Combining social networks and collaborative filtering},
  journal   = {Communications of the ACM},
  year      = {1997},
  groups    = {Recommender Systems},
  owner     = {Cheyenne},
  timestamp = {2009.09.21},
}

@Article{Kazienko2008Hyperlink,
  author      = {Kazienko, Przemysław and Pilarczyk, Marcin},
  title       = {Hyperlink Recommendation Based on Positive and Negative Association Rules},
  journal     = {New Generation Computing},
  year        = {2008},
  volume      = {26},
  pages       = {227-244},
  issn        = {0288-3635},
  note        = {10.1007/s00354-008-0042-z},
  abstract    = {The new HRS method for hyperlink recommendation based
	
	on positive and confined negative association rules is presented in
	the paper.
	
	Discovered with the new PANAMA algorithm rules are merged and
	
	used in the form of recommendation functions, both to assess the existing
	
	hyperlinks and to suggest new ones. Positively and negatively verified
	and
	
	new hyperlinks are presented to the content manager and can considerably
	
	facilitate the maintenance of the web site structure and its adjustment
	to
	
	user behaviour. The experiments confirmed the usefulness of the Hyperlink
	
	Recommender System (HRS) and in particular, of negative recommendations
	
	based on confined negative association rules.},
  affiliation = {Wrocław University of Technology Institute of Applied Informatics Wyb. Wyspiańskiego 27 50-370 Wrocław Poland},
  comment     = {propose a new method for positive and negative hyperlink
	
	recommendations that can be useful in adaptation of web structure},
  file        = {Kazienko2008Hyperlink.pdf:Kazienko2008Hyperlink.pdf:PDF},
  groups      = {Recommender Systems},
  issue       = {3},
  keyword     = {Computer Science},
  publisher   = {Ohmsha, Ltd.},
  url         = {http://dx.doi.org/10.1007/s00354-008-0042-z},
}

@InProceedings{Kelly2001Reading,
  author    = {Kelly, Diane and Belkin, Nicholas J.},
  title     = {Reading ti scrolling and interaction: exploring implicit sources of user preferences for relevance feedback},
  booktitle = {Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval},
  year      = {2001},
  series    = {SIGIR '01},
  pages     = {408--409},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {384045},
  doi       = {http://doi.acm.org/10.1145/383952.384045},
  file      = {Kelly2001Reading.pdf:Kelly2001Reading.pdf:PDF},
  groups    = {Recommender Systems},
  isbn      = {1-58113-331-6},
  location  = {New Orleans, Louisiana, United States},
  numpages  = {2},
  url       = {http://doi.acm.org/10.1145/383952.384045},
}

@InProceedings{Khabbaz2011TopRecs,
  author       = {Khabbaz, M. and Lakshmanan, L.V.S.},
  title        = {TopRecs: Top-k algorithms for item-based collaborative filtering},
  booktitle    = {Proceedings of the 14th International Conference on Extending Database Technology},
  year         = {2011},
  pages        = {213--224},
  organization = {ACM},
  file         = {Khabbaz2011TopRecs.pdf:Khabbaz2011TopRecs.pdf:PDF},
  groups       = {Recommender Systems},
}

@Conference{khoshneshin2010collaborative,
  author       = {Khoshneshin, M. and Street, W.N.},
  title        = {{Collaborative filtering via euclidean embedding}},
  booktitle    = {Proceedings of the fourth ACM conference on Recommender systems},
  year         = {2010},
  pages        = {87--94},
  organization = {ACM},
  abstract     = {Recommendation systems suggest items based on user pref-
	
	erences. Collaborative ltering is a popular approach in
	
	which recommending is based on the rating history of the
	
	system. One of the most accurate and scalable collabo-
	
	rative ltering algorithms is matrix factorization, which is
	
	based on a latent factor model. We propose a novel Eu-
	
	clidean embedding method as an alternative latent factor
	
	model to implement collaborative ltering. In this method,
	
	users and items are embedded in a unied Euclidean space
	
	where the distance between a user and an item is inversely
	
	proportional to the rating. This model is comparable to
	
	matrix factorization in terms of both scalability and accu-
	
	racy while providing several advantages. First, the result of
	
	Euclidean embedding is more intuitively understandable for
	
	humans, allowing useful visualizations. Second, the neigh-
	
	borhood structure of the unied Euclidean space allows very
	
	ecient recommendation queries. Finally, the method facil-
	
	itates online implementation requirements such as mapping
	
	new users or items in an existing model. Our experimental
	
	results conrm these advantages and show that collaborative
	
	ltering via Euclidean embedding is a promising approach
	
	for online recommender systems.},
  comment      = {basic idea:
	
	rating has negative relation with euclidean distance between user
	and item factor vectors},
  file         = {khoshneshin2010collaborative.pdf:khoshneshin2010collaborative.pdf:PDF},
  groups       = {Recommender Systems},
}

@ARTICLE{Kim2007Sparse,
  author = {Kim, H. and Park, H.},
  title = {Sparse non-negative matrix factorizations via alternating non-negativity-constrained
	least squares for microarray data analysis},
  journal = {Bioinformatics},
  year = {2007},
  volume = {23},
  pages = {1495--1502},
  number = {12},
  publisher = {Oxford Univ Press}
}

@INPROCEEDINGS{Kim2013Compact,
  author = {Kim, Hyun Duk and Castellanos, Malu and Hsu, Meichun and Zhai, ChengXiang
	and Dayal, Umeshwar and Ghosh, Riddhiman},
  title = {Compact explanatory opinion summarization},
  booktitle = {Proceedings of the 22nd ACM international conference on Conference
	on information \&\#38; knowledge management},
  year = {2013},
  series = {CIKM '13},
  pages = {1697--1702},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {2505596},
  doi = {10.1145/2505515.2505596},
  isbn = {978-1-4503-2263-8},
  keywords = {compact explanatory summarization, explanatory phrase extraction,
	opinion mining},
  location = {San Francisco, California, USA},
  numpages = {6},
  url = {http://doi.acm.org/10.1145/2505515.2505596}
}

@INPROCEEDINGS{Kim2013Ranking,
  author = {Kim, Hyun Duk and Castellanos, Malu G. and Hsu, Meichun and Zhai,
	ChengXiang and Dayal, Umeshwar and Ghosh, Riddhiman},
  title = {Ranking Explanatory Sentences for Opinion Summarization},
  booktitle = {Proceedings of the 36th International ACM SIGIR Conference on Research
	and Development in Information Retrieval},
  year = {2013},
  series = {SIGIR '13},
  pages = {1069--1072},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {2484172},
  doi = {10.1145/2484028.2484172},
  isbn = {978-1-4503-2034-4},
  keywords = {explanatoriness scoring, explanatory sentence ranking, opinion summarization},
  location = {Dublin, Ireland},
  numpages = {4},
  timestamp = {2014.07.25},
  url = {http://doi.acm.org/10.1145/2484028.2484172}
}

@INPROCEEDINGS{Kim2009Generating,
  author = {Kim, Hyun Duk and Zhai, ChengXiang},
  title = {Generating Comparative Summaries of Contradictory Opinions in Text},
  booktitle = {Proceedings of the 18th ACM Conference on Information and Knowledge
	Management},
  year = {2009},
  series = {CIKM '09},
  pages = {385--394},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {1646004},
  doi = {10.1145/1645953.1646004},
  isbn = {978-1-60558-512-3},
  keywords = {comparative summary, contradictory opinion, contrastive summary, opinion
	summarization},
  location = {Hong Kong, China},
  numpages = {10},
  url = {http://doi.acm.org/10.1145/1645953.1646004}
}

@INPROCEEDINGS{Kim2005Topic,
  author = {Kim, Jong Wook and Candan, K. Sel\c{c}uk and D\"{o}nderler, Mehmet
	E.},
  title = {Topic segmentation of message hierarchies for indexing and navigation
	support},
  booktitle = {WWW '05: Proceedings of the 14th international conference on World
	Wide Web},
  year = {2005},
  pages = {322--331},
  address = {New York, NY, USA},
  publisher = {ACM},
  isbn = {1-59593-046-9},
  location = {Chiba, Japan}
}

@InProceedings{Kim2014Bayesian,
  author    = {Kim, Yong-Deok and Choi, Seungjin},
  title     = {Bayesian Binomial Mixture Model for Collaborative Prediction with Non-random Missing Data},
  booktitle = {Proceedings of the 8th ACM Conference on Recommender Systems},
  year      = {2014},
  series    = {RecSys '14},
  pages     = {201--208},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Collaborative prediction involves filling in missing entries of a
	user-item matrix to predict preferences of users based on their observed
	preferences. Most of existing models assume that the data is missing
	at random (MAR), which is often violated in recommender systems in
	practice. Incorrect assumption on missing data ignores the missing
	data mechanism, leading to biased inferences and prediction. In this
	paper we present a Bayesian binomial mixture model for collaborative
	prediction, where the generative process for data and missing data
	mechanism are jointly modeled to handle non-random missing data.
	Missing data mechanism is modeled by three factors, each of which
	is related to users, items, and rating values. Each factor is modeled
	by Bernoulli random variable, and the observation of rating value
	is determined by the Boolean OR operation of three binary variables.
	We develop computationally-efficient variational inference algorithms,
	where variational parameters have closed-form update rules and the
	computational complexity depends on the number of observed ratings,
	instead of the size of the rating data matrix. We also discuss implementation
	issues on hyperparameter tuning and estimation based on empirical
	Bayes. Experiments on Yahoo! Music and MovieLens datasets confirm
	the useful behavior of our model by demonstrating that: (1) it outperforms
	state-of-the-art methods in yielding higher predictive performance;
	(2) it finds meaningful solutions instead of undesirable boundary
	solutions; (3) it provides rating trend analysis on why ratings are
	observed.},
  acmid     = {2645754},
  comment   = {user i cluster
rating distribution based on cluster
user i , item j, rating v produce 0/1 selector U, M, T
response (not rating) = 1- (1-U)(1-M)(1-T)},
  file      = {Kim2014Bayesian.pdf:Kim2014Bayesian.pdf:PDF},
  isbn      = {978-1-4503-2668-1},
  keywords  = {collaborative filtering, non-random missing data, probabilistic models, recommender systems, variational bayesian inference},
  location  = {Foster City, Silicon Valley, California, USA},
  numpages  = {8},
  timestamp = {2016.06.30},
}

@ARTICLE{kleinberg2008convergence,
  author = {Kleinberg, J.},
  title = {{The convergence of social and technological networks}},
  journal = {Communications of the ACM},
  year = {2008},
  volume = {51},
  pages = {66--72},
  number = {11},
  file = {kleinberg2008convergence.pdf:kleinberg2008convergence.pdf:PDF},
  issn = {0001-0782},
  publisher = {ACM}
}

@ARTICLE{Kleinberg1999Authoritative,
  author = {J. Kleinberg},
  title = {Authoritative sources in a hyperlinked environment},
  journal = {Journal of the ACM},
  year = {1999},
  volume = {46},
  pages = {604--622},
  number = {5},
  owner = {Cheyenne},
  timestamp = {2009.09.21}
}

@Article{Kobayashi2008Tracking,
  author    = {Kobayashi, M. and Yung, R.},
  title     = {Tracking Topic Evolution in On-Line Postings: 2006 IBM Innovation Jam Data},
  journal   = {Lecture Notes in Computer Science},
  year      = {2008},
  volume    = {5012},
  pages     = {616-625},
  groups    = {Twitter},
  publisher = {Springer},
}

@INPROCEEDINGS{Kolari2006Detecting,
  author = {Kolari, P. and Java, A. and Finin, T. and Oates, T. and Joshi, A.},
  title = {Detecting spam blogs: A machine learning approach},
  booktitle = {PROCEEDINGS OF THE NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE},
  year = {2006},
  volume = {21},
  number = {2},
  pages = {1351-1356},
  organization = {Menlo Park, CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999},
  abstract = {Weblogs or blogs are an important new way to publish
	
	 information, engage in discussions, and form communities
	
	 on the Internet. The Blogosphere has unfortunately
	
	 been infected by several varieties of spam-like
	
	 content. Blog search engines, for example, are inundated
	
	 by posts from splogs false blogs with machine
	
	 generated or hijacked content whose sole purpose is to
	
	 host ads or raise the PageRank of target sites. We discuss
	
	 how SVM models based on local and link-based
	
	 features can be used to detect splogs. We present an
	
	 evaluation of learned models and their utility to blog
	
	 search engines; systems that employ techniques differing
	
	 from those of conventional web search engines.}
}

@INPROCEEDINGS{Kondor2014Multiresolution,
  author = {Risi Kondor and Nedelina Teneva and Vikas Garg},
  title = {Multiresolution Matrix Factorization},
  booktitle = {Proceedings of ICML},
  year = {2014},
  pages = {1189-1197},
  abstract = {The types of large matrices that appear in modern Machine Learning
	problems often have complex hierarchical structures that go beyond
	what can be found by traditional linear algebra tools, such as eigendecompositions.
	Inspired by ideas from multiresolution analysis, this paper introduces
	a new notion of matrix factorization that can capture structure in
	matrices at multiple different scales. The resulting Multiresolution
	Matrix Factorizations (MMFs) not only provide a wavelet basis for
	sparse approximation, but can also be used for matrix compression
	(similar to Nystrom approximations) and as a prior for matrix completion.},
  file = {Kondor2014Multiresolution.pdf:Kondor2014Multiresolution.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.06.24}
}

@Article{Konstan1997GroupLens,
  author    = {Konstan, J.A. and Miller, B.N. and Maltz, D. and Herlocker, J.L. and Gordon, L.R. and Riedl, J.},
  title     = {GroupLens: applying collaborative filtering to Usenet news},
  journal   = {Communications of the ACM},
  year      = {1997},
  volume    = {40},
  number    = {3},
  pages     = {77--87},
  groups    = {Recommender Systems},
  publisher = {ACM},
}

@InProceedings{Konstas2009Social,
  author    = {Konstas, Ioannis and Stathopoulos, Vassilios and Jose, Joemon M.},
  title     = {On Social Networks and Collaborative Recommendation},
  booktitle = {Proceedings of the 32Nd International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year      = {2009},
  series    = {SIGIR '09},
  pages     = {195--202},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1571977},
  doi       = {10.1145/1571941.1571977},
  groups    = {Recommender Systems},
  isbn      = {978-1-60558-483-6},
  keywords  = {collaborative filtering, social network, social tagging, web 2.0 IR},
  location  = {Boston, MA, USA},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/1571941.1571977},
}

@Article{Koren2010Factor,
  author     = {Koren, Yehuda},
  title      = {Factor in the neighbors: Scalable and accurate collaborative filtering},
  journal    = {ACM Transactions on Knowledge Discovery from Data.},
  year       = {2010},
  volume     = {4},
  pages      = {1:1--1:24},
  month      = {January},
  issn       = {1556-4681},
  abstract   = {Recommender systems provide users with personalized suggestions for
	products or services. These
	
	systems often rely on collaborating filtering (CF), where past transactions
	are analyzed in order
	
	to establish connections between users and products. The most common
	approach to CF is based
	
	on neighborhood models, which originate from similarities between
	products or users. In this work
	
	we introduce a new neighborhood model with an improved prediction
	accuracy. Unlike previous
	
	approaches that are based on heuristic similarities,we model neighborhood
	relations by minimizing
	
	a global cost function. Further accuracy improvements are achieved
	by extending the model to
	
	exploit both explicit and implicit feedback by the users. Past models
	were limited by the need to
	
	compute all pairwise similarities between items or users, which grow
	quadratically with input size.
	
	In particular, this limitation vastly complicates adopting user similarity
	models, due to the typical
	
	large number of users. Our new model solves these limitations by factoring
	the neighborhood model,
	
	thus making both item-item and user-user implementations scale linearly
	with the size of the data.
	
	The methods are tested on the Netflix data, with encouraging results.},
  acmid      = {1644874},
  address    = {New York, NY, USA},
  articleno  = {1},
  comment    = {use item KNN and user KNN in the matrix factorization framework
	
	the rating is estimated to be 
	
	=
	
	bases (including user base, item base, overall base) 
	
	+
	
	item KNN: all items rated by the user, normalized by the set cardinality,
	offset score x item similarity (which is further decomposed to item
	vectors, dual role)
	
	+
	
	implicit item KNN: all items with u's implicitly feedback, normalized
	by the set cardinality, item similarity (again decomposed to item
	vectors, dual role)
	
	+
	
	user KNN: all users rated item i, normalized by the set cardinality,
	offset score x user similarity (decomposed to two dual role item
	vectors)
	
	
	each items is associated with 3 vectors (2 for explicit rating, dual
	roles like truster and trustee, 1 for implicit feedback)
	
	each user is associated with 2 vectors(},
  file       = {Koren2010Factor.pdf:Koren2010Factor.pdf:PDF},
  groups     = {Recommender Systems},
  issue      = {1},
  issue_date = {January 2010},
  keywords   = {Netflix Prize, Recommender systems, collaborative filtering},
  numpages   = {24},
  publisher  = {ACM},
}

@Conference{koren2009collaborative,
  author       = {Koren, Y.},
  title        = {{Collaborative filtering with temporal dynamics}},
  booktitle    = {Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining},
  year         = {2009},
  pages        = {447--456},
  organization = {ACM},
  comment      = {kdd 2009 best paper
	
	Netflix
	
	assume: item rating baseline will change
	
	user rating baseline will change
	
	the average movie rating made a
	
	sudden jump in early 2004 (1500 days since the first rating in
	
	the dataset).
	
	 ratings tend to increase with the movie
	
	age at the time of the rating.
	
	
	user preference:puk captures the stationary portion of the factor,uk
	·devu(t)
	
	approximates a possible portion that changes linearly over time,
	
	and puk,t absorbs the very local, day-specific variability.},
}

@InProceedings{Koren2008Factorization,
  author       = {Koren, Y.},
  title        = {Factorization meets the neighborhood: a multifaceted collaborative filtering model},
  booktitle    = {Proceeding of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining},
  year         = {2008},
  pages        = {426--434},
  organization = {ACM},
  abstract     = {Recommender systems provide users with personalized suggestions for products or services. These systems often rely on Collaborating Filtering (CF), where past transactions are analyzed in order to establish connections between users and products. The two more successful approaches to CF are latent factor models, which directly profile both users and products, and neighborhood models, which analyze similarities between products or users. In this work we introduce some innovations to both approaches. The factor and neighborhood models can now be smoothly merged, thereby building a more accurate combined model. Further accuracy improvements are achieved by extending the models to exploit both explicit and implicit feedback by the users. The methods are tested on the Netflix data. Results are better than those previously published on that dataset. In addition, we suggest a new evaluation metric, which highlights the differences among methods, based on their performance at a top-K recommendation task.},
  file         = {Koren2008Factorization.PDF:Koren2008Factorization.PDF:PDF},
  groups       = {Recommender Systems},
}

@Article{Koren2009Matrix,
  author    = {Koren, Y. and Bell, R. and Volinsky, C.},
  title     = {Matrix factorization techniques for recommender systems},
  journal   = {Computer},
  year      = {2009},
  volume    = {42},
  number    = {8},
  pages     = {30--37},
  abstract  = {As the Netflix Prize competition has demonstrated,
	
	matrix factorization models
	
	are superior to classic nearest-neighbor
	
	techniques for producing product recommendations,
	
	allowing the incorporation
	
	of additional information such as implicit
	
	feedback, temporal effects, and confidence
	
	levels.},
  comment   = {a survey
	
	matrix factorization
	
	idea: factors
	
	to avoid over-fitting, +regularizer
	
	learning algorithm: stochastic gradient descent or alternating least
	squares
	
	extension:
	
	
	adding biases
	
	additional input sources
	
	temporal dynamics
	
	confidence},
  file      = {Koren2009Matrix.pdf:Koren2009Matrix.pdf:PDF},
  groups    = {Recommender Systems},
  publisher = {IEEE},
}

@ARTICLE{kossinets2006empirical,
  author = {Kossinets, G. and Watts, D.J.},
  title = {{Empirical analysis of an evolving social network}},
  journal = {Science},
  year = {2006},
  volume = {311},
  pages = {88},
  number = {5757},
  publisher = {AAAS}
}

@InProceedings{Krohn-Grimberghe2012Multi,
  author    = {Krohn-Grimberghe, Artus and Drumond, Lucas and Freudenthaler, Christoph and Schmidt-Thieme, Lars},
  title     = {Multi-relational Matrix Factorization Using Bayesian Personalized Ranking for Social Network Data},
  booktitle = {Proceedings of the Fifth ACM International Conference on Web Search and Data Mining},
  year      = {2012},
  series    = {WSDM '12},
  pages     = {173--182},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {A key element of the social networks on the internet such as Facebook
	and Flickr is that they encourage users to create connections between
	themselves, other users and objects.
	
	
	One important task that has been approached in the literature that
	deals with such data is to use social graphs to predict user behavior
	(e.g. joining a group of interest). More specifically, we study the
	cold-start problem, where users only participate in some relations,
	which we will call social relations, but not in the relation on which
	the predictions are made, which we will refer to as target relations.
	
	
	We propose a formalization of the problem and a principled approach
	to it based on multi-relational factorization techniques. Furthermore,
	we derive a principled feature extraction scheme from the social
	data to extract predictors for a classifier on the target relation.
	Experiments conducted on real world datasets show that our approach
	outperforms current methods.},
  acmid     = {2124317},
  comment   = {motivation:
	
	cold start behavior prediction in SN
	
	
	only
	
	social information about certain users is available while in-
	
	teraction data between the items and those users has not
	
	yet been observed.
	
	
	
	idea
	
	
	linear combination of observations on purchase history and relations
	
	
	methodology
	
	MR-BPR
	
	matrix factorization of ranking, higher ratings sigmoid function
	
	
	data
	
	flickr, youtube, blogcategory
	
	
	experiment
	
	AUC},
  file      = {Krohn-Grimberghe2012Multi.pdf:Krohn-Grimberghe2012Multi.pdf:PDF},
  isbn      = {978-1-4503-0747-5},
  keywords  = {cold-start, item prediction, item recommendation, joint factorization, matrix factorization, multi-relational learning, ranking, recommender systems, social network},
  location  = {Seattle, Washington, USA},
  numpages  = {10},
  timestamp = {2015.11.26},
}

@ARTICLE{Kulis2012Kernelized,
  author = {Kulis, B. and Grauman, K.},
  title = {Kernelized Locality-Sensitive Hashing},
  journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
  year = {2012},
  volume = {34},
  pages = {1092-1104},
  number = {6},
  doi = {10.1109/TPAMI.2011.219},
  issn = {0162-8828},
  keywords = {content-based retrieval;file organisation;image classification;image
	matching;image retrieval;arbitrary kernel function;content-based
	retrieval;example-based object classification;fast retrieval method;high-dimensional
	kernelized data;image retrieval task;image search;image-based kernel;kernelized
	locality-sensitive hashing;local feature matching;similarity function;sublinear
	time similarity search guarantees;vision problem;Approximation algorithms;Covariance
	matrix;Databases;Kernel;Measurement;Object recognition;Vectors;Kernel
	methods;Similarity search;central limit theorem;image search.;locality-sensitive
	hashing}
}

@InProceedings{Kumar2004graph-theoretic,
  author    = {Kumar, Ravi and Mahadevan, Uma and Sivakumar, D.},
  title     = {A graph-theoretic approach to extract storylines from search results},
  booktitle = {Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining},
  year      = {2004},
  series    = {KDD '04},
  pages     = {216--225},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {We present a graph-theoretic approach to discover storylines from
	search results. Storylines are windows that offer glimpses into interesting
	themes latent among the top search results for a query; they are
	different from, and complementary to, clusters obtained through traditional
	approaches. Our framework is axiomatically developed and combinatorial
	in nature, based on generalizations of the maximum induced matching
	problem on bipartite graphs. The core algorithmic task involved is
	to mine for signature structures in a robust graph representation
	of the search results. We present a very fast algorithm for this
	task based on local search. Experiments show that the collection
	of storylines extracted through our algorithm offers a concise organization
	of the wealth of information hidden beyond the first page of search
	results.},
  acmid     = {1014078},
  doi       = {http://doi.acm.org/10.1145/1014052.1014078},
  file      = {Kumar2004graph-theoretic.pdf:Kumar2004graph-theoretic.pdf:PDF},
  groups    = {Twitter},
  isbn      = {1-58113-888-1},
  keywords  = {clustering, communities, link analysis, search results, storylines},
  location  = {Seattle, WA, USA},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1014052.1014078},
}

@Article{Kumar1999Trawling,
  author    = {Kumar, R. and Raghavan, P. and Rajagopalan, S. and Tomkins, A.},
  title     = {Trawling the Web for emerging cyber-communities},
  journal   = {Computer Networks-the International Journal of Computer and Telecommunications Networkin},
  year      = {1999},
  volume    = {31},
  number    = {11},
  pages     = {1481--1494},
  owner     = {Cheyenne},
  publisher = {Amsterdam: Elsevier, 1999-},
  timestamp = {2009.09.21},
}

@INPROCEEDINGS{Kunegis2009slashdot,
  author = {Kunegis, J\'{e}r\^{o}me and Lommatzsch, Andreas and Bauckhage, Christian},
  title = {The slashdot zoo: mining a social network with negative edges},
  booktitle = {WWW '09: Proceedings of the 18th international conference on World
	wide web},
  year = {2009},
  pages = {741--750},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1526709.1526809},
  isbn = {978-1-60558-487-4},
  location = {Madrid, Spain}
}

@Conference{kwak2010twitter,
  author       = {Kwak, H. and Lee, C. and Park, H. and Moon, S.},
  title        = {What is Twitter, a social network or a news media?},
  booktitle    = {Proceedings of the 19th international conference on World wide web},
  year         = {2010},
  pages        = {591--600},
  organization = {ACM},
  abstract     = {Twitter, a microblogging service less than three years old, commands
	
	more than 41 million users as of July 2009 and is growing
	
	fast. Twitter users tweet about any topic within the 140-character
	
	limit and follow others to receive their tweets. The goal of this
	
	paper is to study the topological characteristics of Twitter and its
	
	power as a new medium of information sharing.
	
	We have crawled the entire Twitter site and obtained 41:7 million
	
	user profiles, 1:47 billion social relations, 4; 262 trending topics,
	
	and 106 million tweets. In its follower-following topology analysis
	
	we have found a non-power-law follower distribution, a short effective
	
	diameter, and low reciprocity, which all mark a deviation from
	
	known characteristics of human social networks [28]. In order to
	
	identify influentials on Twitter, we have ranked users by the number
	
	of followers and by PageRank and found two rankings to be similar.
	
	Ranking by retweets differs from the previous two rankings,
	
	indicating a gap in influence inferred from the number of followers
	
	and that from the popularity of one’s tweets. We have analyzed the
	
	tweets of top trending topics and reported on their temporal behavior
	
	and user participation. We have classified the trending topics
	
	based on the active period and the tweets and show that the majority
	
	(over 85%) of topics are headline news or persistent news in
	
	nature. A closer look at retweets reveals that any retweeted tweet
	
	is to reach an average of 1; 000 users no matter what the number
	
	of followers is of the original tweet. Once retweeted, a tweet gets
	
	retweeted almost instantly on next hops, signifying fast diffusion
	
	of information after the 1st retweet.
	
	To the best of our knowledge this work is the first quantitative
	
	study on the entire Twittersphere and information diffusion on it.},
  file         = {kwak2010twitter.pdf:kwak2010twitter.pdf:PDF},
  groups       = {Twitter},
}

@INCOLLECTION{Lacerda2008Discovering,
  author = {Gustavo Lacerda and Peter L. Spirtes and Joseph Ramsey and Patrik
	O. Hoyer},
  title = {Discovering Cyclic Causal Models by Independent Components Analysis},
  booktitle = {Proceedings of the Twenty-Fourth Conference on Uncertainty in Artificial
	Intelligence},
  year = {2008},
  abstract = {We generalize Shimizu et al's (2006) ICA-based approach for discovering
	linear non-Gaussian acyclic (LiNGAM) Structural Equation Models (SEMs)
	from causally sufficient, continuous-valued observational data. By
	relaxing the assumption that the generating SEM's graph is acyclic,
	we solve the more general problem of linear non-Gaussian (LiNG) SEM
	discovery. LiNG discovery algorithms output the distribution equivalence
	class of SEMs which, in the large sample limit, represents the population
	distribution. We apply a LiNG discovery algorithm to simulated data.
	Finally, we give sufficient conditions under which only one of the
	SEMs in the output class is 'stable'.},
  file = {Lacerda2008Discovering.pdf:Lacerda2008Discovering.pdf:PDF},
  owner = {csgueste},
  timestamp = {2016.04.27}
}

@ARTICLE{lacoste2008disclda,
  author = {Lacoste-Julien, S. and Sha, F. and Jordan, M.I.},
  title = {DiscLDA: Discriminative learning for dimensionality reduction and
	classification},
  journal = {Advances in Neural Information Processing Systems},
  year = {2008},
  volume = {21},
  file = {lacoste2008disclda.pdf:lacoste2008disclda.pdf:PDF},
  publisher = {Citeseer}
}

@INPROCEEDINGS{Lafferty2001Document,
  author = {Lafferty, John and Zhai, Chengxiang},
  title = {Document language models, query models, and risk minimization for
	information retrieval},
  booktitle = {SIGIR '01: Proceedings of the 24th annual international ACM SIGIR
	conference on Research and development in information retrieval},
  year = {2001},
  pages = {111--119},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/383952.383970},
  isbn = {1-58113-331-6},
  location = {New Orleans, Louisiana, United States}
}

@INPROCEEDINGS{Lampe2007Follow,
  author = {Lampe, Cliff A.C. and Johnston, Erik and Resnick, Paul},
  title = {Follow the reader: filtering comments on slashdot},
  booktitle = {CHI '07: Proceedings of the SIGCHI conference on Human factors in
	computing systems},
  year = {2007},
  pages = {1253--1262},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1240624.1240815},
  file = {Lampe2007Follow.pdf:Lampe2007Follow.pdf:PDF},
  isbn = {978-1-59593-593-9},
  location = {San Jose, California, USA}
}

@INPROCEEDINGS{Lampe2005Follow,
  author = {Lampe, Cliff and Johnston, Erik},
  title = {Follow the (slash) dot: effects of feedback on new members in an
	online community},
  booktitle = {GROUP '05: Proceedings of the 2005 international ACM SIGGROUP conference
	on Supporting group work},
  year = {2005},
  pages = {11--20},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1099203.1099206},
  isbn = {1-59593-223-2},
  location = {Sanibel Island, Florida, USA}
}

@INPROCEEDINGS{Lampe2004Slash(dot),
  author = {Lampe, Cliff and Resnick, Paul},
  title = {Slash(dot) and burn: distributed moderation in a large online conversation
	space},
  booktitle = {CHI '04: Proceedings of the SIGCHI conference on Human factors in
	computing systems},
  year = {2004},
  pages = {543--550},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/985692.985761},
  isbn = {1-58113-702-8},
  location = {Vienna, Austria}
}

@InProceedings{Lappas2009burstiness,
  author    = {Lappas, Theodoros and Arai, Benjamin and Platakis, Manolis and Kotsakos, Dimitrios and Gunopulos, Dimitrios},
  title     = {On burstiness-aware search for document sequences},
  booktitle = {Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining},
  year      = {2009},
  series    = {KDD '09},
  pages     = {477--486},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {As the number and size of large timestamped collections (e.g. sequences
	of digitized newspapers, periodicals, blogs) increase, the problem
	of efficiently indexing and searching such data becomes more important.
	Term burstiness has been extensively researched as a mechanism to
	address event detection in the context of such collections. In this
	paper, we explore how burstiness information can be further utilized
	to enhance the search process. We present a novel approach to model
	the burstiness of a term, using discrepancy theory concepts. This
	allows us to build a parameter-free, linear-time approach to identify
	the time intervals of maximum burstiness for a given term. Finally,
	we describe the first burstiness-driven search framework and thoroughly
	evaluate our approach in the context of different scenarios.},
  acmid     = {1557075},
  doi       = {http://doi.acm.org/10.1145/1557019.1557075},
  file      = {Lappas2009burstiness.pdf:Lappas2009burstiness.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-1-60558-495-9},
  keywords  = {burstiness, document sequences, search},
  location  = {Paris, France},
  numpages  = {10},
  owner     = {linchen},
  timestamp = {2011.11.01},
  url       = {http://doi.acm.org/10.1145/1557019.1557075},
}

@InProceedings{Lappas2009Finding,
  author    = {Lappas, Theodoros and Liu, Kun and Terzi, Evimaria},
  title     = {Finding a team of experts in social networks},
  booktitle = {Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining},
  year      = {2009},
  series    = {KDD '09},
  pages     = {467--476},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1557074},
  doi       = {http://doi.acm.org/10.1145/1557019.1557074},
  file      = {Lappas2009Finding.pdf:Lappas2009Finding.pdf:PDF},
  isbn      = {978-1-60558-495-9},
  keywords  = {graph algorithms, social networks, team formation},
  location  = {Paris, France},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1557019.1557074},
}

@InProceedings{Larrain2015Good,
  author    = {Larrain, Santiago and Trattner, Christoph and Parra, Denis and Graells-Garrido, Eduardo and N{\o}rv{\aa}g, Kjetil},
  title     = {Good Times Bad Times: A Study on Recency Effects in Collaborative Filtering for Social Tagging},
  booktitle = {Proceedings of the 9th ACM Conference on Recommender Systems},
  year      = {2015},
  series    = {RecSys '15},
  pages     = {269--272},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {In this paper, we present work-in-progress of a recently started project
	that aims at studying the effect of time in recommender systems in
	the context of social tagging. Despite the existence of previous
	work in this area, no research has yet made an extensive evaluation
	and comparison of time-aware recommendation methods. With this motivation,
	this paper presents results of a study where we focused on understanding
	(i) "when" to use the temporal information into traditional collaborative
	filtering (CF) algorithms, and (ii) "how" to weight the similarity
	between users and items by exploring the effect of different time-decay
	functions. As the results of our extensive evaluation conducted over
	five social tagging systems (Delicious, BibSonomy, CiteULike, MovieLens,
	and Last.fm) suggest, the step (when) in which time is incorporated
	in the CF algorithm has substantial effect on accuracy, and the type
	of time-decay function (how) plays a role on accuracy and coverage
	mostly under pre-filtering on user-based CF, while item-based shows
	stronger stability over the experimental conditions.},
  acmid     = {2799682},
  comment   = {t the step (pre- or post-filtering)
	
	in which temporal information is incorporated in the recommendation
	
	algorithm has a substantial effect on the performance of the
	
	algorithms. On the other side, the decay function affects in different
	
	ways the version of the CF method: item-based is very stable while
	
	user-based is affected by the decay function. In addition, combining
	
	both user- and item-based recommendation has a small but regular
	
	improvement on ranking accuracy.
	
	
	pre-filtering: rating is modified by a decay function, then similarity
	computation, then KNN
	
	post-filtering: decay the contribution of neighbor in KNN},
  file      = {Larrain2015Good.pdf:Larrain2015Good.pdf:PDF},
  isbn      = {978-1-4503-3692-5},
  keywords  = {collaborative filtering, social tagging, time-aware recommendations},
  location  = {Vienna, Austria},
  numpages  = {4},
  timestamp = {2015.12.04},
}

@InProceedings{Lavrenko2001Relevance,
  author    = {Lavrenko, Victor and Croft, W. Bruce},
  title     = {Relevance based language models},
  booktitle = {Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval},
  year      = {2001},
  series    = {SIGIR '01},
  pages     = {120--127},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {383972},
  doi       = {http://doi.acm.org/10.1145/383952.383972},
  file      = {Lavrenko2001Relevance.pdf:Lavrenko2001Relevance.pdf:PDF},
  isbn      = {1-58113-331-6},
  location  = {New Orleans, Louisiana, United States},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/383952.383972},
}

@InProceedings{Lawrence2009Non-lineara,
  author       = {Lawrence, N.D. and Urtasun, R.},
  title        = {Non-linear matrix factorization with Gaussian processes},
  booktitle    = {Proceedings of the 26th Annual International Conference on Machine Learning},
  year         = {2009},
  pages        = {601--608},
  organization = {ACM},
  abstract     = {A popular approach to collaborative ltering
	
	is matrix factorization. In this paper we develop
	
	a non-linear probabilistic matrix factorization
	
	using Gaussian process latent variable
	
	models. We use stochastic gradient descent
	
	(SGD) to optimize the model. SGD allows us
	
	to apply Gaussian processes to data sets with
	
	millions of observations without approximate
	
	methods. We apply our approach to benchmark
	
	movie recommender data sets. The results
	
	show better than previous state-of-theart
	
	performance.},
  file         = {Lawrence2009Non-lineara.pdf:Lawrence2009Non-lineara.pdf:PDF},
  groups       = {Recommender Systems},
}

@ARTICLE{Lazer2014Parable,
  author = {Lazer, David and Kennedy, Ryan and King, Gary and Vespignani, Alessandro},
  title = {The Parable of Google Flu: Traps in Big Data Analysis},
  journal = {Science},
  year = {2014},
  volume = {343},
  pages = {1203-1205},
  number = {6176},
  abstract = {In February 2013, Google Flu Trends (GFT) made headlines but not for
	a reason that Google executives or the creators of the flu tracking
	system would have hoped. Nature reported that GFT was predicting
	more than double the proportion of doctor visits for influenza-like
	illness (ILI) than the Centers for Disease Control and Prevention
	(CDC), which bases its estimates on surveillance reports from laboratories
	across the United States (1, 2). This happened despite the fact that
	GFT was built to predict CDC reports. Given that GFT is often held
	up as an exemplary use of big data (3, 4), what lessons can we draw
	from this error?},
  doi = {10.1126/science.1248506},
  eprint = {http://www.sciencemag.org/content/343/6176/1203.full.pdf},
  url = {http://www.sciencemag.org/content/343/6176/1203.short}
}

@InProceedings{Lee2010Finding,
  author    = {Lee, Changhyun and Kwak, Haewoon and Park, Hosung and Moon, Sue},
  title     = {Finding influentials based on the temporal order of information adoption in twitter},
  booktitle = {Proceedings of the 19th international conference on World wide web},
  year      = {2010},
  series    = {WWW '10},
  pages     = {1137--1138},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Twitter offers an explicit mechanism to facilitate information diffusion
	and has emerged as a new medium for communication. Many approaches
	to find influentials have been proposed, but they do not consider
	the temporal order of information adoption. In this work, we propose
	a novel method to find influentials by considering both the link
	structure and the temporal order of information adoption in Twitter.
	Our method finds distinct influentials who are not discovered by
	other methods.},
  acmid     = {1772842},
  doi       = {http://doi.acm.org/10.1145/1772690.1772842},
  file      = {Lee2010Finding.pdf:Lee2010Finding.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-1-60558-799-8},
  keywords  = {influentials, information diffusion, ranking, social networks, twitter},
  location  = {Raleigh, North Carolina, USA},
  numpages  = {2},
  url       = {http://doi.acm.org/10.1145/1772690.1772842},
}

@InCollection{Lee2009Reinforcing,
  author      = {Lee, Danielle and Brusilovsky, Peter},
  title       = {Reinforcing Recommendation Using Implicit Negative Feedback},
  booktitle   = {User Modeling, Adaptation, and Personalization},
  publisher   = {Springer Berlin / Heidelberg},
  year        = {2009},
  editor      = {Houben, Geert-Jan and McCalla, Gord and Pianesi, Fabio and Zancanaro, Massimo},
  volume      = {5535},
  series      = {Lecture Notes in Computer Science},
  pages       = {422-427},
  isbn        = {978-3-642-02246-3},
  abstract    = {Recommender systems have explored a range of implicit feedback
	
	approaches to capture users’ current interests and preferences without
	
	intervention of users’ work. However, current research focuses mostly
	on
	
	implicit positive feedback. Implicit negative feedback is still a
	challenge
	
	because users mainly target information they want. There have been
	few studies
	
	assessing the value of negative implicit feedback. In this paper,
	we explore a
	
	specific approach to employ implicit negative feedback and assess
	whether it
	
	can be used to improve recommendation quality.},
  affiliation = {University of Pittsburgh School of Information Sciences 135 N. Bellefield Ave. Pittsburgh PA 15260 USA},
  comment     = {Main Contribution: introduces a simple mechanism to infer negative
	feedback, and use it for user profiling
	
	
	tested in a job finder system Proactive
	
	
	jobs that were opened but not saved as negative job preferences
	
	saved jobs+search options as positive preference
	
	
	build user profiles by the above three
	
	
	Logic is not clear
	
	
	User’s saved jobs + negative prefs works better in finding good jobs
	but worse in finding bad jobs},
  file        = {Lee2009Reinforcing.pdf:Lee2009Reinforcing.pdf:PDF},
  groups      = {Recommender Systems},
  keyword     = {Computer Science},
  url         = {http://dx.doi.org/10.1007/978-3-642-02247-0_47},
}

@ARTICLE{Lee1999Learning,
  author = {Lee, Daniel D and Seung, H Sebastian},
  title = {Learning the parts of objects by non-negative matrix factorization},
  journal = {Nature},
  year = {1999},
  volume = {401},
  pages = {788--791},
  number = {6755},
  publisher = {Nature Publishing Group}
}

@InProceedings{Lee2014Modeling,
  author    = {Lee, Pei and Lakshmanan, Laks V.S. and Tiwari, Mitul and Shah, Sam},
  title     = {Modeling Impression Discounting in Large-scale Recommender Systems},
  booktitle = {Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year      = {2014},
  series    = {KDD '14},
  pages     = {1837--1846},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Recommender systems have become very important for many online activities,
	such as watching movies, shopping for products, and connecting with
	friends on social networks. User behavioral analysis and user feedback
	(both explicit and implicit) modeling are crucial for the improvement
	of any online recommender system. Widely adopted recommender systems
	at LinkedIn such as "People You May Know" and "Endorsements" are
	evolving by analyzing user behaviors on impressed recommendation
	items.
	
	
	In this paper, we address modeling impression discounting of recommended
	items, that is, how to model user's no-action feedback on impressed
	recommended items. The main contributions of this paper include (1)
	large-scale analysis of impression data from LinkedIn and KDD Cup;
	(2) novel anti-noise regression techniques, and its application to
	learn four different impression discounting functions including linear
	decay, inverse decay, exponential decay, and quadratic decay; (3)
	applying these impression discounting functions to LinkedIn's "People
	You May Know" and "Endorsements" recommender systems.},
  acmid     = {2623356},
  comment   = {data?
	
	de-noising?},
  isbn      = {978-1-4503-2956-9},
  keywords  = {impression discounting, recommender system},
  location  = {New York, New York, USA},
  numpages  = {10},
  timestamp = {2015.11.12},
}

@INPROCEEDINGS{Lee2003Learning,
  author = {Wee Sun Lee and Bing Liu},
  title = {Learning with Positive and Unlabeled Examples Using Weighted Logistic
	Regressio},
  booktitle = {Proceedings of the Twentieth International Conference on Machine
	Learning},
  year = {2003},
  file = {Lee2003Learning.pdf:Lee2003Learning.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.09.10}
}

@INPROCEEDINGS{Lefakis2014Dynamic,
  author = {Leonidas Lefakis and Francois Fleuret},
  title = {Dynamic Programming Boosting for Discriminative Macro-Action Discovery},
  booktitle = {Proceedings of ICML},
  year = {2014},
  pages = {1159-1167},
  abstract = {We consider the problem of automatic macro- action discovery in imitation
	learning, which we cast as one of change-point detection. Unlike
	prior work in change-point detection, the present work leverages
	discriminative learning algorithms. Our main contribution is a novel
	supervised learning algorithm which extends the classical Boosting
	framework by combining it with dynamic programming. The resulting
	process alternatively improves the performance of individual strong
	predictors and the estimated change- points in the training sequence.
	Empirical evaluation is presented for the pro- posed method on tasks
	where change-points arise naturally as part of a classification problem.
	Finally we show the applicability of the algorithm to macro-action
	discovery in imitation learning and demonstrate it allows us to solve
	complex image-based goal-planning problems with thou- sands of features.},
  file = {Lefakis2014Dynamic.pdf:Lefakis2014Dynamic.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.06.23}
}

@InProceedings{Lerche2014Using,
  author    = {Lerche, Lukas and Jannach, Dietmar},
  title     = {Using Graded Implicit Feedback for Bayesian Personalized Ranking},
  booktitle = {Proceedings of the 8th ACM Conference on Recommender Systems},
  year      = {2014},
  series    = {RecSys '14},
  pages     = {353--356},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {In many application domains of recommender systems, explicit rating
	information is sparse or non-existent. The preferences of the current
	user have therefore to be approximated by interpreting his or her
	behavior, i.e., the implicit user feedback. In the literature, a
	number of algorithm proposals have been made that rely solely on
	such implicit feedback, among them Bayesian Personalized Ranking
	(BPR).
	
	
	In the BPR approach, pairwise comparisons between the items are made
	in the training phase and an item i is considered to be preferred
	over item j if the user interacted in some form with i but not with
	j. In real-world applications, however, implicit feedback is not
	necessarily limited to such binary decisions as there are, e.g.,
	different types of user actions like item views, cart or purchase
	actions and there can exist several actions for an item over time.
	
	
	In this paper we show how BPR can be extended to deal with such more
	fine-granular, graded preference relations. An empirical analysis
	shows that this extension can help to measurably increase the predictive
	accuracy of BPR on realistic e-commerce datasets.},
  acmid     = {2645759},
  comment   = {BPR 

graded means implicit feedback can be graded by e.g. recency 


We assume that pweightpu,iq returns a positive number
if an interaction between u and i exists, and 0 otherwise.
A preference tuple pu, i, j q is therefore inferred whenever
pweightpu, iq ą pweightpu, jq holds. Generally, the pweight
function can encode arbitrary types of information, includ-
ing, e.g., the time or recency aspects as mentioned above.
The extended set of preference relations D`` for each user S
u is defined as follows:
D`` :“ tpu, i, jq|pweightpu, iq ą pweightpu, jq, i P I, j P Iu},
  isbn      = {978-1-4503-2668-1},
  keywords  = {evaluation, implicit feedback, recommender systems},
  location  = {Foster City, Silicon Valley, California, USA},
  numpages  = {4},
  timestamp = {2015.11.12},
}

@ARTICLE{leskovec2007dynamics,
  author = {Leskovec, J. and Adamic, L.A. and Huberman, B.A.},
  title = {The dynamics of viral marketing},
  journal = {ACM Transactions on the Web (TWEB)},
  year = {2007},
  volume = {1},
  pages = {5},
  number = {1},
  issn = {1559-1131},
  publisher = {ACM}
}

@Conference{leskovec2010predicting,
  author       = {Leskovec, J. and Huttenlocher, D. and Kleinberg, J.},
  title        = {Predicting positive and negative links in online social networks},
  booktitle    = {Proceedings of the 19th international conference on World wide web},
  year         = {2010},
  pages        = {641--650},
  organization = {ACM},
  abstract     = {We study online social networks in which relationships can be either
	
	positive (indicating relations such as friendship) or negative
	
	(indicating relations such as opposition or antagonism). Such a mix
	
	of positive and negative links arise in a variety of online settings;
	
	we study datasets from Epinions, Slashdot and Wikipedia. We find
	
	that the signs of links in the underlying social networks can be predicted
	
	with high accuracy, using models that generalize across this
	
	diverse range of sites. These models provide insight into some of
	
	the fundamental principles that drive the formation of signed links
	
	in networks, shedding light on theories of balance and status from
	
	social psychology; they also suggest social computing applications
	
	by which the attitude of one user toward another can be estimated
	
	from evidence provided by their relationships with other members
	
	of the surrounding social network.},
  comment      = {Data : Epinions
	
	 Slashdot
	
	 Wikipedia
	
	Motivation:1)Edge sign Prediction 2)generalization across datasets3)see
	how edge signs can help other tasks
	
	
	Model :
	
	1)logistic regression
	
	2)features include local : out degrees for output point and in degrees
	for input node
	
	globle: triad type},
  file         = {:leskovec2010predicting.pdf:PDF},
}

@InProceedings{leskovec2005graphs,
  author       = {Leskovec, J. and Kleinberg, J. and Faloutsos, C.},
  title        = {Graphs over time: densification laws, shrinking diameters and possible explanations},
  booktitle    = {Proceedings of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining},
  year         = {2005},
  pages        = {177--187},
  organization = {ACM},
  abstract     = {How do real graphs evolve over time? What are “normal”
	
	growth patterns in social, technological, and information
	
	networks? Many studies have discovered patterns in static
	
	graphs, identifying properties in a single snapshot of a large
	
	network, or in a very small number of snapshots; these include
	
	heavy tails for in- and out-degree distributions, communities,
	
	small-world phenomena, and others. However,
	
	given the lack of information about network evolution over
	
	long periods, it has been hard to convert these findings into
	
	statements about trends over time.
	
	Here we study a wide range of real graphs, and we observe
	
	some surprising phenomena. First, most of these graphs
	
	densify over time, with the number of edges growing superlinearly
	
	in the number of nodes. Second, the average distance
	
	between nodes often shrinks over time, in contrast
	
	to the conventional wisdom that such distance parameters
	
	should increase slowly as a function of the number of nodes
	
	(like O(log n) or O(log(log n)).
	
	Existing graph generation models do not exhibit these
	
	types of behavior, even at a qualitative level. We provide a
	
	new graph generator, based on a “forest fire” spreading process,
	
	that has a simple, intuitive justification, requires very
	
	few parameters (like the “flammability” of nodes), and pro-duces graphs
	exhibiting the full range of properties observed
	
	both in prior work and in the present study.},
  file         = {leskovec2005graphs.pdf:leskovec2005graphs.pdf:PDF},
  isbn         = {159593135X},
}

@Conference{leskovec2008statistical,
  author       = {Leskovec, J. and Lang, K.J. and Dasgupta, A. and Mahoney, M.W.},
  title        = {Statistical properties of community structure in large social and information networks},
  booktitle    = {Proceeding of the 17th international conference on World Wide Web},
  year         = {2008},
  pages        = {695--704},
  organization = {ACM},
  abstract     = {A large body of work has been devoted to identifying community structure
	in networks. A community is often though of as a set of nodes that
	has more connections between its members than to the remainder of
	the network. In this paper, we characterize as a function of size
	the statistical and structural properties of such sets of nodes.
	We define the network community profile plot, which characterizes
	the "best" possible community - according to the conductance measure
	- over a wide range of size scales, and we study over 70 large sparse
	real-world networks taken from a wide range of application domains.
	Our results suggest a significantly more refined picture of community
	structure in large real-world networks than has been appreciated
	previously.
	
	
	Our most striking finding is that in nearly every network dataset
	we examined, we observe tight but almost trivial communities at very
	small scales, and at larger size scales, the best possible communities
	gradually "blend in" with the rest of the network and thus become
	less "community-like." This behavior is not explained, even at a
	qualitative level, by any of the commonly-used network generation
	models. Moreover, this behavior is exactly the opposite of what one
	would expect based on experience with and intuition from expander
	graphs, from graphs that are well-embeddable in a low-dimensional
	structure, and from small social networks that have served as testbeds
	of community detection algorithms. We have found, however, that a
	generative model, in which new edges are added via an iterative "forest
	fire" burning process, is able to produce graphs exhibiting a network
	community structure similar to our observations.},
  file         = {leskovec2008statistical.pdf:leskovec2008statistical.pdf:PDF},
}

@InProceedings{Levi2012Finding,
  author    = {Levi, Asher and Mokryn, Osnat and Diot, Christophe and Taft, Nina},
  title     = {Finding a Needle in a Haystack of Reviews: Cold Start Context-based Hotel Recommender System},
  booktitle = {Proceedings of the Sixth ACM Conference on Recommender Systems},
  year      = {2012},
  series    = {RecSys '12},
  pages     = {115--122},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Online hotel searching is a daunting task due to the wealth of online
	information. Reviews written by other travelers replace the word-of-mouth,
	yet turn the search into a time consuming task. Users do not rate
	enough hotels to enable a collaborative filtering based recommendation.
	Thus, a cold start recommender system is needed. In this work we
	design a cold start hotel recommender system, which uses the text
	of the reviews as its main data. We define context groups based on
	reviews extracted from TripAdvisor.com and Venere.com. We introduce
	a novel weighted algorithm for text mining. Our algorithm imitates
	a user that favors reviews written with the same trip intent and
	from people of similar background (nationality) and with similar
	preferences for hotel aspects, which are our defined context groups.
	Our approach combines numerous elements, including unsupervised clustering
	to build a vocabulary for hotel aspects, semantic analysis to understand
	sentiment towards hotel features, and the profiling of intent and
	nationality groups.
	
	
	We implemented our system which was used by the public to conduct
	150 trip planning experiments. We compare our solution to the top
	suggestions of the mentioned web services and show that users were,
	on average, 20% more satisfied with our hotel recommendations. We
	outperform these web services even more in cities where hotel prices
	are high.},
  acmid     = {2365977},
  comment   = {define three types of context information.
	
	The first is intent, or purpose of the trip. We include 5 categories
	
	of intent, namely business trip, single traveler on vacation, family,
	
	group, couple. The second is nationality. The third context is user
	
	preferences for the different hotel aspects.
	
	
	Thus, a user
	
	using our system is asked to provide her trip intent, nationality,
	and
	
	preferences for these aspects.
	
	
	hotel rating=average hotel rating in the review + bias
	
	hotel rating in the review = accumulated weighted features in all
	sentences
	
	feature weight = multiply feature weight to each context ( intent,
	nationality,preference)
	
	weight to each context = polarity x weight (heuristically designed,
	often frequency ratio based)},
  file      = {Levi2012Finding.pdf:Levi2012Finding.pdf:PDF},
  groups    = {Recommender Systems},
  isbn      = {978-1-4503-1270-7},
  keywords  = {common traits, context-aware recommender systems, opinion/text mining, recommender systems, sentiment analysis},
  location  = {Dublin, Ireland},
  numpages  = {8},
  timestamp = {2014.06.09},
}

@ARTICLE{Lewis2004RCV1,
  author = {Lewis, David D. and Yang, Yiming and Rose, Tony G. and Li, Fan},
  title = {RCV1: A New Benchmark Collection for Text Categorization Research},
  journal = {J. Mach. Learn. Res.},
  year = {2004},
  volume = {5},
  pages = {361--397},
  month = dec,
  acmid = {1005345},
  issn = {1532-4435},
  issue_date = {12/1/2004},
  numpages = {37},
  publisher = {JMLR.org}
}

@InProceedings{Li2011Towards,
  author    = {Beibei Li and Anindya Ghose and Panagiotis G. Ipeirotis},
  title     = {Towards a Theory Model for Product Search},
  booktitle = {Proceedings of the 20th international conference on world wide web},
  year      = {2011},
  pages     = {327-336},
  abstract  = {With the growing pervasiveness of the Internet, online search
	
	for products and services is constantly increasing. Most product
	
	search engines are based on adaptations of theoretical models
	
	devised for information retrieval. However, the decision mechanism
	
	that underlies the process of buying a product is different
	
	than the process of locating relevant documents or objects.
	
	We propose a theory model for product search based on
	
	expected utility theory from economics. Specifically, we propose
	
	a ranking technique in which we rank highest the products that
	
	generate the highest surplus, after the purchase. In a sense, the
	
	top ranked products are the “best value for money” for a specific
	
	user. Our approach builds on research on “demand estimation”
	
	from economics and presents a solid theoretical foundation on
	
	which further research can build on. We build algorithms that
	
	take into account consumer demographics, heterogeneity of
	
	consumer preferences, and also account for the varying price of
	
	the products. We show how to achieve this without knowing the
	
	demographics or purchasing histories of individual consumers
	
	but by using aggregate demand data. We evaluate our work,
	
	by applying the techniques on hotel search. Our extensive
	
	user studies, using more than 15,000 user-provided ranking
	
	comparisons, demonstrate an overwhelming preference for the
	
	rankings generated by our techniques, compared to a large
	
	number of existing strong state-of-the-art baselines.},
  comment   = {surplus=utility(purchasing money)-utility(losing money)+stochastic
	error
	
	utility(purchasing money)=sum [ weight (preference) x characteristics
	]
	
	utility(losing money)=weight x amount of money
	
	logistic regression on aggregated purchase},
  file      = {Li2011Towards.pdf:Li2011Towards.pdf:PDF},
  owner     = {littlep},
  timestamp = {2014.03.26},
}

@INPROCEEDINGS{Li2006CiteSeer$hi$:,
  author = {Li, Huajing and Councill, Isaac G. and Bolelli, Levent and Zhou,
	Ding and Song, Yang and Lee, Wang-Chien and Sivasubramaniam, Anand
	and Giles, C. Lee},
  title = {CiteSeer{$\chi$}: a scalable autonomous scientific digital library},
  booktitle = {InfoScale '06: Proceedings of the 1st international conference on
	Scalable information systems},
  year = {2006},
  pages = {18},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1146847.1146865},
  isbn = {1-59593-428-6},
  location = {Hong Kong}
}

@INPROCEEDINGS{Li2008Scalable,
  author = {Li, Huajing and Nie, Zaiqing and Lee, Wang-Chien and Giles, Lee and
	Wen, Ji-Rong},
  title = {Scalable community discovery on textual data with relations},
  booktitle = {CIKM '08: Proceeding of the 17th ACM conference on Information and
	knowledge management},
  year = {2008},
  pages = {1203--1212},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Every piece of textual data is generated as a method to convey its
	authors' opinion regarding specific topics. Authors deliberately
	organize their writings and create links, i.e., references, acknowledgments,
	for better expression. Thereafter, it is of interest to study texts
	as well as their relations to understand the underlying topics and
	communities. Although many efforts exist in the literature in data
	clustering and topic mining, they are not applicable to community
	discovery on large document corpus for several reasons. First, few
	of them consider both textual attributes as well as relations. Second,
	scalability remains a significant issue for large-scale datasets.
	Additionally, most algorithms rely on a set of initial parameters
	that are hard to be captured and tuned. Motivated by the aforementioned
	observations, a hierarchical community model is proposed in the paper
	which distinguishes community cores from affiliated members. We present
	our efforts to develop a scalable community discovery solution for
	large-scale document corpus. Our proposal tries to quickly identify
	potential cores as seeds of communities through relation analysis.
	To eliminate the influence of initial parameters, an innovative attribute-based
	core merge process is introduced so that the algorithm promises to
	return consistent communities regardless initial parameters. Experimental
	results suggest that the proposed method has high scalability to
	corpus size and feature dimensionality, with more than 15 topical
	precision improvement compared with popular clustering techniques.},
  doi = {http://doi.acm.org/10.1145/1458082.1458241},
  isbn = {978-1-59593-991-3},
  location = {Napa Valley, California, USA},
  owner = {Cheyenne},
  timestamp = {2009.09.30}
}

@INPROCEEDINGS{Li2002Improvement,
  author = {Li, Longzhuang and Shang, Yi and Zhang, Wei},
  title = {Improvement of HITS-based algorithms on web documents},
  booktitle = {WWW '02: Proceedings of the 11th international conference on World
	Wide Web},
  year = {2002},
  pages = {527--535},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {In this paper, we present two ways to improve the precision of HITS-based
	algorithms on Web documents. First, by analyzing the limitations
	of current HITS-based algorithms, we propose a new weighted HITS-based
	method that assigns appropriate weights to in-links of root documents.
	Then, we combine content analysis with HITS-based algorithms and
	study the effects of four representative relevance scoring methods,
	VSM, Okapi, TLS, and CDR, using a set of broad topic queries. Our
	experimental results show that our weighted HITS-based method performs
	significantly better than Bharat's improved HITS algorithm. When
	we combine our weighted HITS-based method or Bharat's HITS algorithm
	with any of the four relevance scoring methods, the combined methods
	are only marginally better than our weighted HITS-based method. Between
	the four relevance-scoring methods, there is no significant quality
	difference when they are combined with a HITS-based algorithm},
  doi = {http://doi.acm.org/10.1145/511446.511514},
  isbn = {1-58113-449-5},
  location = {Honolulu, Hawaii, USA}
}

@InProceedings{Li2011SCENE,
  author    = {Li, Lei and Wang, Dingding and Li, Tao and Knox, Daniel and Padmanabhan, Balaji},
  title     = {SCENE: a scalable two-stage personalized news recommendation system},
  booktitle = {Proceedings of the 34th international ACM SIGIR conference on Research and development in Information},
  year      = {2011},
  series    = {SIGIR '11},
  pages     = {125--134},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2009937},
  doi       = {http://doi.acm.org/10.1145/2009916.2009937},
  file      = {Li2011SCENE.pdf:Li2011SCENE.pdf:PDF},
  groups    = {Recommender Systems},
  isbn      = {978-1-4503-0757-4},
  keywords  = {multi-level news recommendation, news entity, personalization, submodularity, user profile},
  location  = {Beijing, China},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2009916.2009937},
}

@Article{Li2011Personalized,
  author  = {Lei Li and Dingding Wang and Shunzhi Zhu and Tao Li},
  title   = {Personalized News Recommendation: A Review and an Experimental Investigation},
  journal = {Journal of Computer Science \& Technology},
  year    = {2011},
  volume  = {5},
  pages   = {002},
  file    = {Li2011Personalized.pdf:Li2011Personalized.pdf:PDF},
  groups  = {Recommender Systems},
}

@Article{Li2010User,
  author   = {Qing Li and Jia Wang and Yuanzhu Peter Chen and Zhangxi Lin},
  title    = {User comments for news recommendation in forum-based social media},
  journal  = {Information Sciences},
  year     = {2010},
  volume   = {180},
  number   = {24},
  pages    = {4929 - 4939},
  doi      = {http://dx.doi.org/10.1016/j.ins.2010.08.044},
  groups   = {Recommender Systems},
  issn     = {0020-0255},
  keywords = {News recommendation},
  url      = {http://www.sciencedirect.com/science/article/pii/S0020025510004251},
}

@InProceedings{Li2003Time-based,
  author    = {Li, Xiaoyan and Croft, W. Bruce},
  title     = {Time-based language models},
  booktitle = {Proceedings of the twelfth international conference on Information and knowledge management},
  year      = {2003},
  series    = {CIKM '03},
  pages     = {469--475},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {956951},
  doi       = {http://doi.acm.org/10.1145/956863.956951},
  isbn      = {1-58113-723-0},
  keywords  = {information retrieval, language models, recency queries, relevance models, time-based language models},
  location  = {New Orleans, LA, USA},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/956863.956951},
}

@Conference{Li2008Tag-based,
  author       = {Li, X. and Guo, L. and Zhao, Y.E.},
  title        = {Tag-based social interest discovery},
  booktitle    = {Proceeding of the 17th international conference on World Wide Web},
  year         = {2008},
  pages        = {675--684},
  organization = {ACM},
  abstract     = {The success and popularity of social network systems, such
	
	as del.icio.us, Facebook, MySpace, and YouTube, have generated
	
	many interesting and challenging problems to the research
	
	community. Among others, discovering social interests
	
	shared by groups of users is very important because it
	
	helps to connect people with common interests and encourages
	
	people to contribute and share more contents. The
	
	main challenge to solving this problem comes from the difficulty
	
	of detecting and representing the interest of the users.
	
	The existing approaches are all based on the online connections
	
	of users and so unable to identify the common interest
	
	of users who have no online connections.
	
	In this paper, we propose a novel social interest discovery
	
	approach based on user-generated tags. Our approach
	
	is motivated by the key observation that in a social network,
	
	human users tend to use descriptive tags to annotate
	
	the contents that they are interested in. Our analysis on
	
	a large amount of real-world traces reveals that in general,
	
	user-generated tags are consistent with the web content they
	
	are attached to, while more concise and closer to the understanding
	
	and judgments of human users about the content.
	
	Thus, patterns of frequent co-occurrences of user tags can
	
	be used to characterize and capture topics of user interests.
	
	We have developed an Internet Social Interest Discovery system,
	
	ISID, to discover the common user interests and cluster
	
	users and their saved URLs by different interest topics. Our
	
	evaluation shows that ISID can effectively cluster similar
	
	documents by interest topics and discover user communities
	
	with common interests no matter if they have any online
	
	connections.},
  comment      = {Data: del.iciou.us
	
	motivation: use tags to cluster users and describe user interests
	
	analysis of user behavior: the distributions of url save frequency,
	user save frequency and tag user frequency are all long-tailed
	
	analysis: 1)tags usually cover the most important keywords (higer
	rank of tf or tfidf) 2) number of tags stablize (even for very popular
	urls) 3)most pages are described by tags from their contents
	
	methodology:1)discover tag sets by association rules 2)cluster
	
	result: 1)inter-topic content similarity is lower than intra-topic
	2)topics can cover most users' most frequent tags},
  file         = {:D\:\\My Documents\\My Papers\\Li2008Tag-based.pdf:PDF},
  owner        = {linchen},
}

@InProceedings{Li2007Improving,
  author    = {Li, Yinghao and Luk, Wing Pong Robert and Ho, Kei Shiu Edward and Chung, Fu Lai Korris},
  title     = {Improving weak ad-hoc queries using wikipedia asexternal corpus},
  booktitle = {Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval},
  year      = {2007},
  series    = {SIGIR '07},
  pages     = {797--798},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1277914},
  doi       = {http://doi.acm.org/10.1145/1277741.1277914},
  file      = {Li2007Improving.pdf:Li2007Improving.pdf:PDF},
  isbn      = {978-1-59593-597-7},
  keywords  = {Wikipedia, external corpus, pseudo-relevance feedback},
  location  = {Amsterdam, The Netherlands},
  numpages  = {2},
  url       = {http://doi.acm.org/10.1145/1277741.1277914},
}

@InProceedings{Li2010Contextual,
  author    = {Li, Yize and Nie, Jiazhong and Zhang, Yi and Wang, Bingqing and Yan, Baoshi and Weng, Fuliang},
  title     = {Contextual Recommendation Based on Text Mining},
  booktitle = {Proceedings of the 23rd International Conference on Computational Linguistics: Posters},
  year      = {2010},
  series    = {COLING '10},
  pages     = {692--700},
  address   = {Stroudsburg, PA, USA},
  publisher = {Association for Computational Linguistics},
  abstract  = {The potential benefit of integrating contextual information for recommendation
	has received much research attention recently, especially with the
	ever-increasing interest in mobile-based recommendation services.
	However, context based recommendation research is limited due to
	the lack of standard evaluation data with contextual information
	and reliable technology for extracting such information. As a result,
	there are no widely accepted conclusions on how, when and whether
	context helps. Additionally, a system often suffers from the so called
	cold start problem due to the lack of data for training the initial
	context based recommendation model. This paper proposes a novel solution
	to address these problems with automated information extraction techniques.
	We also compare several approaches for utilizing context based on
	a new data set collected using the proposed solution. The experimental
	results demonstrate that 1) IE-based techniques can help create a
	large scale context data with decent quality from online reviews,
	at least for restaurant recommendations; 2) context helps recommender
	systems rank items, however, does not help predict user ratings;
	3) simply using context to filter items hurts recommendation performance,
	while a new probabilistic latent relational model we proposed helps.},
  acmid     = {1944645},
  comment   = {First, context sensitive features are extracted by a hybrid classifier
	of structural patterns and a MaxEnt model. The contextural information
	is then integrated into a probabilistic latent relational model,
	which factorize ratings to item specific features, as well as a combination
	of the current context and user's long term preference},
  file      = {Li2010Contextual.pdf:Li2010Contextual.pdf:PDF},
  location  = {Beijing, China},
  numpages  = {9},
}

@INPROCEEDINGS{Li2014Modelling,
  author = {Zhixing Li and Siqiang Wen and Juanzi Li and Peng Zhang and Jie Tang},
  title = {On Modelling Non-linear Topical Dependencies},
  booktitle = {Proceedings of ICML},
  year = {2014},
  pages = {457-465},
  abstract = {Probabilistic topic models such as Latent Dirichlet Allocation (LDA)
	discover latent topics from large corpora by exploiting words' co-occurring
	relation. By observing the topical similarity between words, we find
	that some other relations, such as semantic or syntax relation between
	words, lead to strong dependence between their topics. In this paper,
	sentences are represented as dependency trees and a Global Topic
	Random Field (GTRF) is presented to model the non-linear dependencies
	between words. To infer our model, a new global factor is defined
	over all edges and the normalization factor of GRF is proven to be
	a constant. As a result, no independent assumption is needed when
	inferring our model. Based on it, we develop an efficient expectation-maximization
	(EM) procedure for parameter estimation. Experimental results on
	four data sets show that GTRF achieves much lower perplexity than
	LDA and linear dependency topic models and produces better topic
	coherence.},
  file = {Li2014Modelling.pdf:Li2014Modelling.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.06.24}
}

@INPROCEEDINGS{Lian2014GeoMF,
  author = {Lian, Defu and Zhao, Cong and Xie, Xing and Sun, Guangzhong and Chen,
	Enhong and Rui, Yong},
  title = {GeoMF: Joint Geographical Modeling and Matrix Factorization for Point-of-interest
	Recommendation},
  booktitle = {Proceedings of the 20th ACM SIGKDD International Conference on Knowledge
	Discovery and Data Mining},
  year = {2014},
  series = {KDD '14},
  pages = {831--840},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Point-of-Interest (POI) recommendation has become an important means
	to help people discover attractive locations. However, extreme sparsity
	of user-POI matrices creates a severe challenge. To cope with this
	challenge, viewing mobility records on location-based social networks
	(LBSNs) as implicit feedback for POI recommendation, we first propose
	to exploit weighted matrix factorization for this task since it usually
	serves collaborative filtering with implicit feedback better. Besides,
	researchers have recently discovered a spatial clustering phenomenon
	in human mobility behavior on the LBSNs, i.e., individual visiting
	locations tend to cluster together, and also demonstrated its effectiveness
	in POI recommendation, thus we incorporate it into the factorization
	model. Particularly, we augment users' and POIs' latent factors in
	the factorization model with activity area vectors of users and influence
	area vectors of POIs, respectively. Based on such an augmented model,
	we not only capture the spatial clustering phenomenon in terms of
	two-dimensional kernel density estimation, but we also explain why
	the introduction of such a phenomenon into matrix factorization helps
	to deal with the challenge from matrix sparsity. We then evaluate
	the proposed algorithm on a large-scale LBSN dataset. The results
	indicate that weighted matrix factorization is superior to other
	forms of factorization models and that incorporating the spatial
	clustering phenomenon into matrix factorization improves recommendation
	performance.},
  acmid = {2623638},
  doi = {10.1145/2623330.2623638},
  file = {Lian2014GeoMF.pdf:Lian2014GeoMF.pdf:PDF},
  isbn = {978-1-4503-2956-9},
  keywords = {kernel density estimation, location recommendation, location-based
	social network, weighted matrix factorization},
  location = {New York, New York, USA},
  numpages = {10},
  timestamp = {2016.03.09},
  url = {http://doi.acm.org/10.1145/2623330.2623638}
}

@InProceedings{Liberty2013Simple,
  author    = {Liberty, Edo},
  title     = {Simple and Deterministic Matrix Sketching},
  booktitle = {Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year      = {2013},
  series    = {KDD '13},
  pages     = {581--588},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {A sketch of a matrix A is another matrix B which is significantly
	smaller than A but still approximates it well. Finding such sketches
	efficiently is an important building block in modern algorithms for
	approximating, for example, the PCA of massive matrices. This task
	is made more challenging in the streaming model, where each row of
	the input matrix can only be processed once and storage is severely
	limited.
	
	
	In this paper we adapt a well known streaming algorithm for approximating
	item frequencies to the matrix sketching setting. The algorithm receives
	n rows of a large matrix A ε ℜ n x m one after the other in a streaming
	fashion. It maintains a sketch B ℜ l x m containing only l << n rows
	but still guarantees that ATA BTB. More accurately, ∀x || x,||=1
	0≤||Ax||2 - ||Bx||2 ≤ 2||A||_f 2 l Or BTB prec ATA and ||ATA - BTB||
	≤ 2 ||A||f2 l.
	
	
	This gives a streaming algorithm whose error decays proportional to
	1/l using O(ml) space. For comparison, random-projection, hashing
	or sampling based algorithms produce convergence bounds proportional
	to 1/√l. Sketch updates per row in A require amortized O(ml) operations
	and the algorithm is perfectly parallelizable. Our experiments corroborate
	the algorithm's scalability and improved convergence rate. The presented
	algorithm also stands out in that it is deterministic, simple to
	implement and elementary to prove.},
  acmid     = {2487623},
  comment   = {KDD best paper},
  doi       = {10.1145/2487575.2487623},
  file      = {Liberty2013Simple.pdf:Liberty2013Simple.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-1-4503-2174-7},
  keywords  = {sketching, streaming},
  location  = {Chicago, Illinois, USA},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/2487575.2487623},
}

@ARTICLE{ChenLin2014LibD3C,
  author = {Chen Lin and Wenqiang Chen and Cheng Qiu and Yunfeng Wu and Sridhar
	Krishnan and Quan Zou},
  title = {LibD3C: Ensemble Classifiers with a Clustering and Dynamic Selection
	Strategy},
  journal = {Neurocomputing},
  year = {2014},
  volume = {123},
  pages = {424-435},
  owner = {littlep},
  timestamp = {2013.11.05}
}

@ARTICLE{Lin2012Identify,
  author = {Lin, Chen and Huang, Zhenhua and Yang, Fan and Zou, Quan},
  title = {Identify content quality in online social networks},
  journal = {IET Communications},
  year = {2012},
  volume = {6},
  pages = {1618--1624},
  number = {12},
  publisher = {IET}
}

@InProceedings{Lin2012Generating,
  author    = {Lin, Chen and Lin, Chun and Li, Jingxuan and Wang, Dingding and Chen, Yang and Li, Tao},
  title     = {Generating event storylines from microblogs},
  booktitle = {Proceedings of the 21st ACM international conference on Information and knowledge management},
  year      = {2012},
  series    = {CIKM '12},
  pages     = {175--184},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2396787},
  doi       = {10.1145/2396761.2396787},
  groups    = {Twitter},
  isbn      = {978-1-4503-1156-4},
  keywords  = {dynamic pseudo relevance feedback, language model, microblog, social media, storyline},
  location  = {Maui, Hawaii, USA},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2396761.2396787},
}

@ARTICLE{Lin2014Personalized,
  author = {Chen Lin and Runquan Xie and Xinjun Guan and Lei Li and Tao Li},
  title = {Personalized news recommendation via implicit social experts },
  journal = {Information Sciences },
  year = {2014},
  volume = {254},
  pages = {1 - 18},
  number = {0},
  doi = {http://dx.doi.org/10.1016/j.ins.2013.08.034},
  issn = {0020-0255},
  keywords = {<!-- Tag Not Handled --><keyword id=#k0005#>Personalization},
  url = {http://www.sciencedirect.com/science/article/pii/S002002551300594X}
}

@INPROCEEDINGS{Lin2012PRemiSE,
  author = {Lin, Chen and Xie, Runquan and Li, Lei and Huang, Zhenhua and Li,
	Tao},
  title = {PRemiSE: personalized news recommendation via implicit social experts},
  booktitle = {Proceedings of the 21st ACM international conference on Information
	and knowledge management},
  year = {2012},
  series = {CIKM '12},
  pages = {1607--1611},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {2398482},
  doi = {10.1145/2396761.2398482},
  isbn = {978-1-4503-1156-4},
  keywords = {expert, matrix factorization, news recommendation, social network},
  location = {Maui, Hawaii, USA},
  numpages = {5},
  url = {http://doi.acm.org/10.1145/2396761.2398482}
}

@INPROCEEDINGS{Lin2009Simultaneously,
  author = {Lin, Chen and Yang, Jiang-Ming and Cai, Rui and Wang, Xin-Jing and
	Wang, Wei},
  title = {Simultaneously modeling semantics and structure of threaded discussions:
	a sparse coding approach and its applications},
  booktitle = {SIGIR '09: Proceedings of the 32nd international ACM SIGIR conference
	on Research and development in information retrieval},
  year = {2009},
  pages = {131--138},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1571941.1571966},
  isbn = {978-1-60558-483-6},
  location = {Boston, MA, USA}
}

@INPROCEEDINGS{Lin2009Modeling,
  author = {Lin, Chen and Yang, Jiang-Ming and Cai, Rui and Wang, Xin-Jing and
	Wang, Wei and Zhang, Lei},
  title = {Modeling semantics and structure of discussion threads},
  booktitle = {WWW '09: Proceedings of the 18th international conference on World
	wide web},
  year = {2009},
  pages = {1103--1104},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1526709.1526877},
  isbn = {978-1-60558-487-4},
  location = {Madrid, Spain}
}

@INPROCEEDINGS{raey,
  author = {Lin, Chen and Yu, Haiyang and Weng, Wei and He, Xianmang},
  title = {Large-Scale Similarity Join with Edit-Distance Constraints},
  booktitle = {Proceedings of 19th International Conference on Database Systems
	for Advanced Applications},
  year = {2014},
  editor = {Bhowmick, SouravS. and Dyreson, CurtisE. and Jensen, ChristianS.
	and Lee, MongLi and Muliantara, Agus and Thalheim, Bernhard},
  volume = {8422},
  series = {Lecture Notes in Computer Science},
  pages = {328-342},
  publisher = {Springer International Publishing},
  doi = {10.1007/978-3-319-05813-9_22},
  isbn = {978-3-319-05812-2},
  keywords = {Similarity join; big data; Map Reduce; data cleaning},
  url = {http://dx.doi.org/10.1007/978-3-319-05813-9_22}
}

@CONFERENCE{lin2008rec,
  author = {Lin, C. and Zhou, H. and Huang, Z. and Wang, W.},
  title = {REC: a novel model to rank experts in communities},
  booktitle = {Web-Age Information Management, 2008. WAIM'08. The Ninth International
	Conference on},
  year = {2008},
  pages = {301--308},
  organization = {IEEE}
}

@ARTICLE{Lin2013Hierarchical,
  author = {Lin, Chen and Zou, Ying and Qin, Ji and Liu, Xiangrong and Jiang,
	Yi and Ke, Caihuan and Zou, Quan},
  title = {Hierarchical Classification of Protein Folds Using a Novel Ensemble
	Classifier},
  journal = {PloS one},
  year = {2013},
  volume = {8},
  number = {2},
  publisher = {Public Library of Science}
}

@Article{Lin2008Storyline-based,
  author   = {Fu-ren Lin and Chia-Hao Liang},
  title    = {Storyline-based summarization for news topic retrospection},
  journal  = {Decision Support Systems},
  year     = {2008},
  volume   = {45},
  number   = {3},
  pages    = {473 - 490},
  issn     = {0167-9236},
  note     = {<ce:title>Special Issue Clusters</ce:title>},
  abstract = {Electronics newspapers gradually become main sources for news readers.
	When facing the numerous reports on a series of events in a topic,
	a summary of stories from news reports will benefit news readers
	in reviewing the news topic efficiently. Besides identifying events
	and presenting news titles and keywords the TDT (Topic Detection
	and Tracking) techniques are used to do, a summarized text to present
	event evolution is necessary for general news readers to review events
	under a news topic. This paper proposes a topic retrospection process
	and implements the SToRe (Story-line based Topic Retrospection) system
	that identifies various events under a news topic, and composes a
	summary that news readers can get the sketch of event evolution in
	the topic. It consists of three main functions: event identification,
	main storyline construction and storyline-based summarization. The
	constructed main storyline can remove the irrelevant events and present
	a main theme. The storyline-based summarization extracts the representative
	sentences and takes the main theme as the template to compose the
	summary. The storyline summary not only provides readers enough information
	to understand the development of a news topic, but also serves as
	an index for readers to search corresponding news reports. Following
	a design science paradigm, a lab experiment is conducted to evaluate
	the SToRe system in the question-and-answer (Q&A) setting. The experimental
	results show that SToRe enables news readers to effectively and efficiently
	capture the evolution of a news topic.},
  doi      = {10.1016/j.dss.2007.06.009},
  file     = {Lin2008Storyline-based.pdf:Lin2008Storyline-based.pdf:PDF},
  groups   = {Twitter},
  keywords = {Topic retrospection},
  url      = {http://www.sciencedirect.com/science/article/pii/S0167923607000930},
}

@InProceedings{Lin2013Pollux,
  author    = {Lin, Liwei and Yu, Xiaohui and Koudas, Nick},
  title     = {Pollux: Towards Scalable Distributed Real-time Search on Microblogs},
  booktitle = {Proceedings of the 16th International Conference on Extending Database Technology},
  year      = {2013},
  series    = {EDBT '13},
  pages     = {335--346},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {The last few years have witnessed a meteoric rise of microblogging
	platforms, such as Twitter and Tumblr. The sheer volume of the microblog
	data and its highly dynamic nature present unique technical challenges
	for the platforms that provide search services. In particular, the
	search service must provide real-time response to queries, and continuously
	update the results as new microblogs are posted. Conventional approaches
	either cannot keep up with the high update rate, or cannot scale
	well to handle the large volume of data.
	
	
	We propose Pollux, a system that provides distributed real-time indexing
	and search service on microblogs. It adopts the distributed stream
	processing paradigm advocated by the recently developed platforms
	that are designed for real-time processing of large volume of data,
	such as Apache S4 and Twitter Storm. Although those open-source platforms
	have found successful applications in production environments, they
	lack some critical features required for real-time search. In particular:
	(1) they only implement partial fault tolerance, and do not provide
	lossless recovery in the event of a node failure, and (2) they do
	not have a facility for storing global data, which is necessary in
	efficiently ranking search results.
	
	
	Addressing those problems, Pollux extends current platforms in two
	important ways. First, we propose a failover strategy that can ensure
	high system availability and no data/state loss in the event of a
	node failure. Second, Pollux adds a global storage facility that
	supports convenient, efficient, and reliable data storage for shared
	data. We describe how to apply Pollux to the task of real-time search.
	We implement Pollux based on Apache S4, and show through extensive
	experiments on a Twitter dataset that the proposed solutions are
	effective, and Pollux can achieve excellent scalability.},
  acmid     = {2452416},
  doi       = {10.1145/2452376.2452416},
  groups    = {Recommender Systems, Twitter},
  isbn      = {978-1-4503-1597-5},
  keywords  = {data stream, distributed processing, fault tolerance, microblog, search},
  location  = {Genoa, Italy},
  numpages  = {12},
  url       = {http://doi.acm.org/10.1145/2452376.2452416},
}

@InProceedings{Lin2013Voices,
  author    = {Lin, Yu-Ru and Margolin, Drew and Keegan, Brian and Lazer, David},
  title     = {Voices of victory: a computational focus group framework for tracking opinion shift in real time},
  booktitle = {Proceedings of the 22nd international conference on World Wide Web},
  year      = {2013},
  series    = {WWW '13},
  pages     = {737--748},
  address   = {Republic and Canton of Geneva, Switzerland},
  publisher = {International World Wide Web Conferences Steering Committee},
  acmid     = {2488453},
  groups    = {Twitter},
  isbn      = {978-1-4503-2035-1},
  keywords  = {computational social science, data-driven journalism, process inference, public opinion, real time system, social meter},
  location  = {Rio de Janeiro, Brazil},
  numpages  = {12},
  url       = {http://dl.acm.org/citation.cfm?id=2488388.2488453},
}

@INPROCEEDINGS{Linderman2014Discovering,
  author = {Scott Linderman and Ryan Adams},
  title = {Discovering Latent Network Structure in Point Process Data},
  booktitle = {Proceedings of ICML},
  year = {2014},
  abstract = {Networks play a central role in modern data analysis, enabling us
	to reason about systems by studying the relationships between their
	parts. Most often in network analysis, the edges are given. However,
	in many systems it is difficult or impossible to measure the network
	directly. Examples of latent networks include economic interactions
	linking financial instruments and patterns of reciprocity in gang
	violence. In these cases, we are limited to noisy observations of
	events associated with each node. To enable analysis of these implicit
	networks, we develop a probabilistic model that combines mutually-exciting
	point processes with random graph models. We show how the Poisson
	superposition principle enables an elegant auxiliary variable formulation
	and a fully-Bayesian, parallel inference algorithm. We evaluate this
	new model empirically on several datasets.},
  file = {Linderman2014Discovering.pdf:Linderman2014Discovering.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.06.22}
}

@INPROCEEDINGS{Lindsey2012Phrase,
  author = {Lindsey, Robert V. and Headden,III, William P. and Stipicevic, Michael
	J.},
  title = {A Phrase-discovering Topic Model Using Hierarchical Pitman-Yor Processes},
  booktitle = {Proceedings of the 2012 Joint Conference on Empirical Methods in
	Natural Language Processing and Computational Natural Language Learning},
  year = {2012},
  series = {EMNLP-CoNLL '12},
  pages = {214--222},
  address = {Stroudsburg, PA, USA},
  publisher = {Association for Computational Linguistics},
  abstract = {Topic models traditionally rely on the bag-of-words assumption. In
	data mining applications, this often results in end-users being presented
	with inscrutable lists of topical unigrams, single words inferred
	as representative of their topics. In this article, we present a
	hierarchical generative probabilistic model of topical phrases. The
	model simultaneously infers the location, length, and topic of phrases
	within a corpus and relaxes the bag-of-words assumption within phrases
	by using a hierarchy of Pitman-Yor processes. We use Markov chain
	Monte Carlo techniques for approximate inference in the model and
	perform slice sampling to learn its hyperparameters. We show via
	an experiment on human subjects that our model finds substantially
	better, more interpretable topical phrases than do competing models.},
  acmid = {2390975},
  file = {Lindsey2012Phrase.pdf:Lindsey2012Phrase.pdf:PDF},
  location = {Jeju Island, Korea},
  numpages = {9},
  timestamp = {2015.08.26},
  url = {http://dl.acm.org/citation.cfm?id=2390948.2390975}
}

@Article{Ling2012Response,
  author   = {Ling, Guang and Yang, Haiqin and Lyu, Michael R and King, Irwin},
  title    = {Response aware model-based collaborative filtering},
  journal  = {arXiv preprint arXiv:1210.4869},
  year     = {2012},
  abstract = {Previous work on recommender systems
	
	mainly focus on fitting the ratings provided
	
	by users. However, the response patterns,
	
	i.e., some items are rated while others not,
	
	are generally ignored. We argue that failing
	
	to observe such response patterns can lead to
	
	biased parameter estimation and sub-optimal
	
	model performance. Although several pieces
	
	of work have tried to model users’ response
	
	patterns, they miss the effectiveness and interpretability
	
	of the successful matrix factorization
	
	collaborative filtering approaches. To
	
	bridge the gap, in this paper, we unify explicit
	
	response models and PMF to establish
	
	the Response Aware Probabilistic Matrix
	
	Factorization (RAPMF) framework. We
	
	show that RAPMF subsumes PMF as a special
	
	case. Empirically we demonstrate the
	
	merits of RAPMF from various aspects.},
  comment  = {RAPMF
	
	
	rating xij cardinal, response rij binary
	
	
	if xij=k
	
	rating is a binomial
	
	consider soft assignment 
	
	uk^r_ij=1 x N(k|UV)^\beta
	
	
	synthetic+yahoo
	
	RMSE
	
	
	beta=0.02 best
	
	
	inference is wrong? cardinal rating how possible normal distribution?},
  file     = {Ling2012Response.pdf:Ling2012Response.pdf:PDF},
}

@BOOK{Liu2007Web,
  title = {Web data mining},
  publisher = {Springer},
  year = {2007},
  author = {Liu, Bing}
}

@INPROCEEDINGS{Liu2005Opinion,
  author = {Liu, Bing and Hu, Minqing and Cheng, Junsheng},
  title = {Opinion Observer: Analyzing and Comparing Opinions on the Web},
  booktitle = {Proceedings of the 14th International Conference on World Wide Web},
  year = {2005},
  series = {WWW '05},
  pages = {342--351},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {The Web has become an excellent source for gathering consumer
	
	opinions. There are now numerous Web sites containing such
	
	opinions, e.g., customer reviews of products, forums, discussion
	
	groups, and blogs. This paper focuses on online customer reviews of
	
	products. It makes two contributions. First, it proposes a novel
	
	framework for analyzing and comparing consumer opinions of
	
	competing products. A prototype system called Opinion Observer is
	
	also implemented. The system is such that with a single glance of
	its
	
	visualization, the user is able to clearly see the strengths and
	
	weaknesses of each product in the minds of consumers in terms of
	
	various product features. This comparison is useful to both potential
	
	customers and product manufacturers. For a potential customer,
	
	he/she can see a visual side-by-side and feature-by-feature
	
	comparison of consumer opinions on these products, which helps
	
	him/her to decide which product to buy. For a product manufacturer,
	
	the comparison enables it to easily gather marketing intelligence
	and
	
	product benchmarking information. Second, a new technique based
	
	on language pattern mining is proposed to extract product features
	
	from Pros and Cons in a particular type of reviews. Such features
	
	form the basis for the above comparison. Experimental results show
	
	that the technique is highly effective and outperform existing
	
	methods significantly.},
  acmid = {1060797},
  doi = {10.1145/1060745.1060797},
  file = {Liu2005Opinion.pdf:Liu2005Opinion.pdf:PDF},
  isbn = {1-59593-046-9},
  keywords = {information extraction, opinion analysis, sentiment analysis, visualization},
  location = {Chiba, Japan},
  numpages = {10},
  url = {http://doi.acm.org/10.1145/1060745.1060797}
}

@InProceedings{Liu2010Distributed,
  author    = {Liu, Chao and Yang, Hung-chih and Fan, Jinliang and He, Li-Wei and Wang, Yi-Min},
  title     = {Distributed nonnegative matrix factorization for web-scale dyadic data analysis on mapreduce},
  booktitle = {Proceedings of the 19th international conference on World wide web},
  year      = {2010},
  series    = {WWW '10},
  pages     = {681--690},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1772760},
  doi       = {10.1145/1772690.1772760},
  groups    = {matrix factorization},
  isbn      = {978-1-60558-799-8},
  keywords  = {distributed computing, dyadic data, mapreduce, nonnegative matrix factorization},
  location  = {Raleigh, North Carolina, USA},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1772690.1772760},
}

@Article{Liu2013Combining,
  author   = {Hongyan Liu and Jun He and Tingting Wang and Wenting Song and Xiaoyang Du},
  title    = {Combining user preferences and user opinions for accurate recommendation},
  journal  = {Electronic Commerce Research and Applications},
  year     = {2013},
  volume   = {12},
  number   = {1},
  pages    = {14 - 23},
  issn     = {1567-4223},
  abstract = {Recommendation systems represent a popular research area with a variety
	of applications. Such systems provide personalized services to the
	user and help address the problem of information overload. Traditional
	recommendation methods such as collaborative filtering suffer from
	low accuracy because of data sparseness though. We propose a novel
	recommendation algorithm based on analysis of an online review. The
	algorithm incorporates two new methods for opinion mining and recommendation.
	As opposed to traditional methods, which are usually based on the
	similarity of ratings to infer user preferences, the proposed recommendation
	method analyzes the difference between the ratings and opinions of
	the user to identify the user’s preferences. This method considers
	explicit ratings and implicit opinions, an action that can address
	the problem of data sparseness. We propose a new feature and opinion
	extraction method based on the characteristics of online reviews
	to extract effectively the opinion of the user from a customer review
	written in Chinese. Based on these methods, we also conduct an empirical
	study of online restaurant customer reviews to create a restaurant
	recommendation system and demonstrate the effectiveness of the proposed
	methods.},
  comment  = {focus on devoloping new features and opinion extraction methods, and
	use a simple recommendation model that aggregates (average) opinions
	over each feature.},
  file     = {Liu2013Combining.pdf:Liu2013Combining.pdf:PDF},
  keywords = {Feature extraction},
}

@InProceedings{Liu2010Personalized,
  author    = {Liu, Jiahui and Dolan, Peter and Pedersen, Elin R{\o}nby},
  title     = {Personalized news recommendation based on click behavior},
  booktitle = {Proceedings of the 15th international conference on Intelligent user interfaces},
  year      = {2010},
  series    = {IUI '10},
  pages     = {31--40},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1719976},
  doi       = {10.1145/1719970.1719976},
  groups    = {Recommender Systems},
  isbn      = {978-1-60558-515-4},
  keywords  = {news trend, personalization, user modeling},
  location  = {Hong Kong, China},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1719970.1719976},
}

@ARTICLE{Liu2010Effects,
  author = {Liu, Jian-Guo and Zhou, Tao and Che, Hong-An and Wang, Bing-Hong
	and Zhang, Yi-Cheng},
  title = {Effects of high-order correlations on personalized recommendations
	for bipartite networks},
  journal = {Physica A: Statistical Mechanics and its Applications},
  year = {2010},
  volume = {389},
  pages = {881--886},
  number = {4},
  publisher = {Elsevier}
}

@InProceedings{Liu2010Online,
  author    = {Liu, Nathan N. and Zhao, Min and Xiang, Evan and Yang, Qiang},
  title     = {Online evolutionary collaborative filtering},
  booktitle = {RecSys '10: Proceedings of the fourth ACM conference on Recommender systems},
  year      = {2010},
  pages     = {95--102},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Collaborative ﬁltering algorithms attempt to predict a user’s interests
	based on his past feedback. In real world applications, a user’s
	
	feedback is often continuously collected over a long period of time.
	
	It is very common for a user’s interests or an item’s popularity to
	
	change over a long period of time. Therefore, the underlying recommendation
	algorithm should be able to adapt to such changes
	
	accordingly. However, most existing algorithms do not distinguish
	
	current and historical data when predicting the users’ current interests.
	In this paper, we consider a new problem - online evolutionary collaborative
	ﬁltering, which tracks user interests over
	
	time in order to make timely recommendations. We extended the
	
	widely used neighborhood based algorithms by incorporating temporal
	information and developed an incremental algorithm for updating neighborhood
	similarities with new data. Experiments on
	
	two real world datasets demonstrated both improved effectiveness
	
	and efﬁciency of the proposed approach.},
  comment   = {Data: Netflix prize dataset
	
	idea: user's interests or item's popularity change over time
	
	main contribution:
	
	1) multiply item rating with a expotienary function that indicates
	the decaying factor over time e^{-\alpha(t-t_{ui})}
	
	2)incremental algorithm
	
	3)distinguish the rating prediction tasks and choice prediction tasks.
	Users are more likely to rate favorite items},
  doi       = {http://doi.acm.org/10.1145/1864708.1864729},
  file      = {Liu2010Online.pdf:Liu2010Online.pdf:PDF},
  groups    = {Recommender Systems},
  isbn      = {978-1-60558-906-0},
  location  = {Barcelona, Spain},
}

@Conference{liu2008predicting,
  author       = {Liu, Y. and Bian, J. and Agichtein, E.},
  title        = {Predicting information seeker satisfaction in community question answering},
  booktitle    = {Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval},
  year         = {2008},
  pages        = {483--490},
  organization = {ACM},
  abstract     = {Question answering communities such as Naver and Yahoo! Answers have
	emerged as popular, and often effective, means of information seeking
	on the web. By posting questions for other participants to answer,
	information seekers can obtain speciﬁc answers
	
	to their questions. Users of popular portals such as Yahoo! Answers
	already have submitted millions of questions and received
	
	hundreds of millions of answers from other participants. However,
	
	it may also take hours –and sometime days– until a satisfactory answer
	is posted. In this paper we introduce the problem of predicting
	
	information seeker satisfaction in collaborative question answering
	
	communities, where we attempt to predict whether a question author
	will be satisﬁed with the answers submitted by the community participants.
	We present a general prediction model, and develop a variety of content,
	structure, and community-focused features for this task. Our experimental
	results, obtained from a largescale evaluation over thousands of
	real questions and user ratings,
	
	demonstrate the feasibility of modeling and predicting asker satisfaction.
	We complement our results with a thorough investigation
	
	of the interactions and information seeking patterns in question answering
	communities that correlate with information seeker satisfaction.
	Our models and predictions could be useful for a variety of
	
	applications such as user intent inference, answer ranking, interface
	
	design, and query suggestion and routing},
  comment      = {We explored three families of classiﬁcation algorithms: Support Vector
	Machines (SVM), Decision trees, Boosting and Naive
	
	Bayes, all using the implementations in the Weka [28] framework.
	
	online predict:before any
	
	answers to the question are contributed
	
	
	offline predict:after some answers have been contributed, allowing
	us to exploit features such as
	
	the number of answers, answer content length, and feedback from
	
	other users (votes},
  file         = {liu2008predicting.pdf:liu2008predicting.pdf:PDF},
}

@INPROCEEDINGS{Liu2006Semi,
  author = {Yi Liu and Rong Jin and Liu Yang},
  title = {Semi-supervised Multi-label Learning by Constrained Non-negative
	Matrix Factorization},
  booktitle = {AAAI},
  year = {2006},
  file = {Liu2006Semi.pdf:Liu2006Semi.pdf:PDF},
  owner = {littlep},
  timestamp = {2015.01.20}
}

@INPROCEEDINGS{Liu2009Topic-link,
  author = {Liu, Yan and Niculescu-Mizil, Alexandru and Gryc, Wojciech},
  title = {Topic-link LDA: joint models of topic and author community},
  booktitle = {ICML '09: Proceedings of the 26th Annual International Conference
	on Machine Learning},
  year = {2009},
  pages = {665--672},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Given a large-scale linked document collection, such as a collection
	of blog posts or a research literature archive, there are two fundamental
	problems that have generated a lot of interest in the research community.
	One is to identify a set of high-level topics covered by the documents
	in the collection; the other is to uncover and analyze the social
	network of the authors of the documents. So far these problems have
	been viewed as separate problems and considered independently from
	each other. In this paper we argue that these two problems are in
	fact inter-dependent and should be addressed together. We develop
	a Bayesian hierarchical approach that performs topic modeling and
	author community discovery in one unified framework. The effectiveness
	of our model is demonstrated on two blog data sets in different domains
	and one research paper citation data from CiteSeer.},
  doi = {http://doi.acm.org/10.1145/1553374.1553460},
  isbn = {978-1-60558-516-1},
  location = {Montreal, Quebec, Canada}
}

@ARTICLE{Liu2010Combining,
  author = {Liu, Y. and Yu, X. and Huang, J.X. and An, A.},
  title = {Combining integrated sampling with SVM ensembles for learning from
	imbalanced datasets},
  journal = {Information Processing \& Management},
  year = {2010},
  issn = {0306-4573},
  publisher = {Elsevier}
}

@InProceedings{Long2012Enhancing,
  author    = {Long, Bo and Bian, Jiang and Dong, Anlei and Chang, Yi},
  title     = {Enhancing Product Search by Best-selling Prediction in e-Commerce},
  booktitle = {Proceedings of the 21st ACM International Conference on Information and Knowledge Management},
  year      = {2012},
  series    = {CIKM '12},
  pages     = {2479--2482},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {With the rapid growth of E-Commerce on the Internet, online product
	search service has emerged as a popular and effective paradigm for
	customers to find desired products and select transactions. Most
	product search engines today are based on adaptations of relevance
	models devised for information retrieval. However, there is still
	a big gap between the mechanism of finding products that customers
	really desire to purchase and that of retrieving products of high
	relevance to customers' query. In this paper, we address this problem
	by proposing a new ranking framework for enhancing product search
	based on dynamic best-selling prediction in E-Commerce. Specifically,
	we first develop an effective algorithm to predict the dynamic best-selling,
	i.e. the volume of sales, for each product item based on its transaction
	history. By incorporating such best-selling prediction with relevance,
	we propose a new ranking model for product search, in which we rank
	higher the product items that are not only relevant to the customer's
	need but with higher probability to be purchased by the customer.
	Results of a large scale evaluation, conducted over the dataset from
	a commercial product search engine, demonstrate that our new ranking
	method is more effective for locating those product items that customers
	really desire to buy at higher rank positions without hurting the
	search relevance.},
  acmid     = {2398671},
  comment   = {Step-1: Computing the relevance between product items and customers’
	
	queries by using traditional relevance model.
	
	Step-2: Best-selling prediction for individual product items based
	
	on the transaction history.
	
	Step-3: Combining the relevance scores with predicted best-selling
	
	scores to generate the ranking.},
  isbn      = {978-1-4503-1156-4},
  keywords  = {best selling prediction, e-commerce, product search, transaction history},
  location  = {Maui, Hawaii, USA},
  numpages  = {4},
}

@InCollection{Lopes2010Non-negative,
  author      = {Lopes, Noel and Ribeiro, Bernardete},
  title       = {Non-negative Matrix Factorization Implementation Using Graphic Processing Units},
  booktitle   = {Intelligent Data Engineering and Automated Learning – IDEAL 2010},
  publisher   = {Springer Berlin / Heidelberg},
  year        = {2010},
  editor      = {Fyfe, Colin and Tino, Peter and Charles, Darryl and Garcia-Osorio, Cesar and Yin, Hujun},
  volume      = {6283},
  series      = {Lecture Notes in Computer Science},
  pages       = {275-283},
  abstract    = {Non-Negative Matrix Factorization (NMF) algorithms decompose a matrix,
	containing only non-negative coefficients, into the product of two
	matrices, usually with reduced ranks. The resulting matrices are
	constrained to have only non-negative coefficients. NMF can be used
	to reduce the number of characteristics in a dataset, while preserving
	the relevant information that allows for the reconstruction of the
	original data. Since negative coefficients are not allowed, the original
	data is reconstructed through additive combinations of the parts-based
	factorized matrix representation. A Graphics Processing Unit (GPU)
	implementation of the NMF algorithms, using both the multiplicative
	and the additive (gradient descent) update rules is presented for
	the Euclidean distance as well as for the divergence cost function.
	The performance results on an image database demonstrate extremely
	high speedups, making the GPU implementations excel by far the CPU
	implementations.},
  affiliation = {CISUC - Center for Informatics and Systems of University of Coimbra, Portugal},
  groups      = {matrix factorization},
  isbn        = {978-3-642-15380-8},
  keyword     = {Computer Science},
  url         = {http://dx.doi.org/10.1007/978-3-642-15381-5_34},
}

@ARTICLE{Losada2007analysis,
  author = {David E. Losada and Leif Azzopardi},
  title = {An analysis on document length retrieval trends in language modeling
	smoothing},
  journal = {Information Retrieval},
  year = {2007},
  volume = {11},
  pages = {109-138},
  number = {2},
  abstract = {Document length is widely recognized as an important factor for adjusting
	retrieval systems. Many models tend to favor the retrieval of either
	short or long documents and, thus, a length-based correction needs
	to be applied for avoiding any length bias. In Language Modeling
	for Information Retrieval, smoothing methods are applied to move
	probability mass from document terms to unseen words, which is often
	dependant upon document length. In this article, we perform an in-depth
	study of this behavior, characterized by the document length retrieval
	trends, of three popular smoothing methods across a number of factors,
	and its impact on the length of documents retrieved and retrieval
	performance. First, we theoretically analyze the Jelinek–Mercer,
	Dirichlet prior and two-stage smoothing strategies and, then, conduct
	an empirical analysis. In our analysis we show how Dirichlet prior
	smoothing caters for document length more appropriately than Jelinek–Mercer
	smoothing which leads to its superior retrieval performance. In a
	follow up analysis, we posit that length-based priors can be used
	to offset any bias in the length retrieval trends stemming from the
	retrieval formula derived by the smoothing technique. We show that
	the performance of Jelinek–Mercer smoothing can be significantly
	improved by using such a prior, which provides a natural and simple
	alternative to decouple the query and document modeling roles of
	smoothing. With the analysis of retrieval behavior conducted in this
	article, it is possible to understand why the Dirichlet Prior smoothing
	performs better than the Jelinek–Mercer, and why the performance
	of the Jelinek–Mercer method is improved by including a length-based
	prior.},
  file = {Losada2007analysis.pdf:Losada2007analysis.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.10.04}
}

@INPROCEEDINGS{Lu2011Learning,
  author = {Lu, Tyler and Boutilier, Craig},
  title = {Learning Mallows models with pairwise preferences},
  booktitle = {Proceedings of the 28th International Conference on Machine Learning
	(ICML-11)},
  year = {2011},
  pages = {145--152},
  file = {Lu2011Learning.pdf:Lu2011Learning.pdf:PDF}
}

@Conference{lu2010exploiting,
  author       = {Lu, Y. and Tsaparas, P. and Ntoulas, A. and Polanyi, L.},
  title        = {Exploiting social context for review quality prediction},
  booktitle    = {Proceedings of the 19th international conference on World wide web},
  year         = {2010},
  pages        = {691--700},
  organization = {ACM},
  abstract     = {Online reviews in which users publish detailed commentary about
	
	their experiences and opinions with products, services, or events
	
	are extremely valuable to users who rely on them to make informed
	
	decisions. However, reviews vary greatly in quality and are constantly
	increasing in number, therefore, automatic assessment of
	
	review helpfulness is of growing importance. Previous work has
	
	addressed the problem by treating a review as a stand-alone document,
	extracting features from the review text, and learning a function
	based on these features for predicting the review quality. In
	
	this work, we exploit contextual information about authors’ identities
	and social networks for improving review quality prediction.
	
	We propose a generic framework for incorporating social context
	
	information by adding regularization constraints to the text-based
	
	predictor. Our approach can effectively use the social context information
	available for large quantities of unlabeled reviews. It also
	
	has the advantage that the resulting predictor is usable even when
	
	social context is unavailable. We validate our framework within
	
	a real commerce portal and experimentally demonstrate that using
	
	social context information can help improve the accuracy of review
	quality prediction especially when the available training data
	
	is sparse.},
  comment      = {Data: Ciao},
  file         = {lu2010exploiting.pdf:lu2010exploiting.pdf:PDF},
  keywords     = {review quality, regulization},
}

@Article{Luo2008collaborative,
  author    = {Luo, H. and Niu, C. and Shen, R. and Ullrich, C.},
  title     = {A collaborative filtering framework based on both local user similarity and global user similarity},
  journal   = {Machine Learning},
  year      = {2008},
  volume    = {72},
  number    = {3},
  pages     = {231--245},
  abstract  = {Collaborative filtering as a classical method of information retrieval
	has been
	
	widely used in helping people to deal with information overload. In
	this paper, we introduce
	
	the concept of local user similarity and global user similarity, based
	on surprisal-based
	
	vector similarity and the application of the concept of maximin distance
	in graph theory.
	
	Surprisal-based vector similarity expresses the relationship between
	any two users based on
	
	the quantities of information (called surprisal) contained in their
	ratings. Global user similarity
	
	defines two users being similar if they can be connected through their
	locally similar
	
	neighbors. Based on both of Local User Similarity and Global User
	Similarity, we develop a
	
	collaborative filtering framework called LS&GS. An empirical study
	using the MovieLens
	
	dataset shows that our proposed framework outperforms other state-of-the-art
	collaborative
	
	filtering algorithms.},
  file      = {Luo2008collaborative.pdf:Luo2008collaborative.pdf:PDF},
  groups    = {Recommender Systems},
  publisher = {Springer},
}

@Article{Luo2012Incremental,
  author     = {Luo, Xin and Xia, Yunni and Zhu, Qingsheng},
  title      = {Incremental Collaborative Filtering recommender based on Regularized Matrix Factorization},
  journal    = {Know.-Based Syst.},
  year       = {2012},
  volume     = {27},
  pages      = {271--280},
  month      = mar,
  acmid      = {2109588},
  address    = {Amsterdam, The Netherlands, The Netherlands},
  doi        = {10.1016/j.knosys.2011.09.006},
  file       = {Luo2012Incremental.pdf:Luo2012Incremental.pdf:PDF},
  groups     = {Recommender Systems, matrix factorization},
  issn       = {0950-7051},
  issue_date = {March, 2012},
  keywords   = {Collaborative Filtering, Incremental learning, Latent Factor Model, Matrix Factorization, Recommender system, Regularized},
  numpages   = {10},
  publisher  = {Elsevier Science Publishers B. V.},
  url        = {http://dx.doi.org/10.1016/j.knosys.2011.09.006},
}

@ARTICLE{von2007tutorial,
  author = {von Luxburg, U.},
  title = {A tutorial on spectral clustering},
  journal = {Statistics and Computing},
  year = {2007},
  volume = {17},
  pages = {395--416},
  number = {4},
  publisher = {Springer}
}

@InProceedings{Lv2011Learning,
  author    = {Lv, Yuanhua and Moon, Taesup and Kolari, Pranam and Zheng, Zhaohui and Wang, Xuanhui and Chang, Yi},
  title     = {Learning to Model Relatedness for News Recommendation},
  booktitle = {Proceedings of the 20th International Conference on World Wide Web},
  year      = {2011},
  series    = {WWW '11},
  pages     = {57--66},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {With the explosive growth of online news readership, recommending
	interesting news articles to users has become extremely important.
	While existing Web services such as Yahoo! and Digg attract users'
	initial clicks by leveraging various kinds of signals, how to engage
	such users algorithmically after their initial visit is largely under-explored.
	In this paper, we study the problem of post-click news recommendation.
	Given that a user has perused a current news article, our idea is
	to automatically identify "related" news articles which the user
	would like to read afterwards. Specifically, we propose to characterize
	relatedness between news articles across four aspects: relevance,
	novelty, connection clarity, and transition smoothness. Motivated
	by this understanding, we define a set of features to capture each
	of these aspects and put forward a learning approach to model relatedness.
	In order to quantitatively evaluate our proposed measures and learn
	a unified relatedness function, we construct a large test collection
	based on a four-month commercial news corpus with editorial judgments.
	The experimental results show that the proposed heuristics can indeed
	capture relatedness, and that the learned unified relatedness function
	works quite effectively.},
  acmid     = {1963417},
  doi       = {10.1145/1963405.1963417},
  file      = {Lv2011Learning.pdf:Lv2011Learning.pdf:PDF},
  groups    = {Recommender Systems, Twitter},
  isbn      = {978-1-4503-0632-4},
  keywords  = {connection clarity, learning, novelty, post-click news recommendation, relatedness, relevance, transition smoothness},
  location  = {Hyderabad, India},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1963405.1963417},
}

@InProceedings{Lv2009Positional,
  author    = {Lv, Yuanhua and Zhai, ChengXiang},
  title     = {Positional language models for information retrieval},
  booktitle = {Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval},
  year      = {2009},
  series    = {SIGIR '09},
  pages     = {299--306},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Although many variants of language models have been proposed for information
	retrieval, there are two related retrieval heuristics remaining "external"
	to the language modeling approach: (1) proximity heuristic which
	rewards a document where the matched query terms occur close to each
	other; (2) passage retrieval which scores a document mainly based
	on the best matching passage. Existing studies have only attempted
	to use a standard language model as a "black box" to implement these
	heuristics, making it hard to optimize the combination parameters.
	
	
	In this paper, we propose a novel positional language model (PLM)
	which implements both heuristics in a unified language model. The
	key idea is to define a language model for each position of a document,
	and score a document based on the scores of its PLMs. The PLM is
	estimated based on propagated counts of words within a document through
	a proximity-based density function, which both captures proximity
	heuristics and achieves an effect of "soft" passage retrieval. We
	propose and study several representative density functions and several
	different PLM-based document ranking strategies. Experiment results
	on standard TREC test collections show that the PLM is effective
	for passage retrieval and performs better than a state-of-the-art
	proximity-based retrieval model.},
  acmid     = {1571994},
  comment   = {a language model
	
	for each position of a document (thus the name positional
	
	language model), and score a document based on the scores
	
	of its PLMs.
	
	
	allow us to model the \best-matching position" in a
	
	document with probabilistic models, thus supporting \soft"
	
	passage retrieval naturally.
	
	
	For each position, the word probability is actual count at this position,
	multiplying a Proximity-based count propagation function from all
	other places in the document, which can be different kernals
	
	
	the score of its best matching position,},
  file      = {Lv2009Positionala.pdf:Lv2009Positionala.pdf:PDF},
  isbn      = {978-1-60558-483-6},
  keywords  = {passage retrieval, positional language models, proximity},
  location  = {Boston, MA, USA},
  numpages  = {8},
}

@Conference{ma2009learning,
  author       = {Ma, H. and King, I. and Lyu, M.R.},
  title        = {Learning to recommend with social trust ensemble},
  booktitle    = {Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval},
  year         = {2009},
  pages        = {203--210},
  organization = {ACM},
  abstract     = {As an indispensable technique in the field of Information
	
	Filtering, Recommender System has been well studied and
	
	developed both in academia and in industry recently. How-
	
	ever, most of current recommender systems suffer the fol-
	
	lowing problems: (1) The large-scale and sparse data of the
	
	user-item matrix seriously affect the recommendation qual-
	
	ity. As a result, most of the recommender systems can-
	
	not easily deal with users who have made very few ratings.
	
	(2) The traditional recommender systems assume that all
	
	the users are independent and identically distributed; this
	
	assumption ignores the connections among users, which is
	
	not consistent with the real world recommendations. Aim-
	
	ing at modeling recommender systems more accurately and
	
	realistically, we propose a novel probabilistic factor analysis
	
	framework, which naturally fuses the users’ tastes and their
	
	trusted friends’ favors together. In this framework, we coin
	
	the term Social Trust Ensemble to represent the formulation
	
	of the social trust restrictions on the recommender systems.
	
	The complexity analysis indicates that our approach can be
	
	applied to very large datasets since it scales linearly with
	
	the number of observations, while the experimental results
	
	show that our method performs better than the state-of-the-
	
	art approaches.},
  comment      = {Motivation: data sparsity (users with few ratings)
	
	 ignore social connections
	
	
	Model:
	
	STE Graphical model
	
	
	 1)rating is generated from user and item latent variables (both represented
	in vector of featuers, gaussian distribution), the generation probability
	is expotienal
	
	 2)rating is generated from trusted user's ratings(linear combinations
	of trust score)
	
	 3)the fusion of the above two (by linear combination)
	
	
	Data: Epinion(Crawl)
	
	Merits: mean abosolute error (abosolute difference between true rating
	and predicted rating)
	
	 root mean squre error},
  file         = {:ma2009learning.pdf:PDF},
  groups       = {Recommender Systems},
}

@InProceedings{Ma2007Effective,
  author    = {Ma, Hao and King, Irwin and Lyu, Michael R.},
  title     = {Effective missing data prediction for collaborative filtering},
  booktitle = {Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval},
  year      = {2007},
  series    = {SIGIR '07},
  pages     = {39--46},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Memory-based collaborative filtering algorithms have been widely adopted
	in many popular recommender systems, although these approaches all
	suffer from data sparsity and poor prediction quality problems. Usually,
	the user-item matrix is quite sparse, which directly leads to inaccurate
	recommendations. This paper focuses the memory-based collaborative
	filtering problems on two crucial factors: (1) similarity computation
	between users or items and (2) missing data prediction algorithms.
	First, we use the enhanced Pearson Correlation Coefficient (PCC)
	algorithm by adding one parameter which overcomes the potential decrease
	of accuracy when computing the similarity of users or items. Second,
	we propose an effective missing data prediction algorithm, in which
	information of both users and items is taken into account. In this
	algorithm, we set the similarity threshold for users and items respectively,
	and the prediction algorithm will determine whether predicting the
	missing data or not. We also address how to predict the missing data
	by employing a combination of user and item information. Finally,
	empirical studies on dataset MovieLens have shown that our newly
	proposed method outperforms other state-of-the-art collaborative
	filtering algorithms and it is more robust against data sparsity.},
  acmid     = {1277751},
  doi       = {http://doi.acm.org/10.1145/1277741.1277751},
  file      = {Ma2007Effective.pdf:Ma2007Effective.pdf:PDF},
  groups    = {Recommender Systems},
  isbn      = {978-1-59593-597-7},
  keywords  = {collaborative filtering, data prediction, data sparsity, recommender system},
  location  = {Amsterdam, The Netherlands},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/1277741.1277751},
}

@InProceedings{Ma2009Learninga,
  author    = {Ma, Hao and Lyu, Michael R. and King, Irwin},
  title     = {Learning to recommend with trust and distrust relationships},
  booktitle = {RecSys '09: Proceedings of the third ACM conference on Recommender systems},
  year      = {2009},
  pages     = {189--196},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {With the exponential growth ofWeb contents, Recommender
	
	System has become indispensable for discovering new information
	
	that might interest Web users. Despite their success
	
	in the industry, traditional recommender systems suffer
	
	from several problems. First, the sparseness of the useritem
	
	matrix seriously affects the recommendation quality.
	
	Second, traditional recommender systems ignore the connections
	
	among users, which loses the opportunity to provide
	
	more accurate and personalized recommendations. In this
	
	paper, aiming at providing more realistic and accurate recommendations,
	
	we propose a factor analysis-based optimization
	
	framework to incorporate the user trust and distrust
	
	relationships into the recommender systems. The contributions
	
	of this paper are three-fold: (1) We elaborate how user
	
	distrust information can benefit the recommender systems.
	
	(2) In terms of the trust relations, distinct from previous
	
	trust-aware recommender systems which are based on some
	
	heuristics, we systematically interpret how to constrain the
	
	objective function with trust regularization. (3) The experimental
	
	results show that the distrust relations among users
	
	are as important as the trust relations. The complexity analysis
	
	shows our method scales linearly with the number of observations,
	
	while the empirical analysis on a large Epinions
	
	dataset proves that our approaches perform better than the
	
	state-of-the-art approaches.},
  comment   = {method:
	
	
	matrix factorization (not probabilistic), trust people should be similar,
	distrust people should be different
	
	the confidence of trust and distrust is affected by the authority
	of users (iteratively define)
	
	
	i distrusts d
	
	if i distrusts a lot of users, then the confidence decreases, if d
	is trusted by a lot of users, then the confidence increase},
  file      = {Ma2009Learninga.pdf:Ma2009Learninga.pdf:PDF},
  groups    = {Recommender Systems},
  isbn      = {978-1-60558-435-5},
  location  = {New York, New York, USA},
}

@Conference{ma2008sorec,
  author       = {Ma, H. and Yang, H. and Lyu, M.R. and King, I.},
  title        = {Sorec: social recommendation using probabilistic matrix factorization},
  booktitle    = {Proceeding of the 17th ACM conference on Information and knowledge management},
  year         = {2008},
  pages        = {931--940},
  organization = {ACM},
  abstract     = {Data sparsity, scalability and prediction quality have been
	
	recognized as the three most crucial challenges that every
	
	collaborative ﬁltering algorithm or recommender system confronts.
	Many existing approaches to recommender systems
	
	can neither handle very large datasets nor easily deal with
	
	users who have made very few ratings or even none at all.
	
	Moreover, traditional recommender systems assume that all
	
	the users are independent and identically distributed; this
	
	assumption ignores the social interactions or connections
	
	among users. In view of the exponential growth of information generated
	by online social networks, social network
	
	analysis is becoming important for many Web applications.
	
	Following the intuition that a person’s social network will
	
	aﬀect personal behaviors on the Web, this paper proposes a
	
	factor analysis approach based on probabilistic matrix factorization
	to solve the data sparsity and poor prediction accuracy problems
	by employing both users’ social network
	
	information and rating records. The complexity analysis
	
	indicates that our approach can be applied to very large
	
	datasets since it scales linearly with the number of observations,
	while the experimental results shows that our method
	
	performs much better than the state-of-the-art approaches,
	
	especially in the circumstance that users have made few or
	
	no ratings.},
  comment      = {idea: social network+rating matrix
	
	PMF
	
	user factor + item factor --> rating
	
	user factor + graph factor --> social network},
  file         = {ma2008sorec.pdf:ma2008sorec.pdf:PDF},
  groups       = {Recommender Systems},
}

@InProceedings{Ma2011Recommender,
  author    = {Ma, Hao and Zhou, Dengyong and Liu, Chao and Lyu, Michael R. and King, Irwin},
  title     = {Recommender Systems with Social Regularization},
  booktitle = {Proceedings of the Fourth ACM International Conference on Web Search and Data Mining},
  year      = {2011},
  series    = {WSDM '11},
  pages     = {287--296},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Although Recommender Systems have been comprehensively analyzed in
	the past decade, the study of social-based recommender systems just
	started. In this paper, aiming at providing a general method for
	improving recommender systems by incorporating social network information,
	we propose a matrix factorization framework with social regularization.
	The contributions of this paper are four-fold: (1) We elaborate how
	social network information can benefit recommender systems; (2) We
	interpret the differences between social-based recommender systems
	and trust-aware recommender systems; (3) We coin the term Social
	Regularization to represent the social constraints on recommender
	systems, and we systematically illustrate how to design a matrix
	factorization objective function with social regularization; and
	(4) The proposed method is quite general, which can be easily extended
	to incorporate other contextual information, like social tags, etc.
	The empirical analysis on two large datasets demonstrates that our
	approaches outperform other state-of-the-art methods.},
  acmid     = {1935877},
  comment   = {method: regularized MF with user and friends similarity
	
	||ui-\Sigma_k \frac{sim(i,k)}{\Sigma_k sim(i,k)}u_k||_2
	
	regulization terms weighted by similarity
	
	two strategies
	
	user and neighbor average 
	
	user and user pair},
  doi       = {10.1145/1935826.1935877},
  file      = {Ma2011Recommender.pdf:Ma2011Recommender.pdf:PDF},
  isbn      = {978-1-4503-0493-1},
  keywords  = {collaborative filtering, matrix factorization, recommender systems, social network, social regularization},
  location  = {Hong Kong, China},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1935826.1935877},
}

@ARTICLE{Macdonald2008High,
  author = {Macdonald, C. and Hannah, D. and Ounis, I.},
  title = {High quality expertise evidence for expert search},
  journal = {Lecture Notes in Computer Science},
  year = {2008},
  volume = {4956},
  pages = {283},
  abstract = {In an Enterprise setting, an expert search system can assist
	
	 users with their Expertise need by suggesting people with relevant
	
	 expertise to the topic of interest. These systems typically work
	by associating
	
	 documentary evidence of expertise to each candidate expert,
	
	 and then ranking the candidates by the extent to which the documents
	
	 in their profile are about the query. There are three important factors
	
	 that affect the retrieval performance of an expert search system
	- firstly,
	
	 the selection of the candidate profiles (the documents associated
	with
	
	 each candidate), secondly, how the topicality of the documents is
	measured,
	
	 and thirdly how the evidence of expertise from the associated
	
	 documents is combined. In this work, we investigate a new dimension
	
	 to expert finding, namely whether some documents are better indicators
	
	 of expertise than others in each candidate's profile. We apply five
	techniques
	
	 to predict the quality documents in candidate profiles, which are
	
	 likely to be good indicators of expertise. The techniques applied
	include
	
	 the identification of possible candidate homepages, and of clustering
	the
	
	 documents in each profile to determine the candidate's main areas
	of
	
	 expertise. The proposed approaches are evaluated on three expert
	search
	
	 task from recent TREC Enterprise tracks and provide conclusions.},
  owner = {Cheyenne},
  publisher = {Springer},
  timestamp = {2009.09.21}
}

@Article{Macdonald2008Voting,
  author    = {Macdonald, C. and Ounis, I.},
  title     = {Voting techniques for expert search},
  journal   = {Knowledge and information systems},
  year      = {2008},
  volume    = {16},
  number    = {3},
  pages     = {259--280},
  owner     = {Cheyenne},
  publisher = {Springer},
  timestamp = {2009.09.21},
}

@CONFERENCE{Macdonald2007belief,
  author = {Macdonald, C. and Ounis, I.},
  title = {A belief network model for expert search},
  booktitle = {Proceedings of 1st conference on Theory of Information Retrieval
	(ICTIR)},
  year = {2007},
  owner = {Cheyenne},
  timestamp = {2009.09.21}
}

@InProceedings{Magdy2012Summarization,
  author    = {Magdy, Walid and Ali, Ahmed and Darwish, Kareem},
  title     = {A Summarization Tool for Time-sensitive Social Media},
  booktitle = {Proceedings of the 21st ACM International Conference on Information and Knowledge Management},
  year      = {2012},
  series    = {CIKM '12},
  pages     = {2695--2697},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Searching social content in general and microblogs (aka tweets) in
	particular has been basic and limited, especially for time-sensitive
	topics. The currently implemented microblog search on sites such
	as Twitter is based on simple word matching and retrieves the most
	recent microblogs that match a given query. Furthermore, a user may
	obtain hundreds or perhaps thousands of microblogs in response to
	a given query, leading to information overload. We present a new
	multidimensional microblog search tool that generates a comprehensive
	report from microblogs instead of a flat list of recent/relevant
	microblogs for a given query. Reports may include tag-clouds, topic
	time series, and most popular and funny microblogs, etc. The tool
	can be configured for monitoring time-sensitive topics using a set
	of predefined queries. We demonstrate our system on Arabic and English
	microblog collections. Additionally, we show a special configuration
	of the system for monitoring the 2012 Egyptian presidential elections.},
  acmid     = {2398730},
  doi       = {10.1145/2396761.2398730},
  groups    = {Twitter},
  isbn      = {978-1-4503-1156-4},
  keywords  = {elections, microblog search, retrieval results summarization, twitter},
  location  = {Maui, Hawaii, USA},
  numpages  = {3},
  url       = {http://doi.acm.org/10.1145/2396761.2398730},
}

@Article{Mairal2010Online,
  author     = {Mairal, Julien and Bach, Francis and Ponce, Jean and Sapiro, Guillermo},
  title      = {Online Learning for Matrix Factorization and Sparse Coding},
  journal    = {J. Mach. Learn. Res.},
  year       = {2010},
  volume     = {11},
  pages      = {19--60},
  month      = mar,
  acmid      = {1756008},
  file       = {Mairal2010Online.pdf:Mairal2010Online.pdf:PDF},
  groups     = {matrix factorization},
  issn       = {1532-4435},
  issue_date = {3/1/2010},
  numpages   = {42},
  publisher  = {JMLR.org},
  url        = {http://dl.acm.org/citation.cfm?id=1756006.1756008},
}

@INPROCEEDINGS{Malioutov2014Convex,
  author = {Dmitry Malioutov and Nikolai Slavov},
  title = {Convex Total Least Squares},
  booktitle = {Proceedings of ICML},
  year = {2014},
  pages = {118-126},
  abstract = {We study the total least squares (TLS) problem that generalizes least
	squares regression by allowing measurement errors in both dependent
	and independent variables. TLS is widely used in applied fields
	including computer vision, system identification and econometrics.
	The special case when all dependent and independent variables have
	the same level of uncorrelated Gaussian noise, known as ordinary
	TLS, can be solved by singular value decomposition (SVD). However,
	SVD cannot solve many important practical TLS problems with realistic
	noise structure, such as having varying measurement noise, known
	structure on the errors, or large outliers requiring robust error-norms.
	To solve such problems, we develop convex relaxation approaches for
	a general class of structured TLS (STLS). We show both theoretically
	and experimentally, that while the plain nuclear norm relaxation
	incurs large approximation errors for STLS, the re-weighted nuclear
	norm approach is very effective, and achieves better accuracy on
	challenging STLS problems than popular non-convex solvers. We describe
	a fast solution based on augmented Lagrangian formulation, and apply
	our approach to an important class of biological problems that use
	population average measurements to infer cell-type and physiological-state
	specific expression levels that are very hard to measure directly.},
  file = {Malioutov2014Convex.pdf:Malioutov2014Convex.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.06.24}
}

@INPROCEEDINGS{Mann2007Simple,
  author = {Mann, Gideon S. and McCallum, Andrew},
  title = {Simple, Robust, Scalable Semi-supervised Learning via Expectation
	Regularization},
  booktitle = {Proceedings of the 24th International Conference on Machine Learning},
  year = {2007},
  series = {ICML '07},
  pages = {593--600},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {1273571},
  doi = {10.1145/1273496.1273571},
  file = {Mann2007Simple.pdf:Mann2007Simple.pdf:PDF},
  isbn = {978-1-59593-793-3},
  location = {Corvalis, Oregon},
  numpages = {8},
  timestamp = {2014.09.09},
  url = {http://doi.acm.org/10.1145/1273496.1273571}
}

@InProceedings{Manzato2012Discovering,
  author    = {Manzato, Marcelo G.},
  title     = {Discovering Latent Factors from Movies Genres for Enhanced Recommendation},
  booktitle = {Proceedings of the Sixth ACM Conference on Recommender Systems},
  year      = {2012},
  series    = {RecSys '12},
  pages     = {249--252},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Current approaches on collaborative filtering factorize user-item
	matrices in order to infer latent factors from ratings previously
	assigned by users. However, they all have to deal with sparseness,
	whose workarounds are prone to bias and/or overfitting. This paper
	proposes a recommender algorithm that is based on a factorized matrix
	composed of user preferences associated to the movies' genres/categories.
	The advantage of using such user-genre matrix factorization model
	is that it requires less computational resources, as the matrix will
	be less sparse and at lower dimension. We present the experimental
	results with a dataset composed of real users, comparing the performance
	of different modules of our algorithm.},
  acmid     = {2366006},
  comment   = {just replace item with genre},
  doi       = {10.1145/2365952.2366006},
  file      = {Manzato2012Discovering.pdf:Manzato2012Discovering.pdf:PDF},
  groups    = {Recommender Systems},
  isbn      = {978-1-4503-1270-7},
  keywords  = {collaborative recommender systems, latent semantic analysis, user profiling, users similarity},
  location  = {Dublin, Ireland},
  numpages  = {4},
  timestamp = {2014.06.09},
  url       = {http://doi.acm.org/10.1145/2365952.2366006},
}

@INPROCEEDINGS{Mao2012SSHLDA,
  author = {Mao, Xian-Ling and Ming, Zhao-Yan and Chua, Tat-Seng and Li, Si and
	Yan, Hongfei and Li, Xiaoming},
  title = {SSHLDA: A Semi-supervised Hierarchical Topic Model},
  booktitle = {Proceedings of the 2012 Joint Conference on Empirical Methods in
	Natural Language Processing and Computational Natural Language Learning},
  year = {2012},
  series = {EMNLP-CoNLL '12},
  pages = {800--809},
  address = {Stroudsburg, PA, USA},
  publisher = {Association for Computational Linguistics},
  acmid = {2391034},
  file = {Mao2012SSHLDA.pdf:Mao2012SSHLDA.pdf:PDF},
  location = {Jeju Island, Korea},
  numpages = {10}
}

@INPROCEEDINGS{Marcus2011Twitinfo,
  author = {Marcus, Adam and Bernstein, Michael S. and Badar, Osama and Karger,
	David R. and Madden, Samuel and Miller, Robert C.},
  title = {Twitinfo: Aggregating and Visualizing Microblogs for Event Exploration},
  booktitle = {Proceedings of the SIGCHI Conference on Human Factors in Computing
	Systems},
  year = {2011},
  series = {CHI '11},
  pages = {227--236},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {1978975},
  doi = {10.1145/1978942.1978975},
  isbn = {978-1-4503-0228-9},
  keywords = {twitter visualization streaming aggregate sentiment},
  location = {Vancouver, BC, Canada},
  numpages = {10},
  url = {http://doi.acm.org/10.1145/1978942.1978975}
}

@InProceedings{Marlin2009Collaborative,
  author    = {Marlin, Benjamin M. and Zemel, Richard S.},
  title     = {Collaborative Prediction and Ranking with Non-random Missing Data},
  booktitle = {Proceedings of the Third ACM Conference on Recommender Systems},
  year      = {2009},
  series    = {RecSys '09},
  pages     = {5--12},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {A fundamental aspect of rating-based recommender systems is the observation
	process, the process by which users choose the items they rate. Nearly
	all research on collaborative filtering and recommender systems is
	founded on the assumption that missing ratings are missing at random.
	The statistical theory of missing data shows that incorrect assumptions
	about missing data can lead to biased parameter estimation and prediction.
	In a recent study, we demonstrated strong evidence for violations
	of the missing at random condition in a real recommender system.
	In this paper we present the first study of the effect of non-random
	missing data on collaborative ranking, and extend our previous results
	regarding the impact of non-random missing data on collaborative
	prediction.},
  acmid     = {1639717},
  comment   = {suppose that there's the hidden variables, the observed ratings
	
	the ratings are dependent on the hidden variables
	
	it first prove that when ratings are not missing at random, then the
	likelihood of observations (including observed ratings, and responses),
	which is the integration over all missing and hidden variables, is
	not proportional to the likelihood of observed ratings
	
	three models
	
	MAR: doesn' consider responses, assume K clusters, and for a prototype
	user in each cluster, a multinomial rating distribution over all
	items
	
	CPT-v: consider reponses, asserts the same conditional missing data
	rates for all items, the response is a bernoulli distribution for
	each rating value
	
	Logit-vd: allows that a rating is missing to depend on both the value
	of the underlying rating and the identity of the item. the response
	is a sigmoid function, with rating value specific and item id specific
	parameters.},
  doi       = {10.1145/1639714.1639717},
  file      = {Marlin2009Collaborative.pdf:Marlin2009Collaborative.pdf:PDF},
  isbn      = {978-1-60558-435-5},
  keywords  = {collaborative filtering, non-random missing data, probabilistic models, ranking, recommender systems},
  location  = {New York, New York, USA},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/1639714.1639717},
}

@InProceedings{Massoudi2011Incorporating,
  author    = {Massoudi, Kamran and Tsagkias, Manos and de Rijke, Maarten and Weerkamp, Wouter},
  title     = {Incorporating query expansion and quality indicators in searching microblog posts},
  booktitle = {Proceedings of the 33rd European conference on Advances in information retrieval},
  year      = {2011},
  series    = {ECIR'11},
  pages     = {362--367},
  address   = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  abstract  = {We propose a retrieval model for searching microblog posts for a
	
	given topic of interest. We develop a language modeling approach tailored
	to
	
	microblogging characteristics, where redundancy-based IR methods cannot
	be
	
	used in a straightforward manner. We enhance this model with two groups
	of
	
	quality indicators: textual and microblog specific. Additionally,
	we propose a dynamic
	
	query expansion model for microblog post retrieval. Experimental results
	
	on Twitter data reveal the usefulness of boolean search, and demonstrate
	the utility
	
	of quality indicators and query expansion in microblog search.},
  acmid     = {1996936},
  comment   = {1) quality indicator
	
	reposts, followers, and recency
	
	
	2)expansion term: by temporal co-occorences, c is the timestamp of
	query, c_d is the timestamp of document d
	
	score(t;Q) = log
	
	{
	
	jNcj /
	
	|{d : t \in d; d \ Nc}|
	
	}
	
	X
	
	\sum_d
	
	e^{-\beta ^{c_d-c}}},
  file      = {Massoudi2011Incorporating.pdf:Massoudi2011Incorporating.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-3-642-20160-8},
  location  = {Dublin, Ireland},
  numpages  = {6},
  url       = {http://dl.acm.org/citation.cfm?id=1996889.1996936},
}

@InProceedings{Mathioudakis2010TwitterMonitor,
  author    = {Mathioudakis, Michael and Koudas, Nick},
  title     = {TwitterMonitor: trend detection over the twitter stream},
  booktitle = {Proceedings of the 2010 international conference on Management of data},
  year      = {2010},
  series    = {SIGMOD '10},
  pages     = {1155--1158},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {We present TwitterMonitor, a system that performs trend detection
	over the Twitter stream. The system identifies emerging topics (i.e.
	'trends') on Twitter in real time and provides meaningful analytics
	that synthesize an accurate description of each topic. Users interact
	with the system by ordering the identified trends using different
	criteria and submitting their own description for each trend.
	
	
	We discuss the motivation for trend detection over social media streams
	and the challenges that lie therein. We then describe our approach
	to trend detection, as well as the architecture of TwitterMonitor.
	Finally, we lay out our demonstration scenario.},
  acmid     = {1807306},
  doi       = {http://doi.acm.org/10.1145/1807167.1807306},
  file      = {Mathioudakis2010TwitterMonitor.pdf:Mathioudakis2010TwitterMonitor.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-1-4503-0032-2},
  keywords  = {social media analysis, trend detection},
  location  = {Indianapolis, Indiana, USA},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/1807167.1807306},
}

@InProceedings{Matsumura2005Mining,
  author    = {Matsumura, Naohiro and Goldberg, David E. and Llor\`{a}, Xavier},
  title     = {Mining directed social network from message board},
  booktitle = {WWW '05: Special interest tracks and posters of the 14th international conference on World Wide Web},
  year      = {2005},
  pages     = {1092--1093},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {In the paper, we present an approach to mining a directed social network
	from a message board on the Internet where vertices denote individuals
	and directed links denote the flow of influence. The influence is
	measured based on propagating terms among individuals via messages.
	The distance with respect to contextual similarity between individuals
	is acquired since the influence indicates the degree of their shared
	interest represented as terms.},
  doi       = {http://doi.acm.org/10.1145/1062745.1062884},
  isbn      = {1-59593-051-5},
  location  = {Chiba, Japan},
}

@Article{matsuo2007polyphonet,
  author    = {Matsuo, Y. and Mori, J. and Hamasaki, M. and Nishimura, T. and Takeda, H. and Hasida, K. and Ishizuka, M.},
  title     = {POLYPHONET: an advanced social network extraction system from the web},
  journal   = {Web Semantics: Science, Services and Agents on the World Wide Web},
  year      = {2007},
  volume    = {5},
  number    = {4},
  pages     = {262--278},
  abstract  = {Social networks play important roles in the Semantic Web: knowledge
	
	 management, information retrieval, ubiquitous computing, and
	
	 so on. We propose a social network extraction system called POLYPHONET,
	
	 which employs several advanced techniques to extract
	
	 relations of persons, detect groups of persons, and obtain keywords
	
	 for a person. Search engines, especially Google, are used to measure
	
	 co-occurrence of information and obtain Web documents.
	
	 Several studies have used search engines to extract social networks
	
	 from theWeb, but our research advances the following points:
	
	 First, we reduce the related methods into simple pseudocodes using
	
	 Google so that we can build up integrated systems. Second,
	
	 we develop several new algorithms for social networking mining
	
	 such as those to classify relations into categories, to make extraction
	
	 scalable, and to obtain and utilize person-to-word relations.
	
	 Third, every module is implemented in POLYPHONET, which has
	
	 been used at four academic conferences, each with more than 500
	
	 participants. We overview that system. Finally, a novel architecture
	
	 called Super Social Network Mining is proposed; it utilizes
	
	 simple modules using Google and is characterized by scalability
	
	 and Relate-Identify processes: Identification of each entity and
	extraction
	
	 of relations are repeated to obtain a more precise social
	
	 network.},
  publisher = {Elsevier},
}

@Article{mccallum2007topic,
  author   = {McCallum, A. and Wang, X. and Corrada-Emmanuel, A.},
  title    = {{Topic and role discovery in social networks with experiments on Enron and academic email}},
  journal  = {Journal of Artificial Intelligence Research},
  year     = {2007},
  volume   = {30},
  pages    = {249--272},
  abstract = {Previous work in social network analysis (SNA) has modeled the existence
	of links
	
	 from one entity to another, but not the attributes such as language
	content or topics
	
	 on those links. We present the Author-Recipient-Topic (ART) model
	for social network
	
	 analysis, which learns topic distributions based on the direction-sensitive
	messages sent
	
	 between entities. The model builds on Latent Dirichlet Allocation
	(LDA) and the Author-
	
	 Topic (AT) model, adding the key attribute that distribution over
	topics is conditioned
	
	 distinctly on both the sender and recipient teering the discovery
	of topics according to
	
	 the relationships between people. We give results on both the Enron
	email corpus and
	
	 a researcher’s email archive, providing evidence not only that clearly
	relevant topics are
	
	 discovered, but that the ART model better predicts people roles and
	gives lower perplexity
	
	 on previously unseen messages. We also present the Role-Author-Recipient-Topic
	(RART)
	
	 model, an extension to ART that explicitly represents people roles.},
}

@CONFERENCE{McDonald2000Expertise,
  author = {McDonald, D.W. and Ackerman, M.S.},
  title = {Expertise recommender: a flexible recommendation system and architecture},
  booktitle = {Proceedings of the 2000 ACM conference on Computer supported cooperative
	work},
  year = {2000},
  pages = {231--240},
  organization = {ACM New York, NY, USA},
  owner = {Cheyenne},
  timestamp = {2009.09.21}
}

@INPROCEEDINGS{McDougall2009Expertise,
  author = {McDougall, Duncan and Macdonald, Craig},
  title = {Expertise search in academia using facets},
  booktitle = {SIGIR '09: Proceedings of the 32nd international ACM SIGIR conference
	on Research and development in information retrieval},
  year = {2009},
  pages = {834--834},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1571941.1572154},
  isbn = {978-1-60558-483-6},
  location = {Boston, MA, USA}
}

@INPROCEEDINGS{Mei2008Topic,
  author = {Mei, Qiaozhu and Cai, Deng and Zhang, Duo and Zhai, ChengXiang},
  title = {Topic modeling with network regularization},
  booktitle = {WWW '08: Proceeding of the 17th international conference on World
	Wide Web},
  year = {2008},
  pages = {101--110},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1367497.1367512},
  isbn = {978-1-60558-085-2},
  location = {Beijing, China}
}

@InProceedings{Mei2007Topic,
  author    = {Mei, Qiaozhu and Ling, Xu and Wondra, Matthew and Su, Hang and Zhai, ChengXiang},
  title     = {Topic Sentiment Mixture: Modeling Facets and Opinions in Weblogs},
  booktitle = {Proceedings of the 16th International Conference on World Wide Web},
  year      = {2007},
  series    = {WWW '07},
  pages     = {171--180},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {In this paper, we define the problem of topic-sentiment analysis on
	Weblogs and propose a novel probabilistic model to capture the mixture
	of topics and sentiments simultaneously. The proposed Topic-Sentiment
	Mixture (TSM) model can reveal the latent topical facets in a Weblog
	collection, the subtopics in the results of an ad hoc query, and
	their associated sentiments. It could also provide general sentiment
	models that are applicable to any ad hoc topics. With a specifically
	designed HMM structure, the sentiment models and topic models estimated
	with TSM can be utilized to extract topic life cycles and sentiment
	dynamics. Empirical experiments on different Weblog datasets show
	that this approach is effective for modeling the topic facets and
	sentiments and extracting their dynamics from Weblog collections.
	The TSM model is quite general; it can be applied to any text collections
	with a mixture of topics and sentiments, thus has many potential
	applications, such as search result summarization, opinion tracking,
	and user behavior prediction.},
  acmid     = {1242596},
  comment   = {sentiment(neutral, positive, negative) to each topic
	
	pgm},
  file      = {Mei2007Topic.pdf:Mei2007Topic.pdf:PDF},
  isbn      = {978-1-59593-654-7},
  keywords  = {mixture model, sentiment analysis, topic models, topic-sentiment mixture, weblogs},
  location  = {Banff, Alberta, Canada},
  numpages  = {10},
}

@InProceedings{Mei2005Discovering,
  author    = {Mei, Qiaozhu and Zhai, ChengXiang},
  title     = {Discovering evolutionary theme patterns from text: an exploration of temporal text mining},
  booktitle = {Proceedings of the eleventh ACM SIGKDD international conference on Knowledge discovery in data mining},
  year      = {2005},
  series    = {KDD '05},
  pages     = {198--207},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Temporal Text Mining (TTM) is concerned with discovering temporal
	patterns in text information collected over time. Since most text
	information bears some time stamps, TTM has many applications in
	multiple domains, such as summarizing events in news articles and
	revealing research trends in scientific literature. In this paper,
	we study a particular TTM task -- discovering and summarizing the
	evolutionary patterns of themes in a text stream. We define this
	new text mining problem and present general probabilistic methods
	for solving this problem through (1) discovering latent themes from
	text; (2) constructing an evolution graph of themes; and (3) analyzing
	life cycles of themes. Evaluation of the proposed methods on two
	different domains (i.e., news articles and literature) shows that
	the proposed methods can discover interesting evolutionary theme
	patterns effectively.},
  acmid     = {1081895},
  doi       = {http://doi.acm.org/10.1145/1081870.1081895},
  file      = {Mei2005Discovering.pdf:Mei2005Discovering.pdf:PDF},
  groups    = {Twitter},
  isbn      = {1-59593-135-X},
  keywords  = {clustering, evolutionary theme patterns, temporal text mining, theme threads},
  location  = {Chicago, Illinois, USA},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1081870.1081895},
}

@INPROCEEDINGS{Mei2008general,
  author = {Mei, Qiaozhu and Zhang, Duo and Zhai, ChengXiang},
  title = {A general optimization framework for smoothing language models on
	graph structures},
  booktitle = {SIGIR '08: Proceedings of the 31st annual international ACM SIGIR
	conference on Research and development in information retrieval},
  year = {2008},
  pages = {611--618},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1390334.1390438},
  isbn = {978-1-60558-164-4},
  location = {Singapore, Singapore}
}

@InProceedings{Meng2009Mining,
  author    = {Meng, Xinfan and Wang, Houfeng},
  title     = {Mining user reviews: from specification to summarization},
  booktitle = {Proceedings of the ACL-IJCNLP 2009 Conference Short Papers},
  year      = {2009},
  series    = {ACLShort '09},
  pages     = {177--180},
  address   = {Stroudsburg, PA, USA},
  publisher = {Association for Computational Linguistics},
  abstract  = {This paper proposes a method to extract product features from user
	reviews and generate a review summary. This method only relies on
	product specifications, which usually are easy to obtain. Other resources
	like segmenter, POS tagger or parser are not required. At feature
	extraction stage, multiple specifications are clustered to extend
	the vocabulary of product features. Hierarchy structure information
	and unit of measurement information are mined from the specification
	to improve the accuracy of feature extraction. At summary generation
	stage, hierarchy information in specifications is used to provide
	a natural conceptual view of product features.},
  acmid     = {1667637},
  file      = {Meng2009Mining.pdf:Meng2009Mining.pdf:PDF},
  location  = {Suntec, Singapore},
  numpages  = {4},
  url       = {http://dl.acm.org/citation.cfm?id=1667583.1667637},
}

@InProceedings{Meng2012Entitycentric,
  author    = {Meng, Xinfan and Wei, Furu and Liu, Xiaohua and Zhou, Ming and Li, Sujian and Wang, Houfeng},
  title     = {Entity-centric topic-oriented opinion summarization in twitter},
  booktitle = {Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining},
  year      = {2012},
  series    = {KDD '12},
  pages     = {379--387},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Microblogging services, such as Twitter, have become popular channels
	for people to express their opinions towards a broad range of topics.
	Twitter generates a huge volume of instant messages (i.e. tweets)
	carrying users' sentiments and attitudes every minute, which both
	necessitates automatic opinion summarization and poses great challenges
	to the summarization system. In this paper, we study the problem
	of opinion summarization for entities, such as celebrities and brands,
	in Twitter. We propose an entity-centric topic-based opinion summarization
	framework, which aims to produce opinion summaries in accordance
	with topics and remarkably emphasizing the insight behind the opinions.
	To this end, we first mine topics from #hashtags, the human-annotated
	semantic tags in tweets. We integrate the #hashtags as weakly supervised
	information into topic modeling algorithms to obtain better interpretation
	and representation for calculating the similarity among them, and
	adopt Affinity Propagation algorithm to group #hashtags into coherent
	topics. Subsequently, we use templates generalized from paraphrasing
	to identify tweets with deep insights, which reveal reasons, express
	demands or reflect viewpoints. Afterwards, we develop a target (i.e.
	entity) dependent sentiment classification approach to identifying
	the opinion towards a given target (i.e. entity) of tweets. Finally,
	the opinion summary is generated through integrating information
	from dimensions of topic, opinion and insight, as well as other factors
	(e.g. topic relevancy, redundancy and language styles) in an unified
	optimization framework. We conduct extensive experiments on a real-life
	data set to evaluate the performance of individual opinion summarization
	modules as well as the quality of the produced summary. The promising
	experiment results show the effectiveness of the proposed framework
	and algorithms.},
  acmid     = {2339592},
  doi       = {10.1145/2339530.2339592},
  file      = {Meng2012Entitycentric.pdf:Meng2012Entitycentric.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-1-4503-1462-6},
  keywords  = {\#hashtag, Twitter, opinion summarization, sentiment analysis, topic analysis},
  location  = {Beijing, China},
  numpages  = {9},
  url       = {http://doi.acm.org/10.1145/2339530.2339592},
}

@InProceedings{Metzler2012Structured,
  author    = {Metzler, Donald and Cai, Congxing and Hovy, Eduard},
  title     = {Structured Event Retrieval over Microblog Archives},
  booktitle = {Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  year      = {2012},
  series    = {NAACL HLT '12},
  pages     = {646--655},
  address   = {Stroudsburg, PA, USA},
  publisher = {Association for Computational Linguistics},
  abstract  = {Microblog streams often contain a considerable amount of information
	about local, regional, national, and global events. Most existing
	microblog search capabilities are focused on recent happenings and
	do not provide the ability to search and explore past events. This
	paper proposes the problem of structured retrieval of historical
	event information over microblog archives. Rather than retrieving
	individual microblog messages in response to an event query, we propose
	retrieving a ranked list of historical event summaries by distilling
	high quality event representations using a novel temporal query expansion
	technique. The results of an exploratory study carried out over a
	large archive of Twitter messages demonstrates both the value of
	the microblog event retrieval task and the effectiveness of our proposed
	search methodologies.},
  acmid     = {2382138},
  file      = {Metzler2012Structured.pdf:Metzler2012Structured.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-1-937284-20-6},
  location  = {Montreal, Canada},
  numpages  = {10},
  url       = {http://dl.acm.org/citation.cfm?id=2382029.2382138},
}

@INPROCEEDINGS{Metzler2005Markov,
  author = {Metzler, Donald and Croft, W. Bruce},
  title = {A Markov Random Field Model for Term Dependencies},
  booktitle = {Proceedings of the 28th Annual International ACM SIGIR Conference
	on Research and Development in Information Retrieval},
  year = {2005},
  series = {SIGIR '05},
  pages = {472--479},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {This paper develops a general, formal framework for modeling term
	dependencies via Markov random fields. The model allows for arbitrary
	text features to be incorporated as evidence. In particular, we make
	use of features based on occurrences of single terms, ordered phrases,
	and unordered phrases. We explore full independence, sequential dependence,
	and full dependence variants of the model. A novel approach is developed
	to train the model that directly maximizes the mean average precision
	rather than maximizing the likelihood of the training data. Ad hoc
	retrieval experiments are presented on several newswire and web collections,
	including the GOV2 collection used at the TREC 2004 Terabyte Track.
	The results show significant improvements are possible by modeling
	dependencies, especially on the larger web collections.},
  acmid = {1076115},
  isbn = {1-59593-034-5},
  keywords = {Markov random fields, information retrieval, phrases, term dependence},
  location = {Salvador, Brazil},
  numpages = {8}
}

@ARTICLE{Meyer2003Face-to-face,
  author = {Meyer, K.A.},
  title = {Face-to-face versus threaded discussions: The role of time and higher-order
	thinking},
  journal = {Journal of Asynchronous Learning Networks},
  year = {2003},
  volume = {7},
  pages = {55--65},
  number = {3}
}

@INPROCEEDINGS{Milette2009Exploiting,
  author = {Milette, Greg P. and Schneider, Michael K. and Ryall, Kathy and Hyland,
	Robert},
  title = {Exploiting social context for expertise propagation},
  booktitle = {SIGIR '09: Proceedings of the 32nd international ACM SIGIR conference
	on Research and development in information retrieval},
  year = {2009},
  pages = {835--835},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1571941.1572155},
  isbn = {978-1-60558-483-6},
  location = {Boston, MA, USA}
}

@ARTICLE{Miller2014Inconsistency,
  author = {Miller, Jeffrey W. and Harrison, Matthew T.},
  title = {Inconsistency of Pitman-Yor Process Mixtures for the Number of Components},
  journal = {J. Mach. Learn. Res.},
  year = {2014},
  volume = {15},
  pages = {3333--3370},
  number = {1},
  month = jan,
  abstract = {In many applications, a finite mixture is a natural model, but it
	can be difficult to choose an appropriate number of components. To
	circumvent this choice, investigators are increasingly turning to
	Dirichlet process mixtures (DPMs), and Pitman-Yor process mixtures
	(PYMs), more generally. While these models may be well-suited for
	Bayesian density estimation, many investigators are using them for
	inferences about the number of components, by considering the posterior
	on the number of components represented in the observed data. We
	show that this posterior is not consistent---that is, on data from
	a finite mixture, it does not concentrate at the true number of components.
	This result applies to a large class of nonparametric mixtures, including
	DPMs and PYMs, over a wide variety of families of component distributions,
	including essentially all discrete families, as well as continuous
	exponential families satisfying mild regularity conditions (such
	as multivariate Gaussians).},
  acmid = {2697071},
  file = {Miller2014Inconsistency.pdf:Miller2014Inconsistency.pdf:PDF},
  issn = {1532-4435},
  issue_date = {January 2014},
  keywords = {Bayesian nonparametrics, Dirichlet process mixture, consistency, finite
	mixture, number of components},
  numpages = {38},
  publisher = {JMLR.org},
  timestamp = {2015.08.26},
  url = {http://dl.acm.org/citation.cfm?id=2627435.2697071}
}

@InProceedings{Milne2007knowledgebased,
  author    = {Milne, David N. and Witten, Ian H. and Nichols, David M.},
  title     = {A knowledge-based search engine powered by wikipedia},
  booktitle = {Proceedings of the sixteenth ACM conference on Conference on information and knowledge management},
  year      = {2007},
  series    = {CIKM '07},
  pages     = {445--454},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {This paper describes Koru, a new search interface that offers
	
	effective domain-independent knowledge-based information
	
	retrieval. Koru exhibits an understanding of the topics of both
	
	queries and documents. This allows it to (a) expand queries
	
	automatically and (b) help guide the user as they evolve their
	
	queries interactively. Its understanding is mined from the vast
	
	investment of manual effort and judgment that is Wikipedia. We
	
	show how this open, constantly evolving encyclopedia can yield
	
	inexpensive knowledge structures that are specifically tailored to
	
	expose the topics, terminology and semantics of individual
	
	document collections. We conducted a detailed user study with 12
	
	participants and 10 topics from the 2005 TREC HARD track, and
	
	found that Koru and its underlying knowledge base offers
	
	significant advantages over traditional keyword search. It was
	
	capable of lending assistance to almost every query issued to it;
	
	making their entry more efficient, improving the relevance of the
	
	documents they return, and narrowing the gap between expert and
	
	novice seekers.},
  acmid     = {1321504},
  doi       = {http://doi.acm.org/10.1145/1321440.1321504},
  file      = {Milne2007knowledgebased.pdf:Milne2007knowledgebased.pdf:PDF},
  isbn      = {978-1-59593-803-9},
  keywords  = {data mining, information retrieval, query expansion, thesauri, wikipedia},
  location  = {Lisbon, Portugal},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1321440.1321504},
}

@INPROCEEDINGS{Mimno2007Expertise,
  author = {Mimno, David and McCallum, Andrew},
  title = {Expertise modeling for matching papers with reviewers},
  booktitle = {KDD '07: Proceedings of the 13th ACM SIGKDD international conference
	on Knowledge discovery and data mining},
  year = {2007},
  pages = {500--509},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {An essential part of an expert-finding task, such as matching reviewers
	to submitted papers, is the ability to model the expertise of a person
	based on documents. We evaluate several measures of the association
	between an author in an existing collection of research papers and
	a previously unseen document. We compare two language model based
	approaches with a novel topic model, Author-Persona-Topic (APT).
	In this model, each author can write under one or more "personas,"
	which are represented as independent distributions over hidden topics.
	Examples of previous papers written by prospective reviewers are
	gathered from the Rexa database, which extracts and disambiguates
	author mentions from documents gathered from the web. We evaluate
	the models using a reviewer matching task based on human relevance
	judgments determining how well the expertise of proposed reviewers
	matches a submission. We find that the APT topic model outperforms
	the other models.},
  doi = {http://doi.acm.org/10.1145/1281192.1281247},
  isbn = {978-1-59593-609-7},
  location = {San Jose, California, USA}
}

@CONFERENCE{Mishne2005Blocking,
  author = {Mishne, G. and Carmel, D. and Lempel, R.},
  title = {Blocking blog spam with language model disagreement},
  booktitle = {Proceedings of the First International Workshop on Adversarial Information
	Retrieval on the Web (AIRWeb)},
  year = {2005},
  address = {Chiba, Japan}
}

@InProceedings{Mladenic2012Text,
  author    = {Mladeni\'{c}, Dunja and Grobelnik, Marko and Fortuna, Bla\v{z} and Rusu, Delia},
  title     = {Text stream processing},
  booktitle = {Proceedings of the 2nd International Conference on Web Intelligence, Mining and Semantics},
  year      = {2012},
  series    = {WIMS '12},
  pages     = {5:1--5:5},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2254138},
  articleno = {5},
  doi       = {10.1145/2254129.2254138},
  file      = {Mladenic2012Text.pdf:Mladenic2012Text.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-1-4503-0915-8},
  keywords  = {entity recognition, semantic web, sentiment analysis, social network analysis, text stream, topic detection, web mining, word sense disambiguation},
  location  = {Craiova, Romania},
  numpages  = {5},
  url       = {http://doi.acm.org/10.1145/2254129.2254138},
}

@CONFERENCE{Mockus2002Expertise,
  author = {Mockus, A. and Herbsleb, J.D.},
  title = {Expertise browser: a quantitative approach to identifying expertise},
  booktitle = {Proceedings of the 24th International Conference on Software Engineering},
  year = {2002},
  pages = {503--512},
  organization = {ACM New York, NY, USA},
  owner = {Cheyenne},
  timestamp = {2009.09.21}
}

@INPROCEEDINGS{Moghaddam2013FLDA,
  author = {Moghaddam, Samaneh and Ester, Martin},
  title = {{The FLDA model for aspect-based opinion mining: addressing the cold
	start problem}},
  booktitle = {Proceedings of the 22nd international conference on World Wide Web},
  year = {2013},
  pages = {909--918},
  month = may,
  publisher = {International World Wide Web Conferences Steering Committee},
  abstract = {Aspect-based opinion mining from online reviews has attracted a lot
	of attention recently. The main goal of all of the proposed methods
	is extracting aspects and/or estimating aspect ratings. Recent works,
	which are often based on Latent Dirichlet Allocation (LDA), consider
	both tasks simultaneously. These models are normally trained at the
	item level, i.e., a model is learned for each item separately. Learning
	a model per item is fine when the item has been reviewed extensively
	and has enough training data. However, in real-life data sets such
	as those from Epinions.com and Amazon.com more than 90% of items
	have less than 10 reviews, so-called cold start items. State-of-the-art
	LDA models for aspect-based opinion mining are trained at the item
	level and therefore perform poorly for cold start items due to the
	lack of sufficient training data. In this paper, we propose a probabilistic
	graphical model based on LDA, called Factorized LDA (FLDA), to address
	the cold start problem. The underlying assumption of FLDA is that
	aspects and ratings of a review are influenced not only by the item
	but also by the reviewer. It further assumes that both items and
	reviewers can be modeled by a set of latent factors which represent
	their aspect and rating distributions. Different from state-of-the-art
	LDA models, FLDA is trained at the category level and learns the
	latent factors using the reviews of all the items of a category,
	in particular the non cold start items, and uses them as prior for
	cold start items. Our experiments on three real-life data sets demonstrate
	the improved effectiveness of the FLDA model in terms of likelihood
	of the held-out test set. We also evaluate the accuracy of FLDA based
	on two application-oriented measures.},
  annote = {应用场景：aspect-based opinion mining 主要特色： 现有从online reviews中aspect-based
	opinion mining的方法都是去extracting aspects和/或estimating aspect ratings。使用LDA在per
	item级别训练则会遇到冷启动问题，文中提Factorized LDA来解决冷启动问题。 潜在假设：一个评论的aspects and
	ratings不仅被item影响，还被reviewer影响，假设在items和reviewers能用一组factors来建模，FLDA在category-level训练，使用一个类别下所有items的评论作为训练数据，避免冷启动问题。
	数据集：Epinions, Amazon, TripAdvisor},
  file = {Moghaddam2013FLDA.pdf:Moghaddam2013FLDA.pdf:PDF},
  isbn = {978-1-4503-2035-1},
  keywords = {aspect identification,aspect-based opinion mining,cold start item,latent
	dirichlet allocation,lda,opinion mining,rating prediction,user modeling},
  mendeley-tags = {lda,opinion mining}
}

@INPROCEEDINGS{Moling2012Optimal,
  author = {Moling, Omar and Baltrunas, Linas and Ricci, Francesco},
  title = {Optimal Radio Channel Recommendations with Explicit and Implicit
	Feedback},
  booktitle = {Proceedings of the Sixth ACM Conference on Recommender Systems},
  year = {2012},
  series = {RecSys '12},
  pages = {75--82},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {The very large majority of recommender systems are running as server-side
	applications, and they are controlled by the content provider, i.e.,
	who provides the recommended items. This paper focuses on a different
	scenario: the user is supposed to be able to access content from
	multiple providers, in our application they offer radio channels,
	and it is up to a personal recommender installed on the clients'
	side to decide which channel to select and recommend to the user.
	We exploit the implicit feedback derived from the user's listening
	behavior, and we model channel recommendation as a sequential decision
	making problem. We have implemented a personal RS that integrates
	reinforcement learning techniques to decide what channel to play
	every time the user asks for a new music track or the current track
	finishes playing. In a live user study we show that the proposed
	system can sequentially select the next channel to play such that
	the users listen to the streamed tracks for a larger fraction, and
	for more time, compared to a baseline system not exploiting implicit
	feedback.},
  acmid = {2365971},
  file = {Moling2012Optimal.pdf:Moling2012Optimal.pdf:PDF},
  isbn = {978-1-4503-1270-7},
  keywords = {implicit feedback, reinforcement learning, sequential music recommendations},
  location = {Dublin, Ireland},
  numpages = {8},
  timestamp = {2015.11.12}
}

@InProceedings{Morinaga2004Tracking,
  author       = {Morinaga, S. and Yamanishi, K.},
  title        = {Tracking dynamics of topic trends using a finite mixture model},
  booktitle    = {Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining},
  year         = {2004},
  pages        = {811--816},
  organization = {ACM},
  file         = {Morinaga2004Tracking.pdf:Morinaga2004Tracking.pdf:PDF},
  groups       = {Twitter},
}

@ARTICLE{Mudambi2010What,
  author = {Mudambi, Susan M and Schuff, David},
  title = {What makes a helpful online review? A study of customer reviews on
	Amazon. com},
  journal = {Management Information Systems Quarterly},
  year = {2010},
  volume = {34},
  pages = {11},
  number = {1},
  abstract = {Customer reviews are increasingly available online for a
	
	wide range of products and services. They supplement other
	
	information provided by electronic storefronts such as product
	
	descriptions, reviews from experts, and personalized
	
	advice generated by automated recommendation systems.
	
	While researchers have demonstrated the benefits of the
	
	presence of customer reviews to an online retailer, a largely
	
	uninvestigated issue is what makes customer reviews helpful
	
	to a consumer in the process of making a purchase decision.
	
	Drawing on the paradigm of search and experience goods
	
	from information economics, we develop and test a model of
	
	customer review helpfulness. An analysis of 1,587 reviews
	
	from Amazon.com across six products indicated that review
	
	extremity, review depth, and product type affect the perceived
	
	helpfulness of the review. Product type moderates the effect
	
	of review extremity on the helpfulness of the review. For
	
	experience goods, reviews with extreme ratings are less helpful
	
	than reviews with moderate ratings. For both product
	
	types, review depth has a positive effect on the helpfulness of
	
	the review, but the product type moderates the effect of review
	
	depth on the helpfulness of the review. Review depth has a
	
	greater positive effect on the helpfulness of the review for
	
	search goods than for experience goods. We discuss the
	
	implications of our findings for both theory and practice.},
  file = {Mudambi2010What.pdf:Mudambi2010What.pdf:PDF},
  timestamp = {2014.10.04}
}

@INPROCEEDINGS{Mukherjee2012Mining,
  author = {Mukherjee, Arjun and Liu, Bing},
  title = {Mining Contentions from Discussions and Debates},
  booktitle = {Proceedings of the 18th ACM SIGKDD International Conference on Knowledge
	Discovery and Data Mining},
  year = {2012},
  series = {KDD '12},
  pages = {841--849},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Social media has become a major source of information for many applications.
	Numerous techniques have been proposed to analyze network structures
	and text contents. In this paper, we focus on fine-grained mining
	of contentions in discussion/debate forums. Contentions are perhaps
	the most important feature of forums that discuss social, political
	and religious issues. Our goal is to discover contention and agreement
	indicator expressions, and contention points or topics both at the
	discussion collection level and also at each individual post level.
	To the best of our knowledge, limited work has been done on such
	detailed analysis. This paper proposes three models to solve the
	problem, which not only model both contention/agreement expressions
	and discussion topics, but also, more importantly, model the intrinsic
	nature of discussions/debates, i.e., interactions among discussants
	or debaters and topic sharing among posts through quoting and replying
	relations. Evaluation results using real-life discussion/debate posts
	from several domains demonstrate the effectiveness of the proposed
	models.},
  acmid = {2339664},
  doi = {10.1145/2339530.2339664},
  file = {Mukherjee2012Mining.pdf:Mukherjee2012Mining.pdf:PDF},
  isbn = {978-1-4503-1462-6},
  keywords = {contention analysis, debates, discussions, social media},
  location = {Beijing, China},
  numpages = {9},
  url = {http://doi.acm.org/10.1145/2339530.2339664}
}

@InProceedings{Murakami2010Support,
  author    = {Murakami, Akiko and Raymond, Rudy},
  title     = {Support or Oppose?: Classifying Positions in Online Debates from Reply Activities and Opinion Expressions},
  booktitle = {Proceedings of the 23rd International Conference on Computational Linguistics: Posters},
  year      = {2010},
  series    = {COLING '10},
  pages     = {869--875},
  address   = {Stroudsburg, PA, USA},
  publisher = {Association for Computational Linguistics},
  abstract  = {We propose a method for the task of identifying the general positions
	of users in online debates, i.e., support or oppose the main topic
	of an online debate, by exploiting local information in their remarks
	within the debate. An online debate is a forum where each user post
	an opinion on a particular topic while other users state their positions
	by posting their remarks within the debate. The supporting or opposing
	remarks are made by directly replying to the opinion, or indirectly
	to other remarks (to express local agreement or disagreement), which
	makes the task of identifying users' general positions difficult.
	A prior study has shown that a link-based method, which completely
	ignores the content of the remarks, can achieve higher accuracy for
	the identification task than methods based solely on the contents
	of the remarks. In this paper, we show that utilizing the textual
	content of the remarks into the link-based method can yield higher
	accuracy in the identification task.},
  acmid     = {1944666},
  comment   = {max-cut to bipartite the network},
  file      = {Murakami2010Support.pdf:Murakami2010Support.pdf:PDF},
  location  = {Beijing, China},
  numpages  = {7},
  url       = {http://dl.acm.org/citation.cfm?id=1944566.1944666},
}

@ARTICLE{Nakatsuji2015Semantic,
  author = {Makoto Nakatsuji and Hiroyuki Toda and Hiroshi Sawada and Jin Guang
	Zheng and James A. Hendler},
  title = {Semantic sensitive tensor factorization },
  journal = {Artificial Intelligence },
  year = {2015},
  pages = { - },
  abstract = {Abstract The ability to predict the activities of users is an important
	one for recommender systems and analyses of social media. User activities
	can be represented in terms of relationships involving three or more
	things (e.g. when a user tags items on a webpage or tweets about
	a location he or she visited). Such relationships can be represented
	as a tensor, and tensor factorization is becoming an increasingly
	important means for predicting users' possible activities. However,
	the prediction accuracy of factorization is poor for ambiguous and/or
	sparsely observed objects. Our solution, Semantic Sensitive Tensor
	Factorization (SSTF), incorporates the semantics expressed by an
	object vocabulary or taxonomy into the tensor factorization. \{SSTF\}
	first links objects to classes in the vocabulary (taxonomy) and resolves
	the ambiguities of objects that may have several meanings. Next,
	it lifts sparsely observed objects to their classes to create augmented
	tensors. Then, it factorizes the original tensor and augmented tensors
	simultaneously. Since it shares semantic knowledge during the factorization,
	it can resolve the sparsity problem. Furthermore, as a result of
	the natural use of semantic information in tensor factorization,
	\{SSTF\} can combine heterogeneous and unbalanced datasets from different
	Linked Open Data sources. We implemented \{SSTF\} in the Bayesian
	probabilistic tensor factorization framework. Experiments on publicly
	available large-scale datasets using vocabularies from linked open
	data and a taxonomy from WordNet show that \{SSTF\} has up to 12%
	higher accuracy in comparison with state-of-the-art tensor factorization
	methods.},
  doi = {http://dx.doi.org/10.1016/j.artint.2015.09.001},
  file = {Nakatsuji2015Semantic.pdf:Nakatsuji2015Semantic.pdf:PDF},
  issn = {0004-3702},
  keywords = {Tensor factorization},
  timestamp = {2015.10.21}
}

@INPROCEEDINGS{Nallapati2008Joint,
  author = {Nallapati, Ramesh M. and Ahmed, Amr and Xing, Eric P. and Cohen,
	William W.},
  title = {Joint latent topic models for text and citations},
  booktitle = {KDD '08: Proceeding of the 14th ACM SIGKDD international conference
	on Knowledge discovery and data mining},
  year = {2008},
  pages = {542--550},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {In this work, we address the problem of joint modeling of text and
	citations in the topic modeling framework. We present two different
	models called the Pairwise-Link-LDA and the Link-PLSA-LDA models.
	
	
	 The Pairwise-Link-LDA model combines the ideas of LDA [4] and Mixed
	Membership Block Stochastic Models [1] and allows modeling arbitrary
	link structure. However, the model is computationally expensive,
	since it involves modeling the presence or absence of a citation
	(link) between every pair of documents. The second model solves this
	problem by assuming that the link structure is a bipartite graph.
	As the name indicates, Link-PLSA-LDA model combines the LDA and PLSA
	models into a single graphical model.
	
	
	 Our experiments on a subset of Citeseer data show that both these
	models are able to predict unseen data better than the baseline model
	of Erosheva and Lafferty [8], by capturing the notion of topical
	similarity between the contents of the cited and citing documents.
	Our experiments on two different data sets on the link prediction
	task show that the Link-PLSA-LDA model performs the best on the citation
	prediction task, while also remaining highly scalable. In addition,
	we also present some interesting visualizations generated by each
	of the models.},
  doi = {http://doi.acm.org/10.1145/1401890.1401957},
  file = {Nallapati2008Joint.pdf:Nallapati2008Joint.pdf:PDF},
  isbn = {978-1-60558-193-4},
  location = {Las Vegas, Nevada, USA}
}

@Conference{nam2009questions,
  author       = {Nam, K.K. and Ackerman, M.S. and Adamic, L.A.},
  title        = {{Questions in, knowledge in?: a study of naver's question answering community}},
  booktitle    = {Proceedings of the 27th international conference on Human factors in computing systems},
  year         = {2009},
  pages        = {779--788},
  organization = {ACM},
  abstract     = {Large general-purposed community question-answering
	
	sites are becoming popular as a new venue for generating
	
	knowledge and helping users in their information needs.
	
	In this paper we analyze the characteristics of knowledge
	
	generation and user participation behavior in the largest
	
	question-answering online community in South Korea,
	
	Naver Knowledge–iN. We collected and analyzed over
	
	2.6 million question/answer pairs from ﬁfteen categories
	
	between 2002 and 2007, and have interviewed twenty six
	
	users to gain insights into their motivations, roles, usage
	
	and expertise. We ﬁnd altruism, learning, and competency
	
	are frequent motivations for top answerers to participate,
	
	but that participation is often highly intermittent. Using a
	
	simple measure of user performance, we ﬁnd that higher
	
	levels of participation correlate with better performance.
	
	We also observe that users are motivated in part through a
	
	point system to build a comprehensive knowledge database.
	
	These and other insights have signiﬁcant implications for
	
	future knowledge generating online communities},
  comment      = {Guru Score
	
	Let bi = 1 if the user provided the best answer to question i
	
	and 0 otherwise, and ni be the number of answer to question
	
	i. We exclude those questions where ni = 1 because there
	
	is no point of comparison about the quality of the answer. A
	
	user providing m answers would be expected to give x best
	
	answers, where x =\sigma_m(1/ni) This probability takes into
	
	account the number of other users answering each question.
	
	The guru measure γ =\frac{\sigma_m bi-x}x{}
	
	, then indicates whether a user’s performance is better or worse than
	chance.},
  file         = {nam2009questions.pdf:nam2009questions.pdf:PDF},
}

@InProceedings{Naveed2011Searching,
  author    = {Naveed, Nasir and Gottron, Thomas and Kunegis, J{\'e}r\^{o}me and Alhadi, Arifah Che},
  title     = {Searching Microblogs: Coping with Sparsity and Document Quality},
  booktitle = {Proceedings of the 20th ACM International Conference on Information and Knowledge Management},
  year      = {2011},
  series    = {CIKM '11},
  pages     = {183--188},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Two of the main challenges in retrieval on microblogs are the inherent
	sparsity of the documents and difficulties in assessing their quality.
	The feature sparsity is immanent to the restriction of the medium
	to short texts. Quality assessment is necessary as the microblog
	documents range from spam over trivia and personal chatter to news
	broadcasts, information dissemination and reports of current hot
	topics. In this paper we analyze how these challenges can influence
	standard retrieval models and propose methods to overcome the problems
	they pose. We consider the sparsity's effect on document length normalization
	and introduce "interestingness" as static quality measure. Our results
	show that deliberately ignoring length normalization yields better
	retrieval results in general and that interestingness improves retrieval
	for underspecified queries.},
  acmid     = {2063607},
  doi       = {10.1145/2063576.2063607},
  groups    = {Twitter},
  isbn      = {978-1-4503-0717-8},
  keywords  = {interestingness, microblog, retweet, twitter},
  location  = {Glasgow, Scotland, UK},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/2063576.2063607},
}

@ARTICLE{Neal2000Markov,
  author = {Neal, Radford M},
  title = {Markov chain sampling methods for Dirichlet process mixture models},
  journal = {Journal of computational and graphical statistics},
  year = {2000},
  volume = {9},
  pages = {249--265},
  number = {2},
  file = {Neal2000Markov.PDF:Neal2000Markov.PDF:PDF},
  publisher = {Taylor \& Francis Group}
}

@InCollection{Negahban2012Iterative,
  author    = {Sahand Negahban and Oh, Sewoong and Shah, Devavrat},
  title     = {Iterative ranking from pair-wise comparisons},
  booktitle = {Advances in Neural Information Processing Systems 25},
  publisher = {Curran Associates, Inc.},
  year      = {2012},
  editor    = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
  pages     = {2474--2482},
  abstract  = {The question of aggregating pairwise comparisons to obtain a global
	ranking over
	
	a collection of objects has been of interest for a very long time:
	be it ranking
	
	of online gamers (e.g. MSR’s TrueSkill system) and chess players,
	aggregating
	
	social opinions, or deciding which product to sell based on transactions.
	In most
	
	settings, in addition to obtaining ranking, finding ‘scores’ for each
	object (e.g.
	
	player’s rating) is of interest to understanding the intensity of
	the preferences.
	
	In this paper, we propose a novel iterative rank aggregation algorithm
	for discovering
	
	scores for objects from pairwise comparisons. The algorithm has a
	natural
	
	random walk interpretation over the graph of objects with edges present
	between
	
	two objects if they are compared; the scores turn out to be the stationary
	probability
	
	of this random walk. The algorithm is model independent. To establish
	
	the efficacy of our method, however, we consider the popular Bradley-Terry-Luce
	
	(BTL) model in which each object has an associated score which determines
	the
	
	probabilistic outcomes of pairwise comparisons between objects. We
	bound the
	
	finite sample error rates between the scores assumed by the BTL model
	and those
	
	estimated by our algorithm. This, in essence, leads to order-optimal
	dependence
	
	on the number of samples required to learn the scores well by our
	algorithm. Indeed,
	
	the experimental evaluation shows that our (model independent) algorithm
	
	performs as well as the Maximum Likelihood Estimator of the BTL model
	and
	
	outperforms a recently proposed algorithm by Ammar and Shah [1]},
  comment   = {construct a graph 
	
	key step: add a self loop to each node
	
	random walk
	
	prove error bound for number of samples, under BTL model},
  file      = {Negahban2012Iterative.pdf:Negahban2012Iterative.pdf:PDF},
  timestamp = {2016.04.19},
  url       = {http://papers.nips.cc/paper/4701-iterative-ranking-from-pair-wise-comparisons.pdf},
}

@BOOK{Neumann1947Theory,
  title = {The Theory of Games and Economic Behavior},
  publisher = {Princeton University Press},
  year = {1947},
  author = {John Von Neumann and Oskar Morgenstern},
  owner = {littlep},
  timestamp = {2014.09.08}
}

@ARTICLE{Newman2003structure,
  author = {Newman, M.E.J},
  title = {The structure and function of complex networks},
  journal = {SIAM Review},
  year = {2003},
  volume = {45},
  pages = {167–256},
  owner = {linchen},
  timestamp = {2010.12.06}
}

@INPROCEEDINGS{Nguyen2014Gaussian,
  author = {Nguyen, Trung V. and Karatzoglou, Alexandros and Baltrunas, Linas},
  title = {Gaussian Process Factorization Machines for Context-aware Recommendations},
  booktitle = {Proceedings of the 37th International ACM SIGIR Conference on Research
	\&\#38; Development in Information Retrieval},
  year = {2014},
  series = {SIGIR '14},
  pages = {63--72},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Context-aware recommendation (CAR) can lead to significant improvements
	in the relevance of the recommended items by modeling the nuanced
	ways in which context influences preferences. The dominant approach
	in context-aware recommendation has been the multidimensional latent
	factors approach in which users, items, and context variables are
	represented as latent features in low-dimensional space. An interaction
	between a user, item, and a context variable is typically modeled
	as some linear combination of their latent features. However, given
	the many possible types of interactions between user, items and contextual
	variables, it may seem unrealistic to restrict the interactions among
	them to linearity.
	
	
	To address this limitation, we develop a novel and powerful non-linear
	probabilistic algorithm for context-aware recommendation using Gaussian
	processes. The method which we call Gaussian Process Factorization
	Machines (GPFM) is applicable to both the explicit feedback setting
	(e.g. numerical ratings as in the Netflix dataset) and the implicit
	feedback setting (i.e. purchases, clicks). We derive stochastic gradient
	descent optimization to allow scalability of the model. We test GPFM
	on five different benchmark contextual datasets. Experimental results
	demonstrate that GPFM outperforms state-of-the-art context-aware
	recommendation methods.},
  acmid = {2609623},
  file = {Nguyen2014Gaussian.pdf:Nguyen2014Gaussian.pdf:PDF},
  isbn = {978-1-4503-2257-7},
  keywords = {collaborative filtering, context-aware recommendation, gaussian processes,
	implicit feedback, nonlinear, probabilistic modeling},
  location = {Gold Coast, Queensland, Australia},
  numpages = {10}
}

@InProceedings{Nichols2012Summarizing,
  author    = {Jeffrey Nichols and Jalal Mahmud and Clemens Drew},
  title     = {Summarizing Sporting Events Using Twitter},
  booktitle = {Proceedings of IUI},
  year      = {2012},
  pages     = {189--198},
  groups    = {Twitter},
  owner     = {linchen},
  timestamp = {2013.08.16},
}

@ARTICLE{NielsonGlobal,
  author = {Nielson},
  title = {Global Faces and Networked Places. A Nielsen report on Social Networking’s
	New Global Footprint},
  file = {NielsonGlobal.pdf:NielsonGlobal.pdf:PDF},
  keywords = {report,online social network},
  owner = {linchen},
  timestamp = {2010.11.23}
}

@INPROCEEDINGS{Nishikawa2010Opinion,
  author = {Nishikawa, Hitoshi and Hasegawa, Takaaki and Matsuo, Yoshihiro and
	Kikui, Genichiro},
  title = {Opinion Summarization with Integer Linear Programming Formulation
	for Sentence Extraction and Ordering},
  booktitle = {Proceedings of the 23rd International Conference on Computational
	Linguistics: Posters},
  year = {2010},
  series = {COLING '10},
  pages = {910--918},
  address = {Stroudsburg, PA, USA},
  publisher = {Association for Computational Linguistics},
  acmid = {1944671},
  location = {Beijing, China},
  numpages = {9},
  url = {http://dl.acm.org/citation.cfm?id=1944566.1944671}
}

@InProceedings{Noll2009,
  author       = {Michael G. Noll and Ghing-man Au Yeung and Nicholas Gibbins and Chiristoph Meinel and Nigel Shadbolt},
  title        = {Telling Experts from Spammers: Expertise Ranking in Folksonomies},
  booktitle    = {Proceedings of 32 Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year         = {2009},
  editor       = {Mark Sanderson and Chengxiang Zhai and Justin Zobel and James Allan and Javed A. Aslam},
  pages        = {612-619},
  address      = {Boston},
  month        = {July},
  organization = {Association for Computing Machinery},
  publisher    = {ACM},
  abstract     = {With a suitable algorithm for ranking the expertise of a user in a
	collaborative tagging system, we will be able to identify experts
	and discover useful and relevant resources through them. We propose
	that the level of expertise of a user with respect to a particular
	topic is mainly determined by two factors. Firstly, an expert should
	possess a high quality collection of resources, while the quality
	of a Web resource depends on the expertise of the users who have
	assigned tags to it. Secondly, an expert should be one who tends
	to identify interesting or useful resources before other users do.
	We propose a graph-based algorithm, SPEAR (SPamming-resistant Expertise
	Analysis and Ranking), which implements these ideas for ranking users
	in a folksonomy. We evaluate our method with experiments on data
	sets collected from Delicious.com comprising over 71,000 Web documents,
	0.5 million users and 2 million shared bookmarks. We also show that
	the algorithm is more resistant to spammers than other methods such
	as the original HITS algorithm and simple statistical measures.},
  comment      = {本文工作：在collaborative tagging系统中发现专家用户和spammers。
	
	直观想法是：考虑专家的动态特性——比其他的作者能更快的发现有用的资源
	
	highlights:非常好的实验设计
	
	disadvantages：naive HITS-style method},
  keywords     = {eExpert search, folksonomy, ranking spammers},
  owner        = {linchen},
  timestamp    = {2009.12.11},
}

@INCOLLECTION{Oh2014Learning,
  author = {Oh, Sewoong and Shah, Devavrat},
  title = {Learning Mixed Multinomial Logit Model from Ordinal Data},
  booktitle = {Advances in Neural Information Processing Systems 27},
  publisher = {Curran Associates, Inc.},
  year = {2014},
  editor = {Z. Ghahramani and M. Welling and C. Cortes and N. D. Lawrence and
	K. Q. Weinberger},
  pages = {595--603},
  abstract = {Motivated by generating personalized recommendations using ordinal
	(or preference) data, we study the question of learning a mixture
	of MultiNomial Logit (MNL) model, a parameterized class of distributions
	over permutations, from partial ordinal or preference data (e.g.
	pair-wise comparisons). Despite its long standing importance across
	disciplines including social choice, operations research and revenue
	management, little is known about this question. In case of single
	MNL models (no mixture), computationally and statistically tractable
	learning from pair-wise comparisons is feasible. However, even learning
	mixture of two MNL model is infeasible in general. Given this state
	of affairs, we seek conditions under which it is feasible to learn
	the mixture model in both computationally and statistically efficient
	manner. To that end, we present a sufficient condition as well as
	an efficient algorithm for learning mixed MNL models from partial
	preferences/comparisons data. In particular, a mixture of MNL components
	over objects can be learnt using samples whose size scales polynomially
	in and (concretely, , with when the model parameters are sufficiently
	{\em incoherent}). The algorithm has two phases: first, learn the
	pair-wise marginals for each component using tensor decomposition;
	second, learn the model parameters for each component using RankCentrality
	introduced by Negahban et al. In the process of proving these results,
	we obtain a generalization of existing analysis for tensor decomposition
	to a more realistic regime where only partial information about each
	sample is available.},
  file = {Oh2014Learning.pdf:Oh2014Learning.pdf:PDF},
  url = {http://papers.nips.cc/paper/5225-learning-mixed-multinomial-logit-model-from-ordinal-data.pdf}
}

@Article{Osborne2000LASSO,
  author    = {Michael R. Osborne and Brett Presnell and Berwin A. Turlach},
  title     = {On the LASSO and Its Dual},
  journal   = {Journal of Computational and Graphical Statistics},
  year      = {2000},
  volume    = {9(2)},
  pages     = {319-337},
  file      = {Osborne2000LASSO.pdf:Osborne2000LASSO.pdf:PDF},
  groups    = {Lasso},
  owner     = {linchen},
  timestamp = {2011.08.11},
}

@INPROCEEDINGS{Ostuni2013Top,
  author = {Ostuni, Vito Claudio and Di Noia, Tommaso and Di Sciascio, Eugenio
	and Mirizzi, Roberto},
  title = {Top-N Recommendations from Implicit Feedback Leveraging Linked Open
	Data},
  booktitle = {Proceedings of the 7th ACM Conference on Recommender Systems},
  year = {2013},
  series = {RecSys '13},
  pages = {85--92},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {The advent of the Linked Open Data (LOD) initiative gave birth to
	a variety of open knowledge bases freely accessible on the Web. They
	provide a valuable source of information that can improve conventional
	recommender systems, if properly exploited. In this paper we present
	SPrank, a novel hybrid recommendation algorithm able to compute top-N
	item recommendations from implicit feedback exploiting the information
	available in the so called Web of Data. We leverage DBpedia, a well-known
	knowledge base in the LOD compass, to extract semantic path-based
	features and to eventually compute recommendations using a learning
	to rank algorithm. Experiments with datasets on two different domains
	show that the proposed approach outperforms in terms of prediction
	accuracy several state-of-the-art top-N recommendation algorithms
	for implicit feedback in situations affected by different degrees
	of data sparsity.},
  acmid = {2507172},
  file = {Ostuni2013Top.pdf:Ostuni2013Top.pdf:PDF},
  isbn = {978-1-4503-2409-0},
  keywords = {dbpedia, hybrid recommender system, implicit feedback, learning to
	rank, linked data, top-n recommendations},
  location = {Hong Kong, China},
  numpages = {8},
  timestamp = {2015.11.12}
}

@InProceedings{Ounis2006Terrier,
  author    = {Ounis, I. and Amati, G. and Plachouras, V. and He, B. and Macdonald, C. and Lioma, C.},
  title     = {{Terrier: A High Performance and Scalable Information Retrieval Platform}},
  booktitle = {Proceedings of ACM SIGIR'06 Workshop on Open Source Information Retrieval (OSIR 2006)},
  year      = {2006},
  location  = {Seattle, Washington, USA},
}

@InProceedings{Ounis2011Overview,
  author    = {Iadh Ounis and Jimmy Lin and Ian Soboroff},
  title     = {Overview of the TREC-2011 Microblog Track},
  year      = {2011},
  abstract  = {logies for information seeking behaviours in microblogging environments
	such as Twitter. It was ﬁrst introduced in 2011, addressing a real-time
	adhoc search task, whereby the user wishes to see
	
	the most recent but relevant information to the query. In particular,
	
	systems should respond to a query by providing a list of relevant
	
	tweets ordered from newest to oldest, starting from the time the
	
	query was issued.
	
	For TREC 2011, we used the Tweets11 corpus. The corpus is
	
	comprised of 16M tweets spread over 2 weeks, sampled courtesy
	
	of Twitter. The corpus is designed to be a reusable, representative
	
	sample of the twittersphere – i.e. both important and spam tweets
	
	are included. As the reusability of a test collection is paramount
	
	in a TREC track, this sample can be obtained at any point in time.
	
	In particular, the TREC Microblog track has used a novel methodology,
	whereby participants sign an agreement for the ids of the
	
	tweets in the corpus. Tools are then provided that permit the downloading
	of the corpus from the Twitter website.
	
	The ﬁrst Microblog track in TREC 2011 has been a remarkable
	
	success. A total of 59 groups participated in the track from across
	
	the world, with 184 submitted runs. Moreover, the track mailing
	
	list has over 450 members, and the @trecmicroblog Twitter account
	
	has over 210 followers on Twitter.},
  file      = {Ounis2011Overview.pdf:Ounis2011Overview.pdf:PDF},
  groups    = {Twitter},
  owner     = {linchen},
  timestamp = {2012.01.11},
}

@INPROCEEDINGS{Ozertem2012Learning,
  author = {Ozertem, Umut and Chapelle, Olivier and Donmez, Pinar and Velipasaoglu,
	Emre},
  title = {Learning to Suggest: A Machine Learning Framework for Ranking Query
	Suggestions},
  booktitle = {Proceedings of the 35th International ACM SIGIR Conference on Research
	and Development in Information Retrieval},
  year = {2012},
  series = {SIGIR '12},
  pages = {25--34},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We consider the task of suggesting related queries to users after
	they issue their initial query to a web search engine. We propose
	a machine learning approach to learn the probability that a user
	may find a follow-up query both useful and relevant, given his initial
	query. Our approach is based on a machine learning model which enables
	us to generalize to queries that have never occurred in the logs
	as well. The model is trained on co-occurrences mined from the search
	logs, with novel utility and relevance models, and the machine learning
	step is done without any labeled data by human judges. The learning
	step allows us to generalize from the past observations and generate
	query suggestions that are beyond the past co-occurred queries. This
	brings significant gains in coverage while yielding modest gains
	in relevance. Both offline (based on human judges) and online (based
	on millions of user interactions) evaluations demonstrate that our
	approach significantly outperforms strong baselines.},
  acmid = {2348290},
  doi = {10.1145/2348283.2348290},
  file = {Ozertem2012Learning.pdf:Ozertem2012Learning.pdf:PDF},
  isbn = {978-1-4503-1472-5},
  keywords = {machine learning, query log mining, query suggestion, search assistance},
  location = {Portland, Oregon, USA},
  numpages = {10},
  timestamp = {2014.03.12},
  url = {http://doi.acm.org/10.1145/2348283.2348290}
}

@Article{o2010tweetmotif,
  author   = {O’Connor, B. and Krieger, M. and Ahn, D.},
  title    = {Tweetmotif: Exploratory search and topic summarization for twitter},
  journal  = {Proceedings of ICWSM},
  year     = {2010},
  abstract = {We present TweetMotif, an exploratory search application
	
	for Twitter. Unlike traditional approaches to information
	
	retrieval, which present a simple list of messages,
	
	TweetMotif groups messages by frequent significant
	
	terms — a result set’s subtopics — which facilitate
	
	navigation and drilldown through a faceted search
	
	interface. The topic extraction system is based on syntactic
	
	filtering, language modeling, near-duplicate detection,
	
	and set cover heuristics. We have used Tweet-
	
	Motif to deflate rumors, uncover scams, summarize
	
	sentiment, and track political protests in real-time. A
	
	demo of TweetMotif, plus its source code, is available
	
	at http://tweetmotif.com.},
  file     = {o2010tweetmotif.pdf:o2010tweetmotif.pdf:PDF},
  groups   = {Twitter},
}

@Book{Page1998pagerank,
  title     = {The pagerank citation ranking: Bringing order to the web. Technical report},
  publisher = {Stanford University},
  year      = {1998},
  author    = {L. Page and S. Brin and R. Motwani and T. Winograd},
  address   = {Stanford, CA},
  owner     = {Cheyenne},
  timestamp = {2009.09.21},
}

@ARTICLE{Paisley2015Nested,
  author = {Paisley, J. and Wang, C. and Blei, D.M. and Jordan, M.I.},
  title = {Nested Hierarchical Dirichlet Processes},
  journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
  year = {2015},
  volume = {37},
  pages = {256-270},
  number = {2},
  month = {Feb},
  abstract = {We develop a nested hierarchical Dirichlet process (nHDP) for hierarchical
	topic modeling. The nHDP generalizes the nested Chinese restaurant
	process (nCRP) to allow each word to follow its own path to a topic
	node according to a per-document distribution over the paths on a
	shared tree. This alleviates the rigid, single-path formulation assumed
	by the nCRP, allowing documents to easily express complex thematic
	borrowings. We derive a stochastic variational inference algorithm
	for the model, which enables efficient inference for massive collections
	of text documents. We demonstrate our algorithm on 1.8 million documents
	from The New York Times and 2.7 million documents from Wikipedia.},
  file = {Paisley2015Nested.pdf:Paisley2015Nested.pdf:PDF},
  issn = {0162-8828},
  keywords = {Atomic measurements;Bayes methods;Data models;Indexes;Pattern analysis;Random
	variables;Stochastic processes;Bayesian nonparametrics;Dirichlet
	process;stochastic optimization;topic modeling},
  timestamp = {2015.09.10}
}

@ARTICLE{Pal2005web,
  author = {Pal, SK and Narayan, BL},
  title = {A web surfer model incorporating topic continuity},
  journal = {IEEE Transactions on Knowledge and Data Engineering},
  year = {2005},
  volume = {17},
  pages = {726--729},
  number = {5}
}

@Article{palla2007quantifying,
  author    = {Palla, G. and Barabasi, A.L. and Vicsek, T.},
  title     = {{Quantifying social group evolution}},
  journal   = {Nature},
  year      = {2007},
  volume    = {446},
  number    = {7136},
  pages     = {664--667},
  issn      = {0028-0836},
  abstract  = {The rich set of interactions between individuals in society
	
	1–7
	
	results in complex community structure, capturing highly connected
	circles of friends, families or professional cliques in a social
	
	network
	
	3,7–10
	
	. Thanks to frequent changes in the activity and communication patterns
	of individuals, the associated social and communication network is
	subject to constant evolution
	
	7,11–16
	
	. Our
	
	knowledge of themechanisms governing the underlying community dynamics
	is limited, but is essential for a deeper understanding
	
	of the development and self-optimization of society as a whole
	
	17–22
	
	.
	
	We have developed an algorithm based on clique percolation
	
	23,24
	
	that allows us to investigate the time dependence of overlapping
	
	communities on a large scale, and thus uncover basic relationships
	
	characterizing community evolution. Our focus is on networks
	
	capturing the collaboration between scientists and the calls between
	mobile phone users. We find that large groups persist for
	
	longer if they are capable of dynamically altering their membership,
	suggesting that an ability to change the group composition
	
	results in better adaptability. The behaviour of small groups displays
	the opposite tendency—the condition for stability is that
	
	their composition remains unchanged. We also show that knowledge of
	the time commitment of members to a given community
	
	can be used for estimating the community’s lifetime. These findings
	offer insight into the fundamental differences between the
	
	dynamics of small groups and large institutions.},
  comment   = {The data sets we consider are (1) the monthly list of articles in
	the
	
	Cornell University Library e-print condensed matter (cond-mat)
	
	archive spanning 142 months, with over 30,000 authors
	
	25
	
	, and (2)
	
	the record of phone calls between the customers of a mobile phone
	
	company spanning 52weeks (accumulated over two-week-long periods),
	and containing the communication patterns of over 4 million
	
	users. Both types of collaboration events (a new article or a phone
	
	call) document the presence of social interaction between the
	
	involved individuals (nodes), and can be represented as (timedependent)
	links. The extraction of the changing link weights from
	
	the primary data is described in Supplementary Information. In
	
	Fig. 1a, b we show the local structure at a given time step in the
	
	two networks in the vicinity of a randomly chosen individual
	
	(marked by a red frame). The communities (social groups represented
	by more densely interconnected parts within a network of
	
	social links) are colour coded, so that black nodes/edges do not
	
	belong to any community, and those that simultaneously belong to
	
	two or more communities are shown in red},
  file      = {palla2007quantifying.pdf:palla2007quantifying.pdf:PDF},
  publisher = {Nature Publishing Group},
}

@ARTICLE{Palmisano2008Using,
  author = {Palmisano, C. and Tuzhilin, A and Gorgoglione, M.},
  title = {Using Context to Improve Predictive Modeling of Customers in Personalization
	Applications},
  journal = {Knowledge and Data Engineering, IEEE Transactions on},
  year = {2008},
  volume = {20},
  pages = {1535-1549},
  number = {11},
  month = {Nov},
  abstract = {The idea that context is important when predicting customer behavior
	has been maintained by scholars in marketing and data mining. However,
	no systematic study measuring how much the contextual information
	really matters in building customer models in personalization applications
	has been done before. In this paper, we study how important the contextual
	information is when predicting customer behavior and how to use it
	when building customer models. It is done by conducting an empirical
	study across a wide range of experimental conditions. The experimental
	results show that context does matter when modeling the behavior
	of individual customers and that it is possible to infer the context
	from the existing data with reasonable accuracy in certain cases.
	It is also shown that significant performance improvements can be
	achieved if the context is "cleverly" modeled, as described in this
	paper. These findings have significant implications for data miners
	and marketers. They show that contextual information does matter
	in personalization and companies have different opportunities to
	both make context valuable for improving predictive performance of
	customers' behavior and decreasing the costs of gathering contextual
	information.},
  doi = {10.1109/TKDE.2008.110},
  issn = {1041-4347},
  keywords = {data mining;marketing data processing;contextual information;contextual
	information gathering;customer behavior;data mining;personalization
	applications;predictive modeling;predictive performance;Context;Data
	mining;Personalization;Predictive modeling;User modeling}
}

@InProceedings{Pan2009Mind,
  author    = {Pan, Rong and Scholz, Martin},
  title     = {Mind the Gaps: Weighting the Unknown in Large-scale One-class Collaborative Filtering},
  booktitle = {Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year      = {2009},
  series    = {KDD '09},
  pages     = {667--676},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {One-Class Collaborative Filtering (OCCF) is a task that naturally
	emerges in recommender system settings. Typical characteristics include:
	Only positive examples can be observed, classes are highly imbalanced,
	and the vast majority of data points are missing. The idea of introducing
	weights for missing parts of a matrix has recently been shown to
	help in OCCF. While existing weighting approaches mitigate the first
	two problems above, a sparsity preserving solution that would allow
	to efficiently utilize data sets with e.g., hundred thousands of
	users and items has not yet been reported. In this paper, we study
	three different collaborative filtering frameworks: Low-rank matrix
	approximation, probabilistic latent semantic analysis, and maximum-margin
	matrix factorization. We propose two novel algorithms for large-scale
	OCCF that allow to weight the unknowns. Our experimental results
	demonstrate their effectiveness and efficiency on different problems,
	including the Netflix Prize data.},
  acmid     = {1557094},
  comment   = {maximal margin matrix factorization
	
	w h (R,R') + \lambda |R'|_{\Sigma}
	
	where h is the hinge loss
	
	W is the weight matrix, where explicit feedback weights 1, and implicit
	feedbacks are weighted according to the confidence of nagative preference},
  doi       = {10.1145/1557019.1557094},
  file      = {Pan2009Mind.pdf:Pan2009Mind.pdf:PDF},
  isbn      = {978-1-60558-495-9},
  keywords  = {collaborative filtering, large-scale, one-class},
  location  = {Paris, France},
  numpages  = {10},
  timestamp = {2015.09.21},
  url       = {http://doi.acm.org/10.1145/1557019.1557094},
}

@InProceedings{Pan2008One,
  author    = {Rong Pan and Yunhong Zhou and Bin Cao and Liu, N.N. and Lukose, R. and Scholz, M. and Qiang Yang},
  title     = {One-Class Collaborative Filtering},
  booktitle = {Data Mining, 2008. ICDM '08. Eighth IEEE International Conference on},
  year      = {2008},
  pages     = {502-511},
  month     = {Dec},
  abstract  = {Many applications of collaborative filtering (CF), such as news item
	recommendation and bookmark recommendation, are most naturally thought
	of as one-class collaborative filtering (OCCF) problems. In these
	problems, the training data usually consist simply of binary data
	reflecting a user's action or inaction, such as page visitation in
	the case of news item recommendation or webpage bookmarking in the
	bookmarking scenario. Usually this kind of data are extremely sparse
	(a small fraction are positive examples), therefore ambiguity arises
	in the interpretation of the non-positive examples. Negative examples
	and unlabeled positive examples are mixed together and we are typically
	unable to distinguish them. For example, we cannot really attribute
	a user not bookmarking a page to a lack of interest or lack of awareness
	of the page. Previous research addressing this one-class problem
	only considered it as a classification task. In this paper, we consider
	the one-class problem under the CF setting. We propose two frameworks
	to tackle OCCF. One is based on weighted low rank approximation;
	the other is based on negative example sampling. The experimental
	results show that our approaches significantly outperform the baselines.},
  comment   = {For positive examples, they
	
	have relative high likeliness to be true
	
	
	The first weighting scheme assumes
	
	that a missing data being a negative example
	
	has an equal chance over all users or all items, that is,
	
	it uniformly assign a weight δ ∈ [0, 1] for “negative” examples.
	
	The second weighting scheme posits that if a
	
	user has more positive examples, it is more likely that
	
	she does not like the other items, that is, the missing
	
	data for this user is negative with higher probability.
	
	The third weighting scheme assumes that if an item
	
	has fewer positive examples, the missing data for this
	
	item is negative with higher probability.},
  doi       = {10.1109/ICDM.2008.16},
  file      = {Pan2008One.pdf:Pan2008One.pdf:PDF},
  issn      = {1550-4786},
  keywords  = {Internet;groupware;information filtering;Web page bookmarking;binary data;bookmark recommendation;news item recommendation;one-class collaborative filtering;training data;DVD;Data mining;Filtering;Fuels;History;International collaboration;Milling machines;Rockets;Sampling methods;Training data;Alternating Least Squares;Collaborative Filtering;Low-Rank Approximations;One-Class},
  timestamp = {2015.09.21},
}

@ARTICLE{Pan2010Survey,
  author = {Sinno Jialin Pan and Qiang Yang},
  title = {A Survey on Transfer Learning},
  journal = {Knowledge and Data Engineering, IEEE Transactions on},
  year = {2010},
  volume = {22},
  pages = {1345-1359},
  number = {10},
  month = {Oct},
  doi = {10.1109/TKDE.2009.191},
  file = {Pan2010Survey.pdf:Pan2010Survey.pdf:PDF},
  issn = {1041-4347},
  keywords = {knowledge engineering;learning by example;optimisation;unsupervised
	learning;data mining;inductive transfer learning;knowledge transfer;machine
	learning;transductive transfer learning;unsupervised transfer learning;Data
	mining;Knowledge engineering;Knowledge transfer;Labeling;Learning
	systems;Machine learning;Machine learning algorithms;Space technology;Testing;Training
	data;Transfer learning;data mining.;machine learning;survey},
  timestamp = {2014.05.12}
}

@INPROCEEDINGS{Pandey2008Exploiting,
  author = {Gaurav Pandey and Julia Luxenburger},
  title = {Exploiting Session Context for Information Retrieval - A Comparative
	Study},
  booktitle = {The 30th Proceedings of European Conference on IR Research},
  year = {2008},
  pages = {652-657},
  owner = {littlep},
  timestamp = {2014.07.15}
}

@InProceedings{Pandit2007Netprobe,
  author    = {Pandit, Shashank and Chau, Duen Horng and Wang, Samuel and Faloutsos, Christos},
  title     = {Netprobe: a fast and scalable system for fraud detection in online auction networks},
  booktitle = {WWW '07: Proceedings of the 16th international conference on World Wide Web},
  year      = {2007},
  pages     = {201--210},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Given a large online network of online auction users and their histories
	of transactions, how can we spot anomalies and auction fraud? This
	paper describes the design and implementation of NetProbe, a system
	that we propose for solving this problem. NetProbe models auction
	users and transactions as a Markov Random Field tuned to detect the
	suspicious patterns that fraudsters create, and employs a Belief
	Propagation mechanism to detect likely fraudsters. Our experiments
	show that NetProbe is both efficient and effective for fraud detection.
	We report experiments on synthetic graphs with as many as 7,000 nodes
	and 30,000 edges, where NetProbe was able to spot fraudulent nodes
	with over 90% precision and recall, within a matter of seconds. We
	also report experiments on a real dataset crawled from eBay, with
	nearly 700,000 transactions between more than 66,000users, where
	NetProbe was highly effective at unearthing hidden networks of fraudsters,
	within a realistic response time of about 6 minutes. For scenarios
	where the underlying data is dynamic in nature, we propose IncrementalNetProbe,
	which is an approximate, but fast, variant of NetProbe. Our experiments
	prove that Incremental NetProbe executes nearly doubly fast as compared
	to NetProbe, while retaining over 99% of its accuracy.},
  doi       = {http://doi.acm.org/10.1145/1242572.1242600},
  isbn      = {978-1-59593-654-7},
  location  = {Banff, Alberta, Canada},
}

@INPROCEEDINGS{Panniello2009Experimental,
  author = {Panniello, Umberto and Tuzhilin, Alexander and Gorgoglione, Michele
	and Palmisano, Cosimo and Pedone, Anto},
  title = {Experimental Comparison of Pre- vs. Post-filtering Approaches in
	Context-aware Recommender Systems},
  booktitle = {Proceedings of the Third ACM Conference on Recommender Systems},
  year = {2009},
  series = {RecSys '09},
  pages = {265--268},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {1639764},
  doi = {10.1145/1639714.1639764},
  file = {Panniello2009Experimental.pdf:Panniello2009Experimental.pdf:PDF},
  isbn = {978-1-60558-435-5},
  keywords = {collaborative filtering, post-filtering, pre-filtering, recommender
	systems},
  location = {New York, New York, USA},
  numpages = {4},
  timestamp = {2014.05.26},
  url = {http://doi.acm.org/10.1145/1639714.1639764}
}

@InCollection{Papagelis2005Incremental,
  author      = {Papagelis, Manos and Rousidis, Ioannis and Plexousakis, Dimitris and Theoharopoulos, Elias},
  title       = {Incremental Collaborative Filtering for Highly-Scalable Recommendation Algorithms},
  booktitle   = {Foundations of Intelligent Systems},
  publisher   = {Springer Berlin / Heidelberg},
  year        = {2005},
  editor      = {Hacid, Mohand-Said and Murray, Neil and Ras, Zbigniew and Tsumoto, Shusaku},
  volume      = {3488},
  series      = {Lecture Notes in Computer Science},
  pages       = {7-17},
  note        = {10.1007/11425274_57},
  affiliation = {Institute of Computer Science, Forth, Heraklion, Greece},
  file        = {Papagelis2005Incremental.pdf:Papagelis2005Incremental.pdf:PDF},
  groups      = {Recommender Systems},
  isbn        = {978-3-540-25878-0},
  keyword     = {Computer Science},
  url         = {http://dx.doi.org/10.1007/11425274_57},
}

@INPROCEEDINGS{Paquet2013One,
  author = {Paquet, Ulrich and Koenigstein, Noam},
  title = {One-class Collaborative Filtering with Random Graphs},
  booktitle = {Proceedings of the 22Nd International Conference on World Wide Web},
  year = {2013},
  series = {WWW '13},
  pages = {999--1008},
  address = {Republic and Canton of Geneva, Switzerland},
  publisher = {International World Wide Web Conferences Steering Committee},
  abstract = {The bane of one-class collaborative filtering is interpreting and
	modelling the latent signal from the missing class. In this paper
	we present a novel Bayesian generative model for implicit collaborative
	filtering. It forms a core component of the Xbox Live architecture,
	and unlike previous approaches, delineates the odds of a user disliking
	an item from simply being unaware of it. The latent signal is treated
	as an unobserved random graph connecting users with items they might
	have encountered. We demonstrate how large-scale distributed learning
	can be achieved through a combination of stochastic gradient descent
	and mean field variational inference over random graph samples. A
	fine-grained comparison is done against a state of the art baseline
	on real world data.},
  acmid = {2488475},
  file = {Paquet2013One.pdf:Paquet2013One.pdf:PDF},
  isbn = {978-1-4503-2035-1},
  keywords = {one-class collaborative filtering, random graph, variational inference},
  location = {Rio de Janeiro, Brazil},
  numpages = {10},
  timestamp = {2015.11.13},
  url = {http://dl.acm.org/citation.cfm?id=2488388.2488475}
}

@Article{Park2008bayesian,
  author    = {Park, T. and Casella, G.},
  title     = {The bayesian lasso},
  journal   = {Journal of the American Statistical Association},
  year      = {2008},
  volume    = {103},
  number    = {482},
  pages     = {681--686},
  abstract  = {The Lasso estimate for linear regression parameters can be interpreted
	as
	
	a Bayesian posterior mode estimate when the regression parameters
	have in-
	
	dependent Laplace (double-exponential) priors. Gibbs sampling from
	this pos-
	
	terior is possible using an expanded hierarchy with conjugate normal
	priors
	
	for the regression parameters and independent exponential priors on
	their vari-
	
	ances. A connection with the inverse Gaussian distribution provides
	tractable
	
	full conditional distributions. The Bayesian Lasso provides interval
	estimates
	
	(Bayesian credible intervals) that can guide variable selection. Moreover,
	the
	
	structure of the hierarchical model provides both Bayesian and likelihood
	meth-
	
	ods for selecting the Lasso parameter. Slight modifications lead to
	Bayesian
	
	versions of other Lasso-related estimation methods like bridge regression
	and a
	
	robust variant.},
  file      = {Park2008bayesian.pdf:Park2008bayesian.pdf:PDF},
  groups    = {Lasso},
  publisher = {ASA},
}

@InProceedings{Parkes2012Random,
  author       = {Parkes, David C and Soufiani, Houssein Azari and Xia, Lirong},
  title        = {Random Utility Theory for Social Choice},
  booktitle    = {Proceeedings of the 25th Annual Conference on Neural Information ProcessingSystems (NIPS'12)},
  year         = {2012},
  pages        = {126-134},
  address      = {, Lake Tahoe, Nevada,},
  month        = {12},
  organization = {Curran Associates and NIPS},
  abstract     = {Random utility theory models an agent's preferences on alternatives
	by drawing a real-valued score on each alternative (typically independently)
	from a parameterized distribution, and then ranking the alternatives
	according to scores. A special case that has received significant
	attention is the Plackett-Luce model, for which fast inference methods
	for maximum likelihood estimators are available. This paper develops
	conditions on general random utility models that enable fast inference
	within a Bayesian framework through MC-EM, providing concave loglikelihood
	functions and bounded sets of global maxima solutions. Results on
	both real-world and simulated data provide support for the scalability
	of the approach and capability for model selection among general
	random utility models including Plackett-Luce.},
  comment      = {propose a framework that allows the random utility model to be of
	exponential family},
  file         = {Parkes2012Random.pdf:Parkes2012Random.pdf:PDF},
  owner        = {csgueste},
  timestamp    = {2016.04.19},
}

@InProceedings{Paul2010Summarizing,
  author    = {Paul, Michael J. and Zhai, ChengXiang and Girju, Roxana},
  title     = {Summarizing Contrastive Viewpoints in Opinionated Text},
  booktitle = {Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing},
  year      = {2010},
  series    = {EMNLP '10},
  pages     = {66--76},
  address   = {Stroudsburg, PA, USA},
  publisher = {Association for Computational Linguistics},
  abstract  = {This paper presents a two-stage approach to
	
	summarizing multiple contrastive viewpoints
	
	in opinionated text. In the first stage, we
	
	use an unsupervised probabilistic approach to
	
	model and extract multiple viewpoints in text.
	
	We experiment with a variety of lexical and
	
	syntactic features, yielding significant performance
	
	gains over bag-of-words feature sets.
	
	In the second stage, we introduce Comparative
	
	LexRank, a novel random walk formulation
	
	to score sentences and pairs of sentences
	
	from opposite viewpoints based on both their
	
	representativeness of the collection as well as
	
	their contrastiveness with each other. Experimental
	
	results show that the proposed approach
	
	can generate informative summaries of
	
	viewpoints in opinionated text},
  acmid     = {1870665},
  comment   = {we will generate two types of multiview
	
	summaries: macro multi-view summary and
	
	micro multi-view summary. A macro multi-view
	
	summary would contain multiple sets of sentences,
	
	each representing a different viewpoint; these different
	
	sets of sentences can be compared to understand
	
	the difference of multiple viewpoints at the “macro
	
	level.” A micro multi-view summary would contain
	
	a set of pairs of contrastive sentences (each pair
	
	consists of two sentences representing two different
	
	viewpoints), making it easy to understand the difference
	
	between two viewpoints at the “micro level.”},
  file      = {Paul2010Summarizing.pdf:Paul2010Summarizing.pdf:PDF},
  location  = {Cambridge, Massachusetts},
  numpages  = {11},
  timestamp = {2015.09.01},
}

@ARTICLE{Pavan2007Dominant,
  author = {Pavan, M. and Pelillo, M.},
  title = {Dominant Sets and Pairwise Clustering},
  journal = {Pattern Analysis and Machine Intelligence, IEEE Transactions on},
  year = {2007},
  volume = {29},
  pages = {167-172},
  number = {1},
  month = {Jan},
  doi = {10.1109/TPAMI.2007.250608},
  issn = {0162-8828},
  keywords = {evolutionary computation;game theory;graph theory;pattern clustering;edge-weighted
	graph;evolutionary game theory;graph-theory;image segmentation;maximal
	complete subgraph;pairwise data clustering;point-set problem;quadratic
	optimization;Clustering algorithms;Cost function;Game theory;Graph
	theory;Image segmentation;Optimization methods;Particle measurements;Solids;Tree
	graphs;Clustering;evolutionary game dynamics;image segmentation;perceptual
	organization.;quadratic optimization;Algorithms;Artificial Intelligence;Cluster
	Analysis;Image Enhancement;Image Interpretation, Computer-Assisted;Information
	Storage and Retrieval;Pattern Recognition, Automated}
}

@INPROCEEDINGS{Pavan2003Dominant,
  author = {Pavan, M. and Pelillo, M.},
  title = {Dominant sets and hierarchical clustering},
  booktitle = {Proceedings. Ninth IEEE International Conference on Computer Vision},
  year = {2003},
  pages = {362 - 369},
  abstract = {Dominant sets are a new graph-theoretic concept that has proven to
	be relevant in partitional (flat) clustering as well as image segmentation
	problems. However, in many computer vision applications, such as
	the organization of an image database, it is important to provide
	the data to be clustered with a hierarchical organization, and it
	is not clear how to do this within the dominant set framework. We
	address precisely this problem, and present a simple and elegant
	solution to it. To this end, we consider a family of (continuous)
	quadratic programs, which contain a parameterized regularization
	term that controls the global shape of the energy landscape. When
	the regularization parameter is zero the local solutions are known
	to be in one-to-one correspondence with dominant sets, but when it
	is positive an interesting picture emerges. We determine bounds for
	the regularization parameter that allow us to exclude from the set
	of local solutions those inducing clusters of size smaller than a
	prescribed threshold. This suggests a new (divisive) hierarchical
	approach to clustering, which is based on the idea of properly varying
	the regularization parameter during the clustering process. Straightforward
	dynamics from evolutionary game theory are used to locate the solutions
	of the quadratic programs at each level of the hierarchy. We apply
	the proposed framework to the problem of organizing a shape database.
	Experiments with three different similarity matrices (and databases)
	reported in the literature have been conducted, and the results confirm
	the effectiveness of our approach.},
  file = {Pavan2003Dominant.pdf:Pavan2003Dominant.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.10.12}
}

@INPROCEEDINGS{Pei2007Probabilistic,
  author = {Pei, Jian and Jiang, Bin and Lin, Xuemin and Yuan, Yidong},
  title = {Probabilistic Skylines on Uncertain Data},
  booktitle = {Proceedings of the 33rd International Conference on Very Large Data
	Bases},
  year = {2007},
  series = {VLDB '07},
  pages = {15--26},
  publisher = {VLDB Endowment},
  abstract = {Uncertain data are inherent in some important applications. Although
	a considerable amount of research has been dedicated to modeling
	uncertain data and answering some types of queries on uncertain data,
	how to conduct advanced analysis on uncertain data remains an open
	problem at large. In this paper, we tackle the problem of skyline
	analysis on uncertain data. We propose a novel probabilistic skyline
	model where an uncertain object may take a probability to be in the
	skyline, and a p-skyline contains all the objects whose skyline probabilities
	are at least p. Computing probabilistic skylines on large uncertain
	data sets is challenging. We develop two efficient algorithms. The
	bottom-up algorithm computes the skyline probabilities of some selected
	instances of uncertain objects, and uses those instances to prune
	other instances and uncertain objects effectively. The top-down algorithm
	recursively partitions the instances of uncertain objects into subsets,
	and prunes subsets and objects aggressively. Our experimental results
	on both the real NBA player data set and the benchmark synthetic
	data sets show that probabilistic skylines are interesting and useful,
	and our two algorithms are efficient on large data sets, and complementary
	to each other in performance.},
  acmid = {1325858},
  file = {Pei2007Probabilistic.pdf:Pei2007Probabilistic.pdf:PDF},
  isbn = {978-1-59593-649-3},
  location = {Vienna, Austria},
  numpages = {12},
  url = {http://dl.acm.org/citation.cfm?id=1325851.1325858}
}

@INPROCEEDINGS{Pelleg2000X,
  author = {Pelleg, Dan and Moore, Andrew W and others},
  title = {X-means: Extending K-means with Efficient Estimation of the Number
	of Clusters.},
  booktitle = {ICML},
  year = {2000},
  pages = {727--734}
}

@InProceedings{Pennacchiotti2011Investigating,
  author    = {Pennacchiotti, Marco and Gurumurthy, Siva},
  title     = {Investigating Topic Models for Social Media User Recommendation},
  booktitle = {Proceedings of the 20th International Conference Companion on World Wide Web},
  year      = {2011},
  series    = {WWW '11},
  pages     = {101--102},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {The goal of this tutorial is to expose participants to the current
	research on social recommender systems (i.e., recommender systems
	for the social web). Participants will become familiar with state-of-the-art
	recommendation methods, their classifications according to various
	criteria, common evaluation methodologies, and potential applications
	that can utilize social recommender systems. Additionally, open issues
	and challenges in the field will be discussed.},
  acmid     = {1963244},
  doi       = {10.1145/1963192.1963244},
  groups    = {Twitter},
  isbn      = {978-1-4503-0637-9},
  keywords  = {LDA, social media, topic models, user recommendation},
  location  = {Hyderabad, India},
  numpages  = {2},
  url       = {http://doi.acm.org/10.1145/1963192.1963244},
}

@CONFERENCE{Petkova2006Hierarchical,
  author = {Petkova, D. and Croft, W.B.},
  title = {Hierarchical language models for expert finding in enterprise corpora},
  booktitle = {18th IEEE International Conference on Tools with Artificial Intelligence,
	2006. ICTAI'06},
  year = {2006},
  pages = {599--608},
  owner = {Cheyenne},
  timestamp = {2009.09.21}
}

@InProceedings{Petrovic2010Streaming,
  author    = {Petrovi\'{c}, Sa\v{s}a and Osborne, Miles and Lavrenko, Victor},
  title     = {Streaming first story detection with application to Twitter},
  booktitle = {Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics},
  year      = {2010},
  series    = {HLT '10},
  pages     = {181--189},
  address   = {Stroudsburg, PA, USA},
  publisher = {Association for Computational Linguistics},
  abstract  = {With the recent rise in popularity and size of social media, there
	is a growing need for systems that can extract useful information
	from this amount of data. We address the problem of detecting new
	events from a stream of Twitter posts. To make event detection feasible
	on web-scale corpora, we present an algorithm based on locality-sensitive
	hashing which is able overcome the limitations of traditional approaches,
	while maintaining competitive results. In particular, a comparison
	with a state-of-the-art system on the first story detection task
	shows that we achieve over an order of magnitude speedup in processing
	time, while retaining comparable performance. Event detection experiments
	on a collection of 160 million Twitter posts show that celebrity
	deaths are the fastest spreading news on Twitter.},
  acmid     = {1858020},
  groups    = {Twitter},
  isbn      = {1-932432-65-5},
  location  = {Los Angeles, California},
  numpages  = {9},
  url       = {http://dl.acm.org/citation.cfm?id=1857999.1858020},
}

@InProceedings{Petrovic2010Streaminga,
  author    = {Petrovi\'{c}, Sa\v{s}a and Osborne, Miles and Lavrenko, Victor},
  title     = {Streaming First Story Detection with Application to Twitter},
  booktitle = {Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics},
  year      = {2010},
  series    = {HLT '10},
  pages     = {181--189},
  address   = {Stroudsburg, PA, USA},
  publisher = {Association for Computational Linguistics},
  acmid     = {1858020},
  groups    = {Recommender Systems},
  isbn      = {1-932432-65-5},
  location  = {Los Angeles, California},
  numpages  = {9},
  url       = {http://dl.acm.org/citation.cfm?id=1857999.1858020},
}

@INPROCEEDINGS{Phan2008Learning,
  author = {Phan, Xuan-Hieu and Nguyen, Le-Minh and Horiguchi, Susumu},
  title = {Learning to classify short and sparse text \& web with hidden topics
	from large-scale data collections},
  booktitle = {WWW '08: Proceeding of the 17th international conference on World
	Wide Web},
  year = {2008},
  pages = {91--100},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1367497.1367510},
  isbn = {978-1-60558-085-2},
  location = {Beijing, China}
}

@InProceedings{Phelan2009Using,
  author    = {Phelan, Owen and McCarthy, Kevin and Smyth, Barry},
  title     = {Using Twitter to Recommend Real-time Topical News},
  booktitle = {Proceedings of the Third ACM Conference on Recommender Systems},
  year      = {2009},
  series    = {RecSys '09},
  pages     = {385--388},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Recommending news stories to users, based on their preferences, has
	long been a favourite domain for recommender systems research. In
	this paper, we describe a novel approach to news recommendation that
	harnesses real-time micro-blogging activity, from a service such
	as Twitter, as the basis for promoting news stories from a user's
	favourite RSS feeds. A preliminary evaluation is carried out on an
	implementation of this technique that shows promising results.},
  acmid     = {1639794},
  doi       = {10.1145/1639714.1639794},
  groups    = {Recommender Systems},
  isbn      = {978-1-60558-435-5},
  keywords  = {content-based recommendation, news recommendation, real-time recommendation, social recommendation, twitter},
  location  = {New York, New York, USA},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/1639714.1639794},
}

@InProceedings{Pil'aszy2010Fast,
  author    = {Pil\'{a}szy, Istv\'{a}n and Zibriczky, D\'{a}vid and Tikk, Domonkos},
  title     = {Fast als-based matrix factorization for explicit and implicit feedback datasets},
  booktitle = {Proceedings of the fourth ACM conference on Recommender systems},
  year      = {2010},
  series    = {RecSys '10},
  pages     = {71--78},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1864726},
  doi       = {http://doi.acm.org/10.1145/1864708.1864726},
  file      = {Pil'aszy2010Fast.pdf:Pil'aszy2010Fast.pdf:PDF},
  groups    = {Recommender Systems},
  isbn      = {978-1-60558-906-0},
  keywords  = {alternating least squares, collaborative filtering, computational complexity, implicit and explicit feedback, matrix factorization, ridge regression},
  location  = {Barcelona, Spain},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/1864708.1864726},
}

@Conference{plangprasopchok2009constructing,
  author       = {Plangprasopchok, A. and Lerman, K.},
  title        = {{Constructing folksonomies from user-specified relations on flickr}},
  booktitle    = {Proceedings of the 18th international conference on World wide web},
  year         = {2009},
  pages        = {781--790},
  organization = {ACM},
  abstract     = {Many social Web sites allow users to publish content and
	
	annotate with descriptive metadata. In addition to
	
	at tags, some social
	
	Web sites have recently began to allow users to organize their content
	and
	
	metadata hierarchically. The social photosharing site Flickr, for
	example,
	
	allows users to group related photos in sets, and related sets in
	collec-
	
	tions. The social bookmarking site Del.icio.us similarly lets users
	group
	
	related tags into bundles. Although the sites themselves don't impose
	
	any constraints on how these hierarchies are used, individuals generally
	
	use them to capture relationships between concepts, most commonly
	the
	
	broader/narrower relations. Collective annotation of content with
	hier-
	
	archical relations may lead to an emergent classication system, called
	a
	
	folksonomy. While some researchers have explored using tags as evidence
	
	for learning folksonomies, we believe that hierarchical relations
	described
	
	above oer a high-quality source of evidence for this task.
	
	We propose a simple approach to aggregate shallow hierarchies created
	
	by many distinct Flickr users into a common folksonomy. Our approach
	
	uses statistics to determine if a particular relation should be retained
	or
	
	discarded. The relations are then woven together into larger hierarchies.
	
	Although we have not carried out a detailed quantitative evaluation
	of
	
	the approach, it looks very promising since it generates very reasonable,
	
	non-trivial hierarchies.},
  file         = {plangprasopchok2009constructing.pdf:plangprasopchok2009constructing.pdf:PDF},
}

@INPROCEEDINGS{Ponte1998language,
  author = {Ponte, Jay M. and Croft, W. Bruce},
  title = {A language modeling approach to information retrieval},
  booktitle = {SIGIR '98: Proceedings of the 21st annual international ACM SIGIR
	conference on Research and development in information retrieval},
  year = {1998},
  pages = {275--281},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/290941.291008},
  isbn = {1-58113-015-5},
  location = {Melbourne, Australia}
}

@INPROCEEDINGS{Porteous2008Fast,
  author = {Porteous, Ian and Newman, David and Ihler, Alexander and Asuncion,
	Arthur and Smyth, Padhraic and Welling, Max},
  title = {Fast collapsed gibbs sampling for latent dirichlet allocation},
  booktitle = {KDD '08: Proceeding of the 14th ACM SIGKDD international conference
	on Knowledge discovery and data mining},
  year = {2008},
  pages = {569--577},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1401890.1401960},
  isbn = {978-1-60558-193-4},
  location = {Las Vegas, Nevada, USA}
}

@INPROCEEDINGS{Potthast2010Opinion,
  author = {Potthast, Martin and Becker, Steffen},
  title = {Opinion Summarization of Web Comments},
  booktitle = {Proceedings of the 32Nd European Conference on Advances in Information
	Retrieval},
  year = {2010},
  series = {ECIR'2010},
  pages = {668--669},
  address = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  acmid = {2128430},
  doi = {10.1007/978-3-642-12275-0_73},
  file = {Potthast2010Opinion.pdf:Potthast2010Opinion.pdf:PDF},
  isbn = {3-642-12274-4, 978-3-642-12274-3},
  location = {Milton Keynes, UK},
  numpages = {2},
  url = {http://dx.doi.org/10.1007/978-3-642-12275-0_73}
}

@INPROCEEDINGS{Pound2011Facet,
  author = {Pound, Jeffrey and Paparizos, Stelios and Tsaparas, Panayiotis},
  title = {Facet Discovery for Structured Web Search: A Query-log Mining Approach},
  booktitle = {Proceedings of the 2011 ACM SIGMOD International Conference on Management
	of Data},
  year = {2011},
  series = {SIGMOD '11},
  pages = {169--180},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {1989342},
  doi = {10.1145/1989323.1989342},
  isbn = {978-1-4503-0661-4},
  keywords = {faceted search, facets, structured web-search},
  location = {Athens, Greece},
  numpages = {12},
  url = {http://doi.acm.org/10.1145/1989323.1989342}
}

@INPROCEEDINGS{Pradel2012Ranking,
  author = {Pradel, Bruno and Usunier, Nicolas and Gallinari, Patrick},
  title = {Ranking with Non-random Missing Ratings: Influence of Popularity
	and Positivity on Evaluation Metrics},
  booktitle = {Proceedings of the Sixth ACM Conference on Recommender Systems},
  year = {2012},
  series = {RecSys '12},
  pages = {147--154},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {The evaluation of recommender systems in terms of ranking has recently
	gained attention, as it seems to better fit the top-k recommendation
	task than the usual ratings prediction task. In that context, several
	authors have proposed to consider missing ratings as some form of
	negative feedback to compensate for the skewed distribution of observed
	ratings when users choose the items they rate. In this work, we study
	two major biases of the selection of items: the first one is that
	some items obtain more ratings than others (popularity effect), and
	the second one is that positive ratings are observed more frequently
	than negative ratings (positivity effect). We present a theoretical
	analysis and experiments on the Yahoo! dataset with randomly selected
	items, which show that considering missing data as a form of negative
	feedback during training may improve performances, but also that
	it can be misleading when testing, favoring models of popularity
	more than models of user preferences.},
  acmid = {2365982},
  isbn = {978-1-4503-1270-7},
  keywords = {evaluation, ranking, recommender system},
  location = {Dublin, Ireland},
  numpages = {8},
  timestamp = {2015.12.23}
}

@TECHREPORT{Procaccia2015Optimal,
  author = {Procaccia, Ariel D and Shah, Nisarg},
  title = {Optimal Aggregation of Uncertain Preferences},
  year = {2015},
  file = {Procaccia2015Optimal.pdf:Procaccia2015Optimal.pdf:PDF}
}

@InProceedings{Qamra2006Mining,
  author    = {Qamra, Arun and Tseng, Belle and Chang, Edward Y.},
  title     = {Mining blog stories using community-based and temporal clustering},
  booktitle = {Proceedings of the 15th ACM international conference on Information and knowledge management},
  year      = {2006},
  series    = {CIKM '06},
  pages     = {58--67},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {In recent years, weblogs, or blogs for short, have become an important
	form of online content. The personal nature of blogs, online interactions
	between bloggers, and the temporal nature of blog entries, differentiate
	blogs from other kinds of Web content. Bloggers interact with each
	other by linking to each other's posts, thus forming online communities.
	Within these communities, bloggers engage in discussions of certain
	issues, through entries in their blogs. Since these discussions are
	often initiated in response to online or offline events, a discussion
	typically lasts for a limited time duration. We wish to extract such
	temporal discussions, or stories, occurring within blogger communities,
	based on some query keywords. We propose a Content-Community-Time
	model that can leverage the content of entries, their timestamps,
	and the community structure of the blogs, to automatically discover
	stories. Doing so also allows us to discover hot stories. We demonstrate
	the effectiveness of our model through several case studies using
	real-world data collected from the blogosphere.},
  acmid     = {1183627},
  doi       = {http://doi.acm.org/10.1145/1183614.1183627},
  file      = {Qamra2006Mining.pdf:Qamra2006Mining.pdf:PDF},
  groups    = {Twitter},
  isbn      = {1-59593-433-2},
  keywords  = {online-communities, time-sensitive clustering, weblogs},
  location  = {Arlington, Virginia, USA},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1183614.1183627},
}

@ARTICLE{Qiu2011Opinion,
  author = {Qiu, Guang and Liu, Bing and Bu, Jiajun and Chen, Chun},
  title = {Opinion word expansion and target extraction through double propagation},
  journal = {Computational linguistics},
  year = {2011},
  volume = {37},
  pages = {9--27},
  number = {1},
  file = {Qiu2011Opinion.pdf:Qiu2011Opinion.pdf:PDF},
  publisher = {MIT Press}
}

@INPROCEEDINGS{Qiu2013Modeling,
  author = {Qiu, Minghui and Yang, Liu and Jiang, Jing},
  title = {Modeling Interaction Features for Debate Side Clustering},
  booktitle = {Proceedings of the 22Nd ACM International Conference on Conference
	on Information and Knowledge Management},
  year = {2013},
  series = {CIKM '13},
  pages = {873--878},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Online discussion forums are popular social media platforms for users
	to express their opinions and discuss controversial issues with each
	other. To automatically identify the sides/stances of posts or users
	from textual content in forums is an important task to help mine
	online opinions. To tackle the task, it is important to exploit user
	posts that implicitly contain support and dispute (interaction) information.
	The challenge we face is how to mine such interaction information
	from the content of posts and how to use them to help identify stances.
	This paper proposes a two-stage solution based on latent variable
	models: an interaction feature identification stage to mine interaction
	features from structured debate posts with known sides and reply
	intentions; and a clustering stage to incorporate interaction features
	and model the interplay between interactions and sides for debate
	side clustering. Empirical evaluation shows that the learned interaction
	features provide good insights into user interactions and that with
	these features our debate side model shows significant improvement
	over other baseline methods.},
  acmid = {2505634},
  doi = {10.1145/2505515.2505634},
  file = {Qiu2013Modeling.pdf:Qiu2013Modeling.pdf:PDF},
  isbn = {978-1-4503-2263-8},
  keywords = {interaction features, latent variable model, side/stance identification},
  location = {San Francisco, California, USA},
  numpages = {6},
  timestamp = {2015.09.01},
  url = {http://doi.acm.org/10.1145/2505515.2505634}
}

@INPROCEEDINGS{Qu2010Bag,
  author = {Qu, Lizhen and Ifrim, Georgiana and Weikum, Gerhard},
  title = {The Bag-of-opinions Method for Review Rating Prediction from Sparse
	Text Patterns},
  booktitle = {Proceedings of the 23rd International Conference on Computational
	Linguistics},
  year = {2010},
  series = {COLING '10},
  pages = {913--921},
  address = {Stroudsburg, PA, USA},
  publisher = {Association for Computational Linguistics},
  abstract = {The problem addressed in this paper is to predict a user's numeric
	rating in a product review from the text of the review. Unigram and
	n-gram representations of text are common choices in opinion mining.
	However, unigrams cannot capture important expressions like "could
	have been better", which are essential for prediction models of ratings.
	N-grams of words, on the other hand, capture such phrases, but typically
	occur too sparsely in the training set and thus fail to yield robust
	predictors. This paper overcomes the limitations of these two models,
	by introducing a novel kind of bag-of-opinions representation, where
	an opinion, within a review, consists of three components: a root
	word, a set of modifier words from the same sentence, and one or
	more negation words. Each opinion is assigned a numeric score which
	is learned, by ridge regression, from a large, domain-independent
	corpus of reviews. For the actual test case of a domain-dependent
	review, the review's rating is predicted by aggregating the scores
	of all opinions in the review and combining it with a domain-dependent
	unigram model. The paper presents a constrained ridge regression
	algorithm for learning opinion scores. Experiments show that the
	bag-of-opinions method outperforms prior state-of-the-art techniques
	for review rating prediction.},
  acmid = {1873884},
  file = {Qu2010Bag.pdf:Qu2010Bag.pdf:PDF},
  location = {Beijing, China},
  numpages = {9}
}

@InProceedings{Qu2011Microblogging,
  author    = {Qu, Yan and Huang, Chen and Zhang, Pengyi and Zhang, Jun},
  title     = {Microblogging after a major disaster in China: a case study of the 2010 Yushu earthquake},
  booktitle = {Proceedings of the ACM 2011 conference on Computer supported cooperative work},
  year      = {2011},
  series    = {CSCW '11},
  pages     = {25--34},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1958830},
  doi       = {http://doi.acm.org/10.1145/1958824.1958830},
  groups    = {Twitter},
  isbn      = {978-1-4503-0556-3},
  keywords  = {Yushu earthquake, disaster response, microblogging},
  location  = {Hangzhou, China},
  numpages  = {10},
  owner     = {linchen},
  timestamp = {2011.11.01},
  url       = {http://doi.acm.org/10.1145/1958824.1958830},
}

@INPROCEEDINGS{Rabinovich2014Inverse,
  author = {Maxim Rabinovich and David Blei},
  title = {The Inverse Regression Topic Model},
  booktitle = {Proceedings of ICML},
  year = {2014},
  pages = {365-373},
  abstract = {\citet{taddy13mnir} proposed multinomial inverse regression (MNIR)
	as a new model of annotated text based on the influence of metadata
	and response variables on the distribution of words in a document.
	While effective, MNIR has no way to exploit structure in the corpus
	to improve its predictions or facilitate exploratory data analysis.
	On the other hand, traditional probabilistic topic models (like latent
	Dirichlet allocation) capture natural heterogeneity in a collection
	but do not account for external variables. In this paper, we introduce
	the inverse regression topic model (IRTM), a mixed-membership extension
	of MNIR that combines the strengths of both methodologies. We present
	two inference algorithms for the IRTM: an efficient batch estimation
	algorithm and an online variant, which is suitable for large corpora.
	We apply these methods to a corpus of 73K Congressional press releases
	and another of 150K Yelp reviews, demonstrating that the IRTM outperforms
	both MNIR and supervised topic models on the prediction task. Further,
	we give examples showing that the IRTM enables systematic discovery
	of in-topic lexical variation, which is not possible with previous
	supervised topic models.},
  file = {Rabinovich2014Inverse.pdf:Rabinovich2014Inverse.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.06.24}
}

@InProceedings{Radinsky2013Mining,
  author    = {Radinsky, Kira and Horvitz, Eric},
  title     = {{Mining the web to predict future events}},
  booktitle = {Proceedings of the sixth ACM international conference on Web search and data mining - WSDM '13},
  year      = {2013},
  pages     = {255},
  address   = {New York, New York, USA},
  month     = feb,
  publisher = {ACM Press},
  abstract  = {We describe and evaluate methods for learning to forecast forthcoming
	events of interest from a corpus containing 22 years of news stories.
	We consider the examples of identifying significant increases in
	the likelihood of disease outbreaks, deaths, and riots in advance
	of the occurrence of these events in the world. We provide details
	of methods and studies, including the automated extraction and generalization
	of sequences of events from news corpora and multiple web resources.
	We evaluate the predictive power of the approach on real-world events
	withheld from the system.},
  doi       = {10.1145/2433396.2433431},
  groups    = {Twitter},
  isbn      = {9781450318693},
  keywords  = {event prediction,future prediction,news prediction,web knowledge for future prediction},
  url       = {http://dl.acm.org/citation.cfm?id=2433396.2433431},
}

@InProceedings{Raghavan2012Review,
  author    = {Raghavan, Sindhu and Gunasekar, Suriya and Ghosh, Joydeep},
  title     = {Review Quality Aware Collaborative Filtering},
  booktitle = {Proceedings of the Sixth ACM Conference on Recommender Systems},
  year      = {2012},
  series    = {RecSys '12},
  pages     = {123--130},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Probabilistic matrix factorization (PMF) and other popular approaches
	to collaborative filtering assume that the ratings given by users
	for products are genuine, and hence they give equal importance to
	all available ratings. However, this is not always true due to several
	reasons including the presence of opinion spam in product reviews.
	In this paper, the possibility of performing collaborative filtering
	while attaching weights or quality scores to the ratings is explored.
	The quality scores, which are determined from the corresponding review
	data are used to "up-weight" or "down-weight" the importance given
	to the individual rating while performing collaborative filtering,
	thereby improving the accuracy of the predictions. First, the measure
	used to capture the quality of the ratings is described. Different
	approaches for estimating the quality score based on the available
	review information are examined. Subsequently, a mathematical formulation
	to incorporate quality scores as weights for the ratings in the basic
	PMF framework is derived. Experimental evaluation on two product
	categories of a benchmark data set from Amazon.com demonstrates the
	efficacy of our approach.},
  acmid     = {2365978},
  comment   = {text,metadata features to predict review score, ground truth is vote
	"helpful" ratio, linear regression
	
	rating with review score, maximal likelihood
	
	PMF framework},
  doi       = {10.1145/2365952.2365978},
  file      = {Raghavan2012Review.pdf:Raghavan2012Review.pdf:PDF},
  groups    = {Recommender Systems},
  isbn      = {978-1-4503-1270-7},
  keywords  = {collaborative filtering, probabilistic matrix factorization, recommender systems, review quality},
  location  = {Dublin, Ireland},
  numpages  = {8},
  timestamp = {2014.06.09},
  url       = {http://doi.acm.org/10.1145/2365952.2365978},
}

@INPROCEEDINGS{Raina2007Self-taught,
  author = {Rajat Raina and Alexix Battle and Honglak Lee and Benjamin Packer
	and Andrew Y.Ng},
  title = {Self-taught Learning: Transfer Learning from Unlabeled Data},
  booktitle = {Proc. 24$^{th}$ ICML},
  year = {2007},
  address = {Corvallis, OR},
  owner = {Cheyenne},
  timestamp = {2009.09.21}
}

@INPROCEEDINGS{Ramage2009Labeled,
  author = {Ramage, Daniel and Hall, David and Nallapati, Ramesh and Manning,
	Christopher D.},
  title = {Labeled LDA: A Supervised Topic Model for Credit Attribution in Multi-labeled
	Corpora},
  booktitle = {Proceedings of the 2009 Conference on Empirical Methods in Natural
	Language Processing: Volume 1 - Volume 1},
  year = {2009},
  series = {EMNLP '09},
  pages = {248--256},
  address = {Stroudsburg, PA, USA},
  publisher = {Association for Computational Linguistics},
  acmid = {1699543},
  isbn = {978-1-932432-59-6},
  location = {Singapore},
  numpages = {9}
}

@INPROCEEDINGS{Ranade2013Online,
  author = {Ranade, Sarvesh and Gupta, Jayant and Varma, Vasudeva and Mamidi,
	Radhika},
  title = {Online Debate Summarization Using Topic Directed Sentiment Analysis},
  booktitle = {Proceedings of the Second International Workshop on Issues of Sentiment
	Discovery and Opinion Mining},
  year = {2013},
  series = {WISDOM '13},
  pages = {7:1--7:6},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Social networking sites provide users a virtual community interaction
	platform to share their thoughts, life experiences and opinions.
	Online debate forum is one such platform where people can take a
	stance and argue in support or opposition of debate topics. An important
	feature of such forums is that, they are dynamic and increase rapidly.
	In such situations, effective opinion summarization approaches are
	needed so that readers need not go through the entire debate. This
	paper aims to summarize online debates by extracting highly topic
	relevant and sentiment rich sentences. The proposed approach takes
	into account topic relevant, document relevant and sentiment based
	features to capture topic opinionated sentences. ROUGE scores are
	used to evaluate our system. Our system significantly outperforms
	several baseline systems and show 5.2% (ROUGE-1), 7.3% (ROUGE-2)
	and 5.5% (ROUGE-L) improvement over the state-of-the-art opinion
	summarization system. The results verify that topic directed sentiment
	features are most important to generate effective debate summaries.},
  acmid = {2502076},
  articleno = {7},
  doi = {10.1145/2502069.2502076},
  file = {Ranade2013Online.pdf:Ranade2013Online.pdf:PDF},
  isbn = {978-1-4503-2332-1},
  location = {Chicago, Illinois},
  numpages = {6},
  timestamp = {2015.08.31},
  url = {http://doi.acm.org/10.1145/2502069.2502076}
}

@Article{Ratkiewicz2010Detecting,
  author    = {Jacob Ratkiewicz and Michael Conover and Mark Meiss and Bruno Gon\c{c}alves and Snehal Patil and Alessandro Flammini and Filippo Menczer},
  title     = {Detecting and Tracking the Spread of Astroturf Memes in Microblog Streams},
  journal   = {CoRR},
  year      = {2010},
  volume    = {abs/1011.3768},
  bibsource = {DBLP, http://dblp.uni-trier.de},
  ee        = {http://arxiv.org/abs/1011.3768},
  groups    = {Twitter},
  owner     = {linchen},
  timestamp = {2011.11.01},
}

@InProceedings{Raue2013Trapped,
  author    = {Raue, Stefan and Azzopardi, Leif and Johnson, Chris W.},
  title     = {\#Trapped!: Social Media Search System Requirements for Emergency Management Professionals},
  booktitle = {Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year      = {2013},
  series    = {SIGIR '13},
  pages     = {1073--1076},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Social media provides a new and potentially rich source of information
	for emergency management services. However, extracting the relevant
	information from such streams poses a number of difficult challenges.
	In this short paper, we survey emergency management professionals
	to ascertain how social media is used when responding to incidents,
	the search strategies that they undertake, and the challenges that
	they face when using social media streams. This research indicates
	that emergency management professionals employ two main strategies
	when searching social media streams: keyword-centric and account-centric
	search strategies. Furthermore, current search interfaces are inadequate
	regarding the requirements of command and control environments in
	the emergency management domain, where the process of information
	seeking is collaborative in nature and needs to support multiple
	information seekers.},
  acmid     = {2484184},
  doi       = {10.1145/2484028.2484184},
  groups    = {Twitter},
  isbn      = {978-1-4503-2034-4},
  keywords  = {emergency management, information seeking},
  location  = {Dublin, Ireland},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/2484028.2484184},
}

@INPROCEEDINGS{Ren2008Dynamic,
  author = {Lu Ren and David B. Dunson and Lawrence Carin},
  title = {The Dynamic Hierarchical Dirichlet Process},
  booktitle = {the 25 th International Conference on Machine Learning},
  year = {2008},
  pages = {824-831},
  address = {Helsinki, Finland},
  file = {Ren2008Dynamic.pdf:Ren2008Dynamic.pdf:PDF},
  owner = {linchen},
  timestamp = {2015.08.26}
}

@InProceedings{Ren2013Personalized,
  author    = {Ren, Zhaochun and Liang, Shangsong and Meij, Edgar and de Rijke, Maarten},
  title     = {Personalized time-aware tweets summarization},
  booktitle = {Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval},
  year      = {2013},
  series    = {SIGIR '13},
  pages     = {513--522},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {We focus on the problem of selecting meaningful tweets given a
	
	user’s interests; the dynamic nature of user interests, the sheer
	volume,
	
	and the sparseness of individual messages make this an challenging
	
	problem. Specifically, we consider the task of time-aware
	
	tweets summarization, based on a user’s history and collaborative
	
	social influences from “social circles.” We propose a time-aware
	
	user behavior model, the Tweet Propagation Model (TPM), in which
	
	we infer dynamic probabilistic distributions over interests and topics.
	
	We then explicitly consider novelty, coverage, and diversity
	
	to arrive at an iterative optimization algorithm for selecting tweets.
	
	Experimental results validate the effectiveness of our personalized
	
	time-aware tweets summarization method based on TPM.},
  acmid     = {2484052},
  doi       = {10.1145/2484028.2484052},
  file      = {Ren2013Personalized.pdf:Ren2013Personalized.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-1-4503-2034-4},
  keywords  = {data enrichment, topic modeling, tweets summarization, twitter},
  location  = {Dublin, Ireland},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2484028.2484052},
}

@InProceedings{Rendle2009BPR,
  author    = {Rendle, Steffen and Freudenthaler, Christoph and Gantner, Zeno and Schmidt-Thieme, Lars},
  title     = {BPR: Bayesian Personalized Ranking from Implicit Feedback},
  booktitle = {Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence},
  year      = {2009},
  series    = {UAI '09},
  pages     = {452--461},
  address   = {Arlington, Virginia, United States},
  publisher = {AUAI Press},
  abstract  = {Item recommendation is the task of predicting a personalized ranking
	on a set of items (e.g. websites, movies, products). In this paper,
	we investigate the most common scenario with implicit feedback (e.g.
	clicks, purchases). There are many methods for item recommendation
	from implicit feedback like matrix factorization (MF) or adaptive
	k-nearest-neighbor (kNN). Even though these methods are designed
	for the item prediction task of personalized ranking, none of them
	is directly optimized for ranking. In this paper we present a generic
	optimization criterion BPR-Opt for personalized ranking that is the
	maximum posterior estimator derived from a Bayesian analysis of the
	problem. We also provide a generic learning algorithm for optimizing
	models with respect to BPR-Opt. The learning method is based on stochastic
	gradient descent with bootstrap sampling. We show how to apply our
	method to two state-of-the-art recommender models: matrix factorization
	and adaptive kNN. Our experiments indicate that for the task of personalized
	ranking our optimization method outperforms the standard learning
	techniques for MF and kNN. The results show the importance of optimizing
	models for the right criterion.},
  acmid     = {1795167},
  comment   = {The remaining
	
	data is a mixture of actually negative and missing
	
	values.
	
	
	logistic regression for pairwise items, which include implicit and
	explicitly rated items},
  file      = {Rendle2009BPR.pdf:Rendle2009BPR.pdf:PDF},
  groups    = {Recommender Systems},
  isbn      = {978-0-9749039-5-8},
  location  = {Montreal, Quebec, Canada},
  numpages  = {10},
  timestamp = {2015.09.21},
}

@INPROCEEDINGS{Rendle2011Fast,
  author = {Rendle, Steffen and Gantner, Zeno and Freudenthaler, Christoph and
	Schmidt-Thieme, Lars},
  title = {Fast Context-aware Recommendations with Factorization Machines},
  booktitle = {Proceedings of the 34th International ACM SIGIR Conference on Research
	and Development in Information Retrieval},
  year = {2011},
  series = {SIGIR '11},
  pages = {635--644},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {The situation in which a choice is made is an important information
	for recommender systems. Context-aware recommenders take this information
	into account to make predictions. So far, the best performing method
	for context-aware rating prediction in terms of predictive accuracy
	is Multiverse Recommendation based on the Tucker tensor factorization
	model. However this method has two drawbacks: (1) its model complexity
	is exponential in the number of context variables and polynomial
	in the size of the factorization and (2) it only works for categorical
	context variables. On the other hand there is a large variety of
	fast but specialized recommender methods which lack the generality
	of context-aware methods.
	
	
	We propose to apply Factorization Machines (FMs) to model contextual
	information and to provide context-aware rating predictions. This
	approach results in fast context-aware recommendations because the
	model equation of FMs can be computed in linear time both in the
	number of context variables and the factorization size. For learning
	FMs, we develop an iterative optimization method that analytically
	finds the least-square solution for one parameter given the other
	ones. Finally, we show empirically that our approach outperforms
	Multiverse Recommendation in prediction quality and runtime.},
  acmid = {2010002},
  doi = {10.1145/2009916.2010002},
  file = {Rendle2011Fast.pdf:Rendle2011Fast.pdf:PDF},
  isbn = {978-1-4503-0757-4},
  keywords = {context-aware recommender system, factorization machine, rating prediction,
	tensor factorization},
  location = {Beijing, China},
  numpages = {10},
  url = {http://doi.acm.org/10.1145/2009916.2010002}
}

@InProceedings{Rendle2008Onlineupdating,
  author    = {Rendle, Steffen and Schmidt-Thie Lars},
  title     = {Online-updating regularized kernel matrix factorization models for large-scale recommender systems},
  booktitle = {Proceedings of the 2008 ACM conference on Recommender systems},
  year      = {2008},
  series    = {RecSys '08},
  pages     = {251--258},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1454047},
  doi       = {http://doi.acm.org/10.1145/1454008.1454047},
  file      = {Rendle2008Onlineupdating.pdf:Rendle2008Onlineupdating.pdf:PDF},
  groups    = {Recommender Systems},
  isbn      = {978-1-60558-093-7},
  keywords  = {matrix factorization, online-update, recommender system},
  location  = {Lausanne, Switzerland},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/1454008.1454047},
}

@InProceedings{Rennie2005Fasta,
  author       = {Rennie, J.D.M. and Srebro, N.},
  title        = {Fast maximum margin matrix factorization for collaborative prediction},
  booktitle    = {Proceedings of the 22nd international conference on Machine learning},
  year         = {2005},
  pages        = {713--719},
  organization = {ACM},
  abstract     = {Maximum Margin Matrix Factorization
	
	(MMMF) was recently suggested (Srebro
	
	et al., 2005) as a convex, infinite dimensional
	
	alternative to low-rank approximations and
	
	standard factor models. MMMF can be formulated
	
	as a semi-definite programming (SDP) and
	
	learned using standard SDP solvers. However,
	
	current SDP solvers can only handle MMMF
	
	problems on matrices of dimensionality up to
	
	a few hundred. Here, we investigate a direct
	
	gradient-based optimization method for MMMF
	
	and demonstrate it on large collaborative prediction
	
	problems. We compare against results
	
	obtained by Marlin (2004) and find that MMMF
	
	substantially outperforms all nine methods he
	
	tested.},
  file         = {Rennie2005Fasta.pdf:Rennie2005Fasta.pdf:PDF},
  groups       = {Recommender Systems},
}

@ARTICLE{Richardson2002intelligent,
  author = {Richardson, M. and Domingos, P.},
  title = {The intelligent surfer: Probabilistic combination of link and content
	information in pagerank},
  journal = {Advances in Neural Information Processing Systems},
  year = {2002},
  volume = {2},
  pages = {1441--1448},
  publisher = {MIT; 1998}
}

@InProceedings{Rosen-Zvi2004author-topic,
  author    = {M. Rosen-Zvi and T. Griffiths and M. Steyvers and P. Smyth},
  title     = {The author-topic model for authors and documents},
  booktitle = {Proceeding of UAI},
  year      = {2004},
  pages     = {487--494},
  groups    = {LDA},
}

@InProceedings{Roth2010Suggesting,
  author    = {Roth, Maayan and Ben-David, Assaf and Deutscher, David and Flysher, Guy and Horn, Ilan and Leichtberg, Ari and Leiser, Naty and Matias, Yossi and Merom, Ron},
  title     = {Suggesting friends using the implicit social graph},
  booktitle = {Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining},
  year      = {2010},
  series    = {KDD '10},
  pages     = {233--242},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1835836},
  doi       = {http://doi.acm.org/10.1145/1835804.1835836},
  file      = {Roth2010Suggesting.pdf:Roth2010Suggesting.pdf:PDF},
  isbn      = {978-1-4503-0055-1},
  keywords  = {contact group clustering, implicit social graph, tie strength},
  location  = {Washington, DC, USA},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1835804.1835836},
}

@InProceedings{Rowlands2010New-web,
  author    = {Rowlands, Tom and Hawking, David and Sankaranarayana, Ramesh},
  title     = {New-web search with microblog annotations},
  booktitle = {Proceedings of the 19th international conference on World wide web},
  year      = {2010},
  series    = {WWW '10},
  pages     = {1293--1296},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Web search engines discover indexable documents by recursively 'crawling'
	from a seed URL. Their rankings take into account link popularity.
	While this works well, it introduces biases towards older documents.
	Older documents are more likely to be the target of links, while
	new documents with few, or no, incoming links are unlikely to rank
	highly in search results.
	
	
	We describe a novel system for 'new-Web' search based on links retrieved
	from the Twitter micro-blogging service. The Twitter service allows
	individuals, organisations and governments to rapidly disseminate
	very short messages to a wide variety of interested parties. When
	a Twitter message contains a URL, we use the Twitter message as a
	description of the URL's target. As Twitter is frequently used for
	discussion of current events, these messages offer useful, up- to-date
	annotations and instantaneous popularity readings for a small, but
	timely, portion of the Web.
	
	
	Our working system is simple and fast and we believe may offer a significant
	advantage in revealing new information on the Web that would otherwise
	be hidden from searchers. Beyond the basic system, we anticipate
	the Twitter messages may add supplementary terms for a URL, or add
	weight to existing terms, and that the reputation or authority of
	each message sender may serve to weight both annotations and query-independent
	popularity.},
  acmid     = {1772905},
  comment   = {twitter's characteristics about ongoing event},
  doi       = {http://doi.acm.org/10.1145/1772690.1772905},
  groups    = {Twitter},
  isbn      = {978-1-60558-799-8},
  keywords  = {demonstration, information retrieval, microblogging, search, twitter, web search},
  location  = {Raleigh, North Carolina, USA},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/1772690.1772905},
}

@InProceedings{Ruzzo1999linear,
  author       = {Ruzzo, W.L. and Tompa, M.},
  title        = {A linear time algorithm for finding all maximal scoring subsequences},
  booktitle    = {Proceedings of the Seventh International Conference on Intelligent Systems for Molecular Biology},
  year         = {1999},
  pages        = {234--241},
  organization = {AAAI Press},
  file         = {Ruzzo1999linear.pdf:Ruzzo1999linear.pdf:PDF},
  groups       = {Twitter},
}

@INPROCEEDINGS{Sahoo2006Incremental,
  author = {Sahoo, Nachiketa and Callan, Jamie and Krishnan, Ramayya and Duncan,
	George and Padman, Rema},
  title = {Incremental Hierarchical Clustering of Text Documents},
  booktitle = {Proceedings of the 15th ACM International Conference on Information
	and Knowledge Management},
  year = {2006},
  series = {CIKM '06},
  pages = {357--366},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Incremental hierarchical text document clustering algorithms are important
	in organizing documents generated from streaming on-line sources,
	such as, Newswire and Blogs. However, this is a relatively unexplored
	area in the text document clustering literature. Popular incremental
	hierarchical clustering algorithms, namely Cobweb and Classit, have
	not been widely used with text document data. We discuss why, in
	the current form, these algorithms are not suitable for text clustering
	and propose an alternative formulation that includes changes to the
	underlying distributional assumption of the algorithm in order to
	conform with the data. Both the original Classit algorithm and our
	proposed algorithm are evaluated using Reuters newswire articles
	and Ohsumed dataset.},
  acmid = {1183667},
  file = {Sahoo2006Incremental.pdf:Sahoo2006Incremental.pdf:PDF},
  isbn = {1-59593-433-2},
  keywords = {hierarchical clustering, incremental clustering, text clustering},
  location = {Arlington, Virginia, USA},
  numpages = {10},
  timestamp = {2015.10.01}
}

@InProceedings{Sakaki2010Earthquake,
  author    = {Sakaki, Takeshi and Okazaki, Makoto and Matsuo, Yutaka},
  title     = {Earthquake shakes Twitter users: real-time event detection by social sensors},
  booktitle = {Proceedings of the 19th international conference on World wide web},
  year      = {2010},
  series    = {WWW '10},
  pages     = {851--860},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Twitter, a popular microblogging service, has received much
	
	attention recently. An important characteristic of Twitter
	
	is its real-time nature. For example, when an earthquake
	
	occurs, people make many Twitter posts (tweets) related
	
	to the earthquake, which enables detection of earthquake
	
	occurrence promptly, simply by observing the tweets. As
	
	described in this paper, we investigate the real-time interaction
	
	of events such as earthquakes, in Twitter, and propose
	
	an algorithm to monitor tweets and to detect a target
	
	event. To detect a target event, we devise a classifier of
	
	tweets based on features such as the keywords in a tweet,
	
	the number of words, and their context. Subsequently, we
	
	produce a probabilistic spatiotemporal model for the target
	
	event that can find the center and the trajectory of the
	
	event location. We consider each Twitter user as a sensor
	
	and apply Kalman filtering and particle filtering, which are
	
	widely used for location estimation in ubiquitous/pervasive
	
	computing. The particle filter works better than other compared
	
	methods in estimating the centers of earthquakes and
	
	the trajectories of typhoons. As an application, we construct
	
	an earthquake reporting system in Japan. Because
	
	of the numerous earthquakes and the large number of Twitter
	
	users throughout the country, we can detect an earthquake
	
	by monitoring tweets with high probability (96% of
	
	earthquakes of Japan Meteorological Agency (JMA) seismic
	
	intensity scale 3 or more are detected). Our system
	
	detects earthquakes promptly and sends e-mails to registered
	
	users. Notification is delivered much faster than the
	
	announcements that are broadcast by the JMA.},
  acmid     = {1772777},
  comment   = {main contribution: detect the center location for an earthquake},
  doi       = {http://doi.acm.org/10.1145/1772690.1772777},
  file      = {Sakaki2010Earthquake.pdf:Sakaki2010Earthquake.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-1-60558-799-8},
  keywords  = {Twitter, earthquake, event detection, location estimation, social sensor},
  location  = {Raleigh, North Carolina, USA},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1772690.1772777},
}

@Article{salakhutdinov2008probabilistic,
  author    = {Salakhutdinov, R. and Mnih, A.},
  title     = {Probabilistic matrix factorization},
  journal   = {Advances in neural information processing systems},
  year      = {2008},
  volume    = {20},
  pages     = {1257--1264},
  abstract  = {Many existing approaches to collaborative filtering can neither handle
	very large
	
	datasets nor easily deal with users who have very few ratings. In
	this paper we
	
	present the Probabilistic Matrix Factorization (PMF) model which scales
	linearly
	
	with the number of observations and, more importantly, performs well
	on the
	
	large, sparse, and very imbalanced Netflix dataset. We further extend
	the PMF
	
	model to include an adaptive prior on the model parameters and show
	how the
	
	model capacity can be controlled automatically. Finally, we introduce
	a constrained
	
	version of the PMF model that is based on the assumption that users
	who
	
	have rated similar sets of movies are likely to have similar preferences.
	The resulting
	
	model is able to generalize considerably better for users with very
	few ratings.
	
	When the predictions of multiple PMF models are linearly combined
	with the
	
	predictions of Restricted Boltzmann Machines models, we achieve an
	error rate
	
	of 0.8861, that is nearly 7% better than the score of Netflix’s own
	system.},
  comment   = {idea: probabilistic matrix factorization
	
	 the property of minimizing least square equals to minimize log posterior
	of normal distribution
	
	main contribution:
	
	1)probabilistic form
	
	2)add bias to improve for infrequent users (user prior: a similarity
	matrix)
	
	 data:
	
	Netflix},
  file      = {salakhutdinov2008probabilistic.pdf:salakhutdinov2008probabilistic.pdf:PDF},
  groups    = {Recommender Systems},
  publisher = {Citeseer},
}

@INPROCEEDINGS{Sanchez-Vilas2011Applying,
  author = {Sanchez-Vilas, Fernando and Ismoilov, Jasur and Lousame, Fab\'{\i}n
	P. and Sanchez, Eduardo and Lama, Manuel},
  title = {Applying Multicriteria Algorithms to Restaurant Recommendation},
  booktitle = {Proceedings of the 2011 IEEE/WIC/ACM International Conferences on
	Web Intelligence and Intelligent Agent Technology - Volume 01},
  year = {2011},
  series = {WI-IAT '11},
  pages = {87--91},
  address = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  abstract = {In this paper we propose two novel multicriteria recommendation algorithms
	and present a comparison with other recommendation approaches in
	the gastronomic domain. The motivation comes from the fact that traditional
	single criterion approaches consider that two users share the same
	taste when they provide similar global ratings on the experienced
	items. However, these users could agree on global ratings while having
	completely different priorities on item attributes and different
	preferences on attribute values. Multicriteria recommenders seem
	to be a promising solution for this problem as they aggregate user
	ratings on several item components in order to generate more accurate
	recommendations. Experiments conducted on Santiago(e)Tapas, a real
	gastronomic contest where customers evaluate different aspects of
	several restaurants, demonstrate that one of our algorithms, Support
	Distance Weighting, outperforms other multi-criteria and single-criterion
	algorithms in terms of prediction precision.},
  acmid = {2052429},
  doi = {10.1109/WI-IAT.2011.124},
  isbn = {978-0-7695-4513-4},
  keywords = {collaborative filtering, multicriteria algorithms, tourism, gastronomy},
  numpages = {5},
  url = {http://dx.doi.org/10.1109/WI-IAT.2011.124}
}

@InProceedings{Sarwar2001Item-based,
  author       = {Sarwar, B. and Karypis, G. and Konstan, J. and Reidl, J.},
  title        = {Item-based collaborative filtering recommendation algorithms},
  booktitle    = {Proceedings of the 10th international conference on World Wide Web},
  year         = {2001},
  pages        = {285--295},
  organization = {ACM},
  comment      = {Generate representative sentences for each date.
	
	The selected sentences should
	
	relevant to query
	
	coverage: cover topics within the date and in the whole relevant articles
	
	coherent: certain degree of dependency on neighbors
	
	diversity: different with other sentences},
  file         = {Sarwar2001Item-based.pdf:Sarwar2001Item-based.pdf:PDF},
  groups       = {Recommender Systems},
}

@BOOK{sarwar2000application,
  title = {{Application of dimensionality reduction in recommender system-a
	case study}},
  publisher = {Citeseer},
  year = {2000},
  author = {Sarwar, B. and Karypis, G. and Konstan, J. and Riedl, J. and MINNESOTA
	UNIV MINNEAPOLIS DEPT OF COMPUTER SCIENCE.},
  file = {sarwar2000application.pdf:sarwar2000application.pdf:PDF}
}

@INPROCEEDINGS{Sato2012Practical,
  author = {Sato, Issei and Kurihara, Kenichi and Nakagawa, Hiroshi},
  title = {Practical Collapsed Variational Bayes Inference for Hierarchical
	Dirichlet Process},
  booktitle = {Proceedings of the 18th ACM SIGKDD International Conference on Knowledge
	Discovery and Data Mining},
  year = {2012},
  series = {KDD '12},
  pages = {105--113},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We introduce a new nonlinear model for classification, in which we
	model the joint distribution of response variable, y, and covariates,
	x, non-parametrically using Dirichlet process mixtures. We keep the
	relationship between y and x linear within each component of the
	mixture. The overall relationship becomes nonlinear if the mixture
	contains more than one component, with different regression coefficients.
	We use simulated data to compare the performance of this new approach
	to alternative methods such as multinomial logit (MNL) models, decision
	trees, and support vector machines. We also evaluate our approach
	on two classification problems: identifying the folding class of
	protein sequences and detecting Parkinson's disease. Our model can
	sometimes improve predictive accuracy. Moreover, by grouping observations
	into sub-populations (i.e., mixture components), our model can sometimes
	provide insight into hidden structure in the data},
  acmid = {2339550},
  doi = {10.1145/2339530.2339550},
  file = {Sato2012Practical.pdf:Sato2012Practical.pdf:PDF},
  isbn = {978-1-4503-1462-6},
  keywords = {collapsed variational bayes inference, hierarchical dirichlet process,
	latent dirichlet allocation, nonparametric bayes},
  location = {Beijing, China},
  numpages = {9},
  timestamp = {2015.08.26},
  url = {http://doi.acm.org/10.1145/2339530.2339550}
}

@INPROCEEDINGS{Sato2010Topic,
  author = {Sato, Issei and Nakagawa, Hiroshi},
  title = {Topic Models with Power-law Using Pitman-Yor Process},
  booktitle = {Proceedings of the 16th ACM SIGKDD International Conference on Knowledge
	Discovery and Data Mining},
  year = {2010},
  series = {KDD '10},
  pages = {673--682},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {1835890},
  doi = {10.1145/1835804.1835890},
  file = {Sato2010Topic.pdf:Sato2010Topic.pdf:PDF},
  isbn = {978-1-4503-0055-1},
  keywords = {Pitman-Yor process, latent dirichlet allocation, nonparametric bayes,
	power-law, topic model},
  location = {Washington, DC, USA},
  numpages = {10},
  timestamp = {2015.08.26},
  url = {http://doi.acm.org/10.1145/1835804.1835890}
}

@InProceedings{Sayyadi2009Event,
  author    = {Sayyadi, Hassan and Hurst, Matthew and Maykov, Alexey},
  title     = {Event Detection and Tracking in Social Streams.},
  booktitle = {Proceedings of the Third International ICWSM Conference},
  year      = {2009},
  pages     = {311-314},
  groups    = {Recommender Systems},
}

@BOOK{Schwartz2005Paradox,
  title = {The Paradox of Choice: Why More Is Less},
  publisher = {Harper Perennial},
  year = {2005},
  author = {Barry Schwartz},
  abstract = {In the spirit of Alvin Toffler’s Future Shock, a social critique of
	our obsession with choice, and how it contributes to anxiety, dissatisfaction
	and regret. This paperback includes a new P.S. section with author
	interviews, insights, features, suggested readings, and more.
	
	
	Whether we’re buying a pair of jeans, ordering a cup of coffee, selecting
	a long-distance carrier, applying to college, choosing a doctor,
	or setting up a 401(k), everyday decisions--both big and small--have
	become increasingly complex due to the overwhelming abundance of
	choice with which we are presented.
	
	
	We assume that more choice means better options and greater satisfaction.
	But beware of excessive choice: choice overload can make you question
	the decisions you make before you even make them, it can set you
	up for unrealistically high expectations, and it can make you blame
	yourself for any and all failures. In the long run, this can lead
	to decision-making paralysis, anxiety, and perpetual stress. And,
	in a culture that tells us that there is no excuse for falling short
	of perfection when your options are limitless, too much choice can
	lead to clinical depression.
	
	
	In The Paradox of Choice, Barry Schwartz explains at what point choice--the
	hallmark of individual freedom and self-determination that we so
	cherish--becomes detrimental to our psychological and emotional well-being.
	In accessible, engaging, and anecdotal prose, Schwartz shows how
	the dramatic explosion in choice--from the mundane to the profound
	challenges of balancing career, family, and individual needs--has
	paradoxically become a problem instead of a solution. Schwartz also
	shows how our obsession with choice encourages us to seek that which
	makes us feel worse.
	
	
	By synthesizing current research in the social sciences, Schwartz
	makes the counterintuitive case that eliminating choices can greatly
	reduce the stress, anxiety, and busyness of our lives. He offers
	eleven practical steps on how to limit choices to a manageable number,
	have the discipline to focus on the important ones and ignore the
	rest, and ultimately derive greater satisfaction from the choices
	you have to make.},
  owner = {littlep},
  timestamp = {2014.07.15}
}

@BOOK{Scott2000Social,
  title = {Social network analysis: A handbook},
  publisher = {Sage},
  year = {2000},
  author = {Scott, J.},
  owner = {Cheyenne},
  timestamp = {2009.09.21}
}

@Article{Sen2009new,
  author    = {Qin Sen and Dai Guan-Zhong},
  title     = {A new local-world evolving network model},
  journal   = {Chinese Physics B},
  year      = {2009},
  volume    = {18},
  number    = {2},
  pages     = {383-390},
  month     = {2},
  file      = {Sen2009new.pdf:Sen2009new.pdf:PDF},
  owner     = {littlep},
  timestamp = {2014.03.19},
}

@ARTICLE{serdyukov2008modeling,
  author = {Serdyukov, P. and Hiemstra, D.},
  title = {{Modeling documents as mixtures of persons for expert finding}},
  journal = {Lecture Notes in Computer Science},
  year = {2008},
  volume = {4956},
  pages = {309},
  abstract = {In this paper we address the problem of searching for knowledgeable
	
	 persons within the enterprise, known as the expert finding (or
	
	 expert search) task. We present a probabilistic algorithm using the
	assumption
	
	 that terms in documents are produced by people who are mentioned
	
	 in them.We represent documents retrieved to a query as mixtures
	
	 of candidate experts language models. Two methods of personal language
	
	 models extraction are proposed, as well as the way of combining
	
	 them with other evidences of expertise. Experiments conducted with
	the
	
	 TREC Enterprise collection demonstrate the superiority of our approach
	
	 in comparison with the best one among existing solutions.},
  file = {serdyukov2008modeling.pdf:serdyukov2008modeling.pdf:PDF},
  publisher = {Springer}
}

@CONFERENCE{Serdyukov2007Generative,
  author = {Serdyukov, P. and Hiemstra, D. and Fokkinga, M. and Apers, P.M.G.},
  title = {Generative modeling of persons and documents for expert search},
  booktitle = {Proceedings of the 30th annual international ACM SIGIR conference
	on Research and development in information retrieval},
  year = {2007},
  pages = {827--828},
  organization = {ACM New York, NY, USA},
  owner = {Cheyenne},
  timestamp = {2009.09.21}
}

@CONFERENCE{Serdyukov2008Modeling,
  author = {Serdyukov, P. and Rode, H. and Hiemstra, D.},
  title = {Modeling expert finding as an absorbing random walk},
  booktitle = {Proceedings of the 31st annual international ACM SIGIR conference
	on Research and development in information retrieval},
  year = {2008},
  pages = {797--798},
  organization = {ACM New York, NY, USA},
  owner = {Cheyenne},
  timestamp = {2009.09.21}
}

@InProceedings{Seroussi2011Personalised,
  author    = {Seroussi, Yanir and Bohnert, Fabian and Zukerman, Ingrid},
  title     = {Personalised rating prediction for new users using latent factor models},
  booktitle = {Proceedings of the 22nd ACM conference on Hypertext and hypermedia},
  year      = {2011},
  series    = {HT '11},
  pages     = {47--56},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1995976},
  doi       = {http://doi.acm.org/10.1145/1995966.1995976},
  file      = {Seroussi2011Personalised.pdf:Seroussi2011Personalised.pdf:PDF},
  groups    = {Recommender Systems},
  isbn      = {978-1-4503-0256-2},
  keywords  = {latent dirichlet allocation, latent factor models, matrix factorization, new users, rating prediction, recommender systems},
  location  = {Eindhoven, The Netherlands},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1995966.1995976},
}

@Article{Serrano2009Extracting,
  author    = {M. Ángeles Serrano and Marián Boguñ and Alessandro Vespignani},
  title     = {Extracting the multiscale backbone of complex weighted networks},
  journal   = {PNAS},
  year      = {2009},
  volume    = {106},
  number    = {16},
  pages     = {6483–6488},
  file      = {Serrano2009Extracting.pdf:Serrano2009Extracting.pdf:PDF},
  owner     = {littlep},
  timestamp = {2014.03.19},
}

@Article{Shahnaz2006Document,
  author   = {Farial Shahnaz and Michael W. Berry and V.Paul Pauca and Robert J. Plemmons},
  title    = {Document clustering using nonnegative matrix factorization},
  journal  = {Information Processing \& Management},
  year     = {2006},
  volume   = {42},
  number   = {2},
  pages    = {373 - 386},
  doi      = {http://dx.doi.org/10.1016/j.ipm.2004.11.005},
  groups   = {matrix factorization},
  issn     = {0306-4573},
  keywords = {Nonnegative matrix factorization},
  url      = {http://www.sciencedirect.com/science/article/pii/S0306457304001542},
}

@InProceedings{Shamma2011Peaks,
  author    = {Shamma, David A. and Kennedy, Lyndon and Churchill, Elizabeth F.},
  title     = {Peaks and persistence: modeling the shape of microblog conversations},
  booktitle = {Proceedings of the ACM 2011 conference on Computer supported cooperative work},
  year      = {2011},
  series    = {CSCW '11},
  pages     = {355--358},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {A microblogged stream is delivered over time, providing an ongoing
	commentary of topics, trends, and issues. In this article, we present
	two methods of finding temporal topics within these Twitter streams.
	Using a normalized term frequency, we demonstrate how an effective
	table of contents can be extracted by finding localized "peaky topics".
	Second, we find "persistent conversations" which have a lower general
	salience but sustain and persist over the tweet corpus, in effect
	the whispering conversation that lingers in the background. These
	methods are demonstrated on a Twitter corpus of 53,000 tweets and
	a second Twitter corpus of 1.1 million tweets; the methods are generalizable
	to apply to any normalized scoring metric across a temporal corpus.
	We propose our method's implications on social media research and
	systems from a textual and social network analysis perpective.},
  acmid     = {1958878},
  doi       = {http://doi.acm.org/10.1145/1958824.1958878},
  file      = {Shamma2011Peaks.pdf:Shamma2011Peaks.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-1-4503-0556-3},
  keywords  = {IR, MTV, commentary, conversation, events, inauguration, information, microblogging, retrieval, twitter},
  location  = {Hangzhou, China},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/1958824.1958878},
}

@INCOLLECTION{Shao2005Mathematics,
  author = {Shao, Li-Song and Zhang, He-Ying and Zheng, Yan-Xin and Dou, Wen-Hua},
  title = {Mathematics Model and Performance Evaluation of a Scalable TCP Congestion
	Control Protocol to LNCS/LNAI Proceedings},
  booktitle = {Grid and Cooperative Computing - GCC 2005},
  publisher = {Springer Berlin / Heidelberg},
  year = {2005},
  editor = {Zhuge, Hai and Fox, Geoffrey},
  volume = {3795},
  series = {Lecture Notes in Computer Science},
  pages = {1054-1065},
  note = {10.1007/11590354_127},
  __markedentry = {[linchen]},
  affiliation = {Computer School, National University of Defence Technology, Changsha,
	China},
  owner = {linchen},
  timestamp = {2011.08.16},
  url = {http://dx.doi.org/10.1007/11590354_127}
}

@InProceedings{Sharifi2010Summarizing,
  author    = {Sharifi, Beaux and Hutton, Mark-Anthony and Kalita, Jugal},
  title     = {Summarizing microblogs automatically},
  booktitle = {Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics},
  year      = {2010},
  series    = {HLT '10},
  pages     = {685--688},
  address   = {Stroudsburg, PA, USA},
  publisher = {Association for Computational Linguistics},
  abstract  = {In this paper, we focus on a recent Web trend 
	
	called microblogging, and in particular a site 
	
	called Twitter. The content of such a site is an 
	
	extraordinarily large number of small textual 
	
	messages, posted by millions of users, at random or in response to
	perceived events or situations. We have developed an algorithm that
	
	
	takes a trending phrase or any phrase specified 
	
	by a user, collects a large number of posts 
	
	containing the phrase, and provides an automatically created summary
	of the posts related 
	
	to the term. We present examples of summaries we produce along with
	initial evaluation},
  acmid     = {1858099},
  comment   = {frequent phrase},
  file      = {Sharifi2010Summarizing.pdf:Sharifi2010Summarizing.pdf:PDF},
  groups    = {Twitter},
  isbn      = {1-932432-65-5},
  location  = {Los Angeles, California},
  numpages  = {4},
  url       = {http://dl.acm.org/citation.cfm?id=1857999.1858099},
}

@INPROCEEDINGS{Shen2010Multi,
  author = {Shen, Chao and Li, Tao},
  title = {Multi-document Summarization via the Minimum Dominating Set},
  booktitle = {Proceedings of the 23rd International Conference on Computational
	Linguistics},
  year = {2010},
  series = {COLING '10},
  pages = {984--992},
  address = {Stroudsburg, PA, USA},
  publisher = {Association for Computational Linguistics},
  abstract = {Multi-document summarization has been an important problem in information
	retrieval. It aims to distill the most important information from
	a set of documents to generate a compressed summary. Given a sentence
	graph generated from a set of documents where vertices represent
	sentences and edges indicate that the corresponding vertices are
	similar, the extracted summary can be described using the idea of
	graph domination. In this paper, we propose a new principled and
	versatile framework for multi-document summarization using the minimum
	dominating set. We show that four well-known summarization tasks
	including generic, query-focused, update, and comparative summarization
	can be modeled as different variations derived from the proposed
	framework. Approximation algorithms for performing summarization
	are also proposed and empirical experiments are conducted to demonstrate
	the effectiveness of our proposed framework.},
  acmid = {1873892},
  location = {Beijing, China},
  numpages = {9}
}

@INPROCEEDINGS{Shen2006Thread,
  author = {Shen, Dou and Yang, Qiang and Sun, Jian-Tao and Chen, Zheng},
  title = {Thread detection in dynamic text message streams},
  booktitle = {SIGIR '06: Proceedings of the 29th annual international ACM SIGIR
	conference on Research and development in information retrieval},
  year = {2006},
  pages = {35--42},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1148170.1148180},
  isbn = {1-59593-369-7},
  location = {Seattle, Washington, USA}
}

@INPROCEEDINGS{Shi2008Generating,
  author = {Shi, Bin and Chang, Kuiyu},
  title = {Generating a concept hierarchy for sentiment analysis},
  booktitle = {Systems, Man and Cybernetics, 2008. SMC 2008. IEEE International
	Conference on},
  year = {2008},
  pages = {312--317},
  organization = {IEEE},
  abstract = {In this paper, we propose an unsupervised machine learning method
	to automatically construct a product hierarchical concept model based
	on the online reviews of this product. Our method starts by representing
	each candidate noun using a feature context vector, which is simply
	a vector of all its co-occurring neighbors excluding itself. We then
	applied bisection clustering to hierarchically cluster the context
	vectors to obtain a cluster hierarchy. Lastly, we proposed and evaluated
	two methods to label each intermediate clustering node with the most
	representative member context feature vector. Experiments conducted
	on 3 sets of on-line reviews (in both Chinese and English) benchmarked
	qualitatively and quantitatively against a well known existing approach
	demonstrated the effectiveness and robustness of our approach.}
}

@ARTICLE{shi2000normalized,
  author = {Shi, J. and Malik, J.},
  title = {{Normalized cuts and image segmentation}},
  journal = {IEEE Transactions on pattern analysis and machine intelligence},
  year = {2000},
  volume = {22},
  pages = {888--905},
  number = {8},
  abstract = {We propose a novel approach for solving the perceptual grouping problem
	in vision. Rather than focusing on local features and their consistencies
	in the image data, our approach aims at extracting the global impression
	of an image. We treat image segmentation as a graph partitioning
	problem and propose a novel global criterion, the normalized cut,
	for segmenting the graph. The normalized cut criterion measures both
	the total dissimilarity between the different groups as well as the
	total similarity within the groups. We show that an efficient computational
	technique based on a generalized eigenvalue problem can be used to
	optimize this criterion. We applied this approach to segmenting static
	images, as well as motion sequences, and found the results to be
	very encouraging}
}

@InProceedings{Shi2009User,
  author    = {Shi, Xiaolin and Zhu, Jun and Cai, Rui and Zhang, Lei},
  title     = {User grouping behavior in online forums},
  booktitle = {Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining},
  year      = {2009},
  series    = {KDD '09},
  pages     = {777--786},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Online forums represent one type of social media that is
	
	particularly rich for studying human behavior in informa-
	
	tion seeking and diusing. The way users join communities
	
	is a re
	
	ection of the changing and expanding of their inter-
	
	ests toward information. In this paper, we study the pat-
	
	terns of user participation behavior, and the feature factors
	
	that in
	
	uence such behavior on dierent forum datasets. We
	
	nd that, despite the relative randomness and lesser com-
	
	mitment of structural relationships in online forums, users'
	
	community joining behaviors display some strong regulari-
	
	ties. One particularly interesting observation is that the very
	
	weak relationships between users dened by online replies
	
	have similar diusion curves as those of real friendships or
	
	co-authorships. We build social selection models, Bipartite
	
	Markov Random Field (BiMRF), to quantitatively evaluate
	
	the prediction performance of those feature factors and their
	
	relationships. Using these models, we show that some fea-
	
	tures carry supplementary information, and the eectiveness
	
	of dierent features vary in dierent types of forums. More-
	
	over, the results of BiMRF with two-star congurations sug-
	
	gest that the feature of user similarity dened by frequency
	
	of communication or number of common friends is inade-
	
	quate to predict grouping behavior, but adding node-level
	
	features can improve the t of the model},
  acmid     = {1557105},
  doi       = {http://doi.acm.org/10.1145/1557019.1557105},
  file      = {Shi2009User.pdf:Shi2009User.pdf:PDF},
  isbn      = {978-1-60558-495-9},
  keywords  = {information diffusion, online forums, social networks, social selection model},
  location  = {Paris, France},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1557019.1557105},
}

@INPROCEEDINGS{Shi2014CARS2,
  author = {Shi, Yue and Karatzoglou, Alexandros and Baltrunas, Linas and Larson,
	Martha and Hanjalic, Alan},
  title = {CARS2: Learning Context-aware Representations for Context-aware Recommendations},
  booktitle = {Proceedings of the 23rd ACM International Conference on Conference
	on Information and Knowledge Management},
  year = {2014},
  series = {CIKM '14},
  pages = {291--300},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Rich contextual information is typically available in many recommendation
	domains allowing recommender systems to model the subtle effects
	of context on preferences. Most contextual models assume that the
	context shares the same latent space with the users and items. In
	this work we propose CARS2, a novel approach for learning context-aware
	representations for context-aware recommendations. We show that the
	context-aware representations can be learned using an appropriate
	model that aims to represent the type of interactions between context
	variables, users and items. We adapt the CARS2 algorithms to explicit
	feedback data by using a quadratic loss function for rating prediction,
	and to implicit feedback data by using a pairwise and a listwise
	ranking loss functions for top-N recommendations. By using stochastic
	gradient descent for parameter estimation we ensure scalability.
	Experimental evaluation shows that our CARS2 models achieve competitive
	recommendation performance, compared to several state-of-the-art
	approaches.},
  acmid = {2662070},
  doi = {10.1145/2661829.2662070},
  isbn = {978-1-4503-2598-1},
  keywords = {collaborative filtering, context-aware recommendation, latent factor
	models, learning representations},
  location = {Shanghai, China},
  numpages = {10},
  url = {http://doi.acm.org/10.1145/2661829.2662070}
}

@INPROCEEDINGS{Shi2012CLiMF,
  author = {Shi, Yue and Karatzoglou, Alexandros and Baltrunas, Linas and Larson,
	Martha and Oliver, Nuria and Hanjalic, Alan},
  title = {CLiMF: Learning to Maximize Reciprocal Rank with Collaborative Less-is-more
	Filtering},
  booktitle = {Proceedings of the Sixth ACM Conference on Recommender Systems},
  year = {2012},
  series = {RecSys '12},
  pages = {139--146},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {In this paper we tackle the problem of recommendation in the scenarios
	with binary relevance data, when only a few (k) items are recommended
	to individual users. Past work on Collaborative Filtering (CF) has
	either not addressed the ranking problem for binary relevance datasets,
	or not specifically focused on improving top-k recommendations. To
	solve the problem we propose a new CF approach, Collaborative Less-is-More
	Filtering (CLiMF). In CLiMF the model parameters are learned by directly
	maximizing the Mean Reciprocal Rank (MRR), which is a well-known
	information retrieval metric for measuring the performance of top-k
	recommendations. We achieve linear computational complexity by introducing
	a lower bound of the smoothed reciprocal rank metric. Experiments
	on two social network datasets demonstrate the effectiveness and
	the scalability of CLiMF, and show that CLiMF significantly outperforms
	a naive baseline and two state-of-the-art CF methods.},
  acmid = {2365981},
  file = {Shi2012CLiMF.pdf:Shi2012CLiMF.pdf:PDF},
  isbn = {978-1-4503-1270-7},
  keywords = {collaborative filtering, learning to rank, less is more, matrix factorization,
	mean reciprocal rank},
  location = {Dublin, Ireland},
  numpages = {8}
}

@InProceedings{Shi2010Listwise,
  author    = {Shi, Yue and Larson, Martha and Hanjalic, Alan},
  title     = {List-wise learning to rank with matrix factorization for collaborative filtering},
  booktitle = {Proceedings of the fourth ACM conference on Recommender systems},
  year      = {2010},
  series    = {RecSys '10},
  pages     = {269--272},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {A ranking approach, ListRank-MF, is proposed for collaborative filtering
	that combines a list-wise learning-to-rank algorithm with matrix
	factorization (MF). A ranked list of items is obtained by minimizing
	a loss function that represents the uncertainty between training
	lists and output lists produced by a MF ranking model. ListRank-MF
	enjoys the advantage of low complexity and is analytically shown
	to be linear with the number of observed ratings for a given user-item
	matrix. We also experimentally demonstrate the effectiveness of ListRank-MF
	by comparing its performance with that of item-based collaborative
	recommendation and a related state-of-the-art collaborative ranking
	approach (CoFiRank).},
  acmid     = {1864764},
  file      = {Shi2010Listwise.pdf:Shi2010Listwise.pdf:PDF},
  groups    = {Recommender Systems},
  isbn      = {978-1-60558-906-0},
  keywords  = {collaborative filtering, learning to rank, matrix factorization, recommendation, recommender systems},
  location  = {Barcelona, Spain},
  numpages  = {4},
}

@ARTICLE{Shimizu2011DirectLiNGAM,
  author = {Shimizu, Shohei and Inazumi, Takanori and Sogawa, Yasuhiro and Hyv\"{a}rinen,
	Aapo and Kawahara, Yoshinobu and Washio, Takashi and Hoyer, Patrik
	O. and Bollen, Kenneth},
  title = {DirectLiNGAM: A Direct Method for Learning a Linear Non-Gaussian
	Structural Equation Model},
  journal = {J. Mach. Learn. Res.},
  year = {2011},
  volume = {12},
  pages = {1225--1248},
  month = jul,
  acmid = {2021040},
  issn = {1532-4435},
  issue_date = {2/1/2011},
  numpages = {24},
  publisher = {JMLR.org},
  url = {http://dl.acm.org/citation.cfm?id=1953048.2021040}
}

@InProceedings{Shou2013Sumblr,
  author    = {Shou, Lidan and Wang, Zhenhua and Chen, Ke and Chen, Gang},
  title     = {Sumblr: continuous summarization of evolving tweet streams},
  booktitle = {Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval},
  year      = {2013},
  series    = {SIGIR '13},
  pages     = {533--542},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {With the explosive growth of microblogging services, shorttext
	
	messages (also known as tweets) are being created and
	
	shared at an unprecedented rate. Tweets in its raw form
	
	can be incredibly informative, but also overwhelming. For
	
	both end-users and data analysts it is a nightmare to plow
	
	through millions of tweets which contain enormous noises
	
	and redundancies. In this paper, we study continuous tweet
	
	summarization as a solution to address this problem. While
	
	traditional document summarization methods focus on static
	
	and small-scale data, we aim to deal with dynamic, quickly
	
	arriving, and large-scale tweet streams. We propose a novel
	
	prototype called Sumblr (SUMmarization By stream cLusteRing)
	
	for tweet streams. We first propose an online tweet
	
	stream clustering algorithm to cluster tweets and maintain
	
	distilled statistics called Tweet Cluster Vectors. Then we develop
	
	a TCV-Rank summarization technique for generating
	
	online summaries and historical summaries of arbitrary time
	
	durations. Finally, we describe a topic evolvement detection
	
	method, which consumes online and historical summaries to
	
	produce timelines automatically from tweet streams. Our
	
	experiments on large-scale real tweets demonstrate the efficiency
	
	and effectiveness of our approach},
  acmid     = {2484045},
  comment   = {event summarization, tweet},
  doi       = {10.1145/2484028.2484045},
  file      = {Shou2013Sumblr.pdf:Shou2013Sumblr.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-1-4503-2034-4},
  keywords  = {continuous summarization, timeline, tweet stream},
  location  = {Dublin, Ireland},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2484028.2484045},
}

@ARTICLE{Si2014Users,
  author = {Jianfeng Si and Qing Li and Tieyun Qian and Xiaotie Deng},
  title = {Users’ interest grouping from online reviews based on topic frequency
	and order},
  journal = {World Wide Web},
  year = {2014},
  volume = {17(6)},
  pages = {1321–1342},
  abstract = {Large volume of online review data can reveal consumers’ major interests
	on domain product, which attracts great research interests from the
	academic community. Most of the existing works focus on the problems
	of review summarization, aspect identification or opinion mining
	from an item’s point of view such as the quality or popularity of
	products. Considering the fact that users who generate those review
	texts draw different attentions to product aspects with respect to
	their own interests, in this article, we aim to learn K users’ interest
	groups indicated by their review writings. Such K interest groups’
	identification can facilitate better understanding of major and potential
	consumers’ concerns which are crucial for applications like product
	improvement on customer-oriented design or diverse marketing strategies.
	Instead of using a traditional text clustering approach, we treat
	the groupId/clusterId as a hidden variable and use a permutation-based
	structural topic model called KMM. Through this model, we infer K
	interest groups’ distribution by discovering not only the frequency
	of product aspects (Topic Frequency), but also the occurrence priority
	of respective aspects (Topic Order). They jointly present an informative
	summarization on the raw review corpus. Our experiment on several
	real-world review datasets demonstrates a competitive solution.},
  file = {SiUsers.pdf:SiUsers.pdf:PDF},
  keywords = {Review analysis, Structural topic modeling, Interest grouping},
  owner = {littlep},
  timestamp = {2014.05.25}
}

@InProceedings{Silva2011Effective,
  author    = {Silva, Ismael Santana and Gomide, Jana\'{\i}na and Veloso, Adriano and Meira,Jr., Wagner and Ferreira, Renato},
  title     = {Effective sentiment stream analysis with self-augmenting training and demand-driven projection},
  booktitle = {Proceedings of the 34th international ACM SIGIR conference on Research and development in Information},
  year      = {2011},
  series    = {SIGIR '11},
  pages     = {475--484},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {How do we analyze sentiments over a set of opinionated Twitter messages?
	This issue has been widely studied in recent years, with a prominent
	approach being based on the application of classification techniques.
	Basically, messages are classified according to the implicit attitude
	of the writer with respect to a query term. A major concern, however,
	is that Twitter (and other media channels) follows the data stream
	model, and thus the classifier must operate with limited resources,
	including labeled data for training classification models. This imposes
	serious challenges for current classification techniques, since they
	need to be constantly fed with fresh training messages, in order
	to track sentiment drift and to provide up-to-date sentiment analysis.
	
	
	We propose solutions to this problem. The heart of our approach is
	a training augmentation procedure which takes as input a small training
	seed, and then it automatically incorporates new relevant messages
	to the training data. Classification models are produced on-the-fly
	using association rules, which are kept up-to-date in an incremental
	fashion, so that at any given time the model properly reflects the
	sentiments in the event being analyzed. In order to track sentiment
	drift, training messages are projected on a demand driven basis,
	according to the content of the message being classified. Projecting
	the training data offers a series of advantages, including the ability
	to quickly detect trending information emerging in the stream. We
	performed the analysis of major events in 2010, and we show that
	the prediction performance remains about the same, or even increases,
	as the stream passes and new training messages are acquired. This
	result holds for different languages, even in cases where sentiment
	distribution changes over time, or in cases where the initial training
	seed is rather small. We derive lower-bounds for prediction performance,
	and we show that our approach is extremely effective under diverse
	learning scenarios, providing gains that range from 7% to 58%.},
  acmid     = {2009981},
  doi       = {http://doi.acm.org/10.1145/2009916.2009981},
  file      = {Silva2011Effective.pdf:Silva2011Effective.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-1-4503-0757-4},
  keywords  = {sentiment analysis, sentiment drift, streams, twitter},
  location  = {Beijing, China},
  numpages  = {10},
  owner     = {linchen},
  timestamp = {2011.11.01},
  url       = {http://doi.acm.org/10.1145/2009916.2009981},
}

@InProceedings{Singla2008Yes,
  author    = {Singla, Parag and Richardson, Matthew},
  title     = {Yes, there is a correlation: - from social networks to personal behavior on the web},
  booktitle = {WWW '08: Proceeding of the 17th international conference on World Wide Web},
  year      = {2008},
  pages     = {655--664},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Characterizing the relationship that exists between a person's social
	group and his/her personal behavior has been a long standing goal
	of social network analysts. In this paper, we apply data mining techniques
	to study this relationship for a population of over 10 million people,
	by turning to online sources of data. The analysis reveals that people
	who chat with each other (using instant messaging) are more likely
	to share interests (their Web searches are the same or topically
	similar). The more time they spend talking, the stronger this relationship
	is. People who chat with each other are also more likely to share
	other personal characteristics, such as their age and location (and,
	they are likely to be of opposite gender). Similar findings hold
	for people who do not necessarily talk to each other but do have
	a friend in common. Our analysis is based on a well-defined mathematical
	formulation of the problem, and is the largest such study we are
	aware of.},
  comment   = {The data : MSN chatting record & MSN search logs.
	
	 Experiment: compare the similarity of query issued (bag of word similarity,
	and exact match query), query category, personal atributes(zip codes,
	age, gender) in general user pairs and linked user pairs.
	
	Also compare the effect of toal duration and average duration. Also
	consider the case of friend sharing(indirected links)
	
	Result: connected user pairs are likely to have higher similarity
	in their interest (shown in query logs), even higher similarity in
	zip codes and age, but oposite in gender. The transivity holds. More
	total duration suggest higher similarity, but more average duration
	indicates lower similarity (compared to less average duration) in
	query and zip, but higer opposity in genter.},
  doi       = {http://doi.acm.org/10.1145/1367497.1367586},
  file      = {:D\:\\My Documents\\My Papers\\SNA\\yes there is a correlation from social networks to personal behavior on the web.pdf:PDF},
  isbn      = {978-1-60558-085-2},
  location  = {Beijing, China},
}

@ARTICLE{Soboroff2006Overview,
  author = {Soboroff, I. and de Vries, A.P. and Craswell, N.},
  title = {Overview of the trec 2006 enterprise track},
  journal = {TREC 2006 Working Notes},
  year = {2006},
  owner = {Cheyenne},
  timestamp = {2009.09.21}
}

@INPROCEEDINGS{Somasundaran2009Recognizing,
  author = {Somasundaran, Swapna and Wiebe, Janyce},
  title = {Recognizing Stances in Online Debates},
  booktitle = {Proceedings of the Joint Conference of the 47th Annual Meeting of
	the ACL and the 4th International Joint Conference on Natural Language
	Processing of the AFNLP: Volume 1 - Volume 1},
  year = {2009},
  series = {ACL '09},
  pages = {226--234},
  address = {Stroudsburg, PA, USA},
  publisher = {Association for Computational Linguistics},
  abstract = {This paper presents an unsupervised opinion analysis method for debate-side
	classification, i.e., recognizing which stance a person is taking
	in an online debate. In order to handle the complexities of this
	genre, we mine the web to learn associations that are indicative
	of opinion stances in debates. We combine this knowledge with discourse
	information, and formulate the debate side classification task as
	an Integer Linear Programming problem. Our results show that our
	method is substantially better than challenging baseline methods.},
  acmid = {1687912},
  file = {Somasundaran2009Recognizing.pdf:Somasundaran2009Recognizing.pdf:PDF},
  isbn = {978-1-932432-45-9},
  location = {Suntec, Singapore},
  numpages = {9},
  url = {http://dl.acm.org/citation.cfm?id=1687878.1687912}
}

@INPROCEEDINGS{Sondberg-Madsen2003Unsupervised,
  author = {Sondberg-Madsen, N. and Thomsen, C. and Pena, J.M.},
  title = {Unsupervised feature subset selection},
  booktitle = {Proceedings of the Workshop on Probabilistic Graphical Models for
	Classification},
  year = {2003},
  pages = {71--82},
  organization = {Citeseer}
}

@Conference{song2007identifying,
  author       = {Song, X. and Chi, Y. and Hino, K. and Tseng, B.},
  title        = {{Identifying opinion leaders in the blogosphere}},
  booktitle    = {Proceedings of the sixteenth ACM conference on Conference on information and knowledge management},
  year         = {2007},
  pages        = {971--974},
  organization = {ACM},
  file         = {song2007identifying.pdf:song2007identifying.pdf:PDF},
}

@InProceedings{Song2006Personalized,
  author    = {Song, Xiaodan and Tseng, Belle L. and Lin, Ching-Yung and Sun, Ming-Ting},
  title     = {Personalized recommendation driven by information flow},
  booktitle = {SIGIR '06: Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval},
  year      = {2006},
  pages     = {509--516},
  address   = {New York, NY, USA},
  publisher = {ACM},
  doi       = {http://doi.acm.org/10.1145/1148170.1148258},
  file      = {:Song2006Personalized.pdf:PDF},
  groups    = {Recommender Systems},
  isbn      = {1-59593-369-7},
  location  = {Seattle, Washington, USA},
}

@ARTICLE{Song2007IKNN:,
  author = {Song, Y. and Huang, J. and Zhou, D. and Zha, H. and Giles, C.L.},
  title = {IKNN: Informative k-nearest neighbor pattern classification},
  journal = {Lecture Notes in Computer Science},
  year = {2007},
  volume = {4702},
  pages = {248},
  owner = {Cheyenne},
  publisher = {Springer},
  timestamp = {2009.09.21}
}

@CONFERENCE{Song2006Boosting,
  author = {Song, Y. and Zhou, D. and Huang, J. and Councill, IG and Zha, H.
	and Giles, CL},
  title = {Boosting the feature space: Text classification for unstructured
	data on the web},
  booktitle = {Data Mining, 2006. ICDM'06. Sixth International Conference on},
  year = {2006},
  pages = {1064--1069},
  owner = {Cheyenne},
  timestamp = {2009.09.21}
}

@InProceedings{Song2008Real,
  author    = {Song, Yang and Zhuang, Ziming and Li, Huajing and Zhao, Qiankun and Li, Jia and Lee, Wang-Chien and Giles, C. Lee},
  title     = {Real-time Automatic Tag Recommendation},
  booktitle = {Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year      = {2008},
  series    = {SIGIR '08},
  pages     = {515--522},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Tags are user-generated labels for entities. Existing research on
	tag recommendation either focuses on improving its accuracy or on
	automating the process, while ignoring the efficiency issue. We propose
	a highly-automated novel framework for real-time tag recommendation.
	The tagged training documents are treated as triplets of (words,
	docs, tags), and represented in two bipartite graphs, which are partitioned
	into clusters by Spectral Recursive Embedding (SRE). Tags in each
	topical cluster are ranked by our novel ranking algorithm. A two-way
	Poisson Mixture Model (PMM) is proposed to model the document distribution
	into mixture components within each cluster and aggregate words into
	word clusters simultaneously. A new document is classified by the
	mixture model based on its posterior probabilities so that tags are
	recommended according to their ranks. Experiments on large-scale
	tagging datasets of scientific documents (CiteULike) and web pages
	del.icio.us) indicate that our framework is capable of making tag
	recommendation efficiently and effectively. The average tagging time
	for testing a document is around 1 second, with over 88% test documents
	correctly labeled with the top nine tags we suggested.},
  acmid     = {1390423},
  doi       = {10.1145/1390334.1390423},
  groups    = {Recommender Systems},
  isbn      = {978-1-60558-164-4},
  keywords  = {graph partitioning, mixture model, tagging system},
  location  = {Singapore, Singapore},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/1390334.1390423},
}

@INPROCEEDINGS{Soufiani2014Computing,
  author = {Soufiani, Hossein Azari and Parkes, David C.and Xia, Lirong},
  title = {Computing Parametric Ranking Models via Rank-Breaking},
  booktitle = {Proceedings of the 31st International Conference on Machine Learning
	(ICML14)},
  year = {2014},
  abstract = {Rank breaking is a methodology introduced by Azari Soufiani et al.
	(2013a) for applying a Generalized Method of Moments (GMM) algorithm
	to the estimation of parametric ranking models. Breaking takes full
	rankings and breaks, or splits them up, into counts for pairs of
	alternatives that occur in particular positions (e.g., first place
	and second place, second place and third place). GMMs are of interest
	because they can achieve significant speed-up relative to maximum
	likelihood approaches and comparable statistical efficiency. We characterize
	the breakings for which the estimator is consistent for random utility
	models (RUMs) including Plackett-Luce and Normal-RUM, develop a general
	sufficient condition for a full breaking to be the only consistent
	breaking, and provide a trichotomy theorem in regard to single-edge
	breakings. Experimental results are presented to show the computational
	efficiency along with statistical performance of the proposed method.},
  file = {Soufiani2014Computing.pdf:Soufiani2014Computing.pdf:PDF},
  owner = {csgueste},
  timestamp = {2016.04.19}
}

@INPROCEEDINGS{Srikanth2003Incorporating,
  author = {Srikanth, Munirathnam and Srihari, Rohini},
  title = {Incorporating Query Term Dependencies in Language Models for Document
	Retrieval},
  booktitle = {Proceedings of the 26th Annual International ACM SIGIR Conference
	on Research and Development in Informaion Retrieval},
  year = {2003},
  series = {SIGIR '03},
  pages = {405--406},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {860523},
  isbn = {1-58113-646-3},
  keywords = {information retrieval, language models},
  location = {Toronto, Canada},
  numpages = {2}
}

@InProceedings{Steck2010Training,
  author    = {Steck, Harald},
  title     = {Training and Testing of Recommender Systems on Data Missing Not at Random},
  booktitle = {Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year      = {2010},
  series    = {KDD '10},
  pages     = {713--722},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Users typically rate only a small fraction of all available items.
	We show that the absence of ratings carries useful information for
	improving the top-k hit rate concerning all items, a natural accuracy
	measure for recommendations. As to test recommender systems, we present
	two performance measures that can be estimated, under mild assumptions,
	without bias from data even when ratings are missing not at random
	(MNAR). As to achieve optimal test results, we present appropriate
	surrogate objective functions for efficient training on MNAR data.
	Their main property is to account for all ratings - whether observed
	or missing in the data. Concerning the top-k hit rate on test data,
	our experiments indicate dramatic improvements over even sophisticated
	methods that are optimized on observed ratings only.},
  acmid     = {1835895},
  comment   = {present a new evaluation metric ATOP, which is the sum of recall@k
	for all k, when k is a fraction, on complete data
	
	prooves that when relevant items are missing at random, and other
	rating values are missing with a higher probability than the relevant
	rating values do, then the average rank of relevant observations
	is an unbiased estimate
	
	and this estimate can be approximated by AUC
	
	use the hinge loss to optimize AUC},
  doi       = {10.1145/1835804.1835895},
  file      = {Steck2010Training.pdf:Steck2010Training.pdf:PDF},
  isbn      = {978-1-4503-0055-1},
  keywords  = {recommender systems},
  location  = {Washington, DC, USA},
  numpages  = {10},
  timestamp = {2015.12.20},
  url       = {http://doi.acm.org/10.1145/1835804.1835895},
}

@INPROCEEDINGS{Steyvers2004Probabilistic,
  author = {Steyvers, Mark and Smyth, Padhraic and Rosen-Zvi, Michal and Griffiths,
	Thomas},
  title = {Probabilistic author-topic models for information discovery},
  booktitle = {KDD '04: Proceedings of the tenth ACM SIGKDD international conference
	on Knowledge discovery and data mining},
  year = {2004},
  pages = {306--315},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We propose a new unsupervised learning technique for extracting information
	from large text collections. We model documents as if they were generated
	by a two-stage stochastic process. Each author is represented by
	a probability distribution over topics, and each topic is represented
	as a probability distribution over words for that topic. The words
	in a multi-author paper are assumed to be the result of a mixture
	of each authors' topic mixture. The topic-word and author-topic distributions
	are learned from data in an unsupervised manner using a Markov chain
	Monte Carlo algorithm. We apply the methodology to a large corpus
	of 160,000 abstracts and 85,000 authors from the well-known CiteSeer
	digital library, and learn a model with 300 topics. We discuss in
	detail the interpretation of the results discovered by the system
	including specific topic and author models, ranking of authors by
	topic and topics by author, significant trends in the computer science
	literature between 1990 and 2002, parsing of abstracts by topics
	and authors and detection of unusual papers by specific authors.
	An online query interface to the model is also discussed that allows
	interactive exploration of author-topic models for corpora such as
	CiteSeer.},
  doi = {http://doi.acm.org/10.1145/1014052.1014087},
  isbn = {1-58113-888-1},
  location = {Seattle, WA, USA}
}

@InProceedings{Suen2013NIFTY,
  author    = {Suen, Caroline and Huang, Sandy and Eksombatchai, Chantat and Sosic, Rok and Leskovec, Jure},
  title     = {NIFTY: A System for Large Scale Information Flow Tracking and Clustering},
  booktitle = {Proceedings of the 22Nd International Conference on World Wide Web},
  year      = {2013},
  series    = {WWW '13},
  pages     = {1237--1248},
  address   = {Republic and Canton of Geneva, Switzerland},
  publisher = {International World Wide Web Conferences Steering Committee},
  acmid     = {2488496},
  file      = {Suen2013NIFTY.pdf:Suen2013NIFTY.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-1-4503-2035-1},
  keywords  = {blogs, information cascades, meme-tracking, networks of diffusion, news media, social networks},
  location  = {Rio de Janeiro, Brazil},
  numpages  = {12},
  url       = {http://dl.acm.org/citation.cfm?id=2488388.2488496},
}

@INPROCEEDINGS{Sun2006Multi-task,
  author = {Sun, Bingjun and Zhou, Ding and Zha, Hongyuan and Yen, John},
  title = {Multi-task text segmentation and alignment based on weighted mutual
	information},
  booktitle = {CIKM '06: Proceedings of the 15th ACM international conference on
	Information and knowledge management},
  year = {2006},
  pages = {846--847},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1183614.1183760},
  isbn = {1-59593-433-2},
  location = {Arlington, Virginia, USA}
}

@INPROCEEDINGS{Sun2008HTM,
  author = {Sun, C. and Gao, B. and Cao, Z. and Li, H.},
  title = {HTM: A topic model for hypertexts},
  booktitle = {Proceedings of the Conference on Empirical Methods in Natural Language
	Processing},
  year = {2008},
  pages = {514--522},
  organization = {Association for Computational Linguistics},
  file = {Sun2008HTM.pdf:Sun2008HTM.pdf:PDF}
}

@InProceedings{Sun2009Learning,
  author    = {Sun, Ke and Cao, Yunbo and Song, Xinying and Song, Young-In and Wang, Xiaolong and Lin, Chin-Yew},
  title     = {Learning to recommend questions based on user ratings},
  booktitle = {Proceeding of the 18th ACM conference on Information and knowledge management},
  year      = {2009},
  series    = {CIKM '09},
  pages     = {751--758},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {At community question answering services, users are usually
	
	encouraged to rate questions by votes. The questions with
	
	the most votes are then recommended and ranked on the top
	
	when users browse questions by category. As users are not
	
	obligated to rate questions, usually only a small proportion
	
	of questions eventually gets rating. Thus, in this paper, we
	
	are concerned with learning to recommend questions from
	
	user ratings of a limited size. To overcome the data sparsity,
	
	we propose to utilize questions without users rating as well.
	
	Further, as there exist certain noises within user ratings (the
	
	preference of some users expressed in their ratings diverges
	
	from that of the majority of users), we design a new algorithm
	
	called ‘majority-based perceptron algorithm’ which
	
	can avoid the influence of noisy instances by emphasizing its
	
	learning over data instances from the majority users. Experimental
	
	results from a large collection of real questions
	
	confirm the effectiveness of our proposals.},
  acmid     = {1646049},
  comment   = {assume there exists certain commonality of the choices of different
	users
	
	The ‘question recommendation’ that
	
	we deﬁne is to discover the questions which can potentially
	
	be rated or chosen as ‘recommendation’ by the majority of
	
	users of a cQA service
	
	model's generalbility
	
	PREDICTING POPULARITY instead of predict content quality
	
	linear combination of the following features
	
	features:
	
	Feature Alias Description
	
	Features about Question (QU)
	
	Title Length The number of words in the title of the question
	
	Description Length The number of words in the description of the question
	
	KL-Divergence Score The ratio between the KL-divergence of the question
	to ‘interesting’ questions within
	
	the training set and the KL-divergence of the question to ‘not interesting’
	questions
	
	within the training set.
	
	WH-Type WH-word leading the title of the question. The WH-words include
	why, what, where,
	
	when, who, whose, and how. ’None’ is used to indicate that none of
	six words occurs.
	
	Posting Time The time when the question was posted
	
	Features about Asker (AS)
	
	Total Questions Posted The total number of the questions that the
	asker posted in the past
	
	Total Stars Received The total number of the stars that the asker
	received in the past
	
	Ratio of Starred Questions Total questions with stars / total questions
	posted
	
	Stars per Question The average star that one question posted by the
	asker received
	
	Total Answer The total number of all the answers that the asker obtained
	for his questions
	
	Answers per Question The average number of the answers that one question
	posted by the asker received},
  doi       = {http://doi.acm.org/10.1145/1645953.1646049},
  file      = {Sun2009Learning.pdf:Sun2009Learning.pdf:PDF},
  isbn      = {978-1-60558-512-3},
  keywords  = {question recommendation, the majority-based perceptron algorithm,QA,learning to rank},
  location  = {Hong Kong, China},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/1645953.1646049},
}

@INPROCEEDINGS{Sun2014Convergence,
  author = {Peng Sun and Tong Zhang and Jie Zhou},
  title = {A Convergence Rate Analysis for LogitBoost, MART and Their Variant},
  booktitle = {Proceedings of ICML},
  year = {2014},
  pages = {1001-1009},
  abstract = {LogitBoost, MART and their variant can be viewed as additive tree
	regression using logistic loss and boosting style optimization. We
	analyze their convergence rates based on a new weak learnability
	formulation. We show that it has $O(\frac{1}{T})$ rate when using
	gradient descent only, while a linear rate is achieved when using
	Newton descent. Moreover, introducing Newton descent when growing
	the trees, as LogitBoost does, leads to a faster linear rate. Empirical
	results on UCI datasets support our analysis.},
  file = {Sun2014Convergence.pdf:Sun2014Convergence.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.06.23}
}

@InProceedings{Sun2010Large-Scale,
  author       = {Sun, Z. and Li, T. and Rishe, N.},
  title        = {Large-Scale Matrix Factorization Using MapReduce},
  booktitle    = {Data Mining Workshops (ICDMW), 2010 IEEE International Conference on},
  year         = {2010},
  pages        = {1242--1248},
  organization = {IEEE},
  groups       = {matrix factorization},
}

@InCollection{Surendran2006Incremental,
  author      = {Surendran, Arun and Sra, Suvrit},
  title       = {Incremental Aspect Models for Mining Document Streams},
  booktitle   = {Knowledge Discovery in Databases: PKDD 2006},
  publisher   = {Springer Berlin / Heidelberg},
  year        = {2006},
  editor      = {Fürnkranz, Johannes and Scheffer, Tobias and Spiliopoulou, Myra},
  volume      = {4213},
  series      = {Lecture Notes in Computer Science},
  pages       = {633-640},
  abstract    = {In this paper we introduce a novel approach for incrementally
	
	building aspect models, and use it to dynamically discover underlying
	
	themes from document streams. Using the new approach we present an
	
	application which we call “query-line tracking” i.e., we automatically
	
	discover and summarize different themes or stories that appear over
	time,
	
	and that relate to a particular query. We present evaluation on news
	
	corpora to demonstrate the strength of our method for both query-line
	
	tracking, online indexing and clustering.},
  affiliation = {Microsoft Research, 1 Microsoft Way, Redmond, WA 98052, USA},
  file        = {Surendran2006Incremental.pdf:Surendran2006Incremental.pdf:PDF},
  groups      = {Twitter},
  isbn        = {978-3-540-45374-1},
  keyword     = {Computer Science},
  owner       = {linchen},
  timestamp   = {2011.11.01},
  url         = {http://dx.doi.org/10.1007/11871637_65},
}

@InProceedings{Suryanto2009Qualityaware,
  author    = {Suryanto, Maggy Anastasia and Lim, Ee Peng and Sun, Aixin and Chiang, Roger H. L.},
  title     = {Quality-aware collaborative question answering: methods and evaluation},
  booktitle = {Proceedings of the Second ACM International Conference on Web Search and Data Mining},
  year      = {2009},
  series    = {WSDM '09},
  pages     = {142--151},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Community Question Answering (QA) portals contain ques-
	
	tions and answers contributed by hundreds of millions of
	
	users. These databases of questions and answers are of
	
	great value if they can be used directly to answer questions
	
	from any user. In this research, we address this collabo-
	
	rative QA task by drawing knowledge from the crowds in
	
	community QA portals such as Yahoo! Answers. Despite
	
	their popularity, it is well known that answers in commu-
	
	nity QA portals have unequal quality. We therefore propose
	
	a quality-aware framework to design methods that select an-
	
	swers from a community QA portal considering answer qual-
	
	ity in addition to answer relevance. Besides using answer
	
	features for determining answer quality, we introduce sev-
	
	eral other quality-aware QA methods using answer quality
	
	derived from the expertise of answerers. Such expertise can
	
	be question independent or question dependent. We evalu-
	
	ate our proposed methods using a database of 95K questions
	
	and 537K answers obtained from Yahoo! Answers. Our ex-
	
	periments have shown that answer quality can improve QA
	
	performance signi¯cantly. Furthermore, question dependent
	
	expertise based methods are shown to outperform methods
	
	using answer features only. It is also found that there are
	
	also good answers not among the best answers identi¯ed by
	
	Yahoo! Answers users.},
  acmid     = {1498820},
  comment   = {find high quality answer relevance*quality
	
	four models are presented to evaluate quality
	
	1) assume answer quality is a normalized combination of user's asking
	expertise (hub in hits) and answeringexpertise (authority in hits)
	
	2)the same assumption, query dependent HITS
	
	3),4)non iterative
	
	quality they use other people's methods},
  doi       = {http://doi.acm.org/10.1145/1498759.1498820},
  file      = {Suryanto2009Qualityaware.pdf:Suryanto2009Qualityaware.pdf:PDF},
  isbn      = {978-1-60558-390-7},
  keywords  = {answer quality, expertise, question answering},
  location  = {Barcelona, Spain},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1498759.1498820},
}

@Article{szomszor2010semantic,
  author    = {Szomszor, M. and Alani, H. and Cantador, I. and O’Hara, K. and Shadbolt, N.},
  title     = {{Semantic modelling of user interests based on cross-folksonomy analysis}},
  journal   = {The Semantic Web-ISWC 2008},
  year      = {2010},
  pages     = {632--648},
  abstract  = {The continued increase inWeb usage, in particular participation in
	folksonomies,
	
	reveals a trend towards a more dynamic and interactive Web where individuals
	
	can organise and share resources. Tagging has emerged as the de-facto
	
	standard for the organisation of such resources, providing a versatile
	and reactive
	
	knowledge management mechanism that users find easy to use and understand.
	It
	
	is common nowadays for users to have multiple profiles in various
	folksonomies,
	
	thus distributing their tagging activities. In this paper, we present
	a method for
	
	the automatic consolidation of user profiles across two popular social
	networking
	
	sites, and subsequent semantic modelling of their interests utilisingWikipedia
	as
	
	a multi-domain model.We evaluate how much can be learned from such
	sites, and
	
	in which domains the knowledge acquired is focussed. Results show
	that far richer
	
	interest profiles can be generated for userswhenmultiple tag-clouds
	are combined.},
  comment   = {Motivation: distributed user profiles
	
	data:flicker & delicious
	
	architecture:1)identify distributed user profiles by homepage URL
	
	2)filter tags (wordnet)
	
	3)link tags to wikipedia for a category
	
	4)define interest
	
	results
	
	users show different interest among different sites},
  file      = {:szomszor2010semantic.pdf:PDF},
  groups    = {Recommender Systems},
  publisher = {Springer},
}

@Article{Tak'acs2007Major,
  author    = {Tak\'{a}cs, G\'{a}bor and Pil\'{a}szy, Istv\'{a}n and N\'{e}meth, Botty\'{a}n and Tikk, Domonkos},
  title     = {Major components of the gravity recommendation system},
  journal   = {SIGKDD Explor. Newsl.},
  year      = {2007},
  volume    = {9},
  number    = {2},
  pages     = {80--83},
  issn      = {1931-0145},
  abstract  = {The Netﬂix Prize is a collaborative ﬁltering problem. This
	
	subﬁeld of machine learning became popular in the late
	
	1990s with the spread of online services that used recommendation
	systems (e.g. Amazon, Yahoo! Music, and of
	
	course Netﬂix). The aim of such a system is to predict
	
	what items a user might like based on his/her and other
	
	users’ previous ratings. The Netﬂix Prize dataset is much
	
	larger than former benchmark datasets, therefore the scalability of
	the algorithms is a must. This paper describes the
	
	major components of our blending based solution, called
	
	the Gravity Recommendation System (GRS). In the Net-
	
	ﬂix Prize contest, it attained RMSE 0.8743 as of November
	
	2007. We now compare the eﬀectiveness of some selected
	
	individual and combined approaches on a particular subset
	
	of the Prize dataset, and discuss their important features
	
	and drawbacks.},
  address   = {New York, NY, USA},
  comment   = {+content by add rows on the factor vector
	
	two approaches: mf & CF by similarity of items},
  doi       = {http://doi.acm.org/10.1145/1345448.1345466},
  file      = {Tak'acs2007Major.pdf:Tak'acs2007Major.pdf:PDF},
  groups    = {Recommender Systems},
  publisher = {ACM},
}

@InProceedings{Takamura2011Summarizing,
  author    = {Takamura, Hiroya and Yokono, Hikaru and Okumura, Manabu},
  title     = {Summarizing a document stream},
  booktitle = {Proceedings of the 33rd European conference on Advances in information retrieval},
  year      = {2011},
  series    = {ECIR'11},
  pages     = {177--188},
  address   = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  abstract  = {We introduce the task of summarizing a stream of short documents on
	microblogs such as Twitter. On microblogs, thousands of short documents
	on a certain topic such as sports matches or TV dramas are posted
	by users. Noticeable characteristics of microblog data are that documents
	are often very highly redundant and aligned on timeline. There can
	be thousands of documents on one event in the topic. Two very similar
	documents will refer to two distinct events when the documents are
	temporally distant. We examine the microblog data to gain more understanding
	of those characteristics, and propose a summarization model for a
	stream of short documents on timeline, along with an approximate
	fast algorithm for generating summary. We empirically show that our
	model generates a good summary on the datasets of microblog documents
	on sports matches.},
  acmid     = {1996913},
  file      = {Takamura2011Summarizing.pdf:Takamura2011Summarizing.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-3-642-20160-8},
  location  = {Dublin, Ireland},
  numpages  = {12},
  url       = {http://dl.acm.org/citation.cfm?id=1996889.1996913},
}

@InProceedings{Tan2008Unsupervised,
  author    = {Tan, Bin and Peng, Fuchun},
  title     = {Unsupervised Query Segmentation Using Generative Language Models and Wikipedia},
  booktitle = {Proceedings of the 17th International Conference on World Wide Web},
  year      = {2008},
  series    = {WWW '08},
  pages     = {347--356},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {In this paper, we propose a novel unsupervised approach to query segmentation,
	an important task in Web search. We use a generative query model
	to recover a query's underlying concepts that compose its original
	segmented form. The model's parameters are estimated using an expectation-maximization
	(EM) algorithm, optimizing the minimum description length objective
	function on a partial corpus that is specific to the query. To augment
	this unsupervised learning, we incorporate evidence from Wikipedia.
	
	
	Experiments show that our approach dramatically improves performance
	over the traditional approach that is based on mutual information,
	and produces comparable results with a supervised method. In particular,
	the basic generative language model contributes a 7.4% improvement
	over the mutual information based method (measured by segment F1
	on the Intersection test set). EM optimization further improves the
	performance by 14.3%. Additional knowledge from Wikipedia provides
	another improvement of 24.3%, adding up to a total of 46% improvement
	(from 0.530 to 0.774).},
  acmid     = {1367545},
  comment   = {EM
	
	generative model: concept->word
	
	concepts are not independent},
  file      = {Tan2008Unsupervised.pdf:Tan2008Unsupervised.pdf:PDF},
  isbn      = {978-1-60558-085-2},
  keywords  = {concept discovery, query segmentation},
  location  = {Beijing, China},
  numpages  = {10},
  timestamp = {2016.04.26},
}

@ARTICLE{Tan2014Object,
  author = {Tan, Chang and Liu, Qi and Chen, Enhong and Xiong, Hui and Wu, Xiang},
  title = {Object-Oriented Travel Package Recommendation},
  journal = {ACM Trans. Intell. Syst. Technol.},
  year = {2014},
  volume = {5},
  pages = {43:1--43:26},
  number = {3},
  month = sep,
  acmid = {2542665},
  address = {New York, NY, USA},
  articleno = {43},
  doi = {10.1145/2542665},
  file = {Tan2014Object.pdf:Tan2014Object.pdf:PDF},
  issn = {2157-6904},
  issue_date = {September 2014},
  keywords = {Bayesian, collaborative filtering, object-oriented, topic model, travel},
  numpages = {26},
  publisher = {ACM},
  timestamp = {2014.10.28},
  url = {http://doi.acm.org/10.1145/2542665}
}

@INPROCEEDINGS{Tan2014Riemannian,
  author = {Mingkui Tan and Ivor W. Tsang and Li Wang and Bart Vandereycken and
	Sinno Jialin Pan},
  title = {Riemannian Pursuit for Big Matrix Recovery},
  booktitle = {Proceedings of ICML},
  year = {2014},
  pages = {1156-1164},
  abstract = {Low rank matrix recovery is a fundamental task in many real-world
	applications. The performance of existing methods, however, deteriorates
	significantly when applied to ill-conditioned or large-scale matrices.
	In this paper, we therefore propose an efficient method, called Riemannian
	Pursuit (RP), that aims to address these two problems simultaneously.
	Our method consists of a sequence of fixed-rank optimization problems.
	Each subproblem, solved by a nonlinear Riemannian conjugate gradient
	method, aims to correct the solution in the most important subspace
	of increasing size. Theoretically, RP converges linearly under mild
	conditions and experimental results show that it substantially outperforms
	existing methods when applied to large-scale and ill-conditioned
	matrices.},
  file = {Tan2014Riemannian.pdf:Tan2014Riemannian.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.06.24}
}

@INPROCEEDINGS{Tandon2014Learning,
  author = {Rashish Tandon and Pradeep Ravikumar},
  title = {Learning Graphs with a Few Hubs},
  booktitle = {Proceedings of ICML},
  year = {2014},
  pages = {535-543},
  abstract = {We consider the problem of recovering the graph structure of a ``hub-networked''
	Ising model given iid samples, under high-dimensional settings, where
	number of nodes $p$ could be potentially larger than the number of
	samples $n$. By a ``hub-networked'' graph, we mean a graph with a
	few ``hub nodes'' with very large degrees. State of the art estimators
	for Ising models have a sample complexity that scales polynomially
	with the maximum node-degree, and are thus ill-suited to recovering
	such graphs with a few hub nodes. Some recent proposals for specifically
	recovering hub graphical models do not come with theoretical guarantees,
	and even empirically provide limited improvements over vanilla Ising
	model estimators. Here, we show that under such low sample settings,
	instead of estimating ``difficult'' components such as hub-neighborhoods,
	we can use quantitative indicators of our inability to do so, and
	thereby identify hub-nodes. This simple procedure allows us to recover
	hub-networked graphs with very strong statistical guarantees even
	under very low sample settings.},
  file = {Tandon2014Learning.pdf:Tandon2014Learning.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.06.24}
}

@InProceedings{Tang2014Understanding,
  author    = {Jian Tang and Zhaoshi Meng and Xuanlong Nguyen and Qiaozhu Mei and Ming Zhang},
  title     = {Understanding the Limiting Factors of Topic Modeling via Posterior Contraction Analysis},
  booktitle = {Proceedings of ICML},
  year      = {2014},
  pages     = {263-271},
  abstract  = {Topic models such as the latent Dirichlet allocation (LDA) have become
	a standard staple in the modeling toolbox of machine learning. They
	have been applied to a vast variety of data sets, contexts, and tasks
	to varying degrees of success. However, to date there is almost no
	formal theory explicating the LDA's behavior, and despite its familiarity
	there is very little systematic analysis of and guidance on the properties
	of the data that affect the inferential performance of the model.
	This paper seeks to address this gap, by providing a systematic analysis
	of factors which characterize the LDA's performance. We present theorems
	elucidating the posterior contraction rates of the topics as the
	amount of data increases, and a thorough supporting empirical study
	using synthetic and real data sets, including news and web-based
	articles and tweet messages. Based on these results we provide practical
	guidance on how to identify suitable data sets for topic models,
	and how to specify particular model parameters.},
  comment   = {best paper
	
	small number of topics, \alpha<0.1, large number of topics, \alpha
	increase
	
	\beta always =0.1
	
	LDA doesn't work well on short texts and long texts(sample)
	
	100 topics for more than 1000 documents},
  file      = {Tang2014Understanding.pdf:Tang2014Understanding.pdf:PDF},
  owner     = {littlep},
  timestamp = {2014.06.24},
}

@InProceedings{Tang2009Multi-topic,
  author    = {Tang, J. and Yao, L. and Chen, D.},
  title     = {Multi-topic based query-oriented summarization},
  booktitle = {SIAM International Conference Data Mining},
  year      = {2009},
  groups    = {Twitter},
}

@Article{tang2010combination,
  author   = {Tang, J. and Yao, L. and Zhang, D. and Zhang, J.},
  title    = {{A combination approach to web user profiling}},
  journal  = {ACM Transactions on Knowledge Discovery from Data},
  year     = {2010},
  abstract = {In this paper, we study the problem of Web user pro¯ling, which is
	aimed at ¯nding, extracting,
	
	and fusing the `semantic'-based user pro¯le from the Web. Previously,
	Web user pro¯ling was
	
	often undertaken by creating a list of keywords for the user, which
	is (sometimes even highly)
	
	insu±cient for main applications. This paper formalizes the pro¯ling
	problem as several subtasks:
	
	pro¯le extraction, pro¯le integration, and user interest discovery.
	We propose a combination
	
	approach to deal with the pro¯ling tasks. Speci¯cally, we employ a
	classi¯cation model to identify
	
	relevant documents for a user from the Web and propose a Tree-structured
	Conditional Random
	
	Fields (TCRF) to extract the pro¯le information from the identi¯ed
	documents; we propose a
	
	uni¯ed probabilistic model to deal with the name ambiguity problem
	(several users with the same
	
	name) when integrating the pro¯le information extracted from di®erent
	sources; ¯nally, we use
	
	a probabilistic topic model to model the extracted user pro¯les, and
	construct the user interest
	
	model. Experimental results on an online system show that the combination
	approach to di®erent
	
	pro¯ling tasks clearly outperforms several baseline methods. The extracted
	pro¯les have been
	
	applied to expert ¯nding, an important application on the Web. Experiments
	show that the
	
	accuracy of expert ¯nding can be improved (ranging from +6% to +26%
	in terms of MAP) by
	
	taking advantage of the pro¯les.},
  comment  = {three main problems
	
	1)user profiling
	
	the author define the schema of researcher profile, including 4 general
	concepts and 29 properties and 4 relations, like concept "researcher"
	has properties such as fax,phone,address,email, BSdate,MSUniv,Phdmajor,
	concept "interest" has property topical aspect and time, etc.
	
	given a researcher name, first get a list of web pages by a search
	engine
	
	use SVM to classify these pages into "homepage" and "web page introducing
	the researcher"
	
	segmentation and tagging
	
	2)name disambiguation
	
	3)user interest discovery},
  file     = {tang2010combination.pdf:tang2010combination.pdf:PDF},
}

@InProceedings{Tang2007Social,
  author    = {Tang, Jie and Zhang, Duo and Yao, Limin},
  title     = {Social Network Extraction of Academic Researchers},
  booktitle = {ICDM '07: Proceedings of the 2007 Seventh IEEE International Conference on Data Mining},
  year      = {2007},
  pages     = {292--301},
  address   = {Washington, DC, USA},
  publisher = {IEEE Computer Society},
  doi       = {http://dx.doi.org/10.1109/ICDM.2007.30},
  isbn      = {0-7695-3018-4},
}

@Article{tangtopic,
  author    = {Tang, J. and Zhang, J. and Jin, R. and Yang, Z. and Cai, K. and Zhang, L. and Su, Z.},
  title     = {{Topic level expertise search over heterogeneous networks}},
  journal   = {Machine Learning Journal},
  year      = {to appear},
  pages     = {1--27},
  issn      = {0885-6125},
  abstract  = {In this paper, we present a topic level expertise search framework
	
	for heterogeneous networks. Different from the traditional Web
	
	search engines that perform retrieval and ranking at document level
	
	(or at object level), we investigate the problem of expertise search
	
	at topic level over heterogeneous networks. In particular, we study
	
	this problem in an academic search and mining system, which extracts
	and integrates the academic data from the distributed Web.
	
	We present a uniﬁed topic model to simultaneously model topical
	
	aspects of different objects in the academic network. Based on the
	
	learned topic models, we investigate the expertise search problem
	
	from three dimensions: ranking, citation tracing analysis, and topical
	graph search. Speciﬁcally, we propose a topic level random
	
	walk method for ranking the different objects. In citation tracing
	
	analysis, we aim to uncover how a piece of work inﬂuences its
	
	follow-up work. Finally, we have developed a topical graph search
	
	function, based on the topic modeling and citation tracing analysis.
	
	Experimental results show that various expertise search and mining
	tasks can indeed beneﬁt from the proposed topic level analysis
	
	approach.},
  file      = {tangtopic.pdf:tangtopic.pdf:PDF},
  publisher = {Springer},
}

@InProceedings{tang2008arnetMiner,
  author    = {Tang, Jie and Zhang, Jing and Yao, Limin and Li, Juanzi and Zhang, Li and Su, Zhong},
  title     = {ArnetMiner: extraction and mining of academic social networks},
  booktitle = {KDD '08: Proceeding of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining},
  year      = {2008},
  pages     = {990--998},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {This paper addresses several key issues in the ArnetMiner system,
	which aims at extracting and mining academic social networks. Specifically,
	the system focuses on: 1) Extracting researcher profiles automatically
	from the Web; 2) Integrating the publication data into the network
	from existing digital libraries; 3) Modeling the entire academic
	network; and 4) Providing search services for the academic network.
	So far, 448,470 researcher profiles have been extracted using a unified
	tagging approach. We integrate publications from online Web databases
	and propose a probabilistic framework to deal with the name ambiguity
	problem. Furthermore, we propose a unified modeling approach to simultaneously
	model topical aspects of papers, authors, and publication venues.
	Search services such as expertise search and people association search
	have been provided based on the modeling results. In this paper,
	we describe the architecture and main features of the system. We
	also present the empirical evaluation of the proposed methods.},
  doi       = {http://doi.acm.org/10.1145/1401890.1402008},
  isbn      = {978-1-60558-193-4},
  location  = {Las Vegas, Nevada, USA},
}

@ARTICLE{Tang2014Detecting,
  author = {Tang, Xuning and Yang, Christopher C.},
  title = {Detecting Social Media Hidden Communities Using Dynamic Stochastic
	Blockmodel with Temporal Dirichlet Process},
  journal = {ACM Trans. Intell. Syst. Technol.},
  year = {2014},
  volume = {5},
  pages = {36:1--36:21},
  number = {2},
  month = apr,
  abstract = {Detecting evolving hidden communities within dynamic social networks
	has attracted significant attention recently due to its broad applications
	in e-commerce, online social media, security intelligence, public
	health, and other areas. Many community network detection techniques
	employ a two-stage approach to identify and detect evolutionary relationships
	between communities of two adjacent time epochs. These techniques
	often identify communities with high temporal variation, since the
	two-stage approach detects communities of each epoch independently
	without considering the continuity of communities across two time
	epochs. Other techniques require identification of a predefined number
	of hidden communities which is not realistic in many applications.
	To overcome these limitations, we propose the Dynamic Stochastic
	Blockmodel with Temporal Dirichlet Process, which enables the detection
	of hidden communities and tracks their evolution simultaneously from
	a network stream. The number of hidden communities is automatically
	determined by a temporal Dirichlet process without human intervention.
	We tested our proposed technique on three different testbeds with
	results identifying a high performance level when compared to the
	baseline algorithm.},
  acmid = {2517085},
  address = {New York, NY, USA},
  articleno = {36},
  doi = {10.1145/2517085},
  file = {Tang2014Detecting.pdf:Tang2014Detecting.pdf:PDF},
  issn = {2157-6904},
  issue_date = {April 2014},
  keywords = {Dynamic Community Detection, Stochastic Blockmodel, Temporal Dirichlet
	Process},
  numpages = {21},
  publisher = {ACM},
  timestamp = {2015.08.26},
  url = {http://doi.acm.org/10.1145/2517085}
}

@Conference{Tantipathananandh2009Constantfactor,
  author       = {Tantipathananandh, C. and Berger-Wolf, T.},
  title        = {{Constant-factor approximation algorithms for identifying dynamic communities}},
  booktitle    = {Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining},
  year         = {2009},
  pages        = {827--836},
  organization = {ACM},
}

@InProceedings{Tao2007Exploration,
  author    = {Tao, Tao and Zhai, ChengXiang},
  title     = {An Exploration of Proximity Measures in Information Retrieval},
  booktitle = {Proceedings of the 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year      = {2007},
  series    = {SIGIR '07},
  pages     = {295--302},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {In most existing retrieval models, documents are scored primarily
	based on various kinds of term statistics such as within-document
	frequencies, inverse document frequencies, and document lengths.
	Intuitively, the proximity of matched query terms in a document can
	also be exploited to promote scores of documents in which the matched
	query terms are close to each other. Such a proximity heuristic,
	however, has been largely under-explored in the literature; it is
	unclear how we can model proximity and incorporate a proximity measure
	into an existing retrieval model. In this paper,we systematically
	explore the query term proximity heuristic. Specifically, we propose
	and study the effectiveness of five different proximity measures,
	each modeling proximity from a different perspective. We then design
	two heuristic constraints and use them to guide us in incorporating
	the proposed proximity measures into an existing retrieval model.
	Experiments on five standard TREC test collections show that one
	of the proposed proximity measures is indeed highly correlated with
	document relevance, and by incorporating it into the KL-divergence
	language model and the Okapi BM25 model, we can significantly improve
	retrieval performance.},
  acmid     = {1277794},
  comment   = {several proximity heuristics
	
	several aggregation methods
	
	simple combine with existing retrieval models},
  file      = {Tao2007Exploration.pdf:Tao2007Exploration.pdf:PDF},
  isbn      = {978-1-59593-597-7},
  keywords  = {distance measures, proximity, retrieval heuristics},
  location  = {Amsterdam, The Netherlands},
  numpages  = {8},
}

@InProceedings{Tao2006Regularized,
  author    = {Tao, Tao and Zhai, ChengXiang},
  title     = {Regularized estimation of mixture models for robust pseudo-relevance feedback},
  booktitle = {Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval},
  year      = {2006},
  series    = {SIGIR '06},
  pages     = {162--169},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Pseudo-relevance feedback has proven to be an effective strategy for
	improving retrieval accuracy in all retrieval models. However the
	performance of existing pseudo feedback methods is often affected
	significantly by some parameters, such as the number of feedback
	documents to use and the relative weight of original query terms;
	these parameters generally have to be set by trial-and-error without
	any guidance. In this paper, we present a more robust method for
	pseudo feedback based on statistical language models. Our main idea
	is to integrate the original query with feedback documents in a single
	probabilistic mixture model and regularize the estimation of the
	language model parameters in the model so that the information in
	the feedback documents can be gradually added to the original query.
	Unlike most existing feedback methods, our new method has no parameter
	to tune. Experiment results on two representative data sets show
	that the new method is significantly more robust than a state-of-the-art
	baseline language modeling approach for feedback with comparable
	or better retrieval accuracy.},
  acmid     = {1148201},
  doi       = {http://doi.acm.org/10.1145/1148170.1148201},
  file      = {Tao2006Regularized.pdf:Tao2006Regularized.pdf:PDF},
  isbn      = {1-59593-369-7},
  keywords  = {EM, mixture model, pseudo feedback, regulation},
  location  = {Seattle, Washington, USA},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/1148170.1148201},
}

@InProceedings{Teevan2011TwitterSearch,
  author    = {Teevan, Jaime and Ramage, Daniel and Morris, Merredith Ringel},
  title     = {\#TwitterSearch: a comparison of microblog search and web search},
  booktitle = {Proceedings of the fourth ACM international conference on Web search and data mining},
  year      = {2011},
  series    = {WSDM '11},
  pages     = {35--44},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Social networking Web sites are not just places to maintain relationships;
	they can also be valuable information sources. However, little is
	known about how and why people search socially-generated content.
	In this paper we explore search behavior on the popular microblogging/social
	networking site Twitter. Using analysis of large-scale query logs
	and supplemental qualitative data, we observe that people search
	Twitter to find temporally relevant information (e.g., breaking news,
	real-time content, and popular trends) and information related to
	people (e.g., content directed at the searcher, information about
	people of interest, and general sentiment and opinion). Twitter queries
	are shorter, more popular, and less likely to evolve as part of a
	session than Web queries. It appears people repeat Twitter queries
	to monitor the associated search results, while changing and developing
	Web queries to learn about a topic. The results returned from the
	different corpora support these different uses, with Twitter results
	including more social chatter and social events, and Web results
	containing more basic facts and navigational content. We discuss
	the implications of these findings for the design of next-generation
	Web search tools that incorporate social media.},
  acmid     = {1935842},
  doi       = {http://doi.acm.org/10.1145/1935826.1935842},
  file      = {Teevan2011TwitterSearch.pdf:Teevan2011TwitterSearch.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-1-4503-0493-1},
  keywords  = {microblogging, qa, social media, social search, web search},
  location  = {Hong Kong, China},
  numpages  = {10},
}

@ARTICLE{Teh2006Hierarchical,
  author = {Teh, Yee Whye and Jordan, Michael I and Beal, Matthew J and Blei,
	David M},
  title = {Hierarchical dirichlet processes},
  journal = {Journal of the american statistical association},
  year = {2006},
  volume = {101},
  pages = {1566-1581},
  number = {476},
  timestamp = {2015.09.01}
}

@Article{Thai-Nghe2011Factorization,
  author  = {Thai-Nghe, N. and Drumond, L. and Horvath, T. and Krohn-Grimberghe, A. and Nanopoulos, A. and Schmidt-Thieme, L.},
  title   = {Factorization techniques for predicting student performance},
  journal = {Educational Recommender Systems and Technologies: Practices and Challenges (In press), OC Santos and JG Boticario, Eds. IGI Global},
  year    = {2011},
  groups  = {Recommender Systems},
}

@ARTICLE{TIBSHIRAN1996Regression,
  author = {ROBERT TIBSHIRAN},
  title = {Regression Shrinkage and Selection via the Lasso},
  journal = {Journal of the Royal Statistical Society. Series B (Methodological)},
  year = {1996},
  volume = {58(1)},
  pages = {267-288},
  file = {TIBSHIRAN1996Regression.pdf:TIBSHIRAN1996Regression.pdf:PDF},
  owner = {linchen},
  timestamp = {2011.08.11}
}

@InProceedings{Tran2012Exploiting,
  author    = {Tran, Tuan A.},
  title     = {Exploiting Temporal Topic Models in Social Media Retrieval},
  booktitle = {Proceedings of the 35th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year      = {2012},
  series    = {SIGIR '12},
  pages     = {999--999},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Many of user generated contents in the Web 2.0 center around real-world
	incidents such as Japanese tsunami, or general concerns such as recent
	economic downturn. Such type of information is always of interest
	to users. For instance, when a user reads a news article about a
	tsunami in Japan, she wants to see related Flickr photos or more
	tweets about it. Conventional keyword-based search is inappropriate,
	since it is not always trivial to formulate ad-hoc interests about
	the event and material. In some cases, the user might want to explore
	emerging topics that dominate different sources. Present systems
	fail to connect topically documents across media, and the user has
	to examine individual sources to infer the topics herself.
	
	
	In this work, we address a special type of user information need,
	temporal topic, which refers to any abstract matter active within
	some points or periods of time. A temporal topic can be a real-world
	event, e.g. the Arab Spring revolution, but can also be a less conceivable
	subject, e.g. the study of vacuum tube computers in 1950s. Topics
	can also be recurrent such as the US presidency campaigns. There
	are extensive studies on how to detect topics from a collection of
	documents, but little uses temporal topics as part of user interest
	to retrieve documents. We believe that temporal topic-based retrieval
	is a one solution to improve user experience of present IR systems,
	as well as to benefit other applications (e.g. topic-sensitive online
	advertisement).
	
	
	Our research goal can be defined in three research questions. The
	first question involves finding latent temporal topics in a social
	media stream, where documents are well equipped with meta-data (timestamps,
	geo-spatial data, etc.). Following mixture models such as LDA, we
	treat each document as a mix of different temporal topic models,
	each model is incorporated with time. A temporal topic consists of
	at least two types of attributes - time and representing words, as
	similar to [4]. The dynamics of temporal topics can be characterized
	in a timeline fashion [4], or using hierarchical structures [1].
	The challenge lies in devising a model flexible enough to diverse
	and rapidly changing data without many parameter assumptions. For
	this, we see Bayesian nonpara-metrics [3] as one promising solution,
	and will extend it to temporal dimension.
	
	
	The second research question is how to retrieve and rank documents
	from different social media sites, based on their relevance to one
	or several given temporal topics. We identify some following challenges.
	The first one is representing temporal topics as queries: although
	there have been attempts using keywords and time window separately
	[2], we aim to unify time and (topical) words in a single query model.
	The second challenge is integrating temporal topic models into ranking
	models. Inspired by our previous work [4], we will use language models
	to capture the relevance scores between documents and topics, and
	investigate advanced methods to index the scores effectively.
	
	
	Our last question involves connecting a given document to documents
	in other sources (data streams or corpora) that shared one of its
	latent temporal topics. This task does not only provide unified insight
	into different social media sites, but also help improve the quality
	of models by data in diverse sources. However, formalizing the semantics
	of "similarity" for documents in different settings based on temporal
	topcis is tricky. One baseline method is to apply Kullback-Leibler
	divergence on comparable features (TF-IDF, n-grams, photo tags, timestamps,..).
	We can also use language models [5] to construct a language model
	for each candidate document, then estimate how likely it generates
	the document of interest within a given temporal topic.},
  acmid     = {2348423},
  doi       = {10.1145/2348283.2348423},
  groups    = {Twitter},
  isbn      = {978-1-4503-1472-5},
  keywords  = {ranking, social media, temporal data analysis, topic model},
  location  = {Portland, Oregon, USA},
  numpages  = {1},
  url       = {http://doi.acm.org/10.1145/2348283.2348423},
}

@INPROCEEDINGS{Trigeorgis2014Deep,
  author = {George Trigeorgis and Konstantinos Bousmalis and Stefanos Zafeiriou
	and Bjoern Schuller},
  title = {A Deep Semi-NMF Model for Learning Hidden Representations},
  booktitle = {Proceedings of ICML},
  year = {2014},
  pages = {1225-1233},
  abstract = {Semi-NMF is a matrix factorization technique that learns a low-dimensional
	representation of a dataset that lends itself to a clustering interpretation.
	It is possible that the mapping between this new representation and
	our original features contains rather complex hierarchical information
	with implicit lower-level hidden attributes, that classical one level
	clustering methodologies can not interpret. In this work we propose
	a novel model, Deep Semi-NMF, that is able to learn such hidden representations
	that allow themselves to an interpretation of clustering according
	to different, unknown attributes of a given dataset. We show that
	by doing so, our model is able to learn low-dimensional representations
	that are better suited for clustering, outperforming Semi-NMF, but
	also other NMF variants.},
  file = {Trigeorgis2014Deep.pdf:Trigeorgis2014Deep.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.06.23}
}

@InProceedings{Tso-Sutter2008Tag-aware,
  author    = {Tso-Sutter, Karen H. L. and Marinho, Leandro Balby and Schmidt-Thie Lars},
  title     = {Tag-aware recommender systems by fusion of collaborative filtering algorithms},
  booktitle = {Proceedings of the 2008 ACM symposium on Applied computing},
  year      = {2008},
  series    = {SAC '08},
  pages     = {1995--1999},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Recommender Systems (RS) aim at predicting items or ratings of items
	that the user are interested in. Collaborative Filtering (CF) algorithms
	such as user- and item-based methods are the dominant techniques
	applied in RS algorithms. To improve recommendation quality, metadata
	such as content information of items has typically been used as additional
	knowledge. With the increasing popularity of the collaborative tagging
	systems, tags could be interesting and useful information to enhance
	RS algorithms. Unlike attributes which are "global" descriptions
	of items, tags are "local" descriptions of items given by the users.
	To the best of our knowledge, there hasn't been any prior study on
	tag-aware RS. In this paper, we propose a generic method that allows
	tags to be incorporated to standard CF algorithms, by reducing the
	three-dimensional correlations to three two-dimensional correlations
	and then applying a fusion method to re-associate these correlations.
	Additionally, we investigate the effect of incorporating tags information
	to different CF algorithms. Empirical evaluations on three CF algorithms
	with real-life data set demonstrate that incorporating tags to our
	proposed approach provides promising and significant results.},
  acmid     = {1364171},
  doi       = {http://doi.acm.org/10.1145/1363686.1364171},
  file      = {Tso-Sutter2008Tag-aware.pdf:Tso-Sutter2008Tag-aware.pdf:PDF},
  groups    = {Recommender Systems},
  isbn      = {978-1-59593-753-7},
  keywords  = {collaborative filtering, recommender systems, tags},
  location  = {Fortaleza, Ceara, Brazil},
  numpages  = {5},
  url       = {http://doi.acm.org/10.1145/1363686.1364171},
}

@INPROCEEDINGS{Tu2013Exploiting,
  author = {Tu, Xinhui and Luo, Jing and Li, Bo and He, Tingting and Liu, Maofu},
  title = {Exploiting proximity feature in statistical translation models for
	information retrieval},
  booktitle = {Proceedings of the 22nd ACM international conference on Conference
	on information and knowledge management},
  year = {2013},
  series = {CIKM '13},
  pages = {1237--1240},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {A main challenge in applying translation language models to information
	retrieval is how to estimate the 'true' probability that a query
	could be generated as a translation of a document. The state-of-art
	methods rely on document-based word co-occurrences to estimate word-word
	translation probabilities. However, these methods do not take into
	account the proximity of co-occurrences. Intuitively, the proximity
	of co-occurrences can be exploited to estimate more accurate translation
	probabilities, since two words occur closer are more likely to be
	related. In this paper, we study how to explicitly incorporate proximity
	information into the existing translation language model, and propose
	a proximity-based translation language model, called TM-P, with three
	variants. In our TM-P models, a new concept (proximity-based word
	co-occurrence frequency) is introduced to model the proximity of
	word co-occurrences, which is then used to estimate translation probabilities.
	Experimental results on standard TREC collections show that our TM-P
	models achieve significant improvements over the state-of-the-art
	translation models.},
  acmid = {2507864},
  file = {Tu2013Exploiting.pdf:Tu2013Exploiting.pdf:PDF},
  isbn = {978-1-4503-2263-8},
  keywords = {information retrieval, proximity information, translation language
	models},
  location = {San Francisco, California, USA},
  numpages = {4},
  timestamp = {2014.10.04}
}

@Article{Tumasjan2010Predicting,
  author  = {Tumasjan, Andranik and Sprenger, Timm O and Sandner, Philipp G and Welpe, Isabell M},
  title   = {Predicting elections with Twitter: What 140 characters reveal about political sentiment},
  journal = {International AAAI Conference on Weblogs and Social Media Washington DC},
  year    = {2010},
  pages   = {178--185},
  groups  = {Twitter},
  url     = {http://www.aaai.org/ocs/index.php/ICWSM/ICWSM10/paper/viewFile/1441/1852},
}

@INPROCEEDINGS{Turpin2007Fast,
  author = {Turpin, Andrew and Tsegay, Yohannes and Hawking, David and Williams,
	Hugh E.},
  title = {Fast Generation of Result Snippets in Web Search},
  booktitle = {Proceedings of the 30th Annual International ACM SIGIR Conference
	on Research and Development in Information Retrieval},
  year = {2007},
  series = {SIGIR '07},
  pages = {127--134},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {The presentation of query biased document snippets as part of results
	pages presented by search engines has become an expectation of search
	engine users. In this paper we explore the algorithms and data structures
	required as part of a search engine to allow efficient generation
	of query biased snippets. We begin by proposing and analysing a document
	compression method that reduces snippet generation time by 58% over
	a baseline using the zlib compression library. These experiments
	reveal that finding documents on secondary storage dominates the
	total cost of generating snippets, and so caching documents in RAM
	is essential for a fast snippet generation process. Using simulation,
	we examine snippet generation performance for different size RAM
	caches. Finally we propose and analyse document reordering and compaction,
	revealing a scheme that increases the number of document cache hits
	with only a marginal affect on snippet quality. This scheme effectively
	doubles the number of documents that can fit in a fixed size cache.},
  acmid = {1277766},
  doi = {10.1145/1277741.1277766},
  file = {Turpin2007Fast.pdf:Turpin2007Fast.pdf:PDF},
  isbn = {978-1-59593-597-7},
  keywords = {document caching, snippet generation, web summaries},
  location = {Amsterdam, The Netherlands},
  numpages = {8},
  timestamp = {2014.08.27},
  url = {http://doi.acm.org/10.1145/1277741.1277766}
}

@InProceedings{Vandic2013Facet,
  author    = {Vandic, Damir and Frasincar, Flavius and Kaymak, Uzay},
  title     = {Facet Selection Algorithms for Web Product Search},
  booktitle = {Proceedings of the 22Nd ACM International Conference on Information \& Knowledge Management},
  year      = {2013},
  series    = {CIKM '13},
  pages     = {2327--2332},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Multifaceted search is a commonly used interaction paradigm in e-commerce
	applications, such as Web shops. Because of the large amount of possible
	product attributes, Web shops usually make use of static information
	to determine which facets should be displayed. Unfortunately, this
	approach does not take into account the user query, leading to a
	non-optimal facet drill down process. In this paper, we focus on
	automatic facet selection, with the goal of minimizing the number
	of steps needed to find the desired product. We propose several algorithms
	for facet selection, which we evaluate against the state-of-the-art
	algorithms from the literature. We implement our approach in a Web
	application called faccy.net. The evaluation is based on simulations
	employing 1000 queries, 980 products, 487 facets, and three drill
	down strategies. As evaluation metrics we use the average number
	of clicks, the average utility, and the top-10 promotion percentage.
	The results show that the Probabilistic Entropy algorithm significantly
	outperforms the other considered algorithms.},
  acmid     = {2505664},
  comment   = {An important problem of multifaceted search is the selection
	
	of facets that should be displayed for each query.
	
	Because products have so many attributes that could be
	
	displayed as facets, Web shops usually have some static
	
	business logic to display certain facets for each result set.},
  isbn      = {978-1-4503-2263-8},
  keywords  = {facet selection, information retrieval, product search},
  location  = {San Francisco, California, USA},
  numpages  = {6},
  timestamp = {2016.04.25},
}

@INPROCEEDINGS{Vinagre2015Collaborative,
  author = {Vinagre, Jo\~{a}o and Jorge, Al\'{\i}pio M\'{a}rio and Gama, Jo\~{a}o},
  title = {Collaborative Filtering with Recency-based Negative Feedback},
  booktitle = {Proceedings of the 30th Annual ACM Symposium on Applied Computing},
  year = {2015},
  series = {SAC '15},
  pages = {963--965},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Many online communities and services continuously generate data that
	can be used by recommender systems. When explicit ratings are not
	available, rating prediction algorithms are not directly applicable.
	Instead, data consists of positive-only user-item interactions, and
	the task is therefore not to predict ratings, but rather to predict
	good items to recommend -- item prediction. One particular challenge
	of positive-only data is how to interpret absent user-item interactions.
	These can either be seen as negative or as unknown preferences. In
	this paper, we propose a recency-based scheme to perform negative
	preference imputation in an incremental matrix factorization algorithm
	designed for streaming data. Our results show that this approach
	substantially improves the accuracy of the baseline method, outperforming
	both classic and state-of-the-art algorithms.},
  acmid = {2695998},
  doi = {10.1145/2695664.2695998},
  isbn = {978-1-4503-3196-8},
  keywords = {data streams, incremental, recommender systems},
  location = {Salamanca, Spain},
  numpages = {3},
  url = {http://doi.acm.org/10.1145/2695664.2695998}
}

@INPROCEEDINGS{Vlachou2013Branch,
  author = {Vlachou, Akrivi and Doulkeridis, Christos and N{\o}rv{\aa}g, Kjetil
	and Kotidis, Yannis},
  title = {Branch-and-bound Algorithm for Reverse Top-k Queries},
  booktitle = {Proceedings of the 2013 ACM SIGMOD International Conference on Management
	of Data},
  year = {2013},
  series = {SIGMOD '13},
  pages = {481--492},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Top-k queries return to the user only the k best objects based on
	
	the individual user preferences and comprise an essential tool for
	
	rank-aware query processing. Assuming a stored data set of user
	
	preferences, reverse top-k queries have been introduced for retrieving
	
	the users that deem a given database object as one of their top-k
	
	results. Reverse top-k queries have already attracted significant
	interest
	
	in research, due to numerous real-life applications such as
	
	market analysis and product placement. Currently, the most efficient
	
	algorithm for computing the reverse top-k set is RTA. RTA
	
	has two main drawbacks when processing a reverse top-k query:
	
	(i) it needs to access all stored user preferences, and (ii) it cannot
	
	avoid executing a top-k query for each user preference that belongs
	
	to the result set. To address these limitations, in this paper, we
	identify
	
	useful properties for processing reverse top-k queries without
	
	accessing each user’s individual preferences nor executing the topk
	
	query. We propose an intuitive branch-and-bound algorithm for
	
	processing reverse top-k queries efficiently and discuss novel optimizations
	
	to boost its performance. Our experimental evaluation
	
	demonstrates the efficiency of the proposed algorithm that outperforms
	
	RTA by a large margin.},
  acmid = {2465278},
  doi = {10.1145/2463676.2465278},
  file = {Vlachou2013Branch.pdf:Vlachou2013Branch.pdf:PDF},
  isbn = {978-1-4503-2037-5},
  keywords = {branch-and-bound algorithm, reverse top-k query},
  location = {New York, New York, USA},
  numpages = {12},
  url = {http://doi.acm.org/10.1145/2463676.2465278}
}

@ARTICLE{Wade2014Improving,
  author = {Wade, Sara and Dunson, David B. and Petrone, Sonia and Trippa, Lorenzo},
  title = {Improving Prediction from Dirichlet Process Mixtures via Enrichment},
  journal = {J. Mach. Learn. Res.},
  year = {2014},
  volume = {15},
  pages = {1041--1071},
  number = {1},
  month = jan,
  abstract = {Flexible covariate-dependent density estimation can be achieved by
	modelling the joint density of the response and covariates as a Dirichlet
	process mixture. An appealing aspect of this approach is that computations
	are relatively easy. In this paper, we examine the predictive performance
	of these models with an increasing number of covariates. Even for
	a moderate number of covariates, we find that the likelihood for
	x tends to dominate the posterior of the latent random partition,
	degrading the predictive performance of the model. To overcome this,
	we suggest using a different nonparametric prior, namely an enriched
	Dirichlet process. Our proposal maintains a simple allocation rule,
	so that computations remain relatively simple. Advantages are shown
	through both predictive equations and examples, including an application
	to diagnosis Alzheimer's disease.},
  acmid = {2638569},
  file = {Wade2014Improving.pdf:Wade2014Improving.pdf:PDF},
  issn = {1532-4435},
  issue_date = {January 2014},
  keywords = {Bayesian nonparametrics, density regression, predictive distribution,
	random partition, urn scheme},
  numpages = {31},
  publisher = {JMLR.org},
  timestamp = {2015.08.26},
  url = {http://dl.acm.org/citation.cfm?id=2627435.2638569}
}

@InProceedings{Walter2009Personalised,
  author    = {Walter, Frank E. and Battiston, Stefano and Schweitzer, Frank},
  title     = {Personalised and dynamic trust in social networks},
  booktitle = {RecSys '09: Proceedings of the third ACM conference on Recommender systems},
  year      = {2009},
  pages     = {197--204},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {We propose a novel trust metric for social networks which
	
	is suitable for application to recommender systems. It is
	
	personalised and dynamic, and allows to compute the indirect
	
	trust between two agents which are not neighbours
	
	based on the direct trust between agents that are neighbours.
	
	In analogy to some personalised versions of PageRank, this
	
	metric makes use of the concept of feedback centrality and
	
	overcomes some of the limitations of other trust metrics.
	
	In particular, it does not neglect cycles and other patterns
	
	characterising social networks, as some other algorithms do.
	
	In order to apply the metric to recommender systems, we
	
	propose a way to make trust dynamic over time. We show
	
	by means of analytical approximations and computer simulations
	
	that the metric has the desired properties. Finally,
	
	we carry out an empirical validation on a dataset crawled
	
	from an Internet community and compare the performance
	
	of a recommender system using our metric to one using collaborative
	
	ltering.},
  comment   = {Data: Epinions
	
	Method: very similar to PageRank, iteration but matrix instead of
	vector
	
	the initial direct trust matrix normalized as S
	
	iteration: T = S+\beta S T
	
	update: consider following rating behavior, add or remove trust points
	
	
	Result: a good beta = 0.8
	
	 the bias of rating: people tend to rate good products},
  file      = {Walter2009Personalised.pdf:Walter2009Personalised.pdf:PDF},
  groups    = {Recommender Systems},
  isbn      = {978-1-60558-435-5},
  location  = {New York, New York, USA},
}

@InProceedings{Wan2013Informational,
  author    = {Wan, Shengxian and Lan, Yanyan and Guo, Jiafeng and Fan, Chaosheng and Cheng, Xueqi},
  title     = {Informational Friend Recommendation in Social Media},
  booktitle = {Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year      = {2013},
  series    = {SIGIR '13},
  pages     = {1045--1048},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2484179},
  doi       = {10.1145/2484028.2484179},
  groups    = {Recommender Systems, Twitter},
  isbn      = {978-1-4503-2034-4},
  keywords  = {diversity, friend recommendation, informational utility},
  location  = {Dublin, Ireland},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/2484028.2484179},
}

@InProceedings{Wanas2008Automatic,
  author    = {Wanas, Nayer and El-Saban, Motaz and Ashour, Heba and Ammar, Waleed},
  title     = {Automatic scoring of online discussion posts},
  booktitle = {WICOW '08: Proceeding of the 2nd ACM workshop on Information credibility on the web},
  year      = {2008},
  pages     = {19--26},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Online discussions forums, known as forums for short, are conversational
	social cyberspaces constituting rich repositories of content and
	an important source of collaborative knowledge. However, most of
	this knowledge is buried inside the forum infrastructure and its
	extraction is both complex and difficult. The ability to automatically
	rate postings in online discussion forums, based on the value of
	their contribution, enhances the ability of users to find knowledge
	within this content. Several key online discussion forums have utilized
	collaborative intelligence to rate the value of postings made by
	users. However, a large percentage of posts go unattended and hence
	lack appropriate rating.
	
	
	In this paper, we focus on automatic rating of postings in online
	discussion forums. A set of features derived from the posting content
	and the threaded discussion structure are generated for each posting.
	These features are grouped into five categories, namely (i) relevance,
	(ii) originality, (iii) forum-specific features, (iv) surface features,
	and (v) posting-component features. Using a non-linear SVM classifier,
	the value of each posting is categorized into one of three levels
	High, Medium, or Low. This rating represents a seed value for each
	posting that is leveraged in filtering forum content. Experimental
	results have shown promising performance on forum data.},
  doi       = {http://doi.acm.org/10.1145/1458527.1458534},
  file      = {Wanas2008Automatic.pdf:Wanas2008Automatic.pdf:PDF},
  isbn      = {978-1-60558-259-7},
  location  = {Napa Valley, California, USA},
}

@InProceedings{Wang2008Continuous,
  author    = {Wang, C. and Blei, D. and Heckerman, D.},
  title     = {Continuous time dynamic topic models},
  booktitle = {The 23rd Conference on Uncertainty in Artificial Intelligence},
  year      = {2008},
  pages     = {1-8},
  file      = {Wang2008Continuous.pdf:Wang2008Continuous.pdf:PDF},
  groups    = {LDA},
}

@INPROCEEDINGS{Wang2011Online,
  author = {Wang, Chong and Paisley, John W and Blei, David M},
  title = {Online variational inference for the hierarchical Dirichlet process},
  booktitle = {International conference on artificial intelligence and statistics},
  year = {2011},
  pages = {752--760},
  abstract = {The hierarchical Dirichlet process (HDP) is a
	
	Bayesian nonparametric model that can be used
	
	to model mixed-membership data with a potentially
	
	infinite number of components. It has been
	
	applied widely in probabilistic topic modeling,
	
	where the data are documents and the components
	
	are distributions of terms that reflect recurring
	
	patterns (or “topics”) in the collection. Given
	
	a document collection, posterior inference is used
	
	to determine the number of topics needed and to
	
	characterize their distributions. One limitation
	
	of HDP analysis is that existing posterior inference
	
	algorithms require multiple passes through
	
	all the data—these algorithms are intractable for
	
	very large scale applications. We propose an online
	
	variational inference algorithm for the HDP,
	
	an algorithm that is easily applicable to massive
	
	and streaming data. Our algorithm is significantly
	
	faster than traditional inference algorithms for the
	
	HDP, and lets us analyze much larger data sets.
	
	We illustrate the approach on two large collections
	
	of text, showing improved performance over online
	
	LDA, the finite counterpart to the HDP topic
	
	model.},
  file = {Wang2011Online.pdf:Wang2011Online.pdf:PDF},
  timestamp = {2015.08.31}
}

@InProceedings{Wang2008Multi-document,
  author       = {Wang, D. and Li, T. and Zhu, S. and Ding, C.},
  title        = {Multi-document summarization via sentence-level semantic analysis and symmetric matrix factorization},
  booktitle    = {Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval},
  year         = {2008},
  pages        = {307--314},
  organization = {ACM},
  groups       = {Twitter},
}

@InProceedings{Wang2009Evolutionary,
  author       = {Wang, D. and Zheng, L. and Li, T. and Deng, Y.},
  title        = {Evolutionary document summarization for disaster management},
  booktitle    = {Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval},
  year         = {2009},
  pages        = {680--681},
  organization = {ACM},
  abstract     = {In this poster, we develop an evolutionary document summarization
	
	system for discovering the changes and differences
	
	in each phase of a disaster evolution. Given a collection of
	
	document streams describing an event, our system generates
	
	a short summary delivering the main development theme of
	
	the event by extracting the most representative and discriminative
	
	sentences at each phase. Experimental results on
	
	the collection of press releases for Hurricane Wilma in 2005
	
	demonstrate the efficacy of our proposal.},
  comment      = {select sentence for higher mutual information in the phase and lower
	mutual information with existing sentences
	
	no phase segmentation},
  file         = {Wang2009Evolutionary.pdf:Wang2009Evolutionary.pdf:PDF},
  groups       = {Twitter},
}

@Article{Wang2011Community,
  author      = {Wang, Fei and Li, Tao and Wang, Xin and Zhu, Shenghuo and Ding, Chris},
  title       = {Community discovery using nonnegative matrix factorization},
  journal     = {Data Mining and Knowledge Discovery},
  year        = {2011},
  volume      = {22},
  pages       = {493-521},
  note        = {10.1007/s10618-010-0181-y},
  affiliation = {School of Computing and Information Sciences, Florida International University, Miami, FL USA},
  file        = {Wang2011Community.pdf:Wang2011Community.pdf:PDF},
  groups      = {matrix factorization},
  issn        = {1384-5810},
  issue       = {3},
  keyword     = {Computer Science},
  publisher   = {Springer Netherlands},
  url         = {http://dx.doi.org/10.1007/s10618-010-0181-y},
}

@Article{Wang2014Feature,
  author    = {Wang, Jing and Ke, Liangwen},
  title     = {Feature subspace transfer for collaborative filtering},
  journal   = {Neurocomputing},
  year      = {2014},
  volume    = {136},
  pages     = {1--6},
  file      = {Wang2014Feature.pdf:Wang2014Feature.pdf:PDF},
  groups    = {Recommender Systems},
  publisher = {Elsevier},
  timestamp = {2014.05.12},
}

@InProceedings{Wang2006Unifying,
  author    = {Wang, Jun and de Vries, Arjen P. and Reinders, Marcel J. T.},
  title     = {Unifying user-based and item-based collaborative filtering approaches by similarity fusion},
  booktitle = {Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval},
  year      = {2006},
  series    = {SIGIR '06},
  pages     = {501--508},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Memory-based methods for collaborative filtering predict new ratings
	by averaging (weighted) ratings between, respectively, pairs of similar
	users or items. In practice, a large number of ratings from similar
	users or similar items are not available, due to the sparsity inherent
	to rating data. Consequently, prediction quality can be poor. This
	paper re-formulates the memory-based collaborative filtering problem
	in a generative probabilistic framework, treating individual user-item
	ratings as predictors of missing ratings. The final rating is estimated
	by fusing predictions from three sources: predictions based on ratings
	of the same item by other users, predictions based on different item
	ratings made by the same user, and, third, ratings predicted based
	on data from other but similar users rating other but similar items.
	Existing user-based and item-based approaches correspond to the two
	simple cases of our framework. The complete model is however more
	robust to data sparsity, because the different types of ratings are
	used in concert, while additional ratings from similar users towards
	similar items are employed as a background model to smooth the predictions.
	Experiments demonstrate that the proposed methods are indeed more
	robust against data sparsity and give better recommendations.},
  acmid     = {1148257},
  doi       = {http://doi.acm.org/10.1145/1148170.1148257},
  file      = {Wang2006Unifying.pdf:Wang2006Unifying.pdf:PDF},
  groups    = {Recommender Systems},
  isbn      = {1-59593-369-7},
  keywords  = {collaborative filtering, recommender systems, similarity fusion, smoothing},
  location  = {Seattle, Washington, USA},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/1148170.1148257},
}

@INPROCEEDINGS{Wang2011Nonparametric,
  author = {Pu Wang and Kathryn Laskey and Carlotta Domeniconi and Michael I.
	Jordan},
  title = {Nonparametric Bayesian Co-clustering Ensembles},
  booktitle = {Proceedings of SIAM International Conference on Data Mining (SDM)},
  year = {2011},
  pages = {331-342},
  abstract = {A nonparametric Bayesian approach to co-clustering ensembles is presented.
	Similar to clustering ensembles, coclustering ensembles combine various
	base co-clustering results to obtain a more robust consensus co-clustering.
	To avoid pre-specifying the number of co-clusters, we specify independent
	Dirichlet process priors for the row and column clusters. Thus, the
	numbers of row- and column-clusters are unbounded a priori; the actual
	numbers of clusters can be learned a posteriori from observations.
	Next, to model non-independence of row- and column-clusters, we employ
	a Mondrian Process as a prior distribution over partitions of the
	data matrix. As a result, the co-clusters are not restricted to a
	regular grid partition, but form nested partitions with varying resolutions.
	The empirical evaluation},
  comment = {Best student paper},
  file = {Wang2011Nonparametric.pdf:Wang2011Nonparametric.pdf:PDF},
  timestamp = {2015.10.21}
}

@InProceedings{Wang2015Exploring,
  author    = {Wang, Suhang and Tang, Jiliang and Wang, Yilin and Liu, Huan},
  title     = {Exploring Implicit Hierarchical Structures for Recommender Systems},
  booktitle = {Proceedings of the 24th International Conference on Artificial Intelligence},
  year      = {2015},
  series    = {IJCAI'15},
  pages     = {1813--1819},
  publisher = {AAAI Press},
  abstract  = {Items in real-world recommender systems exhibit
	
	certain hierarchical structures. Similarly, user preferences
	
	also present hierarchical structures. Recent
	
	studies show that incorporating the explicit hierarchical
	
	structures of items or user preferences
	
	can improve the performance of recommender systems.
	
	However, explicit hierarchical structures are
	
	usually unavailable, especially those of user preferences.
	
	Thus, there’s a gap between the importance
	
	of hierarchical structures and their availability. In
	
	this paper, we investigate the problem of exploring
	
	the implicit hierarchical structures for recommender
	
	systems when they are not explicitly available.
	
	We propose a novel recommendation framework
	
	HSR to bridge the gap, which enables us to
	
	capture the implicit hierarchical structures of users
	
	and items simultaneously. Experimental results on
	
	two real world datasets demonstrate the effectiveness
	
	of the proposed framework.},
  acmid     = {2832501},
  comment   = {one class cf: weighted non-nogative mf
	
	U, V further decompose to hierarchical sub categories
	
	U -> U1U2U3....Ud
	
	where U1 is m item to d1 categories
	
	U2 is d1 to d2 sub categories
	
	U3 is d2 to d3 sub categories etc
	
	In a word, the parameter K is the (final) number of p-layer hidden
	spaces},
  file      = {Wang2015Exploring.pdf:Wang2015Exploring.pdf:PDF},
  isbn      = {978-1-57735-738-4},
  location  = {Buenos Aires, Argentina},
  numpages  = {7},
  timestamp = {2016.03.09},
}

@InProceedings{Wang2015CROWN,
  author    = {S. Wang and B. Zou and C. Li and K. Zhao and Q. Liu and H. Chen},
  title     = {CROWN: A Context-aware RecOmmender for Web News},
  booktitle = {2015 IEEE 31st International Conference on Data Engineering},
  year      = {2015},
  pages     = {1420-1423},
  month     = {April},
  abstract  = {It is popular for most people to read news online since the web sites
	can provide access to news articles from millions of sources around
	the world. For these news web sites, the key challenge is to help
	users find related news articles to read. In this paper, we present
	a system called CROWN (Context-aware RecOmmender for Web News) to
	do Chinese news recommendation. By recommendation, the system can
	retrieve personalized fresh and relevant news articles to mobile
	users according to their particular context. Differing from existing
	mobile news applications which employ rather simple strategies for
	news recommendation, CROWN integrates the contextual information
	in prediction by modeling the data as a tensor. Such context information
	usually includes the time, the location, etc. This demo paper presents
	the implementation of the whole procedure of news recommendation
	in the system of CROWN. Experimental results on a large corpus of
	newly-published Chinese web news show its performance is satisfactory.},
  comment   = {ss},
  doi       = {10.1109/ICDE.2015.7113391},
  file      = {Wang2015CROWN.pdf:Wang2015CROWN.pdf:PDF},
  issn      = {1063-6382},
  keywords  = {Web sites;information retrieval;mobile computing;recommender systems;CROWN;Chinese news recommendation;Web sites;context-aware recommender for Web news;contextual information;mobile users;personalized fresh news article retrieval;relevant news retrieval;Context;Context modeling;Data models;Mobile communication;Predictive models;Tensile stress;Tin},
}

@InProceedings{Wang2006Topics,
  author    = {Wang, Xuerui and McCallum, Andrew},
  title     = {Topics over time: a non-Markov continuous-time model of topical trends},
  booktitle = {KDD '06: Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining},
  year      = {2006},
  pages     = {424--433},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {This paper presents an LDA-style topic model that captures not only
	the low-dimensional structure of data, but also how the structure
	changes over time. Unlike other recent work that relies on Markov
	assumptions or discretization of time, here each topic is associated
	with a continuous distribution over timestamps, and for each generated
	document, the mixture distribution over topics is influenced by both
	word co-occurrences and the document's timestamp. Thus, the meaning
	of a particular topic can be relied upon as constant, but the topics'
	occurrence and correlations change significantly over time. We present
	results on nine months of personal email, 17 years of NIPS research
	papers and over 200 years of presidential state-of-the-union addresses,
	showing improved topics, better timestamp prediction, and interpretable
	trends.},
  doi       = {http://doi.acm.org/10.1145/1150402.1150450},
  file      = {Wang2006Topics.pdf:Wang2006Topics.pdf:PDF},
  groups    = {LDA},
  isbn      = {1-59593-339-5},
  location  = {Philadelphia, PA, USA},
}

@InProceedings{Wang2008Recovering,
  author    = {Wang, Y.C. and Joshi, M. and Cohen, W. and Ros{\'e}, C},
  title     = {Recovering implicit thread structure in newsgroup style conversations},
  booktitle = {Proceedings of the 2nd International Conference on Weblogs and Social Media},
  year      = {2008},
  pages     = {152-160},
  address   = {Seattle, Washington, U.S.A.},
  publisher = {AAAI Press},
  location  = {Seattle, WA, USA},
  owner     = {Cheyenne},
  timestamp = {2009.09.23},
}

@INPROCEEDINGS{Wang2014Rank,
  author = {Zheng Wang and Ming-Jun Lai and Zhaosong Lu and Wei Fan and Hasan
	Davulcu and Jieping Ye},
  title = {Rank-One Matrix Pursuit for Matrix Completion},
  booktitle = {Proceedings of ICML},
  year = {2014},
  pages = {94-102},
  abstract = {Low rank matrix completion has been applied successfully in a wide
	range of machine learning applications, such as collaborative filtering,
	image inpainting and Microarray data imputation. However, many existing
	algorithms are not scalable to large-scale problems, as they involve
	computing singular value decomposition. In this paper, we present
	an efficient and scalable algorithm for matrix completion. The key
	idea is to extend the well-known orthogonal matching pursuit from
	the vector case to the matrix case. In each iteration, we pursue
	a rank-one matrix basis generated by the top singular vector pair
	of the current approximation residual and update the weights for
	all rank-one matrices obtained up to the current iteration. We further
	propose a novel weight updating rule to reduce the time and storage
	complexity, making the proposed algorithm scalable to large matrices.
	We establish the linear convergence of the proposed algorithm. The
	fast convergence is achieved due to the proposed construction of
	matrix bases and the estimation of the weights. We empirically evaluate
	the proposed algorithm on many real-world large scale datasets. Results
	show that our algorithm is much more efficient than state-of-the-art
	matrix completion algorithms while achieving similar or better prediction
	performance.},
  file = {Wang2014Rank.pdf:Wang2014Rank.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.06.24}
}

@InProceedings{Wang2013Querying,
  author    = {Wang, Zheng and Ye, Jieping},
  title     = {Querying Discriminative and Representative Samples for Batch Mode Active Learning},
  booktitle = {Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year      = {2013},
  series    = {KDD '13},
  pages     = {158--166},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2487643},
  comment   = {KDD best paper},
  doi       = {10.1145/2487575.2487643},
  file      = {:Wang2013QueryingPPT.pdf:PDF;Wang2013Querying.pdf:Wang2013Querying.pdf:PDF},
  isbn      = {978-1-4503-2174-7},
  keywords  = {active learning, empirical risk minimization, maximum mean discrepancy, representative and discriminative},
  location  = {Chicago, Illinois, USA},
  numpages  = {9},
  url       = {http://doi.acm.org/10.1145/2487575.2487643},
}

@ARTICLE{watts2002identity,
  author = {Watts, D.J. and Dodds, P.S. and Newman, M.E.J.},
  title = {{Identity and search in social networks}},
  journal = {Science},
  year = {2002},
  volume = {296},
  pages = {1302},
  number = {5571},
  file = {watts2002identity.pdf:watts2002identity.pdf:PDF},
  publisher = {AAAS}
}

@INPROCEEDINGS{Wei2007Dynamic,
  author = {Wei, X. and Sun, J. and Wang, X.},
  title = {Dynamic mixture models for multiple time series},
  booktitle = {Proceedings of the International Joint Conference on Artificial Intelligence},
  year = {2007},
  volume = {459},
  pages = {2909-2914},
  file = {Wei2007Dynamic.pdf:Wei2007Dynamic.pdf:PDF}
}

@ARTICLE{wellman2007network,
  author = {Barry Wellman},
  title = {{The network is personal: Introduction to a special issue of Social
	Networks}},
  journal = {Social Networks},
  year = {2007},
  volume = {29},
  pages = {349--356},
  number = {3},
  publisher = {Elsevier}
}

@Article{welser2007visualizing,
  author   = {Welser, H.T. and Gleave, E. and Fisher, D. and Smith, M.},
  title    = {{Visualizing the signatures of social roles in online discussion groups}},
  journal  = {Journal of Social Structure},
  year     = {2007},
  volume   = {8},
  number   = {2},
  abstract = {Social roles in online discussion forums can be described by patterned
	characteristics of communication between network members which we
	conceive of as 憇tructural signatures.' This paper uses visualization
	methods to reveal these structural signatures and regression analysis
	to confirm the relationship between these signatures and their associated
	roles in Usenet newsgroups. Our analysis focuses on distinguishing
	the signatures of one role from others, the role of 揳nswer people."
	Answer people are individuals whose dominant behavior is to respond
	to questions posed by other users. We found that answer people predominantly
	contribute one or a few messages to discussions initiated by others,
	are disproportionately tied to relative isolates, have few intense
	ties and have few triangles in their local networks. OLS regression
	shows that these signatures are strongly correlated with role behavior
	and, in combination, provide a strongly predictive model for identifying
	role behavior (R2=.72). To conclude, we consider strategies for further
	improving the identification of role behavior in online discussion
	settings and consider how the development of a taxonomy of author
	types could be extended to a taxonomy of newsgroups in particular
	and discussion systems in general.},
  comment  = {There are many important social roles in online discussion groups:
	local experts, answer people,
	
	conversationalists, fans, discussion artists, flame warriors, and
	trolls
	
	
	this paper distinguish answerer and discussion people
	
	authorline
	
	an answer person is seen in the tendency to reply to
	
	discussion threads initiated by others, rather than start a conversation
	by himself
	
	ego network
	
	anser person 's ego network is primarily sparse, starshaped,
	
	and has numerous outward connections to relative isolates. Further,
	the
	
	network has few, if any, triangles or intense (more than two messages
	per dyad) relationships.through. Answer people would have little
	need to send multiple messages to the same
	
	recipient, and question seekers would have little reason to contact
	the other question seekers. but discussion people seem to interact
	with its repliers more often
	
	distribution of neighbour's degree
	
	Answer people are tied to many alters who themselves have few ties
	and few alters who have
	
	many ties. In contrast, discussion people are highly tied to others
	who themselves have high degree},
  file     = {welser2007visualizing.pdf:welser2007visualizing.pdf:PDF},
}

@InProceedings{Weng2010TwitterRank,
  author    = {Weng, Jianshu and Lim, Ee-Peng and Jiang, Jing and He, Qi},
  title     = {TwitterRank: finding topic-sensitive influential twitterers},
  booktitle = {Proceedings of the third ACM international conference on Web search and data mining},
  year      = {2010},
  series    = {WSDM '10},
  pages     = {261--270},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {This paper focuses on the problem of identifying influential users
	of micro-blogging services. Twitter, one of the most notable micro-blogging
	services, employs a social-networking model called "following", in
	which each user can choose who she wants to "follow" to receive tweets
	from without requiring the latter to give permission first. In a
	dataset prepared for this study, it is observed that (1) 72.4% of
	the users in Twitter follow more than 80% of their followers, and
	(2) 80.5% of the users have 80% of users they are following follow
	them back. Our study reveals that the presence of "reciprocity" can
	be explained by phenomenon of homophily. Based on this finding, TwitterRank,
	an extension of PageRank algorithm, is proposed to measure the influence
	of users in Twitter. TwitterRank measures the influence taking both
	the topical similarity between users and the link structure into
	account. Experimental results show that TwitterRank outperforms the
	one Twitter currently uses and other related algorithms, including
	the original PageRank and Topic-sensitive PageRank.},
  acmid     = {1718520},
  doi       = {http://doi.acm.org/10.1145/1718487.1718520},
  file      = {Weng2010TwitterRank.pdf:Weng2010TwitterRank.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-1-60558-889-6},
  keywords  = {influential, pagerank, twitter},
  location  = {New York, New York, USA},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1718487.1718520},
}

@ARTICLE{Wong2012Ontology,
  author = {Wilson Wong and Wei Liu and Mohammed Bennamoun},
  title = {Ontology Learning from Text: A Look Back and into the Future},
  journal = {ACM Computing Surveys},
  year = {2012},
  volume = {44},
  pages = {20:1--20:36},
  number = {4},
  abstract = {Ontologies are often viewed as the answer to the need for interoperable
	semantics in modern information systems. The explosion of textual
	information on the Read/Write Web coupled with the increasing demand
	for ontologies to power the Semantic Web have made (semi-)automatic
	ontology learning from text a very promising research area. This
	together with the advanced state in related areas, such as natural
	language processing, have fueled research into ontology learning
	over the past decade. This survey looks at how far we have come since
	the turn of the millennium and discusses the remaining challenges
	that will define the research directions in this area in the near
	future.},
  file = {Wong2012Ontology.pdf:Wong2012Ontology.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.10.11}
}

@InProceedings{Wu2007Local,
  author    = {Wu, Junjie and Xiong, Hui and Wu, Peng and Chen, Jian},
  title     = {Local decomposition for rare class analysis},
  booktitle = {Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining},
  year      = {2007},
  series    = {KDD '07},
  pages     = {814--823},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Given its importance, the problem of predicting rare classes in large-scale
	multi-labeled data sets has attracted great attentions in the literature.
	However, the rare-class problem remains a critical challenge, because
	there is no natural way developed for handling imbalanced class distributions.
	This paper thus fills this crucial void by developing a method for
	Classification using lOcal clusterinG (COG). Specifically, for a
	data set with an imbalanced class distribution, we perform clustering
	within each large class and produce sub-classes with relatively balanced
	sizes. Then, we apply traditional supervised learning algorithms,
	such as Support Vector Machines (SVMs), for classification. Indeed,
	our experimental results on various real-world data sets show that
	our method produces significantly higher prediction accuracies on
	rare classes than state-of-the-art methods. Furthermore, we show
	that COG can also improve the performance of traditional supervised
	learning algorithms on data sets with balanced class distributions.},
  acmid     = {1281279},
  doi       = {http://doi.acm.org/10.1145/1281192.1281279},
  file      = {Wu2007Local.pdf:Wu2007Local.pdf:PDF},
  isbn      = {978-1-59593-609-7},
  keywords  = {k-means clustering support vector machines, local clustering, rare class analysis},
  location  = {San Jose, California, USA},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1281192.1281279},
}

@InProceedings{Wu2015Clustering,
  author    = {Wu, Rui and Xu, Jiaming and Srikant, Rayadurgam and Massoulie, Laurent and Lelarge, Marc and Hajek, Bruce},
  title     = {Clustering and Inference From Pairwise Comparisons},
  booktitle = {Proceedings of the 2015 ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems},
  year      = {2015},
  series    = {SIGMETRICS '15},
  pages     = {449--450},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Given a set of pairwise comparisons, the classical ranking problem
	computes a single ranking that best represents the preferences of
	all users. In this paper, we study the problem of inferring individual
	preferences, arising in the context of making personalized recommendations.
	In particular, we assume users form clusters; users of the same cluster
	provide similar pairwise comparisons for the items according to the
	Bradley-Terry model. We propose an efficient algorithm to estimate
	the preference for each user: first, compute the net-win vector for
	each user using the comparisons; second, cluster the users based
	on the net-win vectors; third, estimate a single preference for each
	cluster separately. We show that the net-win vectors are much less
	noisy than the high dimensional vectors of pairwise comparisons,
	therefore our algorithm can cluster the users reliably. Moreover,
	we show that, when a cluster is only approximately correct, the maximum
	likelihood estimation for the Bradley-Terry model is still close
	to the true preference.},
  acmid     = {2745887},
  comment   = {two phase: first clustering users, then learn scores
	
	
	user clustering projects the sparse paiwise comparison to a smallaer
	item specific vector},
  doi       = {10.1145/2745844.2745887},
  file      = {Wu2015Clustering.pdf:Wu2015Clustering.pdf:PDF},
  isbn      = {978-1-4503-3486-0},
  keywords  = {bradley-terry model, clustering, inference, ranking},
  location  = {Portland, Oregon, USA},
  numpages  = {2},
  timestamp = {2016.04.19},
  url       = {http://doi.acm.org/10.1145/2745844.2745887},
}

@InProceedings{Wu2011Who,
  author    = {Wu, Shaomei and Jake M. Hofman and Winter A. Mason and Duncan J. Watts},
  title     = {Who Says What to Whom on Twitter},
  booktitle = {Proceedings of the 19th international conference on World wide web},
  year      = {2011},
  abstract  = {We study several longstanding questions in media communications research,
	in the context of the microblogging service Twitter, regarding the
	production, flow, and consumption of information. To do so, we exploit
	a recently introduced feature of Twitter---known as Twitter lists---to
	distinguish between elite users, by which we mean specifically celebrities,
	bloggers, and representatives of media outlets and other formal organizations,
	and ordinary users. Based on this classification, we find a striking
	concentration of attention on Twitter---roughly 50% of tweets consumed
	are generated by just 20K elite users---where the media produces
	the most information, but celebrities are the most followed. We also
	find significant homophily within categories: celebrities listen
	to celebrities, while bloggers listen to bloggers etc; however, bloggers
	in general rebroadcast more information than the other categories.
	Next we re-examine the classical ``two-step flow'' theory of communications,
	finding considerable support for it on Twitter, but also some interesting
	differences. Third, we find that URLs broadcast by different categories
	of users or containing different types of content exhibit systematically
	different lifespans. And finally, we examine the attention paid by
	the different user categories to different news topics.},
  file      = {Wu2011Who.pdf:Wu2011Who.pdf:PDF},
  groups    = {Twitter},
  owner     = {linchen},
  timestamp = {2010.11.24},
}

@InProceedings{Wu2014Learning,
  author    = {Shan-Hung Wu and Hao-Heng Chien and Kuan-Hua Lin and Philip S. Yu},
  title     = {Learning the Consistent Behavior of Common Users for Target Node Prediction across Social Networks},
  booktitle = {Proceedings of ICML},
  year      = {2014},
  abstract  = {We study the target node prediction problem:
	
	given two social networks, identify those
	
	nodes/users from one network (called the source
	
	network) who are likely to join another (called
	
	the target network, with nodes called target
	
	nodes). Although this problem can be solved using
	
	existing techniques in the field of cross domain
	
	classification, we observe that in many realworld
	
	situations the cross-domain classifiers perform
	
	sub-optimally due to the heterogeneity between
	
	source and target networks that prevents
	
	the knowledge from being transferred. In this
	
	paper, we propose learning the consistent behavior
	
	of common users to help the knowledge
	
	transfer. We first present the Consistent Incidence
	
	Co-Factorization (CICF) for identifying
	
	the consistent users, i.e., common users that behave
	
	consistently across networks. Then we introduce
	
	the Domain-UnBiased (DUB) classifiers
	
	that transfer knowledge only through those consistent
	
	users. Extensive experiments are conducted
	
	and the results show that our proposal
	
	copes with heterogeneity and improves prediction
	
	accuracy.},
  comment   = {socialnetwork socialize with each other},
  file      = {Wu2014Learning.pdf:Wu2014Learning.pdf:PDF},
  keywords  = {transfer learning},
  owner     = {littlep},
  timestamp = {2014.06.22},
}

@InProceedings{Xiang2010Temporal,
  author    = {Xiang, Liang and Yuan, Quan and Zhao, Shiwan and Chen, Li and Zhang, Xiatian and Yang, Qing and Sun, Jimeng},
  title     = {Temporal recommendation on graphs via long- and short-term preference fusion},
  booktitle = {Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining},
  year      = {2010},
  series    = {KDD '10},
  pages     = {723--732},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Accurately capturing user preferences over time is a great
	
	practical challenge in recommender systems. Simple correlation
	
	over time is typically not meaningful, since users change
	
	their preferences due to different external events. User behavior
	
	can often be determined by individual’s long-term
	
	and short-term preferences. How to represent users’ longterm
	
	and short-term preferences? How to leverage them
	
	for temporal recommendation? To address these challenges,
	
	we propose Session-based Temporal Graph (STG) which simultaneously
	
	models users’ long-term and short-term preferences
	
	over time. Based on the STG model framework, we
	
	propose a novel recommendation algorithm Injected Preference
	
	Fusion (IPF) and extend the personalized Random
	
	Walk for temporal recommendation. Finally, we evaluate
	
	the effectiveness of our method using two real datasets on
	
	citations and social bookmarking, in which our proposed
	
	method IPF gives 15%-34% improvement over the previous
	
	state-of-the-art.},
  acmid     = {1835896},
  comment   = {a tri-partite graph, user-session-item
	
	
	Users’ long-term and short-term preferences are modeled by user nodes
	and session nodes respectively
	
	
	select current user and current session, propagate preference to any
	item, through shortest path in the tri-partite graph
	
	
	random walk},
  file      = {Xiang2010Temporal.pdf:Xiang2010Temporal.pdf:PDF},
  groups    = {Recommender Systems},
  isbn      = {978-1-4503-0055-1},
  keywords  = {graph, temporal recommendation, user preference},
  location  = {Washington, DC, USA},
  numpages  = {10},
}

@Conference{xiang2010modeling,
  author       = {Xiang, R. and Neville, J. and Rogati, M.},
  title        = {{Modeling relationship strength in online social networks}},
  booktitle    = {Proceedings of the 19th international conference on World wide web},
  year         = {2010},
  pages        = {981--990},
  organization = {ACM},
  abstract     = {Previous work analyzing social networks has mainly focused
	
	on binary friendship relations. However, in online social
	
	networks the low cost of link formation can lead to net-
	
	works with heterogeneous relationship strengths (e.g., ac-
	
	quaintances and best friends mixed together). In this case,
	
	the binary friendship indicator provides only a coarse repre-
	
	sentation of relationship information. In this work, we de-
	
	velop an unsupervised model to estimate relationship strength
	
	from interaction activity (e.g., communication, tagging) and
	
	user similarity. More specically, we formulate a link-based
	
	latent variable model, along with a coordinate ascent op-
	
	timization procedure for the inference. We evaluate our
	
	approach on real-world data from Facebook and LinkedIn,
	
	showing that the estimated link weights result in higher au-
	
	tocorrelation and lead to improved classication accuracy.},
  comment      = {Motivation: 1)infer relationship strength 2) apply relationship strength
	to autocorrelation task (in user profile) and classification task
	
	Data: Facebook and Linkdin
	
	Model:
	
	1) Graphical Model with one latent variable-relationship strength
	
	2) relationship strength is conditioned on (a set of ) user similarities
	
	2) user interactions (binary, say, user tagging) are affeted by relationship
	strength and other auxiliary variables (denoting , say, the tendency
	of tagging behavior of one user)},
  file         = {:xiang2010modeling.pdf:PDF},
}

@INPROCEEDINGS{Xie2010Breaking,
  author = {Xie, Min and Lakshmanan, Laks V.S. and Wood, Peter T.},
  title = {Breaking out of the Box of Recommendations: From Items to Packages},
  booktitle = {Proceedings of the Fourth ACM Conference on Recommender Systems},
  year = {2010},
  series = {RecSys '10},
  pages = {151--158},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {1864739},
  doi = {10.1145/1864708.1864739},
  isbn = {978-1-60558-906-0},
  keywords = {optimization, recommendation algorithms, top-k query processing},
  location = {Barcelona, Spain},
  numpages = {8},
  timestamp = {2014.10.28},
  url = {http://doi.acm.org/10.1145/1864708.1864739}
}

@InProceedings{Xu2006Building,
  author       = {Xu, G. and Ma, W.Y.},
  title        = {Building implicit links from content for forum search},
  booktitle    = {Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval},
  year         = {2006},
  pages        = {300--307},
  organization = {ACM New York, NY, USA},
}

@InProceedings{Xu1996Query,
  author    = {Xu, Jinxi and Croft, W. Bruce},
  title     = {Query expansion using local and global document analysis},
  booktitle = {Proceedings of the 19th annual international ACM SIGIR conference on Research and development in information retrieval},
  year      = {1996},
  series    = {SIGIR '96},
  pages     = {4--11},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Automatic query expansion has long been suggested as a
	
	technique for dealing with the fundamental issue of word
	
	mismatch in information retrieval. A number of approaches
	
	to ezpanrnion have been studied and, more recently, attention
	
	has focused on techniques that analyze the corpus to discover
	
	word relationship (global techniques) and those that analyze
	
	documents retrieved by the initial query ( local feedback). In
	
	this paper, we compare the effectiveness of these approaches
	
	and show that, although global analysis have some advantages,
	
	local analysia is generally more effective. We also show that
	
	using global analysis techniques, such as word contezt and
	
	phrase structure, on the local aet of documents produces results
	
	that are both more effective and more predictable than
	
	simple local feedback.},
  acmid     = {243202},
  doi       = {http://doi.acm.org/10.1145/243199.243202},
  file      = {Xu1996Query.pdf:Xu1996Query.pdf:PDF},
  isbn      = {0-89791-792-8},
  location  = {Zurich, Switzerland},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/243199.243202},
}

@InProceedings{Xu2003Document,
  author    = {Xu, Wei and Liu, Xin and Gong, Yihong},
  title     = {Document clustering based on non-negative matrix factorization},
  booktitle = {Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval},
  year      = {2003},
  series    = {SIGIR '03},
  pages     = {267--273},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {860485},
  doi       = {10.1145/860435.860485},
  groups    = {matrix factorization},
  isbn      = {1-58113-646-3},
  keywords  = {document clustering, non-negative matrix factorization},
  location  = {Toronto, Canada},
  numpages  = {7},
  url       = {http://doi.acm.org/10.1145/860435.860485},
}

@InProceedings{Xu2009Query,
  author    = {Xu, Yang and Jones, Gareth J.F. and Wang, Bin},
  title     = {Query dependent pseudo-relevance feedback based on wikipedia},
  booktitle = {Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval},
  year      = {2009},
  series    = {SIGIR '09},
  pages     = {59--66},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Pseudo-relevance feedback (PRF) via query-expansion has
	
	been proven to be e®ective in many information retrieval
	
	(IR) tasks. In most existing work, the top-ranked documents
	
	from an initial search are assumed to be relevant and used for
	
	PRF. One problem with this approach is that one or more
	
	of the top retrieved documents may be non-relevant, which
	
	can introduce noise into the feedback process. Besides, ex-
	
	isting methods generally do not take into account the sig-
	
	ni¯cantly di®erent types of queries that are often entered
	
	into an IR system. Intuitively, Wikipedia can be seen as a
	
	large, manually edited document collection which could be
	
	exploited to improve document retrieval e®ectiveness within
	
	PRF. It is not obvious how we might best utilize informa-
	
	tion from Wikipedia in PRF, and to date, the potential of
	
	Wikipedia for this task has been largely unexplored. In our
	
	work, we present a systematic exploration of the utilization
	
	of Wikipedia in PRF for query dependent expansion. Specif-
	
	ically, we classify TREC topics into three categories based
	
	on Wikipedia: 1) entity queries, 2) ambiguous queries, and
	
	3) broader queries. We propose and study the e®ectiveness
	
	of three methods for expansion term selection, each model-
	
	ing the Wikipedia based pseudo-relevance information from
	
	a di®erent perspective. We incorporate the expansion terms
	
	into the original query and use language modeling IR to eval-
	
	uate these methods. Experiments on four TREC test collec-
	
	tions, including the large web collection GOV2, show that
	
	retrieval performance of each type of query can be improved.
	
	In addition, we demonstrate that the proposed method out-
	
	performs the baseline relevance model in terms of precision
	
	and robustness.},
  acmid     = {1571954},
  comment   = {queries may vary in semantics. This paper categorize web queries as
	1) queries about a specific entity (EQ),
	
	2) ambiguous queries (AQ), and 3) broader queries (BQ). Queries exactly
	matching one title of an entity page
	
	or a redirect page will be classi¯ed as EQ. queries with both entity
	page and disambiguation
	
	pages will be counted as EQ. queries with terms in the
	
	ambiguous list of terms/phrases is AQ. All other queries are
	
	then classi¯ed as BQ.
	
	
	only the corresponding entity page
	
	from Wikipedia will be used as pseudo-relevant information. Terms
	are selected from entity pages by tfidf. Field information is utilized.},
  doi       = {http://doi.acm.org/10.1145/1571941.1571954},
  file      = {Xu2009Query.pdf:Xu2009Query.pdf:PDF},
  isbn      = {978-1-60558-483-6},
  keywords  = {entity, information retrieval, pseudo-relevance feedback, query expansion, wikipedia},
  location  = {Boston, MA, USA},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/1571941.1571954},
}

@ARTICLE{XU2006s-HITSc:,
  author = {XU, Zhuoming and CAO, Xiao and DONG, Yisheng and HAN, Yahong},
  title = {s-HITSc: an improved model and algorithm for topic distillation on
	the Web},
  journal = {Soft Comput.},
  year = {2006},
  volume = {10},
  pages = {2--11},
  number = {1},
  abstract = {Topic distillation on the Web, namely, finding quality information
	sources related to a given query topic with hyperlink analysis, has
	been shown to be useful in Web IR. Based on the analysis of three
	deficiencies of classical topic distillation algorithm HITS, this
	paper presents an improved model and algorithm named s-HITSc. Given
	a query topic, the improved algorithm can model a neighborhood graph
	at site granularity, compute the relevance weights of the nodes to
	the topic with content analysis, and apply weighted I/O operations
	in its iterative hyperlink analysis. Theoretical analysis and experimental
	results show that s-HITSc can control topic drift and identify more
	reasonable and meaningful authority and hub sites on a given topic.},
  address = {Berlin, Heidelberg},
  doi = {http://dx.doi.org/10.1007/s00500-005-0457-0},
  issn = {1432-7643},
  publisher = {Springer-Verlag}
}

@InProceedings{Xue2005Scalable,
  author    = {Xue, Gui-Rong and Lin, Chenxi and Yang, Qiang and Xi, WenSi and Zeng, Hua-Jun and Yu, Yong and Chen, Zheng},
  title     = {Scalable collaborative filtering using cluster-based smoothing},
  booktitle = {Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval},
  year      = {2005},
  series    = {SIGIR '05},
  pages     = {114--121},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Memory-based approaches for collaborative filtering identify the
	
	similarity between two users by comparing their ratings on a set of
	
	
	items. In the past, the memory-based approaches have been shown
	
	to suffer from two fundamental problems: data sparsity and
	
	difficulty in scalability. Alternatively, the model-based approaches
	
	
	have been proposed to alleviate these problems, but these
	
	approaches tends to limit the range of users. In this paper, we
	
	present a novel approach that combines the advantages of these
	
	two kinds of approaches by introducing a smoothing-based
	
	method. In our approach, clusters generated from the training
	
	data provide the basis for data smoothing and neighborhood
	
	selection. As a result, we provide higher accuracy as well as
	
	increased efficiency in recommendations. Empirical studies on
	
	two datasets (EachMovie and MovieLens) show that our new
	
	proposed approach consistently outperforms other state-of-the-art
	
	
	collaborative filtering algorithms.},
  acmid     = {1076056},
  doi       = {http://doi.acm.org/10.1145/1076034.1076056},
  file      = {Xue2005Scalable.pdf:Xue2005Scalable.pdf:PDF},
  groups    = {Recommender Systems},
  isbn      = {1-59593-034-5},
  keywords  = {clustering, collaborative filtering, smoothing, sparsity data},
  location  = {Salvador, Brazil},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/1076034.1076056},
}

@ARTICLE{Xue2007Multi,
  author = {Xue, Ya and Liao, Xuejun and Carin, Lawrence and Krishnapuram, Balaji},
  title = {Multi-Task Learning for Classification with Dirichlet Process Priors},
  journal = {J. Mach. Learn. Res.},
  year = {2007},
  volume = {8},
  pages = {35--63},
  month = may,
  abstract = {Consider the problem of learning logistic-regression models for multiple
	classification tasks, where the training data set for each task is
	not drawn from the same statistical distribution. In such a multi-task
	learning (MTL) scenario, it is necessary to identify groups of similar
	tasks that should be learned jointly. Relying on a Dirichlet process
	(DP) based statistical model to learn the extent of similarity between
	classification tasks, we develop computationally efficient algorithms
	for two different forms of the MTL problem. First, we consider a
	symmetric multi-task learning (SMTL) situation in which classifiers
	for multiple tasks are learned jointly using a variational Bayesian
	(VB) algorithm. Second, we consider an asymmetric multi-task learning
	(AMTL) formulation in which the posterior density function from the
	SMTL model parameters (from previous tasks) is used as a prior for
	a new task: this approach has the significant advantage of not requiring
	storage and use of all previous data from prior tasks. The AMTL formulation
	is solved with a simple Markov Chain Monte Carlo (MCMC) construction.
	Experimental results on two real life MTL problems indicate that
	the proposed algorithms: (a) automatically identify subgroups of
	related tasks whose training data appear to be drawn from similar
	distributions; and (b) are more accurate than simpler approaches
	such as single-task learning, pooling of data across all tasks, and
	simplified approximations to DP.},
  acmid = {1248661},
  file = {Xue2007Multi.pdf:Xue2007Multi.pdf:PDF},
  issn = {1532-4435},
  issue_date = {5/1/2007},
  numpages = {29},
  publisher = {JMLR.org},
  timestamp = {2015.08,31},
  url = {http://dl.acm.org/citation.cfm?id=1248659.1248661}
}

@InProceedings{Yan2011Evolutionary,
  author       = {Yan, R. and Wan, X. and Otterbacher, J. and Kong, L. and Li, X. and Zhang, Y.},
  title        = {Evolutionary timeline summarization: a balanced optimization framework via iterative substitution},
  booktitle    = {Proceedings of the 34th international ACM SIGIR conference on Research and development in Information},
  year         = {2011},
  pages        = {745--754},
  organization = {ACM},
  abstract     = {Classic news summarization plays an important role with
	
	the exponential document growth on the Web. Many approaches
	
	are proposed to generate summaries but seldom
	
	simultaneously consider evolutionary characteristics of news
	
	plus to traditional summary elements. Therefore, we present
	
	a novel framework for the web mining problem named Evolutionary
	
	Timeline Summarization (ETS). Given the massive
	
	collection of time-stamped web documents related to a general
	
	news query, ETS aims to return the evolution trajectory
	
	along the timeline, consisting of individual but correlated
	
	summaries of each date, emphasizing relevance, coverage,
	
	coherence and cross-date diversity. ETS greatly facilitates
	
	fast news browsing and knowledge comprehension and hence
	
	is a necessity. We formally formulate the task as an optimization
	
	problem via iterative substitution from a set of
	
	sentences to a subset of sentences that satisfies the above requirements,
	
	balancing coherence/diversity measurement and
	
	local/global summary quality. The optimized substitution
	
	is iteratively conducted by incorporating several constraints
	
	until convergence. We develop experimental systems to evaluate
	
	on 6 instinctively different datasets which amount to
	
	10251 documents. Performance comparisons between different
	
	system-generated timelines and manually created ones
	
	by human editors demonstrate the effectiveness of our proposed
	
	framework in terms of ROUGE metrics.},
  file         = {Yan2011Evolutionary.pdf:Yan2011Evolutionary.pdf:PDF},
  groups       = {Twitter},
}

@INPROCEEDINGS{Yan2002gSpan,
  author = {Yan, X. and Han, J.},
  title = {gSpan: Graph-based substructure pattern mining},
  booktitle = {Data Mining, 2002. ICDM 2002. Proceedings. 2002 IEEE International
	Conference on},
  year = {2002},
  pages = {721--724},
  organization = {IEEE}
}

@InProceedings{Yang2013Social,
  author    = {Yang, Bo and Lei, Yu and Liu, Dayou and Liu, Jiming},
  title     = {Social Collaborative Filtering by Trust},
  booktitle = {Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence},
  year      = {2013},
  series    = {IJCAI '13},
  pages     = {2747--2753},
  publisher = {AAAI Press},
  abstract  = {To accurately and actively provide users with their potentially interested
	information or services is the main task of a recommender system.
	Collaborative filtering is one of the most widely adopted recommender
	algorithms, whereas it is suffering the issues of data sparsity and
	cold start that will severely degrade quality of recommendations.
	To address such issues, this article proposes a novel method, trying
	to improve the performance of collaborative filtering recommendation
	by means of elaborately integrating twofold sparse information, the
	conventional rating data given by users and the social trust network
	among the same users. It is a model-based method adopting matrix
	factorization technique to map users into low-dimensional latent
	feature spaces in terms of their trust relationship, aiming to reflect
	users' reciprocal influence on their own opinions more reasonably.
	The validations against a real-world dataset show that the proposed
	method performs much better than state-of-the-art recommendation
	algorithms for social collaborative filtering by trust.},
  acmid     = {2540524},
  comment   = {method: trustMF
	
	increases the weight of regularization term involving more ratings
	
	the link is an observation, users->truster-specific feature space,
	trustee-specific
	
	items-> truster model and trustee model
	
	finally fuse (average) truster and trustee model},
  file      = {Yang2013Social.pdf:Yang2013Social.pdf:PDF},
  isbn      = {978-1-57735-633-2},
  location  = {Beijing, China},
  numpages  = {7},
}

@INPROCEEDINGS{Yang2012Local,
  author = {Yang, Diyi and Chen, Tianqi and Zhang, Weinan and Lu, Qiuxia and
	Yu, Yong},
  title = {Local Implicit Feedback Mining for Music Recommendation},
  booktitle = {Proceedings of the Sixth ACM Conference on Recommender Systems},
  year = {2012},
  series = {RecSys '12},
  pages = {91--98},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Digital music has experienced a quite fascinating transformation during
	the past decades. Thousands of people share or distribute their music
	collections on the Internet, resulting in an explosive increase of
	information and more user dependence on automatic recommender systems.
	Though there are many techniques such as collaborative filtering,
	most approaches focus mainly on users' global behaviors, neglecting
	local actions and the specific properties of music. In this paper,
	we propose a simple and effective local implicit feedback model mining
	users' local preferences to get better recommendation performance
	in both rating and ranking prediction. Moreover, we design an efficient
	training algorithm to speed up the updating procedure, and give a
	method to find the most appropriate time granularity to assist the
	performance. We conduct various experiments to evaluate the performance
	of this model, which show that it outperforms baseline model significantly.
	Integration with existing temporal models achieves a great improvement
	compared to the reported best single model for Yahoo! Music.},
  acmid = {2365973},
  file = {Yang2012Local.pdf:Yang2012Local.pdf:PDF},
  isbn = {978-1-4503-1270-7},
  keywords = {collaborative filtering, efficient training, local implicit feedback,
	recommender system},
  location = {Dublin, Ireland},
  numpages = {8},
  timestamp = {2015.11.12}
}

@InProceedings{Yang2003Dynamic,
  author    = {Jiong Yang},
  title     = {Dynamic clustering of evolving streams with a single pass},
  booktitle = {Data Engineering, 2003. Proceedings. 19th International Conference on},
  year      = {2003},
  pages     = {695-697},
  abstract  = {Stream data is common in many applications, e.g., stock quotes, merchandize
	sales record, system logs, etc.. It is of great importance to analyze
	these stream data. As one of the most commonly used techniques, clustering
	on streams can help to detect and monitor correlations among streams.
	Due to the unique nature of streaming data, direct application of
	most existing clustering algorithms fails to deliver efficient results.
	We introduce a novel model of stream cluster, which employs a weighted
	distance measure. In addition, we device a novel efficient algorithm
	which can effectively discover all stream clusters.},
  doi       = {10.1109/ICDE.2003.1260838},
  keywords  = {computational complexity;data analysis;data mining;pattern clustering;data analysis;data mining;dynamic stream clustering algorithm;incremental algorithm;single pass;stream data;weighted distance measure;Application software;Clustering algorithms;Computer networks;Computer science;Computerized monitoring;Condition monitoring;Data analysis;Marketing and sales;Resource management;Weight measurement},
}

@InProceedings{Yang2011Patterns,
  author    = {Yang, Jaewon and Leskovec, Jure},
  title     = {Patterns of temporal variation in online media},
  booktitle = {Proceedings of the fourth ACM international conference on Web search and data mining},
  year      = {2011},
  series    = {WSDM '11},
  pages     = {177--186},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Online content exhibits rich temporal dynamics, and diverse realtime
	user generated content further intensifies this process. However,
	temporal patterns by which online content grows and fades over time,
	and by which different pieces of content compete for attention remain
	largely unexplored.
	
	
	We study temporal patterns associated with online content and how
	the content's popularity grows and fades over time. The attention
	that content receives on the Web varies depending on many factors
	and occurs on very different time scales and at different resolutions.
	In order to uncover the temporal dynamics of online content we formulate
	a time series clustering problem using a similarity metric that is
	invariant to scaling and shifting. We develop the K-Spectral Centroid
	(K-SC) clustering algorithm that effectively finds cluster centroids
	with our similarity measure. By applying an adaptive wavelet-based
	incremental approach to clustering, we scale K-SC to large data sets.
	
	
	We demonstrate our approach on two massive datasets: a set of 580
	million Tweets, and a set of 170 million blog posts and news media
	articles. We find that K-SC outperforms the K-means clustering algorithm
	in finding distinct shapes of time series. Our analysis shows that
	there are six main temporal shapes of attention of online content.
	We also present a simple model that reliably predicts the shape of
	attention by using information about only a small number of participants.
	Our analyses offer insight into common temporal patterns of the content
	on theWeb and broaden the understanding of the dynamics of human
	attention.},
  acmid     = {1935863},
  doi       = {http://doi.acm.org/10.1145/1935826.1935863},
  file      = {Yang2011Patterns.pdf:Yang2011Patterns.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-1-4503-0493-1},
  keywords  = {social media, time series clustering},
  location  = {Hong Kong, China},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/1935826.1935863},
}

@InProceedings{Yang2011Culture,
  author    = {Yang, Jiang and Morris, Meredith Ringel and Teevan, Jaime and Adamic, Lada A and Ackerman, Mark S},
  title     = {Culture Matters: A Survey Study of Social Q\&A Behavior.},
  booktitle = {ICWSM},
  year      = {2011},
  file      = {Yang2011Culture.pdf:Yang2011Culture.pdf:PDF},
  groups    = {Twitter},
}

@Article{Yang2008Automatic,
  author    = {Yang, K.W. and Huh, S.Y.},
  title     = {Automatic expert identification using a text categorization technique in knowledge management systems},
  journal   = {Expert Systems with Applications},
  year      = {2008},
  volume    = {34},
  number    = {2},
  pages     = {1445--1455},
  owner     = {Cheyenne},
  publisher = {Elsevier},
  timestamp = {2009.09.21},
}

@INPROCEEDINGS{Yang2012Circle,
  author = {Yang, Xiwang and Steck, Harald and Liu, Yong},
  title = {Circle-based Recommendation in Online Social Networks},
  booktitle = {Proceedings of the 18th ACM SIGKDD International Conference on Knowledge
	Discovery and Data Mining},
  year = {2012},
  series = {KDD '12},
  pages = {1267--1275},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {2339728},
  doi = {10.1145/2339530.2339728},
  isbn = {978-1-4503-1462-6},
  keywords = {collaborative filtering, friends circles, online social networks,
	recommender systems},
  location = {Beijing, China},
  numpages = {9},
  url = {http://doi.acm.org/10.1145/2339530.2339728}
}

@InProceedings{Yang1997comparative,
  author       = {Yang, Y. and Pedersen, J.O.},
  title        = {A comparative study on feature selection in text categorization},
  booktitle    = {MACHINE LEARNING-INTERNATIONAL WORKSHOP THEN CONFERENCE-},
  year         = {1997},
  pages        = {412--420},
  organization = {MORGAN KAUFMANN PUBLISHERS, INC.},
}

@InProceedings{Yang2011Social,
  author    = {Yang, Zi and Cai, Keke and Tang, Jie and Zhang, Li and Su, Zhong and Li, Juanzi},
  title     = {Social context summarization},
  booktitle = {Proceedings of the 34th international ACM SIGIR conference on Research and development in Information},
  year      = {2011},
  series    = {SIGIR '11},
  pages     = {255--264},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {We study a novel problem of social context summarization for Web documents.
	Traditional summarization research has focused on extracting informative
	sentences from standard documents. With the rapid growth of online
	social networks, abundant user generated content (e.g., comments)
	associated with the standard documents is available. Which parts
	in a document are social users really caring about? How can we generate
	summaries for standard documents by considering both the informativeness
	of sentences and interests of social users? This paper explores such
	an approach by modeling Web documents and social contexts into a
	unified framework. We propose a dual wing factor graph (DWFG) model,
	which utilizes the mutual reinforcement between Web documents and
	their associated social contexts to generate summaries. An efficient
	algorithm is designed to learn the proposed factor graph model.Experimental
	results on a Twitter data set validate the effectiveness of the proposed
	model. By leveraging the social context information, our approach
	obtains significant improvement (averagely +5.0%-17.3%) over several
	alternative methods (CRF, SVM, LR, PR, and DocLead) on the performance
	of summarization.},
  acmid     = {2009954},
  comment   = {problem definition: given a social context augmented network, the goal is to generate a summary which consists of two pieces of information the most important sentences and the most representative messages


each sentence in the news document and each tweet is associted with a hidden variable whether it should be selected 

simultaneously summarizing documents and tweets : 
tweet: local attribute factor, e.g. tf-idf
intra-domain dependency factor . sequence labeling process , avoid selecting subsequent sentences
inter-domain dependency factor: knowledge from document and tweets

loss function likelihood 

},
  doi       = {http://doi.acm.org/10.1145/2009916.2009954},
  file      = {Yang2011Social.pdf:Yang2011Social.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-1-4503-0757-4},
  keywords  = {document summarization, factor graph, social context, twitter},
  location  = {Beijing, China},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2009916.2009954},
}

@INPROCEEDINGS{Yao2013Unified,
  author = {Yao, Ting and Liu, Yuan and Ngo, Chong-Wah and Mei, Tao},
  title = {Unified Entity Search in Social Media Community},
  booktitle = {Proceedings of the 22Nd International Conference on World Wide Web},
  year = {2013},
  series = {WWW '13},
  pages = {1457--1466},
  address = {Republic and Canton of Geneva, Switzerland},
  publisher = {International World Wide Web Conferences Steering Committee},
  acmid = {2488515},
  isbn = {978-1-4503-2035-1},
  keywords = {entity search, friend suggestion, image tagging, personalized image
	search, social media community},
  location = {Rio de Janeiro, Brazil},
  numpages = {10}
}

@InProceedings{Yao2014Modeling,
  author    = {Yao, Weilong and He, Jing and Huang, Guangyan and Zhang, Yanchun},
  title     = {Modeling Dual Role Preferences for Trust-aware Recommendation},
  booktitle = {Proceedings of the 37th International ACM SIGIR Conference on Research \&\#38; Development in Information Retrieval},
  year      = {2014},
  series    = {SIGIR '14},
  pages     = {975--978},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Unlike in general recommendation scenarios where a user has only a
	single role, users in trust rating network, e.g. Epinions, are associated
	with two different roles simultaneously: as a truster and as a trustee.
	With different roles, users can show distinct preferences for rating
	items, which the previous approaches do not involve. Moreover, based
	on explicit single links between two users, existing methods can
	not capture the implicit correlation between two users who are similar
	but not socially connected. In this paper, we propose to learn dual
	role preferences (truster/trustee-specific preferences) for trust-aware
	recommendation by modeling explicit interactions (e.g., rating and
	trust) and implicit interactions. In particular, local links structure
	of trust network are exploited as two regularization terms to capture
	the implicit user correlation, in terms of truster/trustee-specific
	preferences. Using a real-world and open dataset, we conduct a comprehensive
	experimental study to investigate the performance of the proposed
	model, RoRec. The results show that RoRec outperforms other trust-aware
	recommendation approaches, in terms of prediction accuracy.},
  acmid     = {2609488},
  comment   = {rating = truster-specific interest + trustee-specific interest over
	items
	
	
	for linked users
	
	the truster-specific and trustee-specific interests must be similar
	
	confidence propto truster's out degree and trustee's in degree},
  file      = {Yao2014Modeling.pdf:Yao2014Modeling.pdf:PDF},
  isbn      = {978-1-4503-2257-7},
  keywords  = {collaborative filtering, matrix factorization, network structure, role preference},
  location  = {Gold Coast, Queensland, Australia},
  numpages  = {4},
  timestamp = {2015.11.30},
}

@INPROCEEDINGS{Ye2007Learning,
  author = {Ye, Z.F. and Lu, B.L.},
  title = {Learning Imbalanced Data Sets with a Min-Max Modular Support Vector
	Machine},
  booktitle = {Neural Networks, 2007. IJCNN 2007. International Joint Conference
	on},
  year = {2007},
  pages = {1673--1678},
  organization = {IEEE}
}

@InProceedings{Yih2007Multi-document,
  author    = {Yih, W. and Goodman, J. and Vanderwende, L. and Suzuki, H.},
  title     = {Multi-document summarization by maximizing informative content-words},
  booktitle = {Proceedings of IJCAI},
  year      = {2007},
  volume    = {7},
  groups    = {Twitter},
}

@INPROCEEDINGS{Yin2014Dirichlet,
  author = {Yin, Jianhua and Wang, Jianyong},
  title = {A Dirichlet Multinomial Mixture Model-based Approach for Short Text
	Clustering},
  booktitle = {Proceedings of the 20th ACM SIGKDD International Conference on Knowledge
	Discovery and Data Mining},
  year = {2014},
  series = {KDD '14},
  pages = {233--242},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Short text clustering has become an increasingly important task with
	the popularity of social media like Twitter, Google+, and Facebook.
	It is a challenging problem due to its sparse, high-dimensional,
	and large-volume characteristics. In this paper, we proposed a collapsed
	Gibbs Sampling algorithm for the Dirichlet Multinomial Mixture model
	for short text clustering (abbr. to GSDMM). We found that GSDMM can
	infer the number of clusters automatically with a good balance between
	the completeness and homogeneity of the clustering results, and is
	fast to converge. GSDMM can also cope with the sparse and high-dimensional
	problem of short texts, and can obtain the representative words of
	each cluster. Our extensive experimental study shows that GSDMM can
	achieve significantly better performance than three other clustering
	models.},
  acmid = {2623715},
  file = {Yin2014Dirichlet.pdf:Yin2014Dirichlet.pdf:PDF},
  isbn = {978-1-4503-2956-9},
  keywords = {dirichlet multinomial mixture, gibbs sampling, short text clustering},
  location = {New York, New York, USA},
  numpages = {10}
}

@INPROCEEDINGS{Yoo2009Mining,
  author = {Yoo, Shinjae and Yang, Yiming and Lin, Frank and Moon, Il-Chul},
  title = {Mining social networks for personalized email prioritization},
  booktitle = {KDD '09: Proceedings of the 15th ACM SIGKDD international conference
	on Knowledge discovery and data mining},
  year = {2009},
  pages = {967--976},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1557019.1557124},
  isbn = {978-1-60558-495-9},
  location = {Paris, France}
}

@Article{Yoon2013Practical,
  author  = {Sunmoo Yoon and Noémie Elhadad and Suzanne Bakken},
  title   = {A Practical Approach for Content Mining of Tweets},
  journal = {American Journal of Preventive Medicine},
  year    = {2013},
  volume  = {45},
  number  = {1},
  pages   = {122 - 129},
  doi     = {http://dx.doi.org/10.1016/j.amepre.2013.02.025},
  groups  = {Twitter},
  issn    = {0749-3797},
  url     = {http://www.sciencedirect.com/science/article/pii/S0749379713002432},
}

@InProceedings{Yu2010Document,
  author    = {Yu, Guan and Huang, Ruizhang and Wang, Zhaojun},
  title     = {Document Clustering via Dirichlet Process Mixture Model with Feature Selection},
  booktitle = {Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year      = {2010},
  series    = {KDD '10},
  pages     = {763--772},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {One essential issue of document clustering is to estimate the appropriate
	number of clusters for a document collection to which documents should
	be partitioned. In this paper, we propose a novel approach, namely
	DPMFS, to address this issue. The proposed approach is designed 1)
	to group documents into a set of clusters while the number of document
	clusters is determined by the Dirichlet process mixture model automatically;
	2) to identify the discriminative words and separate them from irrelevant
	noise words via stochastic search variable selection technique. We
	explore the performance of our proposed approach on both a synthetic
	dataset and several realistic document datasets. The comparison between
	our proposed approach and stage-of-the-art document clustering approaches
	indicates that our approach is robust and effective for document
	clustering.},
  acmid     = {1835901},
  comment   = {distinguish word (0,1), like implicit feedback?},
  file      = {Yu2010Document.pdf:Yu2010Document.pdf:PDF},
  isbn      = {978-1-4503-0055-1},
  keywords  = {dirichlet process mixture model, document clustering, feature selection},
  location  = {Washington, DC, USA},
  numpages  = {10},
  timestamp = {2015.08.26},
}

@INPROCEEDINGS{Yu2011Domain,
  author = {Yu, Jianxing and Zha, Zheng-Jun and Wang, Meng and Wang, Kai and
	Chua, Tat-Seng},
  title = {Domain-assisted Product Aspect Hierarchy Generation: Towards Hierarchical
	Organization of Unstructured Consumer Reviews},
  booktitle = {Proceedings of the Conference on Empirical Methods in Natural Language
	Processing},
  year = {2011},
  series = {EMNLP '11},
  pages = {140--150},
  address = {Stroudsburg, PA, USA},
  publisher = {Association for Computational Linguistics},
  abstract = {This paper presents a domain-assisted approach to organize various
	aspects of a product into a hierarchy by integrating domain knowledge
	(e.g., the product specifications), as well as consumer reviews.
	Based on the derived hierarchy, we generate a hierarchical organization
	of consumer reviews on various product aspects and aggregate consumer
	opinions on these aspects. With such organization, user can easily
	grasp the overview of consumer reviews. Furthermore, we apply the
	hierarchy to the task of implicit aspect identification which aims
	to infer implicit aspects of the reviews that do not explicitly express
	those aspects but actually comment on them. The experimental results
	on 11 popular products in four domains demonstrate the effectiveness
	of our approach.},
  acmid = {2145449},
  file = {Yu2011Domain.pdf:Yu2011Domain.pdf:PDF},
  isbn = {978-1-937284-11-4},
  location = {Edinburgh, United Kingdom},
  numpages = {11},
  url = {http://dl.acm.org/citation.cfm?id=2145432.2145449}
}

@TECHREPORT{Yu2009Gibbs,
  author = {Xiaodong Yu},
  title = {Gibbs Sampling Methods for Dirichlet Process Mixture Model: Technical
	Details},
  institution = {University of Maryland, College Park},
  year = {2009},
  file = {Yu2009Gibbs.pdf:Yu2009Gibbs.pdf:PDF},
  owner = {littlep},
  timestamp = {2015.05.19}
}

@InProceedings{Yuan2011Factorization,
  author    = {Yuan, Quan and Chen, Li and Zhao, Shiwan},
  title     = {Factorization vs. Regularization: Fusing Heterogeneous Social Relationships in Top-n Recommendation},
  booktitle = {Proceedings of the Fifth ACM Conference on Recommender Systems},
  year      = {2011},
  series    = {RecSys '11},
  pages     = {245--252},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Collaborative Filtering (CF) based recommender systems often suffer
	from the sparsity problem, particularly for new and inactive users
	when they use the system. The emerging trend of social networking
	sites and their accommodation in other sites like e-commerce can
	potentially help alleviate the sparsity problem with their provided
	social relation data. In this paper, we have particularly explored
	a new kind of social relation, the membership, and its combined effect
	with friendship. The two type of heterogeneous social relations are
	fused into the CF recommender via a factorization process. Due to
	the two relations' respective properties, we adopt different fusion
	strategies: regularization was leveraged for friendship and collective
	matrix factorization (CMF) was proposed for incorporating membership.
	We further developed a unified model to combine the two relations
	together and tested it with real large-scale datasets at five sparsity
	levels. The experiment has not only revealed the significant effect
	of the two relations, especially the membership, in augmenting recommendation
	accuracy in the sparse data condition, but also identified the ability
	of our fusing model in achieving the desired fusion performance.},
  acmid     = {2043975},
  comment   = {method: 
	
	basic mf, relation as rating
	
	fusing membership and friendship together},
  file      = {Yuan2011Factorization.pdf:Yuan2011Factorization.pdf:PDF},
  isbn      = {978-1-4503-0683-6},
  keywords  = {factorization, friendship, membership, regularization, social relationships},
  location  = {Chicago, Illinois, USA},
  numpages  = {8},
  timestamp = {2015.11.26},
}

@InProceedings{Zanardi2008Social,
  author    = {Zanardi, Valentina and Capra, Licia},
  title     = {Social ranking: uncovering relevant content using tag-based recommender systems},
  booktitle = {Proceedings of the 2008 ACM conference on Recommender systems},
  year      = {2008},
  series    = {RecSys '08},
  pages     = {51--58},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Social (or folksonomic) tagging has become a very popular way to describe,
	categorise, search, discover and navigate content within Web 2.0
	websites. Unlike taxonomies, which overimpose a hierarchical categorisation
	of content, folksonomies empower end users by enabling them to freely
	create and choose the categories (in this case, tags) that best describe
	some content. However, as tags are informally defined, continually
	changing, and ungoverned, social tagging has often been criticised
	for lowering, rather than increasing, the efficiency of searching,
	due to the number of synonyms, homonyms, polysemy, as well as the
	heterogeneity of users and the noise they introduce. In this paper,
	we propose Social Ranking, a method that exploits recommender system
	techniques to increase the efficiency of searches within Web 2.0.
	We measure users' similarity based on their past tag activity. We
	infer tags' relationships based on their association to content.
	We then propose a mechanism to answer a user's query that ranks (recommends)
	content based on the inferred semantic distance of the query to the
	tags associated to such content, weighted by the similarity of the
	querying user to the users who created those tags. A thorough evaluation
	conducted on the CiteULike dataset demonstrates that Social Ranking
	neatly improves coverage, while not compromising on accuracy.},
  acmid     = {1454018},
  doi       = {http://doi.acm.org/10.1145/1454008.1454018},
  file      = {Zanardi2008Social.pdf:Zanardi2008Social.pdf:PDF},
  groups    = {Recommender Systems},
  isbn      = {978-1-60558-093-7},
  keywords  = {recommender systems, similarity, tags, web 2.0},
  location  = {Lausanne, Switzerland},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/1454008.1454018},
}

@Article{Zhai2008Statistical,
  author    = {Zhai, C.X.},
  title     = {Statistical language models for information retrieval a critical review},
  journal   = {Foundations and Trends in Information Retrieval},
  year      = {2008},
  volume    = {2},
  number    = {3},
  pages     = {137--213},
  file      = {Zhai2008Statistical.pdf:Zhai2008Statistical.pdf:PDF},
  publisher = {Now Publishers Inc.},
}

@ARTICLE{Zhai2004study,
  author = {Zhai, Chengxiang and Lafferty, John},
  title = {A study of smoothing methods for language models applied to information
	retrieval},
  journal = {ACM Trans. Inf. Syst.},
  year = {2004},
  volume = {22},
  pages = {179--214},
  number = {2},
  address = {New York, NY, USA},
  doi = {http://doi.acm.org/10.1145/984321.984322},
  issn = {1046-8188},
  publisher = {ACM}
}

@InProceedings{Zhai2001Modelbased,
  author    = {Zhai, Chengxiang and Lafferty, John},
  title     = {Model-based feedback in the language modeling approach to information retrieval},
  booktitle = {Proceedings of the tenth international conference on Information and knowledge management},
  year      = {2001},
  series    = {CIKM '01},
  pages     = {403--410},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {502654},
  doi       = {http://doi.acm.org/10.1145/502585.502654},
  file      = {Zhai2001Model-based.pdf:Zhai2001Model-based.pdf:PDF},
  isbn      = {1-58113-436-3},
  location  = {Atlanta, Georgia, USA},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/502585.502654},
}

@INPROCEEDINGS{Zhai2001study,
  author = {Zhai, Chengxiang and Lafferty, John},
  title = {A study of smoothing methods for language models applied to Ad Hoc
	information retrieval},
  booktitle = {Proceedings of the 24th annual international ACM SIGIR conference
	on Research and development in information retrieval},
  year = {2001},
  series = {SIGIR '01},
  pages = {334--342},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {384019},
  doi = {http://doi.acm.org/10.1145/383952.384019},
  isbn = {1-58113-331-6},
  location = {New Orleans, Louisiana, United States},
  numpages = {9},
  url = {http://doi.acm.org/10.1145/383952.384019}
}

@INPROCEEDINGS{Zhang2015Markov,
  author = {Zhang, Aonan and Paisley, John},
  title = {Markov Mixed Membership Models},
  booktitle = {Proceedings of the 32nd International Conference on Machine Learning
	(ICML-15)},
  year = {2015},
  pages = {475--483},
  timestamp = {2015.09.10}
}

@InProceedings{Zhang2011Transfer,
  author    = {Dan Zhang and Yan Liu and Richard D. Lawrence and Vijil Chenthamarakshan},
  title     = {Transfer Latent Semantic Learning: Microblog Mining with Less Supervision},
  booktitle = {Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence},
  year      = {2011},
  pages     = {561-566},
  abstract  = {The increasing volume of information generated on microblogging sites
	such as Twitter raises several challenges to traditional text mining
	techniques. First, most texts from those
	
	sites are abbreviated due to the constraints of limited characters
	in one post; second, the input usually comes in streams
	
	of large-volumes. Therefore, it is of signiﬁcant importance to
	
	develop effective and efﬁcient representations of abbreviated
	
	texts for better ﬁltering and mining. In this paper, we introduce
	a novel transfer learning approach, namely transfer latent semantic
	learning, that utilizes a large number of related
	
	tagged documents with rich information from other sources
	
	(source domain) to help build a robust latent semantic space
	
	for the abbreviated texts (target domain). This is achieved by
	
	simultaneously minimizing the document reconstruction error and the
	classiﬁcation error of the labeled examples from
	
	the source domain by building a classiﬁer with hinge loss
	
	in the latent semantic space. We demonstrate the effectiveness of
	our method by applying them to the task of classifying and tagging
	abbreviated texts. Experimental results on
	
	both synthetic datasets and real application datasets, including Reuters-21578
	and Twitter data, suggest substantial improvements using our approach
	over existing ones},
  bibsource = {DBLP, http://dblp.uni-trier.de},
  ee        = {http://www.aaai.org/ocs/index.php/AAAI/AAAI11/paper/view/3647},
  file      = {Zhang2011Transfer.pdf:Zhang2011Transfer.pdf:PDF},
  groups    = {Twitter},
  owner     = {linchen},
  timestamp = {2011.11.01},
}

@Conference{Zhang2005Searching,
  author       = {Zhang, J. and Ackerman, M.S.},
  title        = {Searching for expertise in social networks: a simulation of potential strategies},
  booktitle    = {Proceedings of the 2005 international ACM SIGGROUP conference on Supporting group work},
  year         = {2005},
  pages        = {71--80},
  organization = {ACM New York, NY, USA},
  owner        = {Cheyenne},
  timestamp    = {2009.09.21},
}

@InProceedings{Zhang2007Expertise,
  author    = {Zhang, Jun and Ackerman, Mark S. and Adamic, Lada},
  title     = {Expertise networks in online communities: structure and algorithms},
  booktitle = {WWW '07: Proceedings of the 16th international conference on World Wide Web},
  year      = {2007},
  pages     = {221--230},
  address   = {New York, NY, USA},
  publisher = {ACM},
  doi       = {http://doi.acm.org/10.1145/1242572.1242603},
  file      = {Zhang2007Expertise.pdf:Zhang2007Expertise.pdf:PDF},
  isbn      = {978-1-59593-654-7},
  location  = {Banff, Alberta, Canada},
}

@INPROCEEDINGS{Zhang2010Evolutionary,
  author = {Zhang, Jianwen and Song, Yangqiu and Zhang, Changshui and Liu, Shixia},
  title = {Evolutionary Hierarchical Dirichlet Processes for Multiple Correlated
	Time-varying Corpora},
  booktitle = {Proceedings of the 16th ACM SIGKDD International Conference on Knowledge
	Discovery and Data Mining},
  year = {2010},
  series = {KDD '10},
  pages = {1079--1088},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {Mining cluster evolution from multiple correlated time-varying text
	corpora is important in exploratory text analytics. In this paper,
	we propose an approach called evolutionary hierarchical Dirichlet
	processes (EvoHDP) to discover interesting cluster evolution patterns
	from such text data. We formulate the EvoHDP as a series of hierarchical
	Dirichlet processes~(HDP) by adding time dependencies to the adjacent
	epochs, and propose a cascaded Gibbs sampling scheme to infer the
	model. This approach can discover different evolving patterns of
	clusters, including emergence, disappearance, evolution within a
	corpus and across different corpora. Experiments over synthetic and
	real-world multiple correlated time-varying data sets illustrate
	the effectiveness of EvoHDP on discovering cluster evolution patterns.},
  acmid = {1835940},
  doi = {10.1145/1835804.1835940},
  file = {Zhang2010Evolutionary.pdf:Zhang2010Evolutionary.pdf:PDF},
  isbn = {978-1-4503-0055-1},
  keywords = {bayesian nonparametric methods, clustering, dirichlet processes, mixture
	models, multiple correlated time-varying corpora},
  location = {Washington, DC, USA},
  numpages = {10},
  timestamp = {2015.08.26},
  url = {http://doi.acm.org/10.1145/1835804.1835940}
}

@Article{Zhang2007Expert,
  author    = {Zhang, J. and Tang, J. and Li, J.},
  title     = {Expert finding in a social network},
  journal   = {Lecture Notes in Computer Science},
  year      = {2007},
  volume    = {4443},
  pages     = {1066-},
  owner     = {Cheyenne},
  publisher = {Springer},
  timestamp = {2009.09.21},
}

@Article{Zhang2014Inferring,
  author     = {Zhang, Jun and Wang, Chaokun and Wang, Jianmin and Yu, Jeffrey Xu},
  title      = {Inferring Continuous Dynamic Social Influence and Personal Preference for Temporal Behavior Prediction},
  journal    = {Proc. VLDB Endow.},
  year       = {2014},
  volume     = {8},
  number     = {3},
  pages      = {269--280},
  month      = nov,
  issn       = {2150-8097},
  abstract   = {It is always attractive and challenging to explore the intricate behavior
	data and uncover people's motivations, preference and habits, which
	can greatly benefit many tasks including link prediction, item recommendation,
	etc. Traditional work usually studies people's behaviors without
	time information in a static or discrete manner, assuming the underlying
	factors stay invariant in a long period. However, we believe people's
	behaviors are dynamic, and the contributing factors including the
	social influence and personal preference for behaviors are varying
	continuously over time. Such continuous dynamics convey important
	knowledge about people's behavior patterns; ignoring them would lead
	to inaccurate models.
	
	
	In this work, we address the continuous dynamic modeling of temporal
	behaviors. To model the fully continuous temporal dynamics of behaviors
	and the underlying factors, we propose the DP-Space, a dynamic preference
	probability space, which can capture their smooth variation in various
	shapes over time with flexible basis functions. Upon that we propose
	a generative dynamic behavior model, ConTyor, which considers the
	temporal item-adoption behaviors as joint effect of dynamic social
	influence and varying personal preference over continuous time. We
	also develop effective inference methods for ConTyor and present
	its applications.
	
	
	We conduct a comprehensive experimental study using real-world datasets
	to evaluate the effectiveness of our model and the temporal modeling.
	Results verify that ConTyor outperforms existing state-of-the-art
	static and temporal models in behavior predictions. Moreover, in
	our detailed study on temporal modeling, we show that temporal modeling
	is superior to static approaches and modeling over continuous time
	is further better than that over discrete time. We also demonstrate
	that the ancient behavior data can still become important and beneficial
	if modeled well.},
  acmid      = {2735516},
  comment    = {model: ConTyor
	
	probability generative model
	
	probability of user behaves in item v is the sum from all u's friends
	behaving in v
	
	probability of choosing a friend is the normalized dynamic preference
	strength function, which is defined as a linear combination of several
	basis functions of real-valued time t
	
	probability of a friend bahaving in item v is modeled in the same
	way with different parameters},
  file       = {Zhang2014Inferring.pdf:Zhang2014Inferring.pdf:PDF},
  issue_date = {November 2014},
  numpages   = {12},
  publisher  = {VLDB Endowment},
}

@InProceedings{Zhang2009Search,
  author    = {Zhang, Ruiqiang and Chang, Yi and Zheng, Zhaohui and Metzler, Donald and Nie, Jian-yun},
  title     = {Search result re-ranking by feedback control adjustment for time-sensitive query},
  booktitle = {Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, Companion Volume: Short Papers},
  year      = {2009},
  series    = {NAACL-Short '09},
  pages     = {165--168},
  address   = {Stroudsburg, PA, USA},
  publisher = {Association for Computational Linguistics},
  abstract  = {We propose a new method to rank a special category of time-sensitive
	queries that are year qualified. The method adjusts the retrieval
	scores of a base ranking function according to time-stamps of web
	documents so that the freshest documents are ranked higher. Our method,
	which is based on feedback control theory, uses ranking errors to
	adjust the search engine behavior. For this purpose, we use a simple
	but effective method to extract year qualified queries by mining
	query logs and a time-stamp recognition method that considers titles
	and urls of web documents. Our method was tested on a commercial
	search engine. The experiments show that our approach can significantly
	improve relevance ranking for year qualified queries even if all
	the existing methods for comparison failed.},
  acmid     = {1620899},
  file      = {Zhang2009Search.pdf:Zhang2009Search.pdf:PDF},
  location  = {Boulder, Colorado},
  numpages  = {4},
  timestamp = {2014.06.14},
  url       = {http://dl.acm.org/citation.cfm?id=1620853.1620899},
}

@Article{Zhang2013Automatic,
  author   = {Renxian Zhang and Wenjie Li and Dehong Gao and You Ouyang},
  title    = {Automatic Twitter Topic Summarization With Speech Acts},
  journal  = {Audio, Speech, and Language Processing, IEEE Transactions on},
  year     = {2013},
  volume   = {21},
  number   = {3},
  pages    = {649-658},
  file     = {Zhang2013Automatic.pdf:Zhang2013Automatic.pdf:PDF},
  groups   = {Twitter},
  issn     = {1558-7916},
  keywords = {document handling;pattern classification;social networking (online);speech processing;Twitter messages;Twitter text;automatic Twitter topic summarization;communicative behavior;extractive method;high-ranking words;human-written summaries;multiclass classification problem;multidocument summarization;round-robin algorithm;social media service;speech act recognition;speech act-guided summarization approach;symbol-based features;template-based summaries;word-based features;Media;Noise measurement;Pragmatics;Speech;Speech recognition;Twitter;Twitter;abstractive summarization;key word/phrase extraction;speech act},
}

@INPROCEEDINGS{Zhang2009Scalable,
  author = {Zhang, Shiming and Mamoulis, Nikos and Cheung, David W.},
  title = {Scalable Skyline Computation Using Object-based Space Partitioning},
  booktitle = {Proceedings of the 2009 ACM SIGMOD International Conference on Management
	of Data},
  year = {2009},
  series = {SIGMOD '09},
  pages = {483--494},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {The skyline operator returns from a set of multi-dimensional objects
	a subset of superior objects that are not dominated by others. This
	operation is considered very important in multi-objective analysis
	of large datasets. Although a large number of skyline methods have
	been proposed, the majority of them focuses on minimizing the I/O
	cost. However, in high dimensional spaces, the problem can easily
	become CPU-bound due to the large number of computations required
	for comparing objects with current skyline points while scanning
	the database. Based on this observation, we propose a dynamic indexing
	technique for skyline points that can be integrated into state-of-the-art
	sort-based skyline algorithms to boost their computational performance.
	The new indexing and dominance checking approach is supported by
	a theoretical analysis, while our experiments show that it scales
	well with the input size and dimensionality not only because unnecessary
	dominance checks are avoided but also because it allows efficient
	dominance checking with the help of bitwise operations.},
  acmid = {1559897},
  doi = {10.1145/1559845.1559897},
  file = {Zhang2009Scalable.pdf:Zhang2009Scalable.pdf:PDF},
  isbn = {978-1-60558-551-2},
  keywords = {preference, skyline, space partitioning},
  location = {Providence, Rhode Island, USA},
  numpages = {12},
  url = {http://doi.acm.org/10.1145/1559845.1559897}
}

@INPROCEEDINGS{Zhang2002Novelty,
  author = {Zhang, Yi and Callan, Jamie and Minka, Thomas},
  title = {Novelty and redundancy detection in adaptive filtering},
  booktitle = {Proceedings of the 25th annual international ACM SIGIR conference
	on Research and development in information retrieval},
  year = {2002},
  series = {SIGIR '02},
  pages = {81--88},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {564393},
  doi = {http://doi.acm.org/10.1145/564376.564393},
  file = {Zhang2002Novelty.pdf:Zhang2002Novelty.pdf:PDF},
  isbn = {1-58113-561-0},
  location = {Tampere, Finland},
  numpages = {8},
  url = {http://doi.acm.org/10.1145/564376.564393}
}

@InProceedings{Zhang2007Efficient,
  author    = {Zhang, Yi and Koren, Jonathan},
  title     = {Efficient bayesian hierarchical user modeling for recommendation system},
  booktitle = {SIGIR '07: Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval},
  year      = {2007},
  pages     = {47--54},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {A content-based personalized recommendation system learns
	
	user speci¯c pro¯les from user feedback so that it can deliver
	
	information tailored to each individual user's interest. A sys-
	
	tem serving millions of users can learn a better user pro¯le
	
	for a new user, or a user with little feedback, by borrowing
	
	information from other users through the use of a Bayesian
	
	hierarchical model. Learning the model parameters to opti-
	
	mize the joint data likelihood from millions of users is very
	
	computationally expensive. The commonly used EM algo-
	
	rithm converges very slowly due to the sparseness of the data
	
	in IR applications. This paper proposes a new fast learning
	
	technique to learn a large number of individual user pro-
	
	¯les. The e±cacy and e±ciency of the proposed algorithm
	
	are justi¯ed by theory and demonstrated on actual user data
	
	from Net°ix and MovieLens.},
  comment   = {Data: Netflix; MovieLens;Reuters Data
	
	Model regression, bayesian},
  doi       = {http://doi.acm.org/10.1145/1277741.1277752},
  file      = {Zhang2007Efficient.pdf:Zhang2007Efficient.pdf:PDF},
  groups    = {Recommender Systems},
  isbn      = {978-1-59593-597-7},
  location  = {Amsterdam, The Netherlands},
}

@INPROCEEDINGS{Zhao2012Increasing,
  author = {Zhao, Gang and Lee, Mong Li and Hsu, Wynne and Chen, Wei},
  title = {Increasing Temporal Diversity with Purchase Intervals},
  booktitle = {Proceedings of the 35th International ACM SIGIR Conference on Research
	and Development in Information Retrieval},
  year = {2012},
  series = {SIGIR '12},
  pages = {165--174},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {The development of Web 2.0 technology has led to huge economic
	
	benefits and challenges for both e-commerce websites
	
	and online shoppers. One core technology to increase sales
	
	and consumers’ satisfaction is the use of recommender systems.
	
	Existing product recommender systems consider the
	
	order of items purchased by users to obtain a list of recommended
	
	items. However, they do not consider the time interval
	
	between the products purchased. For example, there
	
	is often an interval of 2-3 months between the purchase of
	
	printer ink cartridges or refills. Thus, recommending appropriate
	
	ink cartridges one week before the user needs to
	
	replace the depleted ink cartridges would increase the likelihood
	
	of a purchase decision. In this paper, we propose
	
	to utilize the purchase interval information to improve the
	
	performance of the recommender systems for e-commerce.
	
	We design an efficient algorithm to compute the purchase
	
	intervals between product pairs from users’ purchase history
	
	and integrate this information into the marginal utility
	
	model. We evaluate our approach on a real world ecommerce
	
	dataset. Experimental results demonstrate that
	
	our approach significantly improves the conversion rate and
	
	temporal diversity compared to state-of-the-art algorithms.},
  acmid = {2348309},
  doi = {10.1145/2348283.2348309},
  file = {Zhao2012Increasing.pdf:Zhao2012Increasing.pdf:PDF},
  isbn = {978-1-4503-1472-5},
  keywords = {e-commerce, personalization, purchase intervals, recommender system,
	temporal diversity, utility theory},
  location = {Portland, Oregon, USA},
  numpages = {10},
  timestamp = {2014.05.25},
  url = {http://doi.acm.org/10.1145/2348283.2348309}
}

@INPROCEEDINGS{Zhao2012Increasinga,
  author = {Zhao, Gang and Lee, Mong Li and Hsu, Wynne and Chen, Wei},
  title = {Increasing Temporal Diversity with Purchase Intervals},
  booktitle = {Proceedings of the 35th International ACM SIGIR Conference on Research
	and Development in Information Retrieval},
  year = {2012},
  series = {SIGIR '12},
  pages = {165--174},
  address = {New York, NY, USA},
  publisher = {ACM},
  acmid = {2348309},
  doi = {10.1145/2348283.2348309},
  isbn = {978-1-4503-1472-5},
  keywords = {e-commerce, personalization, purchase intervals, recommender system,
	temporal diversity, utility theory},
  location = {Portland, Oregon, USA},
  numpages = {10},
  url = {http://doi.acm.org/10.1145/2348283.2348309}
}

@INPROCEEDINGS{Zhao2014Enhanced,
  author = {Zhao, Jiashu and Huang, Jimmy Xiangji},
  title = {An Enhanced Context-sensitive Proximity Model for Probabilistic Information
	Retrieval},
  booktitle = {Proceedings of the 37th International ACM SIGIR Conference on Research
	and Development in Information Retrieval},
  year = {2014},
  series = {SIGIR '14},
  pages = {1131--1134},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {We propose to enhance proximity-based probabilistic retrieval models
	with more contextual information. A term pair with higher contextual
	relevance of term proximity is assigned a higher weight. Several
	measures are proposed to estimate the contextual relevance of term
	proximity. We assume the top ranked documents from a basic weighting
	model are more relevant to the query, and calculate the contextual
	relevance of term proximity using the top ranked documents. We propose
	a context-sensitive proximity model, and the experimental results
	on standard TREC data sets show the effectiveness of our proposed
	model.},
  acmid = {2609527},
  file = {Zhao2014Enhanced.pdf:Zhao2014Enhanced.pdf:PDF},
  isbn = {978-1-4503-2257-7},
  keywords = {context-sensitive ir, measure, probabilistic model, proximity},
  location = {Gold Coast, Queensland, Australia},
  numpages = {4},
  timestamp = {2014.10.04}
}

@Article{Zhao2014Modeling,
  author     = {Zhao, Jiashu and Huang, Jimmy Xiangji and Ye, Zheng},
  title      = {Modeling Term Associations for Probabilistic Information Retrieval},
  journal    = {ACM Trans. Inf. Syst.},
  year       = {2014},
  volume     = {32},
  number     = {2},
  pages      = {7:1--7:47},
  month      = apr,
  issn       = {1046-8188},
  abstract   = {Traditionally, in many probabilistic retrieval models, query terms
	are assumed to be independent. Although such models can achieve reasonably
	good performance, associations can exist among terms from a human
	being’s point of view. There are some recent studies that investigate
	how to model term associations/dependencies by proximity measures.
	However, the modeling of term associations theoretically under the
	probabilistic retrieval framework is still largely unexplored. In
	this article, we introduce a new concept cross term, to model term
	proximity, with the aim of boosting retrieval performance. With cross
	terms, the association of multiple query terms can be modeled in
	the same way as a simple unigram term. In particular, an occurrence
	of a query term is assumed to have an impact on its neighboring text.
	The degree of the query-term impact gradually weakens with increasing
	distance from the place of occurrence. We use shape functions to
	characterize such impacts. Based on this assumption, we first propose
	a bigram CRoss TErm Retrieval (CRTER2) model as the basis model,
	and then recursively propose a generalized n-gram CRoss TErm Retrieval
	(CRTERn) model for n query terms, where n > 2. Specifically, a bigram
	cross term occurs when the corresponding query terms appear close
	to each other, and its impact can be modeled by the intersection
	of the respective shape functions of the query terms. For an n-gram
	cross term, we develop several distance metrics with different properties
	and employ them in the proposed models for ranking. We also show
	how to extend the language model using the newly proposed cross terms.
	Extensive experiments on a number of TREC collections demonstrate
	the effectiveness of our proposed models.},
  acmid      = {2590988},
  address    = {New York, NY, USA},
  articleno  = {7},
  comment    = {introduce a concept: cross ngram term
	
	weight for cross term: intersection of n individual impact kernels
	
	various kernels},
  file       = {Zhao2014Modeling.pdf:Zhao2014Modeling.pdf:PDF},
  issue_date = {April 2014},
  keywords   = {BM25, Cross term, N-gram, kernel, probabilistic information retrieval, term association},
  numpages   = {47},
  publisher  = {ACM},
  timestamp  = {2016.04.25},
}

@InProceedings{Zhao2009Proximity,
  author    = {Jinglei Zhao and Yeogirl Yun},
  title     = {A Proximity Language Model for Information Retrieval},
  booktitle = {Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval},
  year      = {2009},
  pages     = {291-298},
  abstract  = {The proximity of query terms in a document is a very important information
	to enable ranking models go beyond the "bag of word" assumption in
	information retrieval. This paper studies the integration of term
	proximity information into the unigram language modeling. A new proximity
	language model (PLM) is proposed which views query terms' proximity
	centrality as the Dirichlet hyper-parameter that weights the parameters
	of the unigram document language model. Several forms of proximity
	measure are developed to be used in PLM which could compute a query
	term's proximate centrality in a specific document. In experiments,
	the proximity language model is compared with the basic language
	model and previous works that combine the proximity information with
	language model using linear score combination. The experiment results
	show that the proposed model performs better in both top precision
	and average precision.},
  comment   = {goal:document retrieval
	
	intuition: term proximity
	
	model: a generative model p(w|d) ~ multi(\theta) theta~dir(proximity
	function of word)
	
	highlight: formulate proximity of each word in a generative model
	
	drawbacks:1, each word has only one proximity parameter, which means
	that the proximity here is more like a concept of "centrality"
	
	2, the reasoning for dirichlet? no enough training?
	
	3,computation cost too high},
  keywords  = {information retrieval, proximity model, proximity language model},
  owner     = {linchen},
  timestamp = {2009.12.15},
}

@ARTICLE{Zhao2006Model,
  author = {Zhao, Peng and Yu, Bin},
  title = {On Model Selection Consistency of Lasso},
  journal = {J. Mach. Learn. Res.},
  year = {2006},
  volume = {7},
  pages = {2541--2563},
  month = {December},
  acmid = {1248637},
  file = {Zhao2006Model.pdf:Zhao2006Model.pdf:PDF},
  issn = {1532-4435},
  numpages = {23},
  publisher = {JMLR.org},
  url = {http://portal.acm.org/citation.cfm?id=1248547.1248637}
}

@InProceedings{Zhao2011Comparing,
  author    = {Zhao, Wayne Xin and Jiang, Jing and Weng, Jianshu and He, Jing and Lim, Ee-Peng and Yan, Hongfei and Li, Xiaoming},
  title     = {Comparing twitter and traditional media using topic models},
  booktitle = {Proceedings of the 33rd European conference on Advances in information retrieval},
  year      = {2011},
  series    = {ECIR'11},
  pages     = {338--349},
  address   = {Berlin, Heidelberg},
  publisher = {Springer-Verlag},
  abstract  = {Twitter as a new form of social media can potentially contain much
	useful information, but content analysis on Twitter has not been
	well studied. In particular, it is not clear whether as an information
	source Twitter can be simply regarded as a faster news feed that
	covers mostly the same information as traditional news media. In
	This paper we empirically compare the content of Twitter with a traditional
	news medium, New York Times, using unsupervised topic modeling. We
	use a Twitter-LDA model to discover topics from a representative
	sample of the entire Twitter. We then use text mining techniques
	to compare these Twitter topics with topics from New York Times,
	taking into consideration topic categories and types. We also study
	the relation between the proportions of opinionated tweets and retweets
	and topic categories and types. Our comparisons show interesting
	and useful findings for downstream IR or DM applications.},
  acmid     = {1996934},
  groups    = {Twitter},
  isbn      = {978-3-642-20160-8},
  keywords  = {microblogging, topic modeling, twitter},
  location  = {Dublin, Ireland},
  numpages  = {12},
  url       = {http://dl.acm.org/citation.cfm?id=1996889.1996934},
}

@InProceedings{Zhao2013Timeline,
  author    = {Zhao, Xin Wayne and Guo, Yanwei and Yan, Rui and He, Yulan and Li, Xiaoming},
  title     = {Timeline Generation with Social Attention},
  booktitle = {Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year      = {2013},
  series    = {SIGIR '13},
  pages     = {1061--1064},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Timeline generation is an important research task which can help users
	to have a quick understanding of the overall evolution of any given
	topic. It thus attracts much attention from research communities
	in recent years. Nevertheless, existing work on timeline generation
	often ignores an important factor, the attention attracted to topics
	of interest (hereafter termed "social attention"). Without taking
	into consideration social attention, the generated timelines may
	not reflect users' collective interests. In this paper, we study
	how to incorporate social attention in the generation of timeline
	summaries. In particular, for a given topic, we capture social attention
	by learning users' collective interests in the form of word distributions
	from Twitter, which are subsequently incorporated into a unified
	framework for timeline summary generation. We construct four evaluation
	sets over six diverse topics. We demonstrate that our proposed approach
	is able to generate both informative and interesting timelines. Our
	work sheds light on the feasibility of incorporating social attention
	into traditional text mining tasks.},
  acmid     = {2484103},
  doi       = {10.1145/2484028.2484103},
  groups    = {Twitter},
  isbn      = {978-1-4503-2034-4},
  keywords  = {social media attention, timeline, user interests},
  location  = {Dublin, Ireland},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/2484028.2484103},
}

@ARTICLE{Zheng2013PENETRATE,
  author = {Li Zheng and Lei Li and Wenxing Hong and Tao Li},
  title = {PENETRATE: Personalized news recommendation using ensemble hierarchical
	clustering },
  journal = {Expert Systems with Applications },
  year = {2013},
  volume = {40},
  pages = {2127 - 2136},
  number = {6},
  doi = {http://dx.doi.org/10.1016/j.eswa.2012.10.029},
  issn = {0957-4174},
  keywords = {Personalization},
  url = {http://www.sciencedirect.com/science/article/pii/S0957417412011530}
}

@ARTICLE{Zheng2014Framework,
  author = {Zheng, Li and Li, Tao and Ding, Chris},
  title = {A Framework for Hierarchical Ensemble Clustering},
  journal = {ACM Trans. Knowl. Discov. Data},
  year = {2014},
  volume = {9},
  pages = {9:1--9:23},
  number = {2},
  month = sep,
  acmid = {2611380},
  address = {New York, NY, USA},
  articleno = {9},
  doi = {10.1145/2611380},
  issn = {1556-4681},
  issue_date = {November 2014},
  keywords = {Hierarchical ensemble clustering, ensemble selection, ultra-metric},
  numpages = {23},
  publisher = {ACM},
  url = {http://doi.acm.org/10.1145/2611380}
}

@Article{Zheng2012Extracting,
  author     = {Zheng, Wei-Shi and Lai, JianHuang and Liao, Shengcai and He, Ran},
  title      = {Extracting non-negative basis images using pixel dispersion penalty},
  journal    = {Pattern Recogn.},
  year       = {2012},
  volume     = {45},
  number     = {8},
  pages      = {2912--2926},
  month      = aug,
  acmid      = {2181733},
  address    = {New York, NY, USA},
  doi        = {10.1016/j.patcog.2012.01.022},
  groups     = {matrix factorization},
  issn       = {0031-3203},
  issue_date = {August, 2012},
  keywords   = {Feature extraction, Face image analysis, Non-negative matrix factorization (NMF), Non-negativity constraint, Spatially localized basis images},
  numpages   = {15},
  publisher  = {Elsevier Science Inc.},
  url        = {http://dx.doi.org/10.1016/j.patcog.2012.01.022},
}

@INPROCEEDINGS{Zhou2008Exploring,
  author = {Zhou, Ding and Bian, Jiang and Zheng, Shuyi and Zha, Hongyuan and
	Giles, C. Lee},
  title = {Exploring social annotations for information retrieval},
  booktitle = {WWW '08: Proceeding of the 17th international conference on World
	Wide Web},
  year = {2008},
  pages = {715--724},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1367497.1367594},
  isbn = {978-1-60558-085-2},
  location = {Beijing, China}
}

@InProceedings{Zhou2006Topic,
  author    = {Zhou, Ding and Ji, Xiang and Zha, Hongyuan and Giles, C. Lee},
  title     = {Topic evolution and social interactions: how authors effect research},
  booktitle = {CIKM '06: Proceedings of the 15th ACM international conference on Information and knowledge management},
  year      = {2006},
  pages     = {248--257},
  address   = {New York, NY, USA},
  publisher = {ACM},
  doi       = {http://doi.acm.org/10.1145/1183614.1183653},
  isbn      = {1-59593-433-2},
  location  = {Arlington, Virginia, USA},
}

@INPROCEEDINGS{Zhou2006Probabilistic,
  author = {Zhou, Ding and Manavoglu, Eren and Li, Jia and Giles, C. Lee and
	Zha, Hongyuan},
  title = {Probabilistic models for discovering e-communities},
  booktitle = {WWW '06: Proceedings of the 15th international conference on World
	Wide Web},
  year = {2006},
  pages = {173--182},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1135777.1135807},
  isbn = {1-59593-323-9},
  location = {Edinburgh, Scotland}
}

@Conference{zhou2007co,
  author    = {Zhou, D. and Orshanskiy, S.A. and Zha, H. and Giles, C.L.},
  title     = {{Co-ranking authors and documents in a heterogeneous network}},
  booktitle = {7th IEEE International Conference on Data Mining (ICDM07)},
  year      = {2007},
}

@INPROCEEDINGS{Zhou2008Learning,
  author = {Zhou, Ding and Zhu, Shenghuo and Yu, Kai and Song, Xiaodan and Tseng,
	Belle L. and Zha, Hongyuan and Giles, C. Lee},
  title = {Learning multiple graphs for document recommendations},
  booktitle = {WWW '08: Proceeding of the 17th international conference on World
	Wide Web},
  year = {2008},
  pages = {141--150},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1367497.1367517},
  isbn = {978-1-60558-085-2},
  location = {Beijing, China}
}

@InProceedings{Zhou2011Functionala,
  author       = {Zhou, Ke and Yang, Shuang-Hong and Zha, Hongyuan},
  title        = {Functional matrix factorizations for cold-start recommendation},
  booktitle    = {Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval},
  year         = {2011},
  pages        = {315--324},
  organization = {ACM},
  groups       = {Recommender Systems},
}

@ARTICLE{Zhou2010Solving,
  author = {Zhou, Tao and Kuscsik, Zolt{\'a}n and Liu, Jian-Guo and Medo, Mat{\'u}{\v{s}}
	and Wakeling, Joseph Rushton and Zhang, Yi-Cheng},
  title = {Solving the apparent diversity-accuracy dilemma of recommender systems},
  journal = {Proceedings of the National Academy of Sciences},
  year = {2010},
  volume = {107},
  pages = {4511--4515},
  number = {10},
  file = {Zhou2010Solving.pdf:Zhou2010Solving.pdf:PDF},
  publisher = {National Acad Sciences},
  timestamp = {2016.03.10}
}

@ARTICLE{Zhou2009Graph,
  author = {Zhou, Y. and Cheng, H. and Yu, J.X.},
  title = {Graph clustering based on structural/attribute similarities},
  journal = {Proceedings of the VLDB Endowment},
  year = {2009},
  volume = {2},
  pages = {718--729},
  number = {1},
  publisher = {VLDB Endowment}
}

@INPROCEEDINGS{Zhu2008Modeling,
  author = {Zhu, Jianhan and Song, Dawei and R\"{u}ger, Stefan and Huang, Xiangji},
  title = {Modeling document features for expert finding},
  booktitle = {CIKM '08: Proceeding of the 17th ACM conference on Information and
	knowledge management},
  year = {2008},
  pages = {1421--1422},
  address = {New York, NY, USA},
  publisher = {ACM},
  doi = {http://doi.acm.org/10.1145/1458082.1458312},
  isbn = {978-1-59593-991-3},
  location = {Napa Valley, California, USA}
}

@TECHREPORT{Zhu2008Semi,
  author = {Xiaojin Zhu},
  title = {Semi-Supervised Learning Literature Survey},
  year = {2008},
  file = {Zhu2008Semi.pdf:Zhu2008Semi.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.12.06}
}

@InProceedings{Zhu2013Topic,
  author    = {Zhu, Xingwei and Ming, Zhao-Yan and Zhu, Xiaoyan and Chua, Tat-Seng},
  title     = {{Topic hierarchy construction for the organization of multi-source user generated contents}},
  booktitle = {Proceedings of the 36th international ACM SIGIR conference on Research and development in information retrieval - SIGIR '13},
  year      = {2013},
  pages     = {233},
  address   = {New York, New York, USA},
  month     = jul,
  publisher = {ACM Press},
  doi       = {10.1145/2484028.2484032},
  groups    = {Twitter},
  isbn      = {9781450320344},
  keywords  = {information organization,topic hierarchy,topic model,user generated contents},
  url       = {http://dl.acm.org/citation.cfm?id=2484028.2484032},
}

@InProceedings{Zubiaga2012Towards,
  author    = {Zubiaga, Arkaitz and Spina, Damiano and Amig\'{o}, Enrique and Gonzalo, Julio},
  title     = {Towards real-time summarization of scheduled events from twitter streams},
  booktitle = {Proceedings of the 23rd ACM conference on Hypertext and social media},
  year      = {2012},
  series    = {HT '12},
  pages     = {319--320},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {We deal with shrinking the stream of tweets for scheduled
	
	events in real-time, following two steps: (i) sub-event de-
	
	tection, which determines if something new has occurred,
	
	and (ii) tweet selection, which picks a tweet to describe each
	
	sub-event. By comparing summaries in three languages to
	
	live reports by journalists, we show that simple text analy-
	
	sis methods which do not involve external knowledge lead to
	
	summaries that cover 84% of the sub-events on average, and
	
	100% of key types of sub-events (such as goals in soccer)},
  acmid     = {2310053},
  comment   = {sub event detection
weight term by KLD
select one tweet with maximal sum of term weights},
  doi       = {10.1145/2309996.2310053},
  file      = {Zubiaga2012Towards.pdf:Zubiaga2012Towards.pdf:PDF},
  groups    = {Twitter},
  isbn      = {978-1-4503-1335-3},
  keywords  = {events, real-time, summarization, twitter},
  location  = {Milwaukee, Wisconsin, USA},
  numpages  = {2},
  url       = {http://doi.acm.org/10.1145/2309996.2310053},
}

@Book{CNNIC2014survey,
  title     = {中国互联网络发展状况统计报告},
  year      = {2014},
  author    = {中国互联网络信息中心},
  abstract  = {ift},
  file      = {CNNIC2014survey.pdf:CNNIC2014survey.pdf:PDF},
  groups    = {Twitter},
  owner     = {littlep},
  timestamp = {2014.03.01},
}

@BOOK{CNNIC2013search,
  title = {2013年中国网民搜索行为研究报告},
  year = {2013},
  author = {中国互联网络信息中心},
  file = {CNNIC2013search.pdf:CNNIC2013search.pdf:PDF},
  owner = {littlep},
  timestamp = {2014.03.01}
}

@ARTICLE{Meng2013BigData,
  author = {孟小峰 and 慈祥},
  title = {大数据管理: 概念, 技术与挑战},
  journal = {计算机研究与发展},
  year = {2013},
  volume = {50},
  pages = {146--169},
  number = {1},
  file = {Meng2013BigData.pdf:Meng2013BigData.pdf:PDF}
}

@PHDTHESIS{张亮2009推荐系统中协同过滤算法若干问题的研究,
  author = {张亮},
  title = {推荐系统中协同过滤算法若干问题的研究},
  school = {北京邮电大学},
  year = {2009},
  owner = {linchen},
  timestamp = {2011.07.02}
}

@PhdThesis{张子坤2010在线点评平台如何影响人们的消费行为?——一个信息性社会影响的观点,
  author    = {张子坤},
  title     = {在线点评平台如何影响人们的消费行为?——一个信息性社会影响的观点},
  school    = {中国科学技术大学},
  year      = {2010},
  comment   = {最近来自PewIntemet&AmericanLifeProjeet的调查报告指出，81%的美国
	
	在线用户曾经在网络中搜索过有关产品的信息;而71%会从互联网上收集信息
	
	以确保他们能够买到满意的产品(Horrigan2008)。来自中国的一份调查报告访问
	
	调查了640名BBs(BulletinBoardsystem，电子公告板)用户和博客用户(CIC
	
	2009)。这报告指出82%的这些用户会在互联网上搜索产品信息或者产品的评价
	
	价;56.3%会通过这个方法以熟悉相关产品;而58.7%则表明他们的购买决策很
	
	大程度上受到这些网络信息的影响。总的来讲，在线点评日益成为重要的信息
	
	来源，使得消费者能够在购买决策过程中减少不确定性和提高信心。
	
	
	点评信息在多大的程度上、以及以何种机制影响着消费者
	
	
	一方面来讲，由于互联网的双向交互能力，在线点评可以以非常低的成本在世
	
	界范围内传播;而另一方面，由于信息来源的身份不明，在线点评的可信性受
	
	到一定的质疑 (Dellarocas2003)。进一步地，在线点评在网站中的显示方式、组
	
	织方式、分布方式很大程度上受到互联网信息技术 (IT， hiformationTechn01ogies)
	
	的影响。},
  file      = {:在线点评平台如何影响人们的消费行为_一个信息性社会影响的观点.nh:Text},
  owner     = {linchen},
  timestamp = {2010.11.22},
}

@PhdThesis{朱军芳2010网络上集体行为的动力学研究,
  author    = {朱军芳},
  title     = {网络上集体行为的动力学研究},
  school    = {中国科学技术大学},
  year      = {2010},
  keywords  = {复杂网络；同步；意见动力学；时间间隔分布；恐怖主义},
  owner     = {linchen},
  timestamp = {2010.11.16},
}

@ARTICLE{lin2010meshjoin,
  author = {林子雨 and 林琛 and 冯少荣 and 张东站},
  title = {{MESHJOIN*: 实时数据仓库环境下的数据流更新算法}},
  journal = {计算机科学与探索},
  year = {2010},
  volume = {4(10)},
  pages = {927-939}
}

@Article{huang2010efficiently,
  author  = {黄震华 and 向阳 and 林琛},
  title   = {{有效降低分布式 SKYLINE 查询网络传输代价}},
  journal = {电子学报},
  year    = {2010},
  volume  = {38},
  number  = {004},
  pages   = {848--852},
  issn    = {0372-2112},
}

@ARTICLE{huang2009eapsc,
  author = {黄震华 and 向阳 and 林琛},
  title = {{EAPSC: 有效聚类 skyline 对象集方法}},
  journal = {模式识别与人工智能},
  year = {2009},
  pages = {731--734},
  number = {005},
  issn = {1003-6059}
}

@ARTICLE{huang2009skyline,
  author = {黄震华 and 向阳 and 林琛 and 孙圣力},
  title = {{SKYLINE 查询解析}},
  journal = {电子学报},
  year = {2009},
  volume = {37},
  pages = {1639--1645},
  number = {008},
  issn = {0372-2112}
}

@Article{Zhu2013Impact,
  author  = {Zhu, Feng and Zhang, Xiaoquan},
  title   = {Impact of Online Consumer Reviews on Sales: The Moderating Role of Product and Consumer Characteristics},
  journal = {Journal of Marketing A Quarterly Publication of the American Marketing Association},
  year    = {2013},
  volume  = {74},
  number  = {2},
  pages   = {133-148},
  file    = {:Zhu2013Impact.pdf:PDF},
}

@InProceedings{Jamali2011Generalized,
  author    = {Jamali, Mohsen and Huang, Tianle and Ester, Martin},
  title     = {A Generalized Stochastic Block Model for Recommendation in Social Rating Networks},
  booktitle = {Proceedings of the Fifth ACM Conference on Recommender Systems},
  year      = {2011},
  series    = {RecSys '11},
  pages     = {53--60},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {The rapidly increasing availability of online social networks and the well-known effect of social influence have motivated research on social-network based recommenders. Social influence and selection together lead to the formation of communities of like-minded and well connected users. Exploiting the clustering of users and items is one of the most important approaches for model-based recommendation. Users may belong to multiple communities or groups, but only a few clustering algorithms allow clusters to overlap. One of these algorithms is the probabilistic EM clustering method, which assumes that data is generated from a mixture of Gaussian models. The mixed membership stochastic block model (MMB) transfers the idea of EM clustering from conventional, non-relational data to social network data. In this paper, we introduce a generalized stochastic blockmodel (GSBM) that models not only the social relations but also the rating behavior. This model learns the mixed group membership assignments for both users and items in an SRN. GSBM can predict the future behavior of users, both the rating of items and creation of links to other users. We performed experiments on two real life datasets from Epinions.com and Flixster.com, demonstrating the accuracy of the proposed GSBM for rating prediction as well as link prediction.},
  acmid     = {2043946},
  doi       = {10.1145/2043932.2043946},
  isbn      = {978-1-4503-0683-6},
  keywords  = {clustering, link prediction, social recommendation, stochastic block model},
  location  = {Chicago, Illinois, USA},
  numpages  = {8},
}

@InProceedings{Pattuk2015Privacy,
  author    = {E. Pattuk and M. Kantarcioglu and H. Ulusoy and B. Malin},
  title     = {Privacy-aware dynamic feature selection},
  booktitle = {2015 IEEE 31st International Conference on Data Engineering},
  year      = {2015},
  pages     = {78-88},
  month     = {April},
  abstract  = {Big data will enable the development of novel services that enhance a company's market advantage, competition, or productivity. At the same time, the utilization of such a service could disclose sensitive data in the process, which raises significant privacy concerns. To protect individuals, various policies, such as the Code of Fair Information Practices, as well as recent laws require organizations to capture only the minimal amount of data necessary to support a service. While this is a notable goal, choosing the minimal data is a non-trivial process, especially while considering privacy and utility constraints. In this paper, we introduce a technique to minimize sensitive data disclosure by focusing on privacy-aware feature selection. During model deployment, the service provider requests only a subset of the available features from the client, such that it can produce results with maximal confidence, while minimizing its ability to violate a client's privacy. We propose an iterative approach, where the server requests information one feature at a time until the client-specified privacy budget is exhausted. The overall process is dynamic, such that the feature selected at each step depends on the previously selected features and their corresponding values. We demonstrate our technique with three popular classification algorithms and perform an empirical analysis over three real world datasets to illustrate that, in almost all cases, classifiers that select features using our strategy have the same error-rate as state-of-the art static feature selection methods that fail to preserve privacy.},
  file      = {Pattuk2015Privacy.pdf:Pattuk2015Privacy.pdf:PDF},
  issn      = {1063-6382},
  keywords  = {Big Data;data privacy;feature selection;pattern classification;Big Data;classifier;empirical analysis;error-rate;iterative approach;privacy constraints;privacy-aware dynamic feature selection;sensitive data disclosure minimization;utility constraints;Data privacy;Decision trees;Measurement;Niobium;Privacy;Probability;Servers},
  timestamp = {2016-10-11},
}

@Article{Carroll1997Perceived,
  author    = {Carroll, J. Glynn and Andrew, F. Hayes and James Shanahan},
  title     = {Perceived Support for One's Opinions and Willingness to Speak Out: A Meta-Analysis of Survey Studies on the "Spiral of Silence"},
  journal   = {The Public Opinion Quarterly},
  year      = {1997},
  volume    = {61},
  number    = {3},
  pages     = {452-463},
  abstract  = {We report a meta-analysis of survey studies examining the relationship between people's perceptions of support for their opinions and their willingness to express those opinions. Evidence from the analysis indicates the presence of a very small, but statistically significant, relationship between the degree to which a person believes others hold similar opinions and the willingness to express those opinions. Moderator analyses did not reveal significant moderators of this relationship, although the observed correlations were statistically heterogeneous, suggesting at least one undiscovered moderator.},
  issn      = {0033362X, 15375331},
  publisher = {[Oxford University Press, American Association for Public Opinion Research]},
  url       = {http://www.jstor.org/stable/2749581},
}

@Book{Neolle-Neumann1993spiral,
  title     = {The spiral of silence: Public opinion, our social skin.},
  publisher = {University of Chicago Press.},
  year      = {1993},
  author    = {Neolle-Neumann, Elisabeth},
}

@Article{Kennamer1990Self,
  author  = {Kennamer, J. David},
  title   = {Self-Serving BiBias in Perceiving the Opinions of Others},
  journal = {Communication Research},
  year    = {1990},
  volume  = {17},
  pages   = {393-404},
}

@Article{mcdevitt2003spiral,
  author  = {McDevitt, Michael and Kiousis, Spiro and Wahl-Jorgensen, Karin},
  title   = {Spiral of moderation: Opinion expression in computer-mediated discussion},
  journal = {International Journal of Public Opinion Research},
  year    = {2003},
  volume  = {15},
  number  = {4},
  pages   = {454--470},
}

@Article{Biddle1986Recent,
  author    = {B. J. Biddle},
  title     = {Recent Development in Role Theory},
  journal   = {Annual Review of Sociology},
  year      = {1986},
  volume    = {12},
  pages     = {67-92},
  abstract  = {Role theory concerns one of the most important features of social life, characteristic behavior patterns or roles. It explains roles by presuming that persons are members of social positions and hold expectations for their own behaviors and those of other persons. Its vocabulary and concerns are popular among social scientists and practitioners, and role concepts have generated a lot of research. At least five perspectives may be discriminated in recent work within the field: functional, symbolic interactionist, structural, organizational, and cognitive role theory. Much of role research reflects practical concerns and derived concepts, and research on four such concepts is reviewed: consensus, conformity, role conflict, and role taking. Recent developments suggest both centrifugal and integrative forces within the role field. The former reflect differing perspectival commitments of scholars, confusions and disagreements over use of role concepts, and the fact that role theory is used to analyze various forms of social system. The latter reflect the shared, basic concerns of the field and efforts by role theorists to seek a broad version of the field that will accommodate a wide range of interests.},
  issn      = {03600572, 15452115},
  publisher = {Annual Reviews},
  url       = {http://www.jstor.org/stable/2083195},
}

@Book{Duff2012THINK,
  title     = {THINK Social Psychology},
  publisher = {Pearson},
  year      = {2012},
  author    = {Kimberley J. Duff},
  series    = {THINK},
  edition   = {1},
}

@InProceedings{Zhao2013Originator,
  author    = {Zhao, Xin Wayne and Wang, Jinpeng and He, Yulan and Nie, Jian-Yun and Li, Xiaoming},
  title     = {Originator or propagator?: incorporating social role theory into topic models for twitter content analysis},
  booktitle = {Proceedings of the 22nd ACM international conference on Conference on information \&\#38; knowledge management},
  year      = {2013},
  series    = {CIKM '13},
  pages     = {1649--1654},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {A large number of studies have been devoted to modeling the contents and interactions between users on Twitter. In this paper, we propose a method inspired from Social Role Theory (SRT), which assumes that a user behaves differently with different roles in the generation process of Twitter content. We consider the two most distinctive social roles on Twitter: originator and propagator, who respectively posts original messages and retweets or forwards the messages from others. In addition, we also consider role-specific social interactions, especially implicit interactions between users who share some common interests. All the above elements are integrated into a novel regularized topic model. We evaluate the proposed method on real Twitter data. The results show that our method is more effective than the existing ones which do not distinguish social roles.},
  acmid     = {2505599},
  comment   = {regularize the behaviors with same social roles},
  file      = {Zhao2013Originator.pdf:Zhao2013Originator.pdf:PDF},
  isbn      = {978-1-4503-2263-8},
  keywords  = {social role theory, topic modeling, twitter},
  location  = {San Francisco, California, USA},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/2505515.2505599},
}

@InProceedings{Buntain2014Identifying,
  author    = {Buntain, Cody and Golbeck, Jennifer},
  title     = {Identifying Social Roles in Reddit Using Network Structure},
  booktitle = {Proceedings of the 23rd International Conference on World Wide Web},
  year      = {2014},
  series    = {WWW '14 Companion},
  pages     = {615--620},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {As social networks and the user-generated content that populates them continue to grow in prevalence, size, and influence, understanding how users interact and produce this content becomes increasingly important. Insight into these community dynamics could prove valuable for measuring content trust, providing role-based group recommendations, or evaluating group stability and growth. To this end, we explore user posting behavior on reddit, a large social networking site comprised of many sub-communities in which a user may participate simultaneously. We demonstrate that the well-known "answer-person" role is present in the reddit community, provide an exposition on an automated method for identifying this role based solely on user interactions (foregoing expensive content analysis), and show that users rarely exhibit significant participation in more than one communities.},
  acmid     = {2579231},
  comment   = {features->role classification
answer person, non-answer person},
  file      = {Buntain2014Identifying.pdf:Buntain2014Identifying.pdf:PDF},
  isbn      = {978-1-4503-2745-9},
  keywords  = {online communities, social networks, social roles},
  location  = {Seoul, Korea},
  numpages  = {6},
}

@InProceedings{Zhao2013Inferring,
  author    = {Zhao, Yuchen and Wang, Guan and Yu, Philip S. and Liu, Shaobo and Zhang, Simon},
  title     = {Inferring Social Roles and Statuses in Social Networks},
  booktitle = {Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year      = {2013},
  series    = {KDD '13},
  pages     = {695--703},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Users in online social networks play a variety of social roles and statuses. For example, users in Twitter can be represented as advertiser, content contributor, information receiver, etc; users in Linkedin can be in different professional roles, such as engineer, salesperson and recruiter. Previous research work mainly focuses on using categorical and textual information to predict the attributes of users. However, it cannot be applied to a large number of users in real social networks, since much of such information is missing, outdated and non-standard. In this paper, we investigate the social roles and statuses that people act in online social networks in the perspective of network structures, since the uniqueness of social networks is connecting people. We quantitatively analyze a number of key social principles and theories that correlate with social roles and statuses. We systematically study how the network characteristics reflect the social situations of users in an online society. We discover patterns of homophily, the tendency of users to connect with users with similar social roles and statuses. In addition, we observe that different factors in social theories influence the social role/status of an individual user to various extent, since these social principles represent different aspects of the network. We then introduce an optimization framework based on Factor Conditioning Symmetry, and we propose a probabilistic model to integrate the optimization framework on local structural information as well as network influence to infer the unknown social roles and statuses of online users. We will present experiment results to show the effectiveness of the inference.},
  acmid     = {2487597},
  file      = {Zhao2013Inferring.pdf:Zhao2013Inferring.pdf:PDF},
  isbn      = {978-1-4503-2174-7},
  keywords  = {linkedin, network inference, social networks, social role, social status, user modeling},
  location  = {Chicago, Illinois, USA},
  numpages  = {9},
}

@InProceedings{Liu2015Convolutional,
  author    = {Liu, Qiang and Yu, Feng and Wu, Shu and Wang, Liang},
  title     = {A Convolutional Click Prediction Model},
  booktitle = {Proceedings of the 24th ACM International on Conference on Information and Knowledge Management},
  year      = {2015},
  series    = {CIKM '15},
  pages     = {1743--1746},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {The explosion in online advertisement urges to better estimate the click prediction of ads. For click prediction on single ad impression, we have access to pairwise relevance among elements in an impression, but not to global interaction among key features of elements. Moreover, the existing method on sequential click prediction treats propagation unchangeable for different time intervals. In this work, we propose a novel model, Convolutional Click Prediction Model (CCPM), based on convolution neural network. CCPM can extract local-global key features from an input instance with varied elements, which can be implemented for not only single ad impression but also sequential ad impression. Experiment results on two public large-scale datasets indicate that CCPM is effective on click prediction.},
  acmid     = {2806603},
  doi       = {10.1145/2806416.2806603},
  isbn      = {978-1-4503-3794-6},
  keywords  = {click prediction, convolution neural network},
  location  = {Melbourne, Australia},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/2806416.2806603},
}

@Article{Yu2017Decoding,
  author     = {Yu, Hai-Tao and Jatowt, Adam and Blanco, Roi and Joho, Hideo and Jose, Joemon M.},
  title      = {Decoding Multi-click Search Behavior Based on Marginal Utility},
  journal    = {Inf. Retr.},
  year       = {2017},
  volume     = {20},
  number     = {1},
  pages      = {25--52},
  month      = feb,
  abstract   = {Query logs contain rich feedback information from users interacting with search engines. Therefore, various click models have been developed to interpret users' search behavior and to extract useful knowledge from query logs. However, most existing models are not designed to consider novelty bias in click behavior. The underlying hypothesis behind this paper is that given the previously clicked documents, a user tends to choose documents which provide novel relevant information to satisfy her information need, rather than redundant relevant information. Moreover, the prior click models have been mainly tested on frequently occurring queries, hence, leaving a large proportion of sparse queries uncovered. In this paper, we propose to predict users' click behavior from the perspective of utility theory (i.e., utility and marginal utility). In particular, as a complement to the examination hypothesis, we introduce a new hypothesis called marginal utility hypothesis to characterize the effect of novelty bias on users' click behavior by exploring the semantic divergence among documents in a result list. Moreover, to cope with sparse or unseen queries that have not been observed in the training set, we use a set of descriptive features to quantify the probability of a document being relevant and probability of a document providing marginally (novel) useful information. Finally, a series of experiments are conducted on a real-world data set to validate the effectiveness of the proposed methods. The experimental results verify the effectiveness of interpreting users' click behavior based on the marginal utility hypothesis, especially when query sessions contain sparse queries or unseen query-document pairs.},
  acmid      = {3051655},
  address    = {Hingham, MA, USA},
  doi        = {10.1007/s10791-016-9289-z},
  issn       = {1386-4564},
  issue_date = {February 2017},
  keywords   = {Click model, Marginal utility, Novelty bias, Query session},
  numpages   = {28},
  publisher  = {Kluwer Academic Publishers},
  url        = {https://doi.org/10.1007/s10791-016-9289-z},
}

@InProceedings{Ben-Shimon2015RecSys,
  author    = {Ben-Shimon, David and Tsikinovsky, Alexander and Friedmann, Michael and Shapira, Bracha and Rokach, Lior and Hoerle, Johannes},
  title     = {RecSys Challenge 2015 and the YOOCHOOSE Dataset},
  booktitle = {Proceedings of the 9th ACM Conference on Recommender Systems},
  year      = {2015},
  series    = {RecSys '15},
  pages     = {357--358},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {The 2015 ACM Recommender Systems Challenge offered the opportunity to work on a large-scale e-commerce dataset from a big retailer in Europe which is accepting recommender system as a service from YOOCHOOSE. Participants tackled the problem of predicting what items a user intends to purchase, if any, given a click sequence performed during an activity session on the e-commerce website. The challenge ran for seven months and was very successful, attracting 850 teams from 49 countries which submitted a total of 5,437 solutions. The winners of the challenge scored approximately 50% of the maximum score, which we considered as an impressive achievement. In this paper we provide a brief overview of the challenge and its results.},
  acmid     = {2798723},
  doi       = {10.1145/2792838.2798723},
  isbn      = {978-1-4503-3692-5},
  keywords  = {e-commerce, recommender systems, recsys challenge 2015, yoochoose},
  location  = {Vienna, Austria},
  numpages  = {2},
  url       = {http://doi.acm.org/10.1145/2792838.2798723},
}

@Book{Engel1986Consumer,
  title     = {Consumer Behavior},
  publisher = {The Dryden Press},
  year      = {1986},
  author    = {James F. Engel and Roger D. Blackwell and Paul W. Miniard},
}

@Article{Park1976Effect,
  author    = {C. Whan Park},
  title     = {The Effect of Individual and Situation-Related Factors on Consumer Selection of Judgmental Models},
  journal   = {Journal of Marketing Research},
  year      = {1976},
  volume    = {13},
  number    = {2},
  pages     = {144-151},
  abstract  = {The study reported tests the hypotheses that the consumer's use of a specific judgmental model in evaluating a product is a function of prior familiarity and/or product complexity. The results indicate that the two factors influence the respondent's selection of judgmental models.},
  issn      = {00222437},
  publisher = {American Marketing Association},
  url       = {http://www.jstor.org/stable/3150848},
}

@InProceedings{Frolov2016Fifty,
  author    = {Frolov, Evgeny and Oseledets, Ivan},
  title     = {Fifty Shades of Ratings: How to Benefit from a Negative Feedback in Top-N Recommendations Tasks},
  booktitle = {Proceedings of the 10th ACM Conference on Recommender Systems},
  year      = {2016},
  series    = {RecSys '16},
  pages     = {91--98},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Conventional collaborative filtering techniques treat a top-n recommendations problem as a task of generating a list of the most relevant items. This formulation, however, disregards an opposite -- avoiding recommendations with completely irrelevant items. Due to that bias, standard algorithms, as well as commonly used evaluation metrics, become insensitive to negative feedback. In order to resolve this problem we propose to treat user feedback as a categorical variable and model it with users and items in a ternary way. We employ a third-order tensor factorization technique and implement a higher order folding-in method to support online recommendations. The method is equally sensitive to entire spectrum of user ratings and is able to accurately predict relevant items even from a negative only feedback. Our method may partially eliminate the need for complicated rating elicitation process as it provides means for personalized recommendations from the very beginning of an interaction with a recommender system. We also propose a modification of standard metrics which helps to reveal unwanted biases and account for sensitivity to a negative feedback. Our model achieves state-of-the-art quality in standard recommendation tasks while significantly outperforming other methods in the cold-start "no-positive-feedback" scenarios.},
  acmid     = {2959170},
  doi       = {10.1145/2959100.2959170},
  isbn      = {978-1-4503-4035-9},
  keywords  = {cold-start, collaborative filtering, explicit feedback, recommender systems, tensor factorization},
  location  = {Boston, Massachusetts, USA},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/2959100.2959170},
}

@Article{Pareto1991Manuale,
  author  = {Pareto, Vilfredo Rodr{\'\i}guez V{\'a}zquez and others},
  title   = {Manuale di economia politica con una itroduzione alla scienza sociale. Manual de econom{\'\i}a pol{\'\i}tica: con una introducci{\'o}n a la ciencia social y compendio de econometr{\'\i}a},
  journal = {Econom{\'\i}a pol{\'\i}tica y ciencias sociales;},
  year    = {1991},
}

@Article{Simon1959Theories,
  author    = {Simon, Herbert A},
  title     = {Theories of decision-making in economics and behavioral science},
  journal   = {The American economic review},
  year      = {1959},
  volume    = {49},
  number    = {3},
  pages     = {253--283},
  publisher = {JSTOR},
}

@InProceedings{Zhang2008Avoiding,
  author    = {Zhang, Mi and Hurley, Neil},
  title     = {Avoiding Monotony: Improving the Diversity of Recommendation Lists},
  booktitle = {Proceedings of the 2008 ACM Conference on Recommender Systems},
  year      = {2008},
  series    = {RecSys '08},
  pages     = {123--130},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {1454030},
  doi       = {10.1145/1454008.1454030},
  isbn      = {978-1-60558-093-7},
  keywords  = {accuracy, diversity, metrics, novelty, recommender system},
  location  = {Lausanne, Switzerland},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/1454008.1454030},
}

@InProceedings{Hua2016Automatical,
  author    = {Hua, Ting and Zhang, Xuchao and Wang, Wei and Lu, Chang-Tien and Ramakrishnan, Naren},
  title     = {Automatical Storyline Generation with Help from Twitter},
  booktitle = {Proceedings of the 25th ACM International on Conference on Information and Knowledge Management},
  year      = {2016},
  series    = {CIKM '16},
  pages     = {2383--2388},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Storyline detection aims to connect seemly irrelevant single documents
into meaningful chains, which provides opportunities for
understanding how events evolve over time and what triggers such
evolutions. Most previous work generated the storylines through
unsupervised methods that can hardly reveal underlying factors driving
the evolution process. This paper introduces a Bayesian model
to generate storylines from massive documents and infer the corresponding
hidden relations and topics. In addition, our model is the
first attempt that utilizes Twitter data as human input to “supervise”
the generation of storylines. Through extensive experiments, we
demonstrate our proposed model can achieve significant improvement
over baseline methods and can be used to discover interesting
patterns for real world cases},
  acmid     = {2983698},
  comment   = {short paper
storyline is generated from tweets + embeded links (articles)
model: ASG (topic model, background model)
assumption: different storylines can share common event types, and events can be viewed as various combinations of topics. 
uses the Twitter hashtags created by users as labels to “supervise” story generation in long news reports
weakness: what is a storyline?},
  doi       = {10.1145/2983323.2983698},
  file      = {Hua2016Automatical.pdf:Hua2016Automatical.pdf:PDF},
  isbn      = {978-1-4503-4073-1},
  keywords  = {storyline, topic modeling, twitter},
  location  = {Indianapolis, Indiana, USA},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/2983323.2983698},
}

@InProceedings{Rudra2015Extracting,
  author    = {Rudra, Koustav and Ghosh, Subham and Ganguly, Niloy and Goyal, Pawan and Ghosh, Saptarshi},
  title     = {Extracting Situational Information from Microblogs During Disaster Events: A Classification-Summarization Approach},
  booktitle = {Proceedings of the 24th ACM International on Conference on Information and Knowledge Management},
  year      = {2015},
  series    = {CIKM '15},
  pages     = {583--592},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Microblogging sites like Twitter have become important sources of real-time information during disaster events. A significant amount of valuable situational information is available in these sites; however, this information is immersed among hundreds of thousands of tweets, mostly containing sentiments and opinion of the masses, that are posted during such events. To effectively utilize microblogging sites during disaster events, it is necessary to (i) extract the situational information from among the large amounts of sentiment and opinion, and (ii) summarize the situational information, to help decision-making processes when time is critical. In this paper, we develop a novel framework which first classifies tweets to extract situational information, and then summarizes the information. The proposed framework takes into consideration the typicalities pertaining to disaster events where (i) the same tweet often contains a mixture of situational and non-situational information, and (ii) certain numerical information, such as number of casualties, vary rapidly with time, and thus achieves superior performance compared to state-of-the-art tweet summarization approaches},
  acmid     = {2806485},
  comment   = {classification bag of words, cross domain, svm
pre-processing very important
twitter specific pos,abbreviation expansion, specific end markers
a small fraction contributes to summarizing ,just offer all versions},
  doi       = {10.1145/2806416.2806485},
  file      = {Rudra2015Extracting.pdf:Rudra2015Extracting.pdf:PDF},
  isbn      = {978-1-4503-3794-6},
  keywords  = {classification, disaster events, situational information, summarization, twitter},
  location  = {Melbourne, Australia},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2806416.2806485},
}

@InProceedings{Rudra2016Summarizing,
  author    = {Rudra, Koustav and Banerjee, Siddhartha and Ganguly, Niloy and Goyal, Pawan and Imran, Muhammad and Mitra, Prasenjit},
  title     = {Summarizing Situational Tweets in Crisis Scenario},
  booktitle = {Proceedings of the 27th ACM Conference on Hypertext and Social Media},
  year      = {2016},
  series    = {HT '16},
  pages     = {137--147},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {During mass convergence events such as natural disasters, microblogging platforms like Twitter are widely used by affected people to post situational awareness messages. These crisis-related messages disperse among multiple categories like infrastructure damage, information about missing, injured, and dead people etc. The challenge here is to extract important situational updates from these messages, assign them appropriate informational categories, and finally summarize big trove of information in each category. In this paper, we propose a novel framework which first assigns tweets into different situational classes and then summarize those tweets. In the summarization phase, we propose a two stage summarization framework which first extracts a set of important tweets from the whole set of information through an Integer-linear programming (ILP) based optimization technique and then follows a word graph and content word based abstractive summarization technique to produce the final summary. Our method is time and memory efficient and outperforms the baseline in terms of quality, coverage of events, locations et al., effectiveness, and utility in disaster scenarios.},
  acmid     = {2914600},
  doi       = {10.1145/2914586.2914600},
  file      = {Rudra2016Summarizing.pdf:Rudra2016Summarizing.pdf:PDF},
  isbn      = {978-1-4503-4247-6},
  keywords  = {classification, disaster events, situational information, summarization, twitter},
  location  = {Halifax, Nova Scotia, Canada},
  numpages  = {11},
  url       = {http://doi.acm.org/10.1145/2914586.2914600},
}

@InProceedings{Chin2017TOTEM,
  author    = {Chin, Jin Yao and Bhowmick, Sourav S. and Jatowt, Adam},
  title     = {TOTEM: Personal Tweets Summarization on Mobile Devices},
  booktitle = {Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year      = {2017},
  series    = {SIGIR '17},
  pages     = {1305--1308},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Tweets summarization aims to find a group of representative tweets for a specific topic. In recent times, there have been several research efforts toward devising a variety of techniques to summarize tweets in Twitter. However, these techniques are either not personal (i.e., consider only tweets in the timeline of a specific user) or are too expensive to be realized on a mobile device. Given that 80% of active Twitter users access the site on mobile devices, in this demonstration we present a lightweight, personalized, on-demand, topic modeling-based tweets summarization engine called TOTEM, designed for such devices. Specifically, TOTEM summarizes most recent tweets on a user's timeline and enables her to visualize and navigate representative topics and associated tweets in a user-friendly tap-and-swipe manner.},
  acmid     = {3084138},
  doi       = {10.1145/3077136.3084138},
  isbn      = {978-1-4503-5022-8},
  keywords  = {mobile device, personal, summarization, topic modeling, tweets},
  location  = {Shinjuku, Tokyo, Japan},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/3077136.3084138},
}

@InProceedings{Wei2015Gibberish,
  author    = {Wei, Zhongyu and Gao, Wei},
  title     = {Gibberish, Assistant, or Master?: Using Tweets Linking to News for Extractive Single-Document Summarization},
  booktitle = {Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year      = {2015},
  series    = {SIGIR '15},
  pages     = {1003--1006},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2767835},
  doi       = {10.1145/2766462.2767835},
  isbn      = {978-1-4503-3621-5},
  keywords  = {highlights, single-document summarization, tweets},
  location  = {Santiago, Chile},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/2766462.2767835},
}

@InProceedings{Liu2016LEDS,
  author    = {Liu, Zhi and Huang, Yan and Trampier, Joshua R.},
  title     = {LEDS: Local Event Discovery and Summarization from Tweets},
  booktitle = {Proceedings of the 24th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems},
  year      = {2016},
  series    = {GIS '16},
  pages     = {53:1--53:4},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Twitter is one of the most popular social media platforms where people can share their opinions, thoughts, interests, and whereabouts. In this work, we propose a Local Event Discovery and Summarization (LEDS) framework to detect local events from Twitter. Many existing algorithms for event detection focus on larger-scale events and are not sensitive to smaller-scale local events. Most of the local events detected by these methods are major events such as important sports, shows, or large natural disasters. In this paper, we propose the LEDS framework to detect both larger and smaller events. LEDS contains three key steps: 1) Detecting possible event related terms by monitoring abnormal distribution in different locations and times; 2) Clustering tweets based on their key terms, time, and location distribution; and 3) Extracting descriptions including time, location, and key sentences of local events from clusters. The framework is evaluated on a real world Twitter dataset with more than 60 million tweets. The results show that compared with previous work, LEDS can detect smaller-scale and greater variety of local events. More than 43 percent of detected local events do not have an official organizer, cannot be seen on news media, and only attract the attention from a small group of people.},
  acmid     = {2996928},
  articleno = {53},
  doi       = {10.1145/2996913.2996928},
  isbn      = {978-1-4503-4589-7},
  keywords  = {event summarization, local event detection, tweets},
  location  = {Burlingame, California},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/2996913.2996928},
}

@InProceedings{Gillani2017Post,
  author    = {Gillani, Mehreen and Ilyas, Muhammad U. and Saleh, Saad and Alowibdi, Jalal S. and Aljohani, Naif and Alotaibi, Fahad S.},
  title     = {Post Summarization of Microblogs of Sporting Events},
  booktitle = {Proceedings of the 26th International Conference on World Wide Web Companion},
  year      = {2017},
  series    = {WWW '17 Companion},
  pages     = {59--68},
  address   = {Republic and Canton of Geneva, Switzerland},
  publisher = {International World Wide Web Conferences Steering Committee},
  abstract  = {Every day 645 million Twitter users generate approximately 58 million tweets. This motivates the question if it is possible to generate a summary of events from this rich set of tweets only. Key challenges in post summarization from microblog posts include circumnavigating spam and conversational posts. In this study, we present a novel technique called lexi-temporal clustering (LTC), which identifies key events. LTC uses k-means clustering and we explore the use of various distance measures for clustering using Euclidean, cosine similarity and Manhattan distance. We collected three original data sets consisting of Twitter microblog posts covering sporting events, consisting of a cricket and two football matches. The match summaries generated by LTC were compared against standard summaries taken from sports sections of various news outlets, which yielded up to 81% precision, 58% recall and 62% F-measure on different data sets. In addition, we also report results of all three variants of the recall-oriented understudy for gisting evaluation (ROUGE) software, a tool which compares and scores automatically generated summaries against standard summaries.},
  acmid     = {3054146},
  doi       = {10.1145/3041021.3054146},
  isbn      = {978-1-4503-4914-7},
  keywords  = {summarization, twitter},
  location  = {Perth, Australia},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3041021.3054146},
}

@InProceedings{Rakesh2013Location,
  author    = {Rakesh, Vineeth and Reddy, Chandan K. and Singh, Dilpreet and MS, Ramachandran},
  title     = {Location-specific Tweet Detection and Topic Summarization in Twitter},
  booktitle = {Proceedings of the 2013 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
  year      = {2013},
  series    = {ASONAM '13},
  pages     = {1441--1444},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Automatic detection of tweets that provide Location-specific information will be extremely useful in conveying geo-location based knowledge to the users. However, there is a significant challenge in retrieving such tweets due to the sparsity of geo-tag information, the short textual nature of tweets, and the lack of pre-defined set of topics. In this paper, we develop a novel framework to identify and summarize tweets that are specific to a location. First, we propose a weighting scheme called Location Centric Word Co-occurrence (LCWC) that uses the content of the tweets and the network information of the twitterers to identify tweets that are location-specific. We evaluate the proposed model using a set of annotated tweets and compare the performance with other weighting schemes studied in the literature. This paper reports three key findings: (a) top trending tweets from a location are poor descriptors of location-specific tweets, (b) ranking tweets purely based on users' geo-location cannot ascertain the location specificity of tweets, and (c) users' network information plays an important role in determining the location-specific characteristics of the tweets. Finally, we train a topic model based on Latent Dirichlet Allocation (LDA) using a large collection of local news database and tweet-based Urls to predict the topics from the location-specific tweets and present them using an interactive web-based interface.},
  acmid     = {2492583},
  doi       = {10.1145/2492517.2492583},
  isbn      = {978-1-4503-2240-9},
  location  = {Niagara, Ontario, Canada},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/2492517.2492583},
}

@Article{Xia2016Polarity,
  author   = {Rui Xia and Feng Xu and Jianfei Yu and Yong Qi and Erik Cambria},
  title    = {Polarity shift detection, elimination and ensemble: A three-stage model for document-level sentiment analysis},
  journal  = {Information Processing \& Management},
  year     = {2016},
  volume   = {52},
  number   = {1},
  pages    = {36 - 45},
  issn     = {0306-4573},
  note     = {Emotion and Sentiment in Social and Expressive Media},
  abstract = {The polarity shift problem is a major factor that affects classification performance of machine-learning-based sentiment analysis systems. In this paper, we propose a three-stage cascade model to address the polarity shift problem in the context of document-level sentiment classification. We first split each document into a set of subsentences and build a hybrid model that employs rules and statistical methods to detect explicit and implicit polarity shifts, respectively. Secondly, we propose a polarity shift elimination method, to remove polarity shift in negations. Finally, we train base classifiers on training subsets divided by different types of polarity shifts, and use a weighted combination of the component classifiers for sentiment classification. The results on a range of experiments illustrate that our approach significantly outperforms several alternative methods for polarity shift detection and elimination.},
  comment  = {polarity shift
rule based
hybrid

opinion inconsistency},
  doi      = {https://doi.org/10.1016/j.ipm.2015.04.003},
  keywords = {Sentiment analysis, Sentiment classification, Polarity shift},
  url      = {http://www.sciencedirect.com/science/article/pii/S0306457315000485},
}

@Article{Otaibi2017Machine,
  author   = {J. A. Otaibi and Z. Safi and A. Hassaïne and F. Islam and A. Jaouansis},
  title    = {Machine Learning and Conceptual Reasoning for Inconsistency Detection},
  journal  = {IEEE Access},
  year     = {2017},
  volume   = {5},
  pages    = {338-346},
  abstract = {This paper focuses on detecting inconsistencies within text corpora. It is a very interesting area with many applications. Most existing methods deal with this problem using complicated textual analysis, which is known for not being accurate enough. We propose a new methodology that consists of two steps, the first one being a machine learning step that performs multilevel text categorization. The second one applies conceptual reasoning on the predicted categories in order to detect inconsistencies. This paper has been validated on a set of Islamic advisory opinions (also known as fatwas). This domain is gaining a large interest with users continuously checking the authenticity and relevance of such content. The results show that our method is very accurate and can complement existing methods using the linguistic analysis.},
  comment  = {define inconsistency category -> judgement different
keyword extraction and classification},
  doi      = {10.1109/ACCESS.2016.2642402},
  keywords = {inference mechanisms;learning (artificial intelligence);planning (artificial intelligence);text analysis;Islamic advisory opinions;complicated textual analysis;conceptual reasoning;fatwas;inconsistency detection;linguistic analysis;machine learning;multilevel text categorization;text corpora;Cognition;Context;Density measurement;Natural language processing;Ontologies;Pragmatics;Text categorization;Information extraction;conceptual reasoning;hyper rectangular decomposition;inconsistency detection;text categorization},
}

@Article{Aa2017Comparing,
  author   = {Han van der Aa and Henrik Leopold and Hajo A. Reijers},
  title    = {Comparing textual descriptions to process models – The automatic detection of inconsistencies},
  journal  = {Information Systems},
  year     = {2017},
  volume   = {64},
  pages    = {447 - 460},
  issn     = {0306-4379},
  abstract = {Many organizations maintain textual process descriptions alongside graphical process models. The purpose is to make process information accessible to various stakeholders, including those who are not familiar with reading and interpreting the complex execution logic of process models. Despite this merit, there is a clear risk that model and text become misaligned when changes are not applied to both descriptions consistently. For organizations with hundreds of different processes, the effort required to identify and clear up such conflicts is considerable. To support organizations in keeping their process descriptions consistent, we present an approach to automatically identify inconsistencies between a process model and a corresponding textual description. Our approach detects cases where the two process representations describe activities in different orders and detect process model activities not contained in the textual description. A quantitative evaluation with 53 real-life model-text pairs demonstrates that our approach accurately identifies inconsistencies between model and text.},
  comment  = {process graph v.s. text descriptions inconsistency},
  doi      = {https://doi.org/10.1016/j.is.2016.07.010},
  keywords = {Business process management, Inconsistency detection, Compliance checking, Business process modeling, Natural language processing, Matching},
  url      = {http://www.sciencedirect.com/science/article/pii/S0306437915301666},
}

@Article{Pariyar2014Inconsistency,
  author  = {Pariyar, Amit and Murakami, Yohei and Lin, Donghui and Ishida, Toru},
  title   = {Inconsistency Detection in Multilingual Knowledge Sharing},
  journal = {Journal of Information \&amp; Knowledge Management},
  year    = {2014},
  volume  = {13},
  number  = {04},
  pages   = {1450033},
  doi     = {10.1142/S0219649214500336},
  eprint  = {https://www.worldscientific.com/doi/pdf/10.1142/S0219649214500336},
  url     = {https://www.worldscientific.com/doi/abs/10.1142/S0219649214500336},
}

@InProceedings{Wu2012Probase,
  author    = {Wu, Wentao and Li, Hongsong and Wang, Haixun and Zhu, Kenny Q.},
  title     = {Probase: A Probabilistic Taxonomy for Text Understanding},
  booktitle = {Proceedings of the 2012 ACM SIGMOD International Conference on Management of Data},
  year      = {2012},
  series    = {SIGMOD '12},
  pages     = {481--492},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Knowledge is indispensable to understanding. The ongoing information explosion highlights the need to enable machines to better understand electronic text in human language. Much work has been devoted to creating universal ontologies or taxonomies for this purpose. However, none of the existing ontologies has the needed depth and breadth for universal understanding. In this paper, we present a universal, probabilistic taxonomy that is more comprehensive than any existing ones. It contains 2.7 million concepts harnessed automatically from a corpus of 1.68 billion web pages. Unlike traditional taxonomies that treat knowledge as black and white, it uses probabilities to model inconsistent, ambiguous and uncertain information it contains. We present details of how the taxonomy is constructed, its probabilistic modeling, and its potential applications in text understanding.},
  acmid     = {2213891},
  comment   = {tolerate inconsistency
noise or 
A claim E is false iff every piece of evidence in s1, · · · , sn is fals},
  doi       = {10.1145/2213836.2213891},
  isbn      = {978-1-4503-1247-9},
  keywords  = {knowledgebase, taxonomy, text understanding},
  location  = {Scottsdale, Arizona, USA},
  numpages  = {12},
  url       = {http://doi.acm.org/10.1145/2213836.2213891},
}

@InProceedings{Ho2010Word,
  author    = {Ho, Chukfong and Murad, Masrah Azrifah Azmi and Kadir, Rabiah Abdul and Doraisamy, Shyamala C.},
  title     = {Word Sense Disambiguation-based Sentence Similarity},
  booktitle = {Proceedings of the 23rd International Conference on Computational Linguistics: Posters},
  year      = {2010},
  series    = {COLING '10},
  pages     = {418--426},
  address   = {Stroudsburg, PA, USA},
  publisher = {Association for Computational Linguistics},
  abstract  = {Previous works tend to compute the similarity between two sentences based on the comparison of their nearest meanings. However, the nearest meanings do not always represent their actual meanings. This paper presents a method which computes the similarity between two sentences based on a comparison of their actual meanings. This is achieved by transforming an existing most-outstanding corpus-based measure into a knowledge-based measure, which is then integrated with word sense disambiguation. The experimental results on a standard data set show that the proposed method outperforms the baseline and the improvement achieved is statistically significant at 0.025 levels.},
  acmid     = {1944614},
  file      = {Ho2010Word.pdf:Ho2010Word.pdf:PDF},
  location  = {Beijing, China},
  numpages  = {9},
  url       = {http://dl.acm.org/citation.cfm?id=1944566.1944614},
}

@InProceedings{Guo2012Modeling,
  author    = {Guo, Weiwei and Diab, Mona},
  title     = {Modeling Sentences in the Latent Space},
  booktitle = {Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers - Volume 1},
  year      = {2012},
  series    = {ACL '12},
  pages     = {864--872},
  address   = {Stroudsburg, PA, USA},
  publisher = {Association for Computational Linguistics},
  abstract  = {Sentence Similarity is the process of computing a similarity score between two sentences. Previous sentence similarity work finds that latent semantics approaches to the problem do not perform well due to insufficient information in single sentences. In this paper, we show that by carefully handling words that are not in the sentences (missing words), we can train a reliable latent variable model on sentences. In the process, we propose a new evaluation framework for sentence similarity: Concept Definition Retrieval. The new framework allows for large scale tuning and testing of Sentence Similarity models. Experiments on the new task and previous data sets show significant improvement of our model over baselines and other traditional latent variable models. Our results indicate comparable and even better performance than current state of the art systems addressing the problem of sentence similarity.},
  acmid     = {2390644},
  file      = {Guo2012Modeling.pdf:Guo2012Modeling.pdf:PDF},
  location  = {Jeju Island, Korea},
  numpages  = {9},
  url       = {http://dl.acm.org/citation.cfm?id=2390524.2390644},
}

@InProceedings{Nicosia2017Accurate,
  author    = {Nicosia, Massimo and Moschitti, Alessandro},
  title     = {Accurate Sentence Matching with Hybrid Siamese Networks},
  booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
  year      = {2017},
  series    = {CIKM '17},
  pages     = {2235--2238},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Recent neural network approaches to sentence matching compute the probability of two sentences being similar by minimizing a logistic loss. In this paper, we learn sentence representations by means of a siamese network, which: (i) uses encoders that share parameters; and (ii) enables the comparison between two sentences in terms of their euclidean distance, by minimizing a contrastive loss. Moreover, we add a multilayer perceptron in the architecture to simultaneously optimize the contrastive and the logistic losses. This way, our network can exploit a more informative feedback, given by the logistic loss, which is also quantified by the distance that the two sentences have according to their representation in the euclidean space. We show that jointly minimizing the two losses yields higher accuracy than minimizing them independently. We verify this finding by evaluating several baseline architectures in two sentence matching tasks: question paraphrasing and textual entailment recognition. Our network approaches the state of the art, while being much simpler and faster to train, and with less parameters than its competitors.},
  acmid     = {3133156},
  doi       = {10.1145/3132847.3133156},
  isbn      = {978-1-4503-4918-5},
  keywords  = {joint loss, natural language processing, neural networks, question similarity, sentence matching, sentence similarity, siamese network},
  location  = {Singapore, Singapore},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/3132847.3133156},
}

@InProceedings{Zheng2014Deviation,
  author    = {Zheng, Yong and Mobasher, Bamshad and Burke, Robin},
  title     = {Deviation-Based Contextual SLIM Recommenders},
  booktitle = {Proceedings of the 23rd ACM International Conference on Conference on Information and Knowledge Management},
  year      = {2014},
  series    = {CIKM '14},
  pages     = {271--280},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Context-aware recommender systems (CARS) help improve the effectiveness of recommendations by adapting to users' preferences in different contextual situations. One approach to CARS that has been shown to be particularly effective is Context-Aware Matrix Factorization (CAMF). CAMF incorporates contextual dependencies into the standard matrix factorization (MF) process, where users and items are represented as collections of weights over various latent factors. In this paper, we introduce another CARS approach based on an extension of matrix factorization, namely, the Sparse Linear Method (SLIM). We develop a family of deviation-based contextual SLIM (CSLIM) recommendation algorithms by learning rating deviations in different contextual conditions. Our CSLIM approach is better at explaining the underlying reasons behind contextual recommendations, and our experimental evaluations over five context-aware data sets demonstrate that these CSLIM algorithms outperform the state-of-the-art CARS algorithms in the top-N recommendation task. We also discuss the criteria for selecting the appropriate CSLIM algorithm in advance based on the underlying characteristics of the data.},
  acmid     = {2661987},
  comment   = {\hat{S_{i,j,c}}=\sum_h \hat{R_{i,h,c}} W_{h,j} 


\hat{R_{i,j,c}}=R_{i,j} + \Sum_l D_{j,l} c_l

min_{D,W} R-\hat{S}


},
  doi       = {10.1145/2661829.2661987},
  file      = {Zheng2014Deviation.pdf:Zheng2014Deviation.pdf:PDF},
  isbn      = {978-1-4503-2598-1},
  keywords  = {context, context-aware recommendation, contextual, matrix factorization, recommendation, slim},
  location  = {Shanghai, China},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2661829.2661987},
}

@InProceedings{Zheng2014CSLIM,
  author    = {Zheng, Yong and Mobasher, Bamshad and Burke, Robin},
  title     = {CSLIM: Contextual SLIM Recommendation Algorithms},
  booktitle = {Proceedings of the 8th ACM Conference on Recommender Systems},
  year      = {2014},
  series    = {RecSys '14},
  pages     = {301--304},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Context-aware recommender systems (CARS) take contextual conditions into account when providing item recommendations. In recent years, context-aware matrix factorization (CAMF) has emerged as an extension of the matrix factorization technique that also incorporates contextual conditions. In this paper, we introduce another matrix factorization approach for contextual recommendations, the contextual SLIM (CSLIM) recommendation approach. It is derived from the sparse linear method (SLIM) which was designed for Top-N recommendations in traditional recommender systems. Based on the experimental evaluations over several context-aware data sets, we demonstrate that CLSIM can be an effective approach for context-aware recommendations, in many cases outperforming state-of-the-art CARS algorithms in the Top-N recommendation task.},
  acmid     = {2645756},
  comment   = {CSLIM-I: aggregate over the same user

CSLIM-U: aggregate over the same item

CSLIM-C: },
  doi       = {10.1145/2645710.2645756},
  isbn      = {978-1-4503-2668-1},
  keywords  = {context, context-aware recommendation, matrix factorization, recommendation, slim},
  location  = {Foster City, Silicon Valley, California, USA},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/2645710.2645756},
}

@Article{Shi2014Collaborative,
  author     = {Shi, Yue and Larson, Martha and Hanjalic, Alan},
  title      = {Collaborative Filtering Beyond the User-Item Matrix: A Survey of the State of the Art and Future Challenges},
  journal    = {ACM Comput. Surv.},
  year       = {2014},
  volume     = {47},
  number     = {1},
  pages      = {3:1--3:45},
  month      = may,
  abstract   = {Over the past two decades, a large amount of research effort has been devoted to developing algorithms that generate recommendations. The resulting research progress has established the importance of the user-item (U-I) matrix, which encodes the individual preferences of users for items in a collection, for recommender systems. The U-I matrix provides the basis for collaborative filtering (CF) techniques, the dominant framework for recommender systems. Currently, new recommendation scenarios are emerging that offer promising new information that goes beyond the U-I matrix. This information can be divided into two categories related to its source: rich side information concerning users and items, and interaction information associated with the interplay of users and items. In this survey, we summarize and analyze recommendation scenarios involving information sources and the CF algorithms that have been recently developed to address them. We provide a comprehensive introduction to a large body of research, more than 200 key references, with the aim of supporting the further development of recommender systems exploiting information beyond the U-I matrix. On the basis of this material, we identify and discuss what we see as the central challenges lying ahead for recommender system technology, both in terms of extensions of existing techniques as well as of the integration of techniques and technologies drawn from other research areas.},
  acmid      = {2556270},
  address    = {New York, NY, USA},
  articleno  = {3},
  doi        = {10.1145/2556270},
  file       = {Shi2014Collaborative.pdf:Shi2014Collaborative.pdf:PDF},
  issn       = {0360-0300},
  issue_date = {July 2014},
  keywords   = {Algorithms, applications, challenges, collaborative filtering, recommender systems, social networks, survey},
  numpages   = {45},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/2556270},
}

@Article{Chen2015Recommender,
  author   = {Chen, Li and Chen, Guanliang and Wang, Feng},
  title    = {Recommender systems based on user reviews: the state of the art},
  journal  = {User Modeling and User-Adapted Interaction},
  year     = {2015},
  volume   = {25},
  number   = {2},
  pages    = {99--154},
  month    = {Jun},
  abstract = {In recent years, a variety of review-based recommender systems have been developed, with the goal of incorporating the valuable information in user-generated textual reviews into the user modeling and recommending process. Advanced text analysis and opinion mining techniques enable the extraction of various types of review elements, such as the discussed topics, the multi-faceted nature of opinions, contextual information, comparative opinions, and reviewers' emotions. In this article, we provide a comprehensive overview of how the review elements have been exploited to improve standard content-based recommending, collaborative filtering, and preference-based product ranking techniques. The review-based recommender system's ability to alleviate the well-known rating sparsity and cold-start problems is emphasized. This survey classifies state-of-the-art studies into two principal branches: review-based user profile building and review-based product profile building. In the user profile sub-branch, the reviews are not only used to create term-based profiles, but also to infer or enhance ratings. Multi-faceted opinions can further be exploited to derive the weight/value preferences that users place on particular features. In another sub-branch, the product profile can be enriched with feature opinions or comparative opinions to better reflect its assessment quality. The merit of each branch of work is discussed in terms of both algorithm development and the way in which the proposed algorithms are evaluated. In addition, we discuss several future trends based on the survey, which may inspire investigators to pursue additional studies in this area.},
  day      = {01},
  doi      = {10.1007/s11257-015-9155-5},
  issn     = {1573-1391},
  url      = {https://doi.org/10.1007/s11257-015-9155-5},
}

@Article{Chen2013Preference,
  author   = {Li Chen and Feng Wang},
  title    = {Preference-based clustering reviews for augmenting e-commerce recommendation},
  journal  = {Knowledge-Based Systems},
  year     = {2013},
  volume   = {50},
  pages    = {44 - 59},
  abstract = {In the area of e-commerce, there exists a special, implicit community being composed of product reviewers. A reviewer normally provides two types of info: one is the overall rating on the product(s) that s/he experienced, and another is the textual review that contains her/his detailed opinions on the product(s). However, for the high-risk products (such as digital cameras, computers, and cars), a reviewer usually commented one or few products due to her/his infrequent usage experiences. It hence raises a question of how to identify the preference similarity among reviewers. In this paper, we propose a novel clustering method based on Latent Class Regression model (LCRM), which is essentially able to consider both the overall ratings and feature-level opinion values (as extracted from textual reviews) to identify reviewers’ preference homogeneity. Particularly, we extend the model to infer individual reviewers’ weighted feature preferences within the same iterative process. As a result, both the cluster-level and reviewer-level preferences are derived. We further test the impact of these derived preferences on augmenting recommendation for the active buyer. That is, given the reviewers’ feature preferences, we aim to establish the connection between the active buyer and the cluster of reviewers by revealing their preferences’ inter-relevance. In the experiment, we tested the proposed recommender algorithm with two real-world datasets. More notably, we compared it with multiple related approaches, including the non-review based method and non-LCRM based variations. The experiment demonstrates the superior performance of our approach in terms of increasing the system’s recommendation accuracy.},
  doi      = {https://doi.org/10.1016/j.knosys.2013.05.006},
  issn     = {0950-7051},
  keywords = {Recommender system, Product reviews, Opinion mining, Multi-attribute utility theory, Preference learning, Latent class regression model, Clustering, E-commerce},
  url      = {http://www.sciencedirect.com/science/article/pii/S095070511300155X},
}

@InProceedings{Zheng2015Similarity,
  author    = {Zheng, Yong and Mobasher, Bamshad and Burke, Robin},
  title     = {Similarity-Based Context-Aware Recommendation},
  booktitle = {Web Information Systems Engineering -- WISE 2015},
  year      = {2015},
  editor    = {Wang, Jianyong and Cellary, Wojciech and Wang, Dingding and Wang, Hua and Chen, Shu-Ching and Li, Tao and Zhang, Yanchun},
  pages     = {431--447},
  address   = {Cham},
  publisher = {Springer International Publishing},
  abstract  = {Context-aware recommender systems (CARS) take context into consideration when modeling user preferences. There are two general ways to integrate context with recommendation: contextual filtering and contextual modeling. Currently, the most effective context-aware recommendation algorithms are based on a contextual modeling approach that estimate deviations in ratings across different contexts. In this paper, we propose context similarity as an alternative contextual modeling approach and examine different ways to represent context similarity and incorporate it into recommendation. More specifically, we show how context similarity can be integrated into the sparse linear method and matrix factorization algorithms. Our experimental results demonstrate that learning context similarity is a more effective approach to context-aware recommendation than modeling contextual rating deviations.},
  comment   = {non-contextual rating, where c_E is an empty context

sim(c_k,c_E) can be measured by independently computing each dimension, or via a latent space
similarity is learnt! not assigned


this approach can be embed in CSLIM or CAMF. all variants of CSLIM are better than CAMFnon

\hat{r}=ui sim(c_k,c_E)

},
  isbn      = {978-3-319-26190-4},
}

@InProceedings{Zheng2014Splitting,
  author    = {Zheng, Yong and Burke, Robin and Mobasher, Bamshad},
  title     = {Splitting Approaches for Context-aware Recommendation: An Empirical Study},
  booktitle = {Proceedings of the 29th Annual ACM Symposium on Applied Computing},
  year      = {2014},
  series    = {SAC '14},
  pages     = {274--279},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {User and item splitting are well-known approaches to context-aware recommendation. To perform item splitting, multiple copies of an item are created based on the contexts in which it has been rated. User splitting performs a similar treatment with respect to users. The combination of user and item splitting: UI splitting, splits both users and items in the data set to boost context-aware recommendations. In this paper, we perform an empirical comparison of these three context-aware splitting approaches (CASA) on multiple data sets, and we also compare them with other popular context-aware collaborative filtering (CACF) algorithms. To evaluate those algorithms, we propose new evaluation metrics specific to contextual recommendation. The experiments reveal that CASA typically outperform other popular CACF algorithms, but there is no clear winner among the three splitting approaches. However, we do find some underlying patterns or clues for the application of CASA.},
  acmid     = {2554989},
  comment   = {usage patterns reveal dependence between contexts and user/items, user splitting is preferred if contexts are more dependent with users than items.


UI splitting outperforms other two splitting approaches in RMSE

},
  doi       = {10.1145/2554850.2554989},
  isbn      = {978-1-4503-2469-4},
  keywords  = {context, context-aware recommendation, context-aware splitting approaches, experiment, recommendation},
  location  = {Gyeongju, Republic of Korea},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/2554850.2554989},
}

@InProceedings{Pena2017Unsupervised,
  author    = {Pe\~{n}a, Francisco J.},
  title     = {Unsupervised Context-Driven Recommendations Based On User Reviews},
  booktitle = {Proceedings of the Eleventh ACM Conference on Recommender Systems},
  year      = {2017},
  series    = {RecSys '17},
  pages     = {426--430},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {In this work we present Rich-Context, a context-driven recommender system that extracts contextual information using topic modeling without the need to define keywords. Our system uses the mined context to produce recommendations. We propose a methodology to measure the quality of context topic models along with a novel way to represent context that allows it to be used as side-information in a recommendation engine. Results show that Rich-Context makes more accurate predictions than five well-established recommendation algorithms.},
  acmid     = {3109865},
  comment   = {rich-context is a query-based context-driven recommender system, users write queries stating the context in which they intend to travel
first classify specific and generic reviews
then do topic modeling, pick topics which are related to contexts (appear more ofen in specific reviews)
r -> to contextual topics},
  doi       = {10.1145/3109859.3109865},
  isbn      = {978-1-4503-4652-8},
  keywords  = {context-aware recommender systems, context-driven recommender system, review-mining, topic modeling},
  location  = {Como, Italy},
  numpages  = {5},
  url       = {http://doi.acm.org/10.1145/3109859.3109865},
}

@InProceedings{Gong2012Robust,
  author    = {Gong, Pinghua and Ye, Jieping and Zhang, Changshui},
  title     = {Robust Multi-task Feature Learning},
  booktitle = {Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year      = {2012},
  series    = {KDD '12},
  pages     = {895--903},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Multi-task learning (MTL) aims to improve the performance of multiple related tasks by exploiting the intrinsic relationships among them. Recently, multi-task feature learning algorithms have received increasing attention and they have been successfully applied to many applications involving high dimensional data. However, they assume that all tasks share a common set of features, which is too restrictive and may not hold in real-world applications, since outlier tasks often exist. In this paper, we propose a Robust Multi-Task Feature Learning algorithm (rMTFL) which simultaneously captures a common set of features among relevant tasks and identifies outlier tasks. Specifically, we decompose the weight (model) matrix for all tasks into two components. We impose the well-known group Lasso penalty on row groups of the first component for capturing the shared features among relevant tasks. To simultaneously identify the outlier tasks, we impose the same group Lasso penalty but on column groups of the second component. We propose to employ the accelerated gradient descent to efficiently solve the optimization problem in rMTFL, and show that the proposed algorithm is scalable to large-size problems. In addition, we provide a detailed theoretical analysis on the proposed rMTFL formulation. Specifically, we present a theoretical bound to measure how well our proposed rMTFL approximates the true evaluation, and provide bounds to measure the error between the estimated weights of rMTFL and the underlying true weights. Moreover, by assuming that the underlying true weights are above the noise level, we present a sound theoretical result to show how to obtain the underlying true shared features and outlier tasks (sparsity patterns). Empirical studies on both synthetic and real-world data demonstrate that our proposed rMTFL is capable of simultaneously capturing shared features among tasks and identifying outlier tasks.},
  acmid     = {2339672},
  comment   = {(1)multi-task learning: several data sets, number of samples in each data set could be different, same number of features, target value could be either regression or classification, could be different(2) y-wx, w=p+q, where p is common tasks, q is outlier tasks, therefore regularizer p_1,2 q^T_1,2 (3) experiment: syntetic data + real world data http://adni.loni.usc.edu/
},
  doi       = {10.1145/2339530.2339672},
  isbn      = {978-1-4503-1462-6},
  keywords  = {feature selection, multi-task learning, outlier tasks detection},
  location  = {Beijing, China},
  numpages  = {9},
  url       = {http://doi.acm.org/10.1145/2339530.2339672},
}

@InProceedings{Zhang2016Collaborative,
  author    = {Zhang, Fuzheng and Yuan, Nicholas Jing and Lian, Defu and Xie, Xing and Ma, Wei-Ying},
  title     = {Collaborative Knowledge Base Embedding for Recommender Systems},
  booktitle = {Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year      = {2016},
  series    = {KDD '16},
  pages     = {353--362},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Among different recommendation techniques, collaborative filtering usually suffer from limited performance due to the sparsity of user-item interactions. To address the issues, auxiliary information is usually used to boost the performance. Due to the rapid collection of information on the web, the knowledge base provides heterogeneous information including both structured and unstructured data with different semantics, which can be consumed by various applications. In this paper, we investigate how to leverage the heterogeneous information in a knowledge base to improve the quality of recommender systems. First, by exploiting the knowledge base, we design three components to extract items' semantic representations from structural content, textual content and visual content, respectively. To be specific, we adopt a heterogeneous network embedding method, termed as TransR, to extract items' structural representations by considering the heterogeneity of both nodes and relationships. We apply stacked denoising auto-encoders and stacked convolutional auto-encoders, which are two types of deep learning based embedding techniques, to extract items' textual representations and visual representations, respectively. Finally, we propose our final integrated framework, which is termed as Collaborative Knowledge Base Embedding (CKE), to jointly learn the latent representations in collaborative filtering as well as items' semantic representations from the knowledge base. To evaluate the performance of each embedding component as well as the whole system, we conduct extensive experiments with two real-world datasets from different scenarios. The results reveal that our approaches outperform several widely adopted state-of-the-art recommendation methods.},
  acmid     = {2939673},
  comment   = {(1) first learn representations by TRansR, textual representation by a deep network SDAE, visual representation by SCAE (all previous work) (2) proposed model CKE is a BPR framework, parameters user feature, item feature = the above combined + offset , sigmoid of inner product 
},
  doi       = {10.1145/2939672.2939673},
  groups    = {Knowledge graph},
  isbn      = {978-1-4503-4232-2},
  keywords  = {collaborative joint learning, knowledge base embedding, recommender systems},
  location  = {San Francisco, California, USA},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2939672.2939673},
}

@InProceedings{Mele2017Linking,
  author    = {Mele, Ida and Bahrainian, Seyed Ali and Crestani, Fabio},
  title     = {Linking News Across Multiple Streams for Timeliness Analysis},
  booktitle = {Proceedings of the 2017 ACM on Conference on Information and Knowledge Management},
  year      = {2017},
  series    = {CIKM '17},
  pages     = {767--776},
  address   = {New York, NY, USA},
  publisher = {ACM},
  note      = {novelty minimum, good application},
  abstract  = {Linking multiple news streams based on the reported events and analyzing the streams' temporal publishing patterns are two very important tasks for information analysis, discovering newsworthy stories, studying the event evolution, and detecting untrustworthy sources of information. In this paper, we propose techniques for cross-linking news streams based on the reported events with the purpose of analyzing the temporal dependencies among streams.

Our research tackles two main issues: (1) how news streams are connected as reporting an event or the evolution of the same event and (2) how timely the newswires report related events using different publishing platforms. Our approach is based on dynamic topic modeling for detecting and tracking events over the timeline and on clustering news according to the events. We leverage the event-based clustering to link news across different streams and present two scoring functions for ranking the streams based on their timeliness in publishing news about a specific event.},
  acmid     = {3132988},
  comment   = {challenge1: emerging topic
		solution: dDTM, non-linear dependency
		challenge2: number of topics undetermined
		solution: Bayesian model comparing
		framework: dTM -> topic as observations, HMM chain -> topics as dimensions, clustering to events 
		HMM number of states: BIC 
		applications: frequent pattern mining, ranking based on timeliness

200 topics},
  doi       = {10.1145/3132847.3132988},
  groups    = {LDA},
  isbn      = {978-1-4503-4918-5},
  keywords  = {dynamic topic modeling, event mining, news streams, temporal analysis},
  location  = {Singapore, Singapore},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/3132847.3132988},
}

@InProceedings{Takeda2017Evolution,
  author    = {Takeda, Naoto and Seki, Yohei and Morishita, Mimpei and Inagaki, Yoichi},
  title     = {Evolution of Information Needs Based on Life Event Experiences with Topic Transition},
  booktitle = {Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year      = {2017},
  series    = {SIGIR '17},
  pages     = {1009--1012},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {We propose a method to clarify the evolution of users' information needs related to a user's interests and actions based upon life events such as "childbirth." First, we extract topic transitions using dynamic topic models from blogs posted by users who have experienced life events. Next, we select the topics by computing the differences in topic probabilities before and after the life event. We evaluated our method based on three life events: "childbirth," "finding employment," and "marriage." Our method selected life event-relevant topics such as "child development," "working life," and "wedding ceremony." We found mothers' information needs such as "how to introduce baby food," employees' information needs such as "preparing an induction programme," and couples' information needs such as "wedding reception planning" in each topic.},
  acmid     = {3080703},
  comment   = {DTM -> select life event relevant topics, compute difference in topic probabilities before and after life event (mean and variance)},
  doi       = {10.1145/3077136.3080703},
  groups    = {LDA},
  isbn      = {978-1-4503-5022-8},
  keywords  = {dtms (dynamic topic models), information needs, life event},
  location  = {Shinjuku, Tokyo, Japan},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/3077136.3080703},
}

@InProceedings{Zhang2015Dynamic,
  author    = {Zhang, Hao and Kim, Gunhee and Xing, Eric P.},
  title     = {Dynamic Topic Modeling for Monitoring Market Competition from Online Text and Image Data},
  booktitle = {Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year      = {2015},
  series    = {KDD '15},
  pages     = {1425--1434},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {We propose a dynamic topic model for monitoring temporal evolution of market competition by jointly leveraging tweets and their associated images. For a market of interest (e.g. luxury goods), we aim at automatically detecting the latent topics (e.g. bags, clothes, luxurious) that are competitively shared by multiple brands (e.g. Burberry, Prada, and Chanel), and tracking temporal evolution of the brands' stakes over the shared topics. One of key applications of our work is social media monitoring that can provide companies with temporal summaries of highly overlapped or discriminative topics with their major competitors. We design our model to correctly address three major challenges: multiview representation of text and images, modeling of competitiveness of multiple brands over shared topics, and tracking their temporal evolution. As far as we know, no previous model can satisfy all the three challenges. For evaluation, we analyze about 10 millions of tweets and 8 millions of associated images of the 23 brands in the two categories of luxury and beer. Through experiments, we show that the proposed approach is more successful than other candidate methods for the topic modeling of competition. We also quantitatively demonstrate the generalization power of the proposed method for three prediction tasks.},
  acmid     = {2783293},
  comment   = {DTM 
word, visual, brand
},
  doi       = {10.1145/2783258.2783293},
  groups    = {LDA},
  isbn      = {978-1-4503-3664-2},
  keywords  = {dynamic topic models, market competition, text and images},
  location  = {Sydney, NSW, Australia},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2783258.2783293},
}

@InProceedings{Zhu2016Recruitment,
  author    = {Zhu, Chen and Zhu, Hengshu and Xiong, Hui and Ding, Pengliang and Xie, Fang},
  title     = {Recruitment Market Trend Analysis with Sequential Latent Variable Models},
  booktitle = {Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year      = {2016},
  series    = {KDD '16},
  pages     = {383--392},
  address   = {New York, NY, USA},
  publisher = {ACM},
  note      = {well},
  abstract  = {Recruitment market analysis provides valuable understanding of industry-specific economic growth and plays an important role for both employers and job seekers. With the rapid development of online recruitment services, massive recruitment data have been accumulated and enable a new paradigm for recruitment market analysis. However, traditional methods for recruitment market analysis largely rely on the knowledge of domain experts and classic statistical models, which are usually too general to model large-scale dynamic recruitment data, and have difficulties to capture the fine-grained market trends. To this end, in this paper, we propose a new research paradigm for recruitment market analysis by leveraging unsupervised learning techniques for automatically discovering recruitment market trends based on large-scale recruitment data. Specifically, we develop a novel sequential latent variable model, named MTLVM, which is designed for capturing the sequential dependencies of corporate recruitment states and is able to automatically learn the latent recruitment topics within a Bayesian generative framework. In particular, to capture the variability of recruitment topics over time, we design hierarchical dirichlet processes for MTLVM. These processes allow to dynamically generate the evolving recruitment topics. Finally, we implement a prototype system to empirically evaluate our approach based on real-world recruitment data in China. Indeed, by visualizing the results from MTLVM, we can successfully reveal many interesting findings, such as the popularity of LBS related jobs reached the peak in the 2nd half of 2014, and decreased in 2015.},
  acmid     = {2939689},
  comment   = {MTLVM : recruit state evolves, transition matrix \rho
 generation: recuit state, strategy -> demand -> topic -> word 
CRP 
},
  doi       = {10.1145/2939672.2939689},
  groups    = {LDA},
  isbn      = {978-1-4503-4232-2},
  keywords  = {latent variable model, recruitment market, trend analysis},
  location  = {San Francisco, California, USA},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2939672.2939689},
}

@InProceedings{Pan2013Crowd,
  author    = {Pan, Bei and Zheng, Yu and Wilkie, David and Shahabi, Cyrus},
  title     = {Crowd Sensing of Traffic Anomalies based on Human Mobility and Social Media},
  booktitle = {Proceedings of the 21st ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems},
  year      = {2013},
  series    = {SIGSPATIAL'13},
  pages     = {344--353},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {The advances in mobile computing and social networking services enable people to probe the dynamics of a city. In this paper, we address the problem of detecting and describing traffic anomalies using crowd sensing with two forms of data, human mobility and social media. Traffic anomalies are caused by accidents, control, protests, sport events, celebrations, disasters and other events. Unlike existing traffic-anomaly-detection methods, we identify anomalies according to drivers' routing behavior on an urban road network. Here, a detected anomaly is represented by a sub-graph of a road network where drivers' routing behaviors significantly differ from their original patterns. We then try to describe the detected anomaly by mining representative terms from the social media that people posted when the anomaly happened. The system for detecting such traffic anomalies can benefit both drivers and transportation authorities, e.g., by notifying drivers approaching an anomaly and suggesting alternative routes, as well as supporting traffic jam diagnosis and dispersal. We evaluate our system with a GPS trajectory dataset generated by over 30,000 taxicabs over a period of 3 months in Beijing, and a dataset of tweets collected from WeiBo, a Twitter-like social site in China. The results demonstrate the effectiveness and efficiency of our system.},
  acmid     = {2525343},
  comment   = {framework cascade

anamaly detection in trajectory, seed selection, graph expansion

impact analysis for each anamaly 
term mining to annotate},
  doi       = {10.1145/2525314.2525343},
  isbn      = {978-1-4503-2521-9},
  keywords  = {city dynamics, human as a sensor, human mobility, traffic anomaly},
  location  = {Orlando, Florida},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2525314.2525343},
}

@InCollection{Tintarev2011Designing,
  author    = {Tintarev, Nava and Masthoff, Judith},
  title     = {Designing and evaluating explanations for recommender systems},
  booktitle = {Recommender systems handbook},
  publisher = {Springer},
  year      = {2011},
  pages     = {479--510},
}

@Article{Cramer2008effects,
  author    = {Cramer, Henriette and Evers, Vanessa and Ramlal, Satyan and Van Someren, Maarten and Rutledge, Lloyd and Stash, Natalia and Aroyo, Lora and Wielinga, Bob},
  title     = {The effects of transparency on trust in and acceptance of a content-based art recommender},
  journal   = {User Modeling and User-Adapted Interaction},
  year      = {2008},
  volume    = {18},
  number    = {5},
  pages     = {455},
  publisher = {Springer},
}

@InCollection{Yoo2011Creating,
  author    = {Yoo, Kyung-Hyan and Gretzel, Ulrike},
  title     = {Creating more credible and persuasive recommender systems: The influence of source characteristics on recommender system evaluations},
  booktitle = {Recommender systems handbook},
  publisher = {Springer},
  year      = {2011},
  pages     = {455--477},
}

@InProceedings{Sharma2013Do,
  author       = {Sharma, Amit and Cosley, Dan},
  title        = {Do social explanations work?: studying and modeling the effects of social explanations in recommender systems},
  booktitle    = {Proceedings of the 22nd international conference on World Wide Web},
  year         = {2013},
  pages        = {1133--1144},
  organization = {ACM},
}

@InProceedings{Zhang2014Explicit,
  author       = {Zhang, Yongfeng and Lai, Guokun and Zhang, Min and Zhang, Yi and Liu, Yiqun and Ma, Shaoping},
  title        = {Explicit factor models for explainable recommendation based on phrase-level sentiment analysis},
  booktitle    = {Proceedings of the 37th international ACM SIGIR conference on Research \& development in information retrieval},
  year         = {2014},
  pages        = {83--92},
  organization = {ACM},
}

@InProceedings{He2015Trirank,
  author       = {He, Xiangnan and Chen, Tao and Kan, Min-Yen and Chen, Xiao},
  title        = {Trirank: Review-aware explainable recommendation by modeling aspects},
  booktitle    = {Proceedings of the 24th ACM International on Conference on Information and Knowledge Management},
  year         = {2015},
  pages        = {1661--1670},
  organization = {ACM},
}

@InProceedings{McAuley2013Hidden,
  author       = {McAuley, Julian and Leskovec, Jure},
  title        = {Hidden factors and hidden topics: understanding rating dimensions with review text},
  booktitle    = {Proceedings of the 7th ACM conference on Recommender systems},
  year         = {2013},
  pages        = {165--172},
  organization = {ACM},
}

@InProceedings{Ren2017Social,
  author       = {Ren, Zhaochun and Liang, Shangsong and Li, Piji and Wang, Shuaiqiang and de Rijke, Maarten},
  title        = {Social collaborative viewpoint regression with explainable recommendations},
  booktitle    = {Proceedings of the tenth ACM international conference on web search and data mining},
  year         = {2017},
  pages        = {485--494},
  organization = {ACM},
}

@InProceedings{Wang2018Tem,
  author    = {X Wang, X He, F Feng, L Nie, TS Chua},
  title     = {Tem: Tree-enhanced embedding model for explainable recommendation},
  booktitle = {Proceedings of the World Wide Web Conference},
  year      = {2018},
}

@InProceedings{Costa2018Automatic,
  author    = {Costa, Felipe and Ouyang, Sixun and Dolog, Peter and Lawlor, Aonghus},
  title     = {Automatic Generation of Natural Language Explanations},
  booktitle = {Proceedings of the 23rd International Conference on Intelligent User Interfaces Companion},
  year      = {2018},
  series    = {IUI '18 Companion},
  pages     = {57:1--57:2},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3180366},
  articleno = {57},
  doi       = {10.1145/3180308.3180366},
  isbn      = {978-1-4503-5571-1},
  keywords  = {Explainability, Explanations, Natural Language Generation, Neural Network, Recommender systems},
  location  = {Tokyo, Japan},
  numpages  = {2},
  url       = {http://doi.acm.org/10.1145/3180308.3180366},
}

@InProceedings{Wu2016Collaborative,
  author    = {Wu, Yao and DuBois, Christopher and Zheng, Alice X. and Ester, Martin},
  title     = {Collaborative Denoising Auto-Encoders for Top-N Recommender Systems},
  booktitle = {Proceedings of the Ninth ACM International Conference on Web Search and Data Mining},
  year      = {2016},
  series    = {WSDM '16},
  pages     = {153--162},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2835837},
  comment   = {a general NN framework for top-N recommendation 
for implicit feedback 1-0
first, randomly drop-out/mask-out noise, by overwriting some of the positive feedback to be 0 by probability "q". to make it unbiased, scale these feedback to be  1/1-q by probability 1-q
then, each user is represented as a I+1 dimensional vector, where I is the size of the item universe, the rest is the user-specific node (user-id)
a hidden layer with K nodes and an additional bias node
input-> hidden layer mapping could be identity or sigmoid function
output all observations, without user ids, without corruptions
hidden layer to output could be identity or sigmoid too
loss function is the L2-regularized square or logistic 
denoising helps!},
  doi       = {10.1145/2835776.2835837},
  isbn      = {978-1-4503-3716-8},
  keywords  = {collaborative filtering, denoising auto- encoders, recommender systems},
  location  = {San Francisco, California, USA},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2835776.2835837},
}

@InProceedings{Tong2017Simpler,
  author    = {Tong, Yongxin and Chen, Yuqiang and Zhou, Zimu and Chen, Lei and Wang, Jie and Yang, Qiang and Ye, Jieping and Lv, Weifeng},
  title     = {The Simpler The Better: A Unified Approach to Predicting Original Taxi Demands Based on Large-Scale Online Platforms},
  booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year      = {2017},
  series    = {KDD '17},
  pages     = {1653--1662},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Taxi-calling apps are gaining increasing popularity for their efficiency in dispatching idle taxis to passengers in need. To precisely balance the supply and the demand of taxis, online taxicab platforms need to predict the Unit Original Taxi Demand (UOTD), which refers to the number of taxi-calling requirements submitted per unit time (e.g., every hour) and per unit region (e.g., each POI). Predicting UOTD is non-trivial for large-scale industrial online taxicab platforms because both accuracy and flexibility are essential. Complex non-linear models such as GBRT and deep learning are generally accurate, yet require labor-intensive model redesign after scenario changes (e.g., extra constraints due to new regulations). To accurately predict UOTD while remaining flexible to scenario changes, we propose LinUOTD, a unified linear regression model with more than 200 million dimensions of features. The simple model structure eliminates the need of repeated model redesign, while the high-dimensional features contribute to accurate UOTD prediction. We further design a series of optimization techniques for efficient model training and updating. Evaluations on two large-scale datasets from an industrial online taxicab platform verify that LinUOTD outperforms popular non-linear models in accuracy. We envision our experiences to adopt simple linear models with high-dimensional features in UOTD prediction as a pilot study and can shed insights upon other industrial large-scale spatio-temporal prediction problems.},
  acmid     = {3098018},
  comment   = {a unique application: unit original taxi demand 
extensive study on taxi demand prediction (pick ups) but the original taxi demand (calls) not sufficient
study features: temporal , event (e.g. discount strategy), POI, etc.
models are simple : markov (because including temporal features), GBDT, NN, etc.
},
  doi       = {10.1145/3097983.3098018},
  isbn      = {978-1-4503-4887-4},
  keywords  = {feature engineering, prediction, unit original taxi demands},
  location  = {Halifax, NS, Canada},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/3097983.3098018},
}

@InProceedings{Wang2017Location,
  author    = {Wang, Hao and Fu, Yanmei and Wang, Qinyong and Yin, Hongzhi and Du, Changying and Xiong, Hui},
  title     = {A Location-Sentiment-Aware Recommender System for Both Home-Town and Out-of-Town Users},
  booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year      = {2017},
  series    = {KDD '17},
  pages     = {1135--1143},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Spatial item recommendation has become an important means to help people discover interesting locations, especially when people pay a visit to unfamiliar regions. Some current researches are focusing on modelling individual and collective geographical preferences for spatial item recommendation based on users' check-in records, but they fail to explore the phenomenon of user interest drift across geographical regions, i.e., users would show different interests when they travel to different regions. Besides, they ignore the influence of public comments for subsequent users' check-in behaviors. Specifically, it is intuitive that users would refuse to check in to a spatial item whose historical reviews seem negative overall, even though it might fit their interests. Therefore, it is necessary to recommend the right item to the right user at the right location. In this paper, we propose a latent probabilistic generative model called LSARS to mimic the decision-making process of users' check-in activities both in home-town and out-of-town scenarios by adapting to user interest drift and crowd sentiments, which can learn location-aware and sentiment-aware individual interests from the contents of spatial items and user reviews. Due to the sparsity of user activities in out-of-town regions, LSARS is further designed to incorporate the public preferences learned from local users' check-in behaviors. Finally, we deploy LSARS into two practical application scenes: spatial item recommendation and target user discovery. Extensive experiments on two large-scale location-based social networks (LBSNs) datasets show that LSARS achieves better performance than existing state-of-the-art methods.},
  acmid     = {3098122},
  comment   = {data: yelp & foursquare check in data
model: topic model
for each user, draw a region, for each region, draw a spatial item, the location is a Gaussian distibution over the mean of the spatial item
for each user, draw a topic, a word, for a word ,draw a sentiment

applications:
item recommendation
user discovery},
  doi       = {10.1145/3097983.3098122},
  isbn      = {978-1-4503-4887-4},
  keywords  = {check-in behavior, crowd sentiment, recommendation, user interest drift},
  location  = {Halifax, NS, Canada},
  numpages  = {9},
  url       = {http://doi.acm.org/10.1145/3097983.3098122},
}

@InProceedings{Zhang2016GMove,
  author    = {Zhang, Chao and Zhang, Keyang and Yuan, Quan and Zhang, Luming and Hanratty, Tim and Han, Jiawei},
  title     = {GMove: Group-Level Mobility Modeling Using Geo-Tagged Social Media},
  booktitle = {Proceedings of the 22Nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year      = {2016},
  series    = {KDD '16},
  pages     = {1305--1314},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Understanding human mobility is of great importance to various applications, such as urban planning, traffic scheduling, and location prediction. While there has been fruitful research on modeling human mobility using tracking data (e.g., GPS traces), the recent growth of geo-tagged social media (GeoSM) brings new opportunities to this task because of its sheer size and multi-dimensional nature. Nevertheless, how to obtain quality mobility models from the highly sparse and complex GeoSM data remains a challenge that cannot be readily addressed by existing techniques. We propose GMove, a group-level mobility modeling method using GeoSM data. Our insight is that the GeoSM data usually contains multiple user groups, where the users within the same group share significant movement regularity. Meanwhile, user grouping and mobility modeling are two intertwined tasks: (1) better user grouping offers better within-group data consistency and thus leads to more reliable mobility models; and (2) better mobility models serve as useful guidance that helps infer the group a user belongs to. GMove thus alternates between user grouping and mobility modeling, and generates an ensemble of Hidden Markov Models (HMMs) to characterize group-level movement regularity. Furthermore, to reduce text sparsity of GeoSM data, GMove also features a text augmenter. The augmenter computes keyword correlations by examining their spatiotemporal distributions. With such correlations as auxiliary knowledge, it performs sampling-based augmentation to alleviate text sparsity and produce high-quality HMMs.
Our extensive experiments on two real-life data sets demonstrate that GMove can effectively generate meaningful group-level mobility models. Moreover, with context-aware location prediction as an example application, we find that GMove significantly outperforms baseline mobility models in terms of prediction accuracy.},
  acmid     = {2939793},
  comment   = {instrinct states: working?
how do they move?

(1) keyword augmentation
longitude-latitude-time grid
keyword signature: frequency on the grids
keyword correlation: consine similarity of the signatures
keyword augmentation: sample other keywords to append to based on the keyword correlations

(2) HMM, observation: keyword

(3) user grouping

application: context aware location prediction},
  doi       = {10.1145/2939672.2939793},
  isbn      = {978-1-4503-4232-2},
  keywords  = {human mobility, movement pattern, social media, spatiotemporal data, twitter},
  location  = {San Francisco, California, USA},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2939672.2939793},
}

@InProceedings{EspinNoboa2016Discovering,
  author    = {Esp\'{\i}n Noboa, Lisette and Lemmerich, Florian and Singer, Philipp and Strohmaier, Markus},
  title     = {Discovering and Characterizing Mobility Patterns in Urban Spaces: A Study of Manhattan Taxi Data},
  booktitle = {Proceedings of the 25th International Conference Companion on World Wide Web},
  year      = {2016},
  series    = {WWW '16 Companion},
  pages     = {537--542},
  address   = {Republic and Canton of Geneva, Switzerland},
  publisher = {International World Wide Web Conferences Steering Committee},
  abstract  = {Nowadays, human movement in urban spaces can be traced digitally in many cases. It can be observed that movement patterns are not constant, but vary across time and space. In this work, we characterize such spatio-temporal patterns with an innovative combination of two separate approaches that have been utilized for studying human mobility in the past. First, by using non-negative tensor factorization (NTF), we are able to cluster human behavior based on spatio-temporal dimensions. Second, for characterizing these clusters, we propose to use HypTrails, a Bayesian approach for expressing and comparing hypotheses about human trails. To formalize hypotheses, we utilize publicly available Web data (i.e., Foursquare and census data). By studying taxi data in Manhattan, we can discover and characterize human mobility patterns that cannot be identified in a collective analysis. As one example, we find a group of taxi rides that end at locations with a high number of party venues on weekend nights. Our findings argue for a more fine-grained analysis of human mobility in order to make informed decisions for e.g., enhancing urban structures, tailored traffic control and location-based recommender systems.},
  acmid     = {2890468},
  comment   = {10 hypothesis
NTF tensor factorization: departure arrival time},
  doi       = {10.1145/2872518.2890468},
  isbn      = {978-1-4503-4144-8},
  keywords  = {human keywords, hyptrails, tensor factorization},
  location  = {Montr\&\#233;al, Qu\&\#233;bec, Canada},
  numpages  = {6},
  url       = {https://doi.org/10.1145/2872518.2890468},
}

@Article{Toch2018Analyzing,
  author    = {Toch, Eran and Lerner, Boaz and Ben-Zion, Eyal and Ben-Gal, Irad},
  title     = {Analyzing large-scale human mobility data: a survey of machine learning methods and applications},
  journal   = {Knowledge and Information Systems},
  year      = {2018},
  pages     = {1--23},
  abstract  = {Human mobility patterns reflect many aspects of life, from the global spread of infectious diseases to urban planning and daily commute patterns. In recent years, the prevalence of positioning methods and technologies, such as the global positioning system, cellular radio tower geo-positioning, and WiFi positioning systems, has driven efforts to collect human mobility data and to mine patterns of interest within these data in order to promote the development of location-based services and applications. The efforts to mine significant patterns within large-scale, high-dimensional mobility data have solicited use of advanced analysis techniques, usually based on machine learning methods, and therefore, in this paper, we survey and assess different approaches and models that analyze and learn human mobility patterns using mainly machine learning methods. We categorize these approaches and models in a taxonomy based on their positioning characteristics, the scale of analysis, the properties of the modeling approach, and the class of applications they can serve. We find that these applications can be categorized into three classes: user modeling, place modeling, and trajectory modeling, each class with its characteristics. Finally, we analyze the short-term trends and future challenges of human mobility analysis.},
  comment   = {application:

user modeling
place modeling
trajectory modeling},
  publisher = {Springer},
}

@InProceedings{Xue2017Deep,
  author    = {Xue, Hong-Jian and Dai, Xinyu and Zhang, Jianbing and Huang, Shujian and Chen, Jiajun},
  title     = {Deep Matrix Factorization Models for Recommender Systems.},
  booktitle = {IJCAI},
  year      = {2017},
  pages     = {3203--3209},
  abstract  = {Recommender systems usually make personalized recommendation with user-item interaction ratings, implicit feedback and auxiliary information. Matrix factorization is the basic idea to predict a personalized ranking over a set of items for an individual user with the similarities among users and items. In this paper, we propose a novel matrix factorization model with neural network architecture. Firstly, we construct a user-item matrix with explicit ratings and non-preference implicit feedback. With this matrix as the input, we present a deep structure learning architecture to learn a common low dimensional space for the representations of users and items. Secondly, we design a new loss function based on binary cross entropy, in which we consider both explicit ratings and implicit feedback for a better optimization. The experimental results show the effectiveness of both our proposed model and the loss function. On several benchmark datasets, our model outperformed other state-of-the-art methods. We also conduct extensive experiments to evaluate the performance within different experimental settings.},
  comment   = {input: interaction matrix
user vector -> multi-layer hidden space -> pq cosine similarity -> interaction 
item vector -> multi-layer hidden space },
}

@InProceedings{Chang2016Crowd,
  author    = {Chang, Shuo and Harper, F. Maxwell and Terveen, Loren Gilbert},
  title     = {Crowd-Based Personalized Natural Language Explanations for Recommendations},
  booktitle = {Proceedings of the 10th ACM Conference on Recommender Systems},
  year      = {2016},
  series    = {RecSys '16},
  pages     = {175--182},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Explanations are important for users to make decisions on whether to take recommendations. However, algorithm generated explanations can be overly simplistic and unconvincing. We believe that humans can overcome these limitations. Inspired by how people explain word-of-mouth recommendations, we designed a process, combining crowdsourcing and computation, that generates personalized natural language explanations. We modeled key topical aspects of movies, asked crowdworkers to write explanations based on quotes from online movie reviews, and personalized the explanations presented to users based on their rating history. We evaluated the explanations by surveying 220 MovieLens users, finding that compared to personalized tag-based explanations, natural language explanations: 1) contain a more appropriate amount of information, 2) earn more trust from users, and 3) make users more satisfied. This paper contributes to the research literature by describing a scalable process for generating high quality and personalized natural language explanations, improving on state-of-the-art content-based explanations, and showing the feasibility and advantages of approaches that combine human wisdom with algorithmic processes.},
  acmid     = {2959153},
  comment   = {It's a system, algorithm aided crowd workers},
  doi       = {10.1145/2959100.2959153},
  isbn      = {978-1-4503-4035-9},
  keywords  = {clustering, crowdsourcing, natural language processing, recommendation explanations, word2vec},
  location  = {Boston, Massachusetts, USA},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/2959100.2959153},
}

@InProceedings{Munigala2018PersuAIDE,
  author    = {Munigala, Vitobha and Mishra, Abhijit and Tamilselvam, Srikanth G. and Khare, Shreya and Dasgupta, Riddhiman and Sankaran, Anush},
  title     = {PersuAIDE ! An Adaptive Persuasive Text Generation System for Fashion Domain},
  booktitle = {Companion Proceedings of the The Web Conference 2018},
  year      = {2018},
  series    = {WWW '18},
  pages     = {335--342},
  address   = {Republic and Canton of Geneva, Switzerland},
  publisher = {International World Wide Web Conferences Steering Committee},
  abstract  = {Persuasiveness is a creative art which aims at inducing certain set of beliefs in the target audience. In an e-commerce setting, for a newly launched product, persuasive descriptions are often composed to motivate an online buyer towards a successful purchase. Such descriptions can be catchy taglines, product-summaries, style-tipsetc.. In this paper, we present PersuAIDE! - a persuasive system based on linguistic creativity to generate various forms of persuasive sentences from the input product specification. To demonstrate the effectiveness of the proposed system, we have applied the technology to fashion domain, where, for a given fashion product like"red collar shirt" we were able to generate descriptive sentences that not only explain the item but also garner positive attention, making it persuasive. PersuAIDE! identifies fashion related keywords from input specifications and intelligently expands the keywords to creative phrases. Once such compatible phrases are obtained, persuasive descriptions are synthesized from the set of phrases and input keywords with the help of a neural language model trained on a large domain-specific fashion corpus. We evaluate the system on a large fashion corpus collected from different sources using (a) automatic text generation metrics used for Machine Translation and Automatic Summarization evaluation and Readability measurement, and (b) human judgment scores evaluating the persuasiveness and fluency of the generated text. Experimental results and qualitative analysis show that an unsupervised system like ours can produce more creative and better constructed persuasive output than supervised generative counterparts based on neural sequence-to-sequence models and statistical machine translation.},
  acmid     = {3186345},
  comment   = {usupervised!

keyword extraction (feature)
named entities
expansion based on a domain corpus
sentence generation, using language model LM
},
  doi       = {10.1145/3184558.3186345},
  isbn      = {978-1-4503-5640-4},
  keywords  = {persuasion in fashion, persuasive systems, persuasiveness, style-tip generation},
  location  = {Lyon, France},
  numpages  = {8},
  url       = {https://doi.org/10.1145/3184558.3186345},
}

@InProceedings{Wang2018TEM,
  author    = {Wang, Xiang and He, Xiangnan and Feng, Fuli and Nie, Liqiang and Chua, Tat-Seng},
  title     = {TEM: Tree-enhanced Embedding Model for Explainable Recommendation},
  booktitle = {Proceedings of the 2018 World Wide Web Conference},
  year      = {2018},
  series    = {WWW '18},
  pages     = {1543--1552},
  address   = {Republic and Canton of Geneva, Switzerland},
  publisher = {International World Wide Web Conferences Steering Committee},
  abstract  = {While collaborative filtering is the dominant technique in personalized recommendation, it models user-item interactions only and cannot provide concrete reasons for a recommendation. Meanwhile, the rich side information affiliated with user-item interactions (e.g., user demographics and item attributes), which provide valuable evidence that why a recommendation is suitable for a user, has not been fully explored in providing explanations.
On the technical side, embedding-based methods, such as Wide&Deep and neural factorization machines, provide state-of-the-art recommendation performance. However, they work like a black-box, for which the reasons underlying a prediction cannot be explicitly presented. On the other hand, tree-based methods like decision trees predict by inferring decision rules from data. While being explainable, they cannot generalize to unseen feature interactions thus fail in collaborative filtering applications.
In this work, we propose a novel solution named Tree-enhanced Embedding Method that combines the strengths of embedding-based and tree-based models. We first employ a tree-based model to learn explicit decision rules (aka. cross features) from the rich side information. We next design an embedding model that can incorporate explicit cross features and generalize to unseen cross features on user ID and item ID. At the core of our embedding method is an easy-to-interpret attention network, making the recommendation process fully transparent and explainable. We conduct experiments on two datasets of tourist attraction and restaurant recommendation, demonstrating the superior performance and explainability of our solution.},
  acmid     = {3186066},
  comment   = {GBDT trees get cross features
attention net, attention weight -> cross feature coefficients},
  doi       = {10.1145/3178876.3186066},
  isbn      = {978-1-4503-5639-8},
  keywords  = {embedding-based model, explainable recommendation, neural attention network, tree-based model},
  location  = {Lyon, France},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3178876.3186066},
}

@Article{Zhang2018Explainable,
  author   = {Zhang, Yongfeng and Chen, Xu},
  title    = {Explainable Recommendation: A Survey and New Perspectives},
  journal  = {arXiv preprint arXiv:1804.11192},
  year     = {2018},
  abstract = {Explainable Recommendation refers to the personalized recommendation algorithms that address the problem of why -- they not only provide the user with the recommendations, but also make the user aware why such items are recommended by generating recommendation explanations, which help to improve the effectiveness, efficiency, persuasiveness, and user satisfaction of recommender systems. In recent years, a large number of explainable recommendation approaches -- especially model-based explainable recommendation algorithms -- have been proposed and adopted in real-world systems. 
In this survey, we review the work on explainable recommendation that has been published in or before the year of 2018. We first high-light the position of explainable recommendation in recommender system research by categorizing recommendation problems into the 5W, i.e., what, when, who, where, and why. We then conduct a comprehensive survey of explainable recommendation itself in terms of three aspects: 1) We provide a chronological research line of explanations in recommender systems, including the user study approaches in the early years, as well as the more recent model-based approaches. 2) We provide a taxonomy for explainable recommendation algorithms, including user-based, item-based, model-based, and post-model explanations. 3) We summarize the application of explainable recommendation in different recommendation tasks, including product recommendation, social recommendation, POI recommendation, etc. We devote a chapter to discuss the explanation perspectives in the broader IR and machine learning settings, as well as their relationship with explainable recommendation research. We end the survey by discussing potential future research directions to promote the explainable recommendation research area.},
  comment  = {different forms of explanations
user-based, item-based
content-based ( feature, visualization)  
textual 
visual
social
hybrid

model:
matrix factorization
graph based
deep learning
knowledge based embedding
data mining
post hoc (not relevant to algorithm)
},
}

@InBook{Tintarev2011Designinga,
  pages     = {479--510},
  title     = {Designing and Evaluating Explanations for Recommender Systems},
  publisher = {Springer US},
  year      = {2011},
  author    = {Tintarev, Nava and Masthoff, Judith},
  editor    = {Ricci, Francesco and Rokach, Lior and Shapira, Bracha and Kantor, Paul B.},
  address   = {Boston, MA},
  isbn      = {978-0-387-85820-3},
  abstract  = {This chapter gives an overview of the area of explanations in recommender systems. We approach the literature from the angle of evaluation: that is, we are interested in what makes an explanation ``good'', and suggest guidelines as how to best evaluate this. We identify seven benefits that explanations may contribute to a recommender system, and relate them to criteria used in evaluations of explanations in existing systems, and how these relate to evaluations with live recommender systems. We also discuss how explanations can be affected by how recommendations are presented, and the role the interaction with the recommender system plays w.r.t. explanations. Finally, we describe a number of explanation styles, and how they may be related to the underlying algorithms. Examples of explanations in existing systems are mentioned throughout.},
  booktitle = {Recommender Systems Handbook},
  comment   = {goals: 
transparency
scrutability
trust
effectiveness
persuasiveness
efficiency
satisfaction},
  doi       = {10.1007/978-0-387-85820-3_15},
  url       = {https://doi.org/10.1007/978-0-387-85820-3_15},
}

@InBook{Yoo2011Creatinga,
  pages     = {455--477},
  title     = {Creating More Credible and Persuasive Recommender Systems: The Influence of Source Characteristics on Recommender System Evaluations},
  publisher = {Springer US},
  year      = {2011},
  author    = {Yoo, Kyung-Hyan and Gretzel, Ulrike},
  editor    = {Ricci, Francesco and Rokach, Lior and Shapira, Bracha and Kantor, Paul B.},
  address   = {Boston, MA},
  isbn      = {978-0-387-85820-3},
  abstract  = {Whether users are likely to accept the recommendations provided by a recommender system is of utmost importance to system designers and the marketers who implement them. By conceptualizing the advice seeking and giving relationship as a fundamentally social process, important avenues for understanding the persuasiveness of recommender systems open up. Specifically, research regarding the influence of source characteristics, which is abundant in the context of humanhuman relationships, can provide an important framework for identifying potential influence factors. This chapter reviews the existing literature on source characteristics in the context of human-human, human-computer, and human-recommender system interactions. It concludes that many social cues that have been identified as influential in other contexts have yet to be implemented and tested with respect to recommender systems. Implications for recommender system research and design are discussed.},
  booktitle = {Recommender Systems Handbook},
  comment   = {persuasiveness related to trust },
  doi       = {10.1007/978-0-387-85820-3_14},
  url       = {https://doi.org/10.1007/978-0-387-85820-3_14},
}

@InProceedings{Chen2018Neural,
  author    = {Chen, Chong and Zhang, Min and Liu, Yiqun and Ma, Shaoping},
  title     = {Neural Attentional Rating Regression with Review-level Explanations},
  booktitle = {Proceedings of the 2018 World Wide Web Conference},
  year      = {2018},
  series    = {WWW '18},
  pages     = {1583--1592},
  address   = {Republic and Canton of Geneva, Switzerland},
  publisher = {International World Wide Web Conferences Steering Committee},
  abstract  = {Reviews information is dominant for users to make online purchasing decisions in e-commerces. However, the usefulness of reviews is varied. We argue that less-useful reviews hurt model's performance, and are also less meaningful for user's reference. While some existing models utilize reviews for improving the performance of recommender systems, few of them consider the usefulness of reviews for recommendation quality. In this paper, we introduce a novel attention mechanism to explore the usefulness of reviews, and propose a Neural Attentional Regression model with Review-level Explanations (NARRE) for recommendation. Specifically, NARRE can not only predict precise ratings, but also learn the usefulness of each review simultaneously. Therefore, the highly-useful reviews are obtained which provide review-level explanations to help users make better and faster decisions. Extensive experiments on benchmark datasets of Amazon and Yelp on different domains show that the proposed NARRE model consistently outperforms the state-of-the-art recommendation approaches, including PMF, NMF, SVD++, HFT, and DeepCoNN in terms of rating prediction, by the proposed attention model that takes review usefulness into consideration. Furthermore, the selected reviews are shown to be effective when taking existing review-usefulness ratings in the system as ground truth. Besides, crowd-sourcing based evaluations reveal that in most cases, NARRE achieves equal or even better performances than system's usefulness rating method in selecting reviews. And it is flexible to offer great help on the dominant cases in real e-commerce scenarios when the ratings on review-usefulness are not available in the system.},
  acmid     = {3186070},
  comment   = {latent factor model
CNN text processor: input: a sequence of words, outputs a n-dimensional vector representation for the input
first layer, word embedding learnt from any pre-trained embeddings
second layer: convolutional layer, m neurons, each associated with a filter which produces features by applying convolution operator on word vectors
max pooling to capture the most important feature 
output concatenation of the output from its m neurons
passes to a fully connected layer

goal is to select both useful and representative reviews as well as predicting ratings
consists a user modeling and an item modeling

e.g. in item modeling, first every review is transformed to a text matrix
convolutional layer
attentional layer for weighing each review

finally, interaction between user and item modeled by inner product 

loss function: square loss rating},
  doi       = {10.1145/3178876.3186070},
  isbn      = {978-1-4503-5639-8},
  keywords  = {explainable recommendation, neural attention network, recommender systems, review usefulness},
  location  = {Lyon, France},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3178876.3186070},
}

@InProceedings{He2017Neural,
  author    = {He, Xiangnan and Chua, Tat-Seng},
  title     = {Neural Factorization Machines for Sparse Predictive Analytics},
  booktitle = {Proceedings of the 40th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year      = {2017},
  series    = {SIGIR '17},
  pages     = {355--364},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Many predictive tasks of web applications need to model categorical variables, such as user IDs and demographics like genders and occupations. To apply standard machine learning techniques, these categorical predictors are always converted to a set of binary features via one-hot encoding, making the resultant feature vector highly sparse. To learn from such sparse data effectively, it is crucial to account for the interactions between features.

Factorization Machines (FMs) are a popular solution for efficiently using the second-order feature interactions. However, FM models feature interactions in a linear way, which can be insufficient for capturing the non-linear and complex inherent structure of real-world data. While deep neural networks have recently been applied to learn non-linear feature interactions in industry, such as the Wide&Deep by Google and DeepCross by Microsoft, the deep structure meanwhile makes them difficult to train.

In this paper, we propose a novel model Neural Factorization Machine (NFM) for prediction under sparse settings. NFM seamlessly combines the linearity of FM in modelling second-order feature interactions and the non-linearity of neural network in modelling higher-order feature interactions. Conceptually, NFM is more expressive than FM since FM can be seen as a special case of NFM without hidden layers. Empirical results on two regression tasks show that with one hidden layer only, NFM significantly outperforms FM with a 7.3% relative improvement. Compared to the recent deep learning methods Wide&Deep and DeepCross, our NFM uses a shallower structure but offers better performance, being much easier to train and tune in practice.},
  acmid     = {3080777},
  comment   = {NFM: real valued feature vector sparse, zero means no feature
target = linear regression part + feature interactions f(x)

embedding layer: fully connected
embedding vecotr for each feature  x_i v_i 
bi-interaction layer: pooling : element wise product 
hidden layer: z a stack of  (multiple)fully connected layers, with weights , activation function non-linear 
prediction layer: output the transformed h^Tz_final layer

},
  doi       = {10.1145/3077136.3080777},
  isbn      = {978-1-4503-5022-8},
  keywords  = {deep learning, factorization machines, neural networks, recommendation, regression, sparse data},
  location  = {Shinjuku, Tokyo, Japan},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/3077136.3080777},
}

@InProceedings{Zaheer2016Exponential,
  author    = {Zaheer, Manzil and Wick, Michael and Tristan, Jean-Baptiste and Smola, Alex and Steele, Guy},
  title     = {Exponential stochastic cellular automata for massively parallel inference},
  booktitle = {Artificial Intelligence and Statistics},
  year      = {2016},
  pages     = {966--975},
  abstract  = {We propose an embarrassingly parallel, memory efficient inference algorithm for latent variable models in which the complete data likelihood is in the exponential family. The algorithm is a stochastic cellular automaton and converges to a valid maximum a posteriori fixed point. Applied to latent Dirichlet allocation we find that our algorithm is over an order or magnitude faster than the fastest current approaches. A simple C++/MPI implementation on a 20-node Amazon EC2 cluster samples at more than 1 billion tokens per second. We process 3 billion documents and achieve predictive power competitive with collapsed Gibbs sampling and variational inference.},
  comment   = {only applies for exponential family

sufficient moment 
stochastic EM sample z which is dependent on the sufficient statistics

keep two copies 
for all cell z independently in parrallel do 
read sufficient statistics from copy round mod s
compute stochastic updates using stochastic EM
write sufficient statistics to copy round mod 2 + 1},
}

@InProceedings{Abdollahi2017Using,
  author    = {Abdollahi, Behnoush and Nasraoui, Olfa},
  title     = {Using Explainability for Constrained Matrix Factorization},
  booktitle = {Proceedings of the Eleventh ACM Conference on Recommender Systems},
  year      = {2017},
  series    = {RecSys '17},
  pages     = {79--83},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Accurate model-based Collaborative Filtering (CF) approaches, such as Matrix Factorization (MF), tend to be black-box machine learning models that lack interpretability and do not provide a straightforward explanation for their outputs. Yet explanations have been shown to improve the transparency of a recommender system by justifying recommendations, and this in turn can enhance the user's trust in the recommendations. Hence, one main challenge in designing a recommender system is mitigating the trade-off between an explainable technique with moderate prediction accuracy and a more accurate technique with no explainable recommendations. In this paper, we focus on factorization models and further assume the absence of any additional data source, such as item content or user attributes. We propose an explainability constrained MF technique that computes the top-n recommendation list from items that are explainable. Experimental results show that our method is effective in generating accurate and explainable recommendations.},
  acmid     = {3109913},
  comment   = {neighbor style explanation how many similar users rate

empirical density distribution of the similar users' ratings on the recommended item
explainability graph  user and item explainability
as a regularizer in MF},
  doi       = {10.1145/3109859.3109913},
  isbn      = {978-1-4503-4652-8},
  keywords  = {explanations, interpretable models, latent factor models, matrix factorization, recommender systems},
  location  = {Como, Italy},
  numpages  = {5},
  url       = {http://doi.acm.org/10.1145/3109859.3109913},
}

@InProceedings{See2017Get,
  author    = {See, Abigail and Liu, Peter J and Manning, Christopher D},
  title     = {Get To The Point: Summarization with Pointer-Generator Networks},
  booktitle = {Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  year      = {2017},
  volume    = {1},
  pages     = {1073--1083},
  abstract  = {Neural sequence-to-sequence models have provided a viable new approach for abstractive text summarization (meaning they are not restricted to simply selecting and rearranging passages from the original text). However, these models have two shortcomings: they are liable to reproduce factual details inaccurately, and they tend to repeat themselves. In this work we propose a novel architecture that augments the standard sequence-to-sequence attentional model in two orthogonal ways. First, we use a hybrid pointer-generator network that can copy words from the source text via pointing, which aids accurate reproduction of information, while retaining the ability to produce novel words through the generator. Second, we use coverage to keep track of what has been summarized, which discourages repetition. We apply our model to the CNN / Daily Mail summarization task, outperforming the current abstractive state-of-the-art by at least 2 ROUGE points.},
  comment   = {sequence-to-sequence attentional model
on each step t, decoder's input word embedding of the previous word(reference summary)
decoder state st
attention distribution 
output attention over encoder hidden states
concatenation to two linear layers to produce the vocabularory

pointer-generator network
timestep t, generate a probability of hidden context, state and decoder state , decoder input and bias
vocabulary: p generate vocab + (1- p generate) attention 
},
}

@InProceedings{Ifada2014Tensor,
  author    = {Ifada, Noor and Nayak, Richi},
  title     = {Tensor-based Item Recommendation Using Probabilistic Ranking in Social Tagging Systems},
  booktitle = {Proceedings of the 23rd International Conference on World Wide Web},
  year      = {2014},
  series    = {WWW '14 Companion},
  pages     = {805--810},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {A common problem with the use of tensor modeling in generating quality recommendations for large datasets is scalability. In this paper, we propose the Tensor-based Recommendation using Probabilistic Ranking method that generates the reconstructed tensor using block-striped parallel matrix multiplication and then probabilistically calculates the preferences of user to rank the recommended items. Empirical analysis on two real-world datasets shows that the proposed method is scalable for large tensor datasets and is able to outperform the benchmarking methods in terms of accuracy.},
  acmid     = {2579243},
  comment   = {user dimension, item dimension, tag dimension, tensor
tucker decomposition 
a core tensor and three factor matrices 
core tensor px q xr
factor matrices uxp, I x q, Tx R

ranking to give recommendation, 
two lists are created for each user, item list Zu and tag list Xu
p(Zu|Xu) Naive Bayes p(i|Xu)
},
  doi       = {10.1145/2567948.2579243},
  isbn      = {978-1-4503-2745-9},
  keywords  = {folksonomy, item recommendation, probabilistic ranking, social tagging systems, tensor model},
  location  = {Seoul, Korea},
  numpages  = {6},
  url       = {http://doi.acm.org/10.1145/2567948.2579243},
}

@Article{Moe2012Online,
  author    = {Moe, Wendy W and Schweidel, David A},
  title     = {Online product opinions: Incidence, evaluation, and evolution},
  journal   = {Marketing Science},
  year      = {2012},
  volume    = {31},
  number    = {3},
  pages     = {372--386},
  abstract  = {Whereas recent research has demonstrated the impact of online product ratings and reviews on product sales, we still have a limited understanding of the individual's decision to contribute these opinions. In this research, we empirically model the individual's decision to provide a product rating and investigate factors that influence this decision. Specifically, we consider how previously posted ratings may affect an individual's posting behavior in terms of whether to contribute (incidence) and what to contribute (evaluation), and we identify selection effects that influence the incidence decision and adjustment effects that influence the evaluation decision. Across individuals, our results show that positive ratings environments increase posting incidence, whereas negative ratings environments discourage posting. Our results also indicate important differences across individuals in how they respond to previously posted ratings, with less frequent posters exhibiting bandwagon behavior and more active customers revealing differentiation behavior. These dynamics affect the evolution of online product opinions. Through simulations, we illustrate how the evolution of posted product opinions is shaped by the underlying customer base and show that customer bases with the same median opinion may evolve in substantially different ways because of the presence of a core group of "activists" posting increasingly negative opinions.},
  comment   = {conceptual model of the consumer rating process
prepurchase evaluation
purchase decision and product experience
postpurchase evaluation
indicendence decision -> evaluation decision
posted product ratings},
  publisher = {INFORMS},
  timestamp = {2018-07-30},
}

@InProceedings{Lakkaraju2017Selective,
  author    = {Lakkaraju, Himabindu and Kleinberg, Jon and Leskovec, Jure and Ludwig, Jens and Mullainathan, Sendhil},
  title     = {The Selective Labels Problem: Evaluating Algorithmic Predictions in the Presence of Unobservables},
  booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year      = {2017},
  series    = {KDD '17},
  pages     = {275--284},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Evaluating whether machines improve on human performance is one of the central questions of machine learning. However, there are many domains where the data is selectively labeled, in the sense that the observed outcomes are themselves a consequence of the existing choices of the human decision-makers. For instance, in the context of judicial bail decisions, we observe the outcome of whether a defendant fails to return for their court appearance only if the human judge decides to release the defendant on bail. This selective labeling makes it harder to evaluate predictive models as the instances for which outcomes are observed do not represent a random sample of the population. Here we propose a novel framework for evaluating the performance of predictive models on selectively labeled data. We develop an approach called contraction which allows us to compare the performance of predictive models and human decision-makers without resorting to counterfactual inference. Our methodology harnesses the heterogeneity of human decision-makers and facilitates effective evaluation of predictive models even in the presence of unmeasured confounders (unobservables) which influence both human decisions and the resulting outcomes. Experimental results on real world datasets spanning diverse domains such as health care, insurance, and criminal justice demonstrate the utility of our evaluation metric in comparing human decisions and machine predictions.},
  acmid     = {3098066},
  comment   = {problem formulation
input= data+ model
data: including observed feature and unobserved feature (they are accessible to human judges), labels (yes, no, NA),  response (whether or not the human decision maker makes a decision)
if respond, the label should be either 0/1

black box predictive model
problem is to evaluate the model performance

framework
acceptance rate = make a yes response
failure rate = undesirable label ratio,
i.e. 100 defendants, releases 70, 20 commit crimes
failure rate = 0.2, accptance rate = 0.7

compare the black box model with the human judge, be forcing the acceptance rate of the model to be the same as that of the judge and measuring the corresponding failure rate.
however, because of the missing labels, failure rate can not be determined

solution
contraction， 
pick the most (this is another judge) lenient judge who made the most responses, detain the instances with highest risk by the model to obtain an equal number of responses for the judge to be compared
so the outcomes of labels are all observed},
  doi       = {10.1145/3097983.3098066},
  isbn      = {978-1-4503-4887-4},
  keywords  = {evaluating machine learning algorithms, selective labels, unmeasured confounders, unobservables},
  location  = {Halifax, NS, Canada},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/3097983.3098066},
}

@InProceedings{Cheng2017Learning,
  author    = {Cheng, Peizhe and Wang, Shuaiqiang and Ma, Jun and Sun, Jiankai and Xiong, Hui},
  title     = {Learning to Recommend Accurate and Diverse Items},
  booktitle = {Proceedings of the 26th International Conference on World Wide Web},
  year      = {2017},
  series    = {WWW '17},
  pages     = {183--192},
  address   = {Republic and Canton of Geneva, Switzerland},
  publisher = {International World Wide Web Conferences Steering Committee},
  abstract  = {In this study, we investigate diversified recommendation problem by supervised learning, seeking significant improvement in diversity while maintaining accuracy. In particular, we regard each user as a training instance, and heuristically choose a subset of accurate and diverse items as ground-truth for each user. We then represent each user or item as a vector resulted from the factorization of the user-item rating matrix. In our paper, we try to discover a factorization for matching the following supervised learning task. In doing this, we define two coupled optimization problems, parameterized matrix factorization and structural learning, to formulate our task. And we propose a diversified collaborative filtering algorithm (DCF) to solve the coupled problems. We also introduce a new pairwise accuracy metric and a normalized topic coverage diversity metric to measure the performance of accuracy and diversity respectively. Extensive experiments on benchmark datasets show the performance gains of DCF in comparison with the state-of-the-art algorithms.},
  acmid     = {3052585},
  comment   = {problem: input rating data, output accurate and diversified items

model:structural SVM 

rating -> r = uSv, s = diagonal matrix of parameters
boundary w^T (\phi(x)-\phi(x')) \geq loss (pair)
x x' pairwise,
x positive samples, (1) filter high rated > average user-specific rating, controlled by a parameter \gamma (2) greedily choose l items maximizing the F-measure, w.r.t. accuracy and diversity
x' other rated items
\phi(x) feature vectors including rating approximation differences, item , regularizers and L1 regularizers

},
  doi       = {10.1145/3038912.3052585},
  isbn      = {978-1-4503-4913-0},
  keywords  = {collaborative filtering, diversity, recommender systems, structural svm},
  location  = {Perth, Australia},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3038912.3052585},
}

@InProceedings{Koyejo2013Retargeted,
  author    = {Koyejo, Oluwasanmi and Acharyya, Sreangsu and Ghosh, Joydeep},
  title     = {Retargeted Matrix Factorization for Collaborative Filtering},
  booktitle = {Proceedings of the 7th ACM Conference on Recommender Systems},
  year      = {2013},
  series    = {RecSys '13},
  pages     = {49--56},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {The ranking quality at the top of the list is crucial in many real-world applications of recommender systems. In this paper, we present a novel framework that allows for pointwise as well as listwise training with respect to various ranking metrics. This is based on a training objective function where we assume that, for given a user, the recommender system predicts scores for all items that follow approximately a Gaussian distribution. We motivate this assumption from the properties of implicit feedback data. As a model, we use matrix factorization and extend it by non-linear activation functions, as customary in the literature of artificial neural networks. In particular, we use non-linear activation functions derived from our Gaussian assumption. Our preliminary experimental results show that this approach is competitive with state-of-the-art methods with respect to optimizing the Area under the ROC curve, while it is particularly effective in optimizing the head of the ranked list.},
  acmid     = {2507185},
  comment   = {1 },
  doi       = {10.1145/2507157.2507185},
  isbn      = {978-1-4503-2409-0},
  keywords  = {collaborative filtering, learning to rank, matrix factorization},
  location  = {Hong Kong, China},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/2507157.2507185},
}

@InProceedings{Steck2015Gaussian,
  author    = {Steck, Harald},
  title     = {Gaussian Ranking by Matrix Factorization},
  booktitle = {Proceedings of the 9th ACM Conference on Recommender Systems},
  year      = {2015},
  series    = {RecSys '15},
  pages     = {115--122},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {The ranking quality at the top of the list is crucial in many real-world applications of recommender systems. In this paper, we present a novel framework that allows for pointwise as well as listwise training with respect to various ranking metrics. This is based on a training objective function where we assume that, for given a user, the recommender system predicts scores for all items that follow approximately a Gaussian distribution. We motivate this assumption from the properties of implicit feedback data. As a model, we use matrix factorization and extend it by non-linear activation functions, as customary in the literature of artificial neural networks. In particular, we use non-linear activation functions derived from our Gaussian assumption. Our preliminary experimental results show that this approach is competitive with state-of-the-art methods with respect to optimizing the Area under the ROC curve, while it is particularly effective in optimizing the head of the ranked list.},
  acmid     = {2800185},
  comment   = {SVD++
user = neighbor items vector (another parameter space)
latent item vector

NN interpretation

ranking loss 
derivative of the ranking loss can be decomposed to 
derivative wrt to the ranking
ranking wrt to normalized score, which is a probit function, if the score is Gaussian distributed. is a hinge loss if it is a linear function
normalized score wrt to  score, 1/std_u for each user
score to parameter

loss wrt to rank
 AUC = 1/N+N_ [(N+1) N+ - C2(N++1) - \sum r+]
NDCG = \sum 1/log (r++1)

},
  doi       = {10.1145/2792838.2800185},
  isbn      = {978-1-4503-3692-5},
  keywords  = {collaborative filtering, learning to rank, matrix factorization, recommender systems},
  location  = {Vienna, Austria},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/2792838.2800185},
}

@InProceedings{Hu2017Decoupled,
  author    = {Hu, Jun and Li, Ping},
  title     = {Decoupled Collaborative Ranking},
  booktitle = {Proceedings of the 26th International Conference on World Wide Web},
  year      = {2017},
  series    = {WWW '17},
  pages     = {1321--1329},
  address   = {Republic and Canton of Geneva, Switzerland},
  publisher = {International World Wide Web Conferences Steering Committee},
  abstract  = {We propose a new pointwise collaborative ranking approach for recommender systems, which focuses on improving ranking performance at the top of recommended list. Our approach is different from common pointwise methods in that we consider user ratings as ordinal rather than viewing them as real values or categorical labels. In addition, positively rated items (higher rating scores) are emphasized more in our method in order to improve the performance at the top of recommended list.

In our method, user ratings are modeled based on an ordinal classification framework, which is made up of a sequence of binary classification problems in which one discriminates between ratings no less than a specific ordinal category c and ratings below that category ({̥ c}vs.{< c}). The results are used subsequently to generate a ranking score that puts higher weights on the output of those binary classification problems concerning high values of c so as to improve the ranking performance at the top of list. As our method crucially builds on a decomposition into binary classification problems, we call our proposed method as Decoupled Collaborative Ranking (DCR). As an extension, we impose pairwise learning on DCR, which yields further improvement with regard to the ranking performance of the proposed method. We demonstrate through extensive experiments on benchmark datasets that our method outperforms many considered state-of-the-art collaborative ranking algorithms in terms of the NDCG metric.},
  acmid     = {3052685},
  comment   = {rating = ordinal categorical labels
s-level rating matrix -> S ordinal binary categorical matrix

for each binary matrix R=UV
p(r=1)=uv+1/2, wrt, |u|\leq 1, |v|\leq 1
maximal log likelihood 

from binary classification to ranking: 
SC_{ui}=\sum t f(t)P(r_{ui}=t)
where f(t) is the score relevance

P(r_{ui}=t)=p(r_{ui}\geq t)- p(r_{ui}\geq t+1)

for topN recommendation, f(t) is a monotone increasing function of relevance level t

extension: loss = Indicator g(u,i,j)
g(u,i,j)=SC_{ui}-SC{uj}},
  doi       = {10.1145/3038912.3052685},
  isbn      = {978-1-4503-4913-0},
  keywords  = {collaborative ranking, matrix factorization, recommender systems},
  location  = {Perth, Australia},
  numpages  = {9},
  timestamp = {2018-08-03},
  url       = {https://doi.org/10.1145/3038912.3052685},
}

@InProceedings{Christakopoulou2015Collaborative,
  author    = {Christakopoulou, Konstantina and Banerjee, Arindam},
  title     = {Collaborative Ranking with a Push at the Top},
  booktitle = {Proceedings of the 24th International Conference on World Wide Web},
  year      = {2015},
  series    = {WWW '15},
  pages     = {205--215},
  address   = {Republic and Canton of Geneva, Switzerland},
  publisher = {International World Wide Web Conferences Steering Committee},
  abstract  = {The goal of collaborative filtering is to get accurate recommendations at the top of the list for a set of users. From such a perspective, collaborative ranking based formulations with suitable ranking loss functions are natural. While recent literature has explored the idea based on objective functions such as NDCG or Average Precision, such objectives are difficult to optimize directly. In this paper, building on recent advances from the learning to rank literature, we introduce a novel family of collaborative ranking algorithms which focus on accuracy at the top of the list for each user while learning the ranking functions collaboratively. We consider three specific formulations, based on collaborative p-norm push, infinite push, and reverse-height push, and propose efficient optimization methods for learning these models. Experimental results illustrate the value of collaborative ranking, and show that the proposed methods are competitive, usually better than existing popular approaches to personalized recommendation.},
  acmid     = {2741678},
  comment   = {height of a non-relevant item is the number of relevant examples ranked below it by the learned ranking function
so the goal is to make the heights of non-relevant items small
or height of the relevant items big (reverse height)

hight originally is the \sum [f(k+)\leq f(j-)]
make a difference, \delta (k,j) = f(k+)-f(j-)
the logistic loss of the difference as the surrogate 
and \delta=u(vk-vj)

objective = 
p-norm = the sum wrt negative of surrogate loss
infinite = max wrt negative
reverse = inverse log function 
},
  doi       = {10.1145/2736277.2741678},
  isbn      = {978-1-4503-3469-3},
  keywords  = {collaborative ranking, infinite push, recommender systems},
  location  = {Florence, Italy},
  numpages  = {11},
  url       = {https://doi.org/10.1145/2736277.2741678},
}

@InProceedings{Ritter2012Open,
  author    = {Ritter, Alan and Mausam and Etzioni, Oren and Clark, Sam},
  title     = {Open Domain Event Extraction from Twitter},
  booktitle = {Proceedings of the 18th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year      = {2012},
  series    = {KDD '12},
  pages     = {1104--1112},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Tweets are the most up-to-date and inclusive stream of in- formation and commentary on current events, but they are also fragmented and noisy, motivating the need for systems that can extract, aggregate and categorize important events. Previous work on extracting structured representations of events has focused largely on newswire text; Twitter's unique characteristics present new challenges and opportunities for open-domain event extraction. This paper describes TwiCal-- the first open-domain event-extraction and categorization system for Twitter. We demonstrate that accurately extracting an open-domain calendar of significant events from Twitter is indeed feasible. In addition, we present a novel approach for discovering important event categories and classifying extracted events based on latent variable models. By leveraging large volumes of unlabeled data, our approach achieves a 14% increase in maximum F1 over a supervised baseline. A continuously updating demonstration of our system can be viewed at http://statuscalendar.com; Our NLP tools are available at http://github.com/aritter/ twitter_nlp.},
  acmid     = {2339704},
  comment   = {system paper, Twical 
extracts a 4-tuple representation of events = a named entity, event phrase, calendar date, event type 

framework:
tweets-> POS Tag -> 1) temporal resolution (identify timestamps?) 2) NER (trained on in-domain tweets dataset )3) event tagger -> 1) significance ranking by measuring the strength of association between each NE and date based on the number of tweets they co-occur2) event classification (unsupervised)-> calendar entries for only significant events},
  doi       = {10.1145/2339530.2339704},
  isbn      = {978-1-4503-1462-6},
  keywords  = {information extraction, social media},
  location  = {Beijing, China},
  numpages  = {9},
  url       = {http://doi.acm.org/10.1145/2339530.2339704},
}

@Article{Hou2017Learning,
  author     = {Hou, Lei and Li, Juanzi and Li, Xiao-Li and Tang, Jie and Guo, Xiaofei},
  title      = {Learning to Align Comments to News Topics},
  journal    = {ACM Trans. Inf. Syst.},
  year       = {2017},
  volume     = {36},
  number     = {1},
  pages      = {9:1--9:31},
  month      = jul,
  issn       = {1046-8188},
  acmid      = {3072591},
  address    = {New York, NY, USA},
  articleno  = {9},
  comment    = {With the rapid proliferation of social media, increasingly more people express their opinions and reviews (user-generated content (UGC)) on recent news articles through various online services, such as news portals, forums, discussion groups, and microblogs. Clearly, identifying hot topics that users greatly care about can improve readers’ news browsing experience and facilitate research into interaction analysis between news and UGC. Furthermore, it is of great benefit to public opinion monitoring and management for both industry and government agencies. However, it is extremely time consuming, if not impossible, to manually examine the large amount of available social content. In this article, we formally define the news comment alignment problem and propose a novel framework that: (1) automatically extracts topics from a given news article and its associated comments, (2) identifies and extends positive examples with different degrees of confidence using three methods (i.e., hypersphere, density, and cluster chain), and (3) completes the alignment between news sentences and comments through a weighted-SVM classifier. Extensive experiments show that our proposed framework significantly outperforms state-of-the-art methods.},
  doi        = {10.1145/3072591},
  issue_date = {August 2017},
  keywords   = {User-generated content, alignment, cluster chain, density, dependent topic model, pu learning},
  numpages   = {31},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/3072591},
}

@Article{Broder2002Taxonomy,
  author     = {Broder, Andrei},
  title      = {A Taxonomy of Web Search},
  journal    = {SIGIR Forum},
  year       = {2002},
  volume     = {36},
  number     = {2},
  pages      = {3--10},
  month      = sep,
  issn       = {0163-5840},
  abstract   = {Classic IR (information retrieval) is inherently predicated on users searching for information, the so-called "information need". But the need behind a web search is often not informational -- it might be navigational (give me the url of the site I want to reach) or transactional (show me sites where I can perform a certain transaction, e.g. shop, download a file, or find a map). We explore this taxonomy of web searches and discuss how global search engines evolved to deal with web-specific needs.},
  acmid      = {792552},
  address    = {New York, NY, USA},
  doi        = {10.1145/792550.792552},
  issue_date = {Fall 2002},
  numpages   = {8},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/792550.792552},
}

@InProceedings{Ai2017Characterizing,
  author    = {Ai, Qingyao and Dumais, Susan T. and Craswell, Nick and Liebling, Dan},
  title     = {Characterizing Email Search Using Large-scale Behavioral Logs and Surveys},
  booktitle = {Proceedings of the 26th International Conference on World Wide Web},
  year      = {2017},
  series    = {WWW '17},
  pages     = {1511--1520},
  address   = {Republic and Canton of Geneva, Switzerland},
  publisher = {International World Wide Web Conferences Steering Committee},
  abstract  = {As the number of email users and messages continues to grow, search is becoming more important for finding information in personal archives. In spite of its importance, email search is much less studied than web search, particularly using large-scale behavioral log analysis. In this paper we report the results of a large-scale log analysis of email search and complement this with a survey to better understand email search intent and success. We characterize email search behaviors and highlight differences from web search. When searching for email, people know many attributes about what they are looking for; they often look for specific known items; their queries are shorter and they click on fewer items than in web search. Although repeat queries are common in both email and web search, repeat visits to the same search result are much less common in email search suggesting that the same query is used for different search intents over time. We consider search intent from multiple angles. In email search logs, we find that people use email search not just to find information but also to perform tasks such as cleanup or organization, and that the distribution of actions they perform depends on the type of query. In our survey, people reported that they looked for specific information in both email search and web search, but they were much less likely to search for general information on a topic in email. The differences in overall behavior, re-finding patterns and search intents we observed between email and web search have important implications for the design of email search algorithms and interfaces.},
  acmid     = {3052615},
  comment   = {a large-scale log analysis and a survey

, we define an email search session as a sequence of activities following a search query such that the gap be- tween successive actions is less than 10 minutes

Interactions on search result lists: query ID, internal message IDs of the results, and clicks within the re- sults.
• Interactions on messages: Open, reply, forward, delete, move, link click, open attachments, etc.

We first asked participants to describe in their own words what they were looking for. We then asked what the first query they used to search was, what they remembered about the email/page they were looking for, and why they were searching for the email/page. We asked about search success, the number of queries and the time to complete their search. To better understand re-finding behavior, we asked whether they had issued the query before and whether they had clicked the same re- sult before. Finally, we asked questions about their email and browser software, and optional demographic informa- tion (gender and age).

query intent
specific query need a certain email
specific query need other emails may serve too
general query need

distributions},
  doi       = {10.1145/3038912.3052615},
  isbn      = {978-1-4503-4913-0},
  keywords  = {email search, query log analysis, re-finding, user evaluation},
  location  = {Perth, Australia},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3038912.3052615},
}

@InProceedings{He2016Fast,
  author    = {He, Xiangnan and Zhang, Hanwang and Kan, Min-Yen and Chua, Tat-Seng},
  title     = {Fast Matrix Factorization for Online Recommendation with Implicit Feedback},
  booktitle = {Proceedings of the 39th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year      = {2016},
  series    = {SIGIR '16},
  pages     = {549--558},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {This paper contributes improvements on both the effectiveness and efficiency of Matrix Factorization (MF) methods for implicit feedback. We highlight two critical issues of existing works. First, due to the large space of unobserved feedback, most existing works resort to assign a uniform weight to the missing data to reduce computational complexity. However, such a uniform assumption is invalid in real-world settings. Second, most methods are also designed in an offline setting and fail to keep up with the dynamic nature of online data. We address the above two issues in learning MF models from implicit feedback. We first propose to weight the missing data based on item popularity, which is more effective and flexible than the uniform-weight assumption. However, such a non-uniform weighting poses efficiency challenge in learning the model. To address this, we specifically design a new learning algorithm based on the element-wise Alternating Least Squares (eALS) technique, for efficiently optimizing a MF model with variably-weighted missing data. We exploit this efficiency to then seamlessly devise an incremental update strategy that instantly refreshes a MF model given new feedback. Through comprehensive experiments on two public datasets in both offline and online protocols, we show that our implemented, open-source (https://github.com/hexiangnan/sigir16-eals) eALS consistently outperforms state-of-the-art implicit MF methods.},
  acmid     = {2911489},
  comment   = {MF 
weighted regression function, which associates a confidence to each prediction in the implicit feedback matrix R
missing entries are usually assigned to a zero rui value but non-zero wui weight

Alternating Least Square (derivative = zero ) involves matrix inversion 
previous study sets missing weight to be uniform (same )
element wise ALS more efficient by avoiding matrix inversion

it is desired to assign a higher weight to the negative feedback
the first term denotes the prediction error of the observed entries, The second term accounts for the miss- ing data with confidence related to item popularity
confidence of item i = c_o (base coefficient ) popularity of this item ^ power of \alpha / \sum_ all items popularity of item^ power of \alpha

good explanation on why negative sampling underperforms for BPR, due to SGD
eALS avoids this by exact optimization},
  doi       = {10.1145/2911451.2911489},
  isbn      = {978-1-4503-4069-4},
  keywords  = {ALS, coordinate descent, implicit feedback, item recommendation, matrix factorization, online learning},
  location  = {Pisa, Italy},
  numpages  = {10},
  timestamp = {2018-08-07},
  url       = {http://doi.acm.org/10.1145/2911451.2911489},
}

@InProceedings{Zhang2017Modeling,
  author    = {Zhang, Xiaoying and Zhao, Junzhou and Lui, John C.S.},
  title     = {Modeling the Assimilation-Contrast Effects in Online Product Rating Systems: Debiasing and Recommendations},
  booktitle = {Proceedings of the Eleventh ACM Conference on Recommender Systems},
  year      = {2017},
  series    = {RecSys '17},
  pages     = {98--106},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {The unbiasedness of online product ratings, an important property to ensure that users' ratings indeed reflect their true evaluations to products, is vital both in shaping consumer purchase decisions and providing reliable recommendations. Recent experimental studies showed that distortions from historical ratings would ruin the unbiasedness of subsequent ratings. How to "discover" the distortions from historical ratings in each single rating (or at the micro-level), and perform the "debiasing operations" in real rating systems are the main objectives of this work.
Using 42 million real customer ratings, we first show that users either "assimilate" or "contrast" to historical ratings under different scenarios: users conform to historical ratings if historical ratings are not far from the product quality (assimilation), while users deviate from historical ratings if historical ratings are significantly different from the product quality (contrast). This phenomenon can be explained by the well-known psychological argument: the "Assimilate-Contrast" theory. However, none of the existing works on modeling historical ratings' influence have taken this into account, and this motivates us to propose the Historical Influence Aware Latent Factor Model (HIALF), the first model for real rating systems to capture and mitigate historical distortions in each single rating. HIALF also allows us to study the influence patterns of historical ratings from a modeling perspective, and it perfectly matches the assimilation and contrast effects we previously observed. Also, HIALF achieves significant improvements in predicting subsequent ratings, and accurately predicts the relationships revealed in previous empirical measurements on real ratings. Finally, we show that HIALF can contribute to better recommendations by decoupling users' real preference from distorted ratings, and reveal the intrinsic product quality for wiser consumer purchase decisions.},
  acmid     = {3109885},
  comment   = {biases in rating},
  doi       = {10.1145/3109859.3109885},
  isbn      = {978-1-4503-4652-8},
  keywords  = {modeling and debiasing historical ratings' influence, recommender systems},
  location  = {Como, Italy},
  numpages  = {9},
  url       = {http://doi.acm.org/10.1145/3109859.3109885},
}

@InProceedings{Rendle2014Improving,
  author    = {Rendle, Steffen and Freudenthaler, Christoph},
  title     = {Improving Pairwise Learning for Item Recommendation from Implicit Feedback},
  booktitle = {Proceedings of the 7th ACM International Conference on Web Search and Data Mining},
  year      = {2014},
  series    = {WSDM '14},
  pages     = {273--282},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Pairwise algorithms are popular for learning recommender systems from implicit feedback. For each user, or more generally context, they try to discriminate between a small set of selected items and the large set of remaining (irrelevant) items. Learning is typically based on stochastic gradient descent (SGD) with uniformly drawn pairs. In this work, we show that convergence of such SGD learning algorithms slows down considerably if the item popularity has a tailed distribution. We propose a non-uniform item sampler to overcome this problem. The proposed sampler is context-dependent and oversamples informative pairs to speed up convergence. An efficient implementation with constant amortized runtime costs is developed. Furthermore, it is shown how the proposed learning algorithm can be applied to a large class of recommender models. The properties of the new learning algorithm are studied empirically on two real-world recommender system problems. The experiments indicate that the proposed adaptive sampler improves the state-of-the art learning algorithm largely in convergence without negative effects on prediction quality or iteration runtime.},
  acmid     = {2556248},
  comment   = {
apply it to MF and FM (factorization machines)},
  doi       = {10.1145/2556195.2556248},
  isbn      = {978-1-4503-2351-2},
  keywords  = {factorization model, item recommendation, matrix factorization, recommender systems},
  location  = {New York, New York, USA},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/2556195.2556248},
}

@InProceedings{Shi2010List,
  author    = {Shi, Yue and Larson, Martha and Hanjalic, Alan},
  title     = {List-wise Learning to Rank with Matrix Factorization for Collaborative Filtering},
  booktitle = {Proceedings of the Fourth ACM Conference on Recommender Systems},
  year      = {2010},
  series    = {RecSys '10},
  pages     = {269--272},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {A ranking approach, ListRank-MF, is proposed for collaborative filtering that combines a list-wise learning-to-rank algorithm with matrix factorization (MF). A ranked list of items is obtained by minimizing a loss function that represents the uncertainty between training lists and output lists produced by a MF ranking model. ListRank-MF enjoys the advantage of low complexity and is analytically shown to be linear with the number of observed ratings for a given user-item matrix. We also experimentally demonstrate the effectiveness of ListRank-MF by comparing its performance with that of item-based collaborative recommendation and a related state-of-the-art collaborative ranking approach (CoFiRank).},
  acmid     = {1864764},
  doi       = {10.1145/1864708.1864764},
  isbn      = {978-1-60558-906-0},
  keywords  = {collaborative filtering, learning to rank, matrix factorization, recommendation, recommender systems},
  location  = {Barcelona, Spain},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/1864708.1864764},
}

@InProceedings{Weston2011Wsabie,
  author    = {Weston, Jason and Bengio, Samy and Usunier, Nicolas},
  title     = {Wsabie: Scaling up to large vocabulary image annotation},
  booktitle = {IJCAI},
  year      = {2011},
  volume    = {11},
  pages     = {2764--2770},
}

@InProceedings{Zhang2013Optimizing,
  author    = {Zhang, Weinan and Chen, Tianqi and Wang, Jun and Yu, Yong},
  title     = {Optimizing Top-n Collaborative Filtering via Dynamic Negative Item Sampling},
  booktitle = {Proceedings of the 36th International ACM SIGIR Conference on Research and Development in Information Retrieval},
  year      = {2013},
  series    = {SIGIR '13},
  pages     = {785--788},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Collaborative filtering techniques rely on aggregated user preference data to make personalized predictions. In many cases, users are reluctant to explicitly express their preferences and many recommender systems have to infer them from implicit user behaviors, such as clicking a link in a webpage or playing a music track. The clicks and the plays are good for indicating the items a user liked (i.e., positive training examples), but the items a user did not like (negative training examples) are not directly observed. Previous approaches either randomly pick negative training samples from unseen items or incorporate some heuristics into the learning model, leading to a biased solution and a prolonged training period. In this paper, we propose to dynamically choose negative training samples from the ranked list produced by the current prediction model and iteratively update our model. The experiments conducted on three large-scale datasets show that our approach not only reduces the training time, but also leads to significant performance gains.},
  acmid     = {2484126},
  doi       = {10.1145/2484028.2484126},
  isbn      = {978-1-4503-2034-4},
  keywords  = {negative item sampling, ranking-oriented collaborative filtering, recommender systems},
  location  = {Dublin, Ireland},
  numpages  = {4},
  url       = {http://doi.acm.org/10.1145/2484028.2484126},
}

@InProceedings{Yu2016RankMBPR,
  author    = {Yu, Lu and Zhou, Ge and Zhang, Chuxu and Huang, Junming and Liu, Chuang and Zhang, Zi-Ke},
  title     = {RankMBPR: Rank-Aware Mutual Bayesian Personalized Ranking for Item Recommendation},
  booktitle = {Web-Age Information Management},
  year      = {2016},
  editor    = {Cui, Bin and Zhang, Nan and Xu, Jianliang and Lian, Xiang and Liu, Dexi},
  pages     = {244--256},
  address   = {Cham},
  publisher = {Springer International Publishing},
  abstract  = {Previous works indicated that pairwise methods are state-of- the-art approaches to fit users' taste from implicit feedback. In this paper, we argue that constructing item pairwise samples for a fixed user is insufficient, because taste differences between two users with respect to a same item can not be explicitly distinguished. Moreover, the rank position of positive items are not used as a metric to measure the learning magnitude in the next step. Therefore, we firstly define a confidence function to dynamically control the learning step-size for updating model parameters. Sequently, we introduce a generic way to construct mutual pairwise loss from both users' and items' perspective. Instead of user-oriented pairwise sampling strategy alone, we incorporate item pairwise samples into a popular pairwise learning framework, bayesian personalized ranking (BPR), and propose mutual bayesian personalized ranking (MBPR) method. In addition, a rank-aware adaptively sampling strategy is proposed to come up with the final approach, called RankMBPR. Empirical studies are carried out on four real-world datasets, and experimental results in several metrics demonstrate the efficiency and effectiveness of our proposed method, comparing with other baseline algorithms.},
  isbn      = {978-3-319-39937-9},
}

@Article{Liu2012Enhancing,
  author   = {Qi Liu and Enhong Chen and Hui Xiong and Chris H. Q. Ding and Jian Chen},
  title    = {Enhancing Collaborative Filtering by User Interest Expansion via Personalized Ranking},
  journal  = {IEEE TRANSACTIONS ON SYSTEMS, MAN, AND CYBERNETICS—PART B: CYBERNETICS},
  year     = {2012},
  volume   = {42},
  number   = {1},
  pages    = {218-233},
  abstract = {Recommender systems suggest a few items from many possible choices to the users by understanding their past behaviors. In these systems, the user behaviors are influenced by the hidden interests of the users. Learning to leverage the information about user interests is often critical for making better recommendations. However, existing collaborative-filtering-based recommender systems are usually focused on exploiting the in- formation about the user’s interaction with the systems; the in- formation about latent user interests is largely underexplored. To that end, inspired by the topic models, in this paper, we pro- pose a novel collaborative-filtering-based recommender system by user interest expansion via personalized ranking, named iExpand. The goal is to build an item-oriented model-based collaborative- filtering framework. The iExpand method introduces a three- layer, user–interests–item, representation scheme, which leads to more accurate ranking recommendation results with less compu- tation cost and helps the understanding of the interactions among users, items, and user interests. Moreover, iExpand strategically deals with many issues that exist in traditional collaborative- filtering approaches, such as the overspecialization problem and the cold-start problem. Finally, we evaluate iExpand on three benchmark data sets, and experimental results show that iExpand can lead to better ranking performance than state-of-the-art meth- ods with a significant margin.},
  comment  = {LDA+ pagerank for topic transition + topic item correlation},
}

@InProceedings{Lee2014Local,
  author    = {Lee, Joonseok and Bengio, Samy and Kim, Seungyeon and Lebanon, Guy and Singer, Yoram},
  title     = {Local Collaborative Ranking},
  booktitle = {Proceedings of the 23rd International Conference on World Wide Web},
  year      = {2014},
  series    = {WWW '14},
  pages     = {85--96},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Personalized recommendation systems are used in a wide variety of applications such as electronic commerce, social networks, web search, and more. Collaborative filtering approaches to recommendation systems typically assume that the rating matrix (e.g., movie ratings by viewers) is low-rank. In this paper, we examine an alternative approach in which the rating matrix is locally low-rank. Concretely, we assume that the rating matrix is low-rank within certain neighborhoods of the metric space defined by (user, item) pairs. We combine a recent approach for local low-rank approximation based on the Frobenius norm with a general empirical risk minimization for ranking losses. Our experiments indicate that the combination of a mixture of local low-rank matrices each of which was trained to minimize a ranking loss outperforms many of the currently used state-of-the-art recommendation systems. Moreover, our method is easy to parallelize, making it a viable approach for large scale real-world rank-based recommendation systems.},
  acmid     = {2567970},
  comment   = {pairwise ranking

local low rank + kernel},
  doi       = {10.1145/2566486.2567970},
  isbn      = {978-1-4503-2744-2},
  keywords  = {collaborative filtering, ranking, recommender systems},
  location  = {Seoul, Korea},
  numpages  = {12},
  url       = {http://doi.acm.org/10.1145/2566486.2567970},
}

@Article{Pan2015Adaptive,
  author    = {Pan, Weike and Zhong, Hao and Xu, Congfu and Ming, Zhong},
  title     = {Adaptive Bayesian personalized ranking for heterogeneous implicit feedbacks},
  journal   = {Knowledge-Based Systems},
  year      = {2015},
  volume    = {73},
  pages     = {173--180},
  comment   = {BPR++

sampling},
  publisher = {Elsevier},
}

@InProceedings{Tay2018Latent,
  author    = {Tay, Yi and Anh Tuan, Luu and Hui, Siu Cheung},
  title     = {Latent Relational Metric Learning via Memory-based Attention for Collaborative Ranking},
  booktitle = {Proceedings of the 2018 World Wide Web Conference},
  year      = {2018},
  series    = {WWW '18},
  pages     = {729--739},
  address   = {Republic and Canton of Geneva, Switzerland},
  publisher = {International World Wide Web Conferences Steering Committee},
  abstract  = {This paper proposes a new neural architecture for collaborative ranking with implicit feedback. Our model, LRML (Latent Relational Metric Learning) is a novel metric learning approach for recommendation. More specifically, instead of simple push-pull mechanisms between user and item pairs, we propose to learn latent relations that describe each user item interaction. This helps to alleviate the potential geometric inflexibility of existing metric learning approaches. This enables not only better performance but also a greater extent of modeling capability, allowing our model to scale to a larger number of interactions. In order to do so, we employ a augmented memory module and learn to attend over these memory blocks to construct latent relations. The memory-based attention module is controlled by the user-item interaction, making the learned relation vector specific to each user-item pair. Hence, this can be interpreted as learning an exclusive and optimal relational translation for each user-item interaction. The proposed architecture demonstrates the state-of-the-art performance across multiple recommendation benchmarks. LRML outperforms other metric learning models by 6%-7.5% in terms of Hits@10 and nDCG@10 on large datasets such as Netflix and MovieLens20M. Moreover, qualitative studies also demonstrate evidence that our proposed model is able to infer and encode explicit sentiment, temporal and attribute information despite being only trained on implicit feedback. As such, this ascertains the ability of LRML to uncover hidden relational structure within implicit datasets.},
  acmid     = {3186154},
  doi       = {10.1145/3178876.3186154},
  isbn      = {978-1-4503-5639-8},
  keywords  = {attention mechanism, collaborative ranking, deep learning, implicit feedback, information retrieval, neural networks, recommender system, collaborative filtering},
  location  = {Lyon, France},
  numpages  = {11},
  url       = {https://doi.org/10.1145/3178876.3186154},
}

@Article{Guo2016Personalized,
  author    = {Guo, Weiyu and Wu, Shu and Wang, Liang and Tan, Tieniu},
  title     = {Personalized ranking with pairwise Factorization Machines},
  journal   = {Neurocomputing},
  year      = {2016},
  volume    = {214},
  pages     = {191--200},
  abstract  = {Pairwise learning is a vital technique for personalized ranking with implicit feedback. Given the assumption that each user is more interested in items which have been previously se- lected by the user than the remaining ones, pairwise learning algorithms can well learn users’ preference, from not only the observed user feedbacks but also the underlying interactions between users and items. However, a mass of training instances are randomly derived ac- cording to such assumption, which makes the learning procedure often converge slowly and even result in poor predictive models. In addition, the cold start problem often perplexes pairwise learning methods, since most of traditional methods in personalized ranking only take explicit ratings or implicit feedbacks into consideration. For dealing with the above issues, this work proposes a novel personalized ranking model which incorporates implicit feedback with content information by making use of Factorization Machines. For efficiently estimating the parameters of the proposed model, we develop an adaptive sampler to draw informative training instances based on content information of users and items. The exper- imental results show that, our adaptive item sampler indeed can speed up our model, and our model outperforms advanced methods in personalized ranking.},
  comment   = {BPR
factorization machine: order 2 feature interactions
adaptive sampling},
  publisher = {Elsevier},
}

@Article{Tran2016Modelling,
  author    = {Tran, Truyen and Phung, Dinh and Venkatesh, Svetha},
  title     = {Modelling human preferences for ranking and collaborative filtering: a probabilistic ordered partition approach},
  journal   = {Knowledge and Information Systems},
  year      = {2016},
  volume    = {47},
  number    = {1},
  pages     = {157--188},
  month     = {Apr},
  issn      = {0219-3116},
  abstract  = {Learning preference models from human generated data is an important task in modern information processing systems. Its popular setting consists of simple input ratings, assigned with numerical values to indicate their relevancy with respect to a specific query. Since ratings are often specified within a small range, several objects may have the same ratings, thus creating ties among objects for a given query. Dealing with this phenomena presents a general problem of modelling preferences in the presence of ties and being query-specific. To this end, we present in this paper a novel approach by constructing probabilistic models directly on the collection of objects exploiting the combinatorial structure induced by the ties among them. The proposed probabilistic setting allows exploration of a super-exponential combinatorial state-space with unknown numbers of partitions and unknown order among them. Learning and inference in such a large state-space are challenging, and yet we present in this paper efficient algorithms to perform these tasks. Our approach exploits discrete choice theory, imposing generative process such that the finite set of objects is partitioned into subsets in a stagewise procedure, and thus reducing the state-space at each stage significantly. Efficient Markov chain Monte Carlo algorithms are then presented for the proposed models. We demonstrate that the model can potentially be trained in a large-scale setting of hundreds of thousands objects using an ordinary computer. In fact, in some special cases with appropriate model specification, our models can be learned in linear time. We evaluate the models on two application areas: (i) document ranking with the data from the Yahoo! challenge and (ii) collaborative filtering with movie data. We demonstrate that the models are competitive against state-of-the-arts.},
  day       = {01},
  doi       = {10.1007/s10115-015-0840-9},
  timestamp = {2018-08-18},
  url       = {https://doi.org/10.1007/s10115-015-0840-9},
}

@InProceedings{Sun2017MRLR,
  author    = {Sun, Zhu and Yang, Jie and Zhang, Jie and Bozzon, Alessandro and Chen, Yu and Xu, Chi},
  title     = {MRLR: multi-level representation learning for personalized ranking in recommendation},
  booktitle = {26th International Joint Conferences on Artificial Intelligence},
  year      = {2017},
  pages     = {2807--2813},
  abstract  = {Representation learning (RL) has recently proven to be effective in capturing local item relation- ships by modeling item co-occurrence in individual user’s interaction record. However, the value of RL for recommendation has not reached the full poten- tial due to two major drawbacks: 1) recommenda- tion is modeled as a rating prediction problem but should essentially be a personalized ranking one; 2) multi-level organizations of items are neglected for fine-grained item relationships. We design a uni- fied Bayesian framework MRLR to learn user and item embeddings from a multi-level item organiza- tion, thus benefiting from RL as well as achieving the goal of personalized ranking. Extensive valida- tion on real-world datasets shows that MRLR con- sistently outperforms state-of-the-art algorithms},
  comment   = { learn user and item embed- dings from both item co-rated relationships and user-specific ranked lists of items

maximizing the following posterior probability, two components : item co-rated and personal ranking

co-rated: soft max
personal ranking: soft max based on MF
category for item feature constraints
},
}

@InProceedings{Yu2018Walkranker,
  author       = {Yu, Lu and Zhang, Chuxu and Pei, Shichao and Sun, Guolei and Zhang, Xiangliang},
  title        = {Walkranker: A unified pairwise ranking model with multiple relations for item recommendation},
  year         = {2018},
  organization = {AAAI},
  abstract     = {Top-N item recommendation techniques, e.g., pairwise mod- els, learn the rank of users’ preferred items through separat- ing items into positive samples if user-item interactions ex- ist, and negative samples otherwise. This separation results in an important issue: the extreme imbalance between positive and negative samples, because the number of items with user actions is much less than those without actions. The prob- lem is even worse for “cold-start” users. In addition, existing learning models only consider the observed user-item prox- imity, while neglecting other useful relations, such as the un- observed but potentially helpful user-item relations, and high- order proximity in user-user, item-item relations. In this pa- per, we aim at incorporating multiple types of user-item rela- tions into a unified pairwise ranking model towards approx- imately optimizing ranking metrics mean average precision (MAP), and mean reciprocal rank (MRR). Instead of taking statical separation of positive and negative sets, we employ a random walk approach to dynamically draw positive samples from short random walk sequences, and a rank-aware nega- tive sampling method to draw negative samples for efficiently learning the proposed pairwise ranking model. The proposed method is compared with several state-of-the-art baselines on two large and sparse datasets. Experimental results show that our proposed model outperforms the other baselines with av- erage 4% at different top-N metrics, in particular for cold- start users with 6% on average.},
}

@InProceedings{Sharma2013Pairwise,
  author    = {Sharma, Amit and Yan, Baoshi},
  title     = {Pairwise Learning in Recommendation: Experiments with Community Recommendation on Linkedin},
  booktitle = {Proceedings of the 7th ACM Conference on Recommender Systems},
  year      = {2013},
  series    = {RecSys '13},
  pages     = {193--200},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Many online systems present a list of recommendations and infer user interests implicitly from clicks or other contextual actions. For modeling user feedback in such settings, a common approach is to consider items acted upon to be relevant to the user, and irrelevant otherwise. However, clicking some but not others conveys an implicit ordering of the presented items. Pairwise learning, which leverages such implicit ordering between a pair of items, has been successful in areas such as search ranking. In this work, we study whether pairwise learning can improve community recommendation. We first present two novel pairwise models adapted from logistic regression. Both offline and online experiments in a large real-world setting show that incorporating pairwise learning improves the recommendation performance. However, the improvement is only slight. We find that users' preferences regarding the kinds of communities they like can differ greatly, which adversely affect the effectiveness of features derived from pairwise comparisons. We therefore propose a probabilistic latent semantic indexing model for pairwise learning (Pairwise PLSI), which assumes a set of users' latent preferences between pairs of items. Our experiments show favorable results for the Pairwise PLSI model and point to the potential of using pairwise learning for community recommendation.},
  acmid     = {2507175},
  doi       = {10.1145/2507157.2507175},
  isbn      = {978-1-4503-2409-0},
  keywords  = {community recommendation, pairwise learning},
  location  = {Hong Kong, China},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/2507157.2507175},
}

@InProceedings{Christakopoulou2016Local,
  author    = {Christakopoulou, Evangelia and Karypis, George},
  title     = {Local Item-Item Models For Top-N Recommendation},
  booktitle = {Proceedings of the 10th ACM Conference on Recommender Systems},
  year      = {2016},
  series    = {RecSys '16},
  pages     = {67--74},
  address   = {New York, NY, USA},
  publisher = {ACM},
  abstract  = {Item-based approaches based on SLIM (Sparse LInear Methods) have demonstrated very good performance for top-N recommendation; however they only estimate a single model for all the users. This work is based on the intuition that not all users behave in the same way -- instead there exist subsets of like-minded users. By using different item-item models for these user subsets, we can capture differences in their preferences and this can lead to improved performance for top-N recommendations. In this work, we extend SLIM by combining global and local SLIM models. We present a method that computes the prediction scores as a user-specific combination of the predictions derived by a global and local item-item models. We present an approach in which the global model, the local models, their user-specific combination, and the assignment of users to the local models are jointly optimized to improve the top-N recommendation performance. Our experiments show that the proposed method improves upon the standard SLIM model and outperforms competing top-N recommendation approaches.},
  acmid     = {2959185},
  comment   = {rating optimization 
based on SLIM},
  doi       = {10.1145/2959100.2959185},
  isbn      = {978-1-4503-4035-9},
  keywords  = {collaborative filtering, local models, slim, top-n recommendation},
  location  = {Boston, Massachusetts, USA},
  numpages  = {8},
  url       = {http://doi.acm.org/10.1145/2959100.2959185},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:Recommender Systems\;0\;0\;\;\;\;;
2 StaticGroup:Knowledge graph\;0\;1\;\;\;\;;
2 StaticGroup:Psychological\;0\;1\;\;\;\;;
1 StaticGroup:Statistical Model\;0\;1\;\;\;\;;
2 StaticGroup:LDA\;0\;1\;\;\;\;;
2 StaticGroup:Lasso\;0\;1\;\;\;\;;
2 StaticGroup:matrix factorization\;0\;1\;\;\;\;;
1 StaticGroup:Twitter\;0\;1\;\;\;\;;
}

@Comment{jabref-meta: groupsversion:
3;
}
